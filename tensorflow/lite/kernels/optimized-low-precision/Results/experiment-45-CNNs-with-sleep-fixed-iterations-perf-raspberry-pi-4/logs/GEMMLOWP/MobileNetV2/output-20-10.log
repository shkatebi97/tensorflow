STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [0]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/MobileNetV2.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/MobileNetV2.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (50176, 3, ), and Output shape (12544, 32, ), and the ID is 0
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (16, 32, ), Input shape (12544, 32, ), and Output shape (12544, 16, ), and the ID is 1	Changing Input Shape
	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (96, 16, ), Input shape (12544, 16, ), and Output shape (12544, 96, ), and the ID is 2
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (24, 96, ), Input shape (3136, 96, ), and Output shape (3136, 24, ), and the ID is 3
NOT Applying Conv Low-Precision for Kernel shape (144, 24, ), Input shape (3136, 24, ), and Output shape (3136, 144, ), and the ID is 4
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (24, 144, ), Input shape (3136, 144, ), and Output shape (3136, 24, ), and the ID is 5
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(144, 24, ), Input shape (3136, 24, ), and Output shape (3136, 144, ), and the ID is 6
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (32, 144, ), Input shape (784, 144, ), and Output shape (784, 32, ), and the ID is 7
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, )	Changing Input Shape
, and the ID is 8
NOT Applying Conv Low-Precision for Kernel shape (32, 192, ), Input shape (784, 192, ), and Output shape (784, 32, )	Changing Input Shape
, and the ID is 9
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, ), and the ID is 10
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (32, 192, ), Input shape (784, 192, ), and Output shape 	Changing Input Shape
(784, 32, ), and the ID is 11
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, ), and the ID is 12
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 192, ), Input shape (196, 192, ), and Output shape (196, 64, ), and the ID is 13
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape 	Changing Input Shape
(196, 64, ), and Output shape (196, 384, ), and the ID is 14
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape (196, 384, ), and Output shape (196, 64, ), and the ID is 15
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 16
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape (196, 384, ), and Output shape (196, 64, ), and the ID is 	Changing Input Shape
17
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 18	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape (196, 384, ), and Output shape (196, 64, ), and the ID is 19
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 20
NOT Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (196, 384, ), and Output shape (196, 96, ), and the ID is 21
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, )	Changing Input Shape
, and the ID is 22
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (196, 576, ), and Output shape (196, 96, ), and the ID is 23
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, ), and the ID is 24
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (196, 576, ), and Output shape (196, 96, ), and the ID is 25	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, )	Changing Input Shape
, and the ID is 26
NOT Applying Conv Low-Precision for Kernel shape (160, 576, ), Input shape (49, 576, )	Changing Input Shape
, and Output shape (49, 160, ), and the ID is 27
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape (49, 160, ), and Output shape (49, 960, ), and the ID is 28
NOT Applying Conv Low-Precision for Kernel shape (160, 960, ), Input shape (49, 960, ), and Output shape 	Changing Input Shape
(49, 160, ), and the ID is 29
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape (49, 160, ), and Output shape (49, 960, ), and the ID is 30
NOT Applying Conv Low-Precision for Kernel shape (160, 960, ), Input shape (49, 960, ), and Output shape (49, 160, ), and the ID is 31	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape (49, 160, ), and Output shape 	Changing Input Shape
(49, 960, ), and the ID is 32
NOT Applying Conv Low-Precision for Kernel shape (320, 960, ), Input shape (49, 960, ), and Output shape (49, 320, ), and the ID is 33	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (1280, 320, ), Input shape (49, 320, ), and Output shape (49, 1280, ), and the ID is 34
	Changing Input Shape
NOT Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 5 Number of Temp Tensors
The input model file size (MB): 3.94093
Initialized session in 18.595ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=10 first=1197325 curr=1171741 min=1170120 max=1203266 avg=1.18324e+06 std=12834

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=1195641 curr=1196366 min=1171852 max=1196366 avg=1.18406e+06 std=8435

Inference timings in us: Init: 18595, First inference: 1197325, Warmup (avg): 1.18324e+06, Inference (avg): 1.18406e+06
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=6.01953 overall=10.7539
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	    6.546	    6.546	100.000%	100.000%	   504.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	    6.546	    6.546	100.000%	100.000%	   504.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	     6.546	   100.000%	   100.000%	   504.000	        1

Timings (microseconds): count=1 curr=6546
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.020	  100.516	  101.434	  8.572%	  8.572%	     0.000	        1	[mobilenetv2_1.00_224/Conv1_relu/Relu6;mobilenetv2_1.00_224/bn_Conv1/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv1/Conv2D]:0
	       DEPTHWISE_CONV_2D	          101.466	    1.501	    1.499	  0.127%	  8.698%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_depthwise_relu/Relu6;mobilenetv2_1.00_224/expanded_conv_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_depthwise/depthwise;mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3]:1
	                 CONV_2D	          102.978	   51.647	   52.237	  4.414%	 13.113%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_project/Conv2D]:2
	                 CONV_2D	          155.226	  275.842	  278.230	 23.512%	 36.625%	     0.000	        1	[mobilenetv2_1.00_224/block_1_expand_relu/Relu6;mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_expand/Conv2D]:3
	                     PAD	          433.468	   26.858	   26.920	  2.275%	 38.900%	     0.000	        1	[mobilenetv2_1.00_224/block_1_pad/Pad]:4
	       DEPTHWISE_CONV_2D	          460.400	    2.514	    2.511	  0.212%	 39.112%	     0.000	        1	[mobilenetv2_1.00_224/block_1_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_1_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_depthwise/depthwise;mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3]:5
	                 CONV_2D	          462.923	   22.007	   22.217	  1.877%	 40.989%	     0.000	        1	[mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_project/Conv2D]:6
	                 CONV_2D	          485.151	  106.377	  106.199	  8.974%	 49.964%	     0.000	        1	[mobilenetv2_1.00_224/block_2_expand_relu/Relu6;mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_expand/Conv2D]:7
	       DEPTHWISE_CONV_2D	          591.362	    2.433	    2.316	  0.196%	 50.159%	     0.000	        1	[mobilenetv2_1.00_224/block_2_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_depthwise/depthwise;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3]:8
	                 CONV_2D	          593.689	   24.908	   24.544	  2.074%	 52.234%	     0.000	        1	[mobilenetv2_1.00_224/block_2_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_project/Conv2D]:9
	                     ADD	          618.243	    7.129	    7.055	  0.596%	 52.830%	     0.000	        1	[mobilenetv2_1.00_224/block_2_add/add]:10
	                 CONV_2D	          625.308	  109.155	  105.909	  8.950%	 61.780%	     0.000	        1	[mobilenetv2_1.00_224/block_3_expand_relu/Relu6;mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_expand/Conv2D]:11
	                     PAD	          731.228	   10.279	   10.178	  0.860%	 62.640%	     0.000	        1	[mobilenetv2_1.00_224/block_3_pad/Pad]:12
	       DEPTHWISE_CONV_2D	          741.417	    1.031	    0.915	  0.077%	 62.717%	     0.000	        1	[mobilenetv2_1.00_224/block_3_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_depthwise/depthwise]:13
	                 CONV_2D	          742.341	    7.919	    7.783	  0.658%	 63.375%	     0.000	        1	[mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_project/Conv2D]:14
	                 CONV_2D	          750.135	   35.591	   34.968	  2.955%	 66.330%	     0.000	        1	[mobilenetv2_1.00_224/block_4_expand_relu/Relu6;mobilenetv2_1.00_224/block_4_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_expand/Conv2D]:15
	       DEPTHWISE_CONV_2D	          785.113	    0.766	    0.770	  0.065%	 66.395%	     0.000	        1	[mobilenetv2_1.00_224/block_4_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3]:16
	                 CONV_2D	          785.891	    8.500	    8.392	  0.709%	 67.104%	     0.000	        1	[mobilenetv2_1.00_224/block_4_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_project/Conv2D]:17
	                     ADD	          794.294	    2.388	    2.371	  0.200%	 67.304%	     0.000	        1	[mobilenetv2_1.00_224/block_4_add/add]:18
	                 CONV_2D	          796.672	   35.516	   35.051	  2.962%	 70.266%	     0.000	        1	[mobilenetv2_1.00_224/block_5_expand_relu/Relu6;mobilenetv2_1.00_224/block_5_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_expand/Conv2D]:19
	       DEPTHWISE_CONV_2D	          831.734	    1.046	    0.786	  0.066%	 70.333%	     0.000	        1	[mobilenetv2_1.00_224/block_5_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_5_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3]:20
	                 CONV_2D	          832.528	    8.643	    8.393	  0.709%	 71.042%	     0.000	        1	[mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_project/Conv2D]:21
	                     ADD	          840.933	    2.384	    2.373	  0.201%	 71.243%	     0.000	        1	[mobilenetv2_1.00_224/block_5_add/add]:22
	                 CONV_2D	          843.313	   35.724	   35.028	  2.960%	 74.203%	     0.000	        1	[mobilenetv2_1.00_224/block_6_expand_relu/Relu6;mobilenetv2_1.00_224/block_6_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_expand/Conv2D]:23
	                     PAD	          878.352	    3.526	    3.494	  0.295%	 74.498%	     0.000	        1	[mobilenetv2_1.00_224/block_6_pad/Pad]:24
	       DEPTHWISE_CONV_2D	          881.855	    0.303	    0.275	  0.023%	 74.521%	     0.000	        1	[mobilenetv2_1.00_224/block_6_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_depthwise/depthwise]:25
	                 CONV_2D	          882.137	    4.031	    3.905	  0.330%	 74.851%	     0.000	        1	[mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_project/Conv2D]:26
	                 CONV_2D	          886.050	   17.804	   13.375	  1.130%	 75.981%	     0.000	        1	[mobilenetv2_1.00_224/block_7_expand_relu/Relu6;mobilenetv2_1.00_224/block_7_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_expand/Conv2D]:27
	       DEPTHWISE_CONV_2D	          899.435	    0.439	    0.370	  0.031%	 76.013%	     0.000	        1	[mobilenetv2_1.00_224/block_7_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_7_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:28
	                 CONV_2D	          899.813	    5.175	    4.838	  0.409%	 76.421%	     0.000	        1	[mobilenetv2_1.00_224/block_7_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_project/Conv2D]:29
	                     ADD	          904.661	    1.197	    1.200	  0.101%	 76.523%	     0.000	        1	[mobilenetv2_1.00_224/block_7_add/add]:30
	                 CONV_2D	          905.870	   13.563	   13.156	  1.112%	 77.635%	     0.000	        1	[mobilenetv2_1.00_224/block_8_expand_relu/Relu6;mobilenetv2_1.00_224/block_8_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_expand/Conv2D]:31
	       DEPTHWISE_CONV_2D	          919.036	    0.398	    0.368	  0.031%	 77.666%	     0.000	        1	[mobilenetv2_1.00_224/block_8_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_8_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:32
	                 CONV_2D	          919.411	    4.875	    4.817	  0.407%	 78.073%	     0.000	        1	[mobilenetv2_1.00_224/block_8_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_project/Conv2D]:33
	                     ADD	          924.237	    1.244	    1.204	  0.102%	 78.175%	     0.000	        1	[mobilenetv2_1.00_224/block_8_add/add]:34
	                 CONV_2D	          925.448	   13.350	   13.166	  1.113%	 79.287%	     0.000	        1	[mobilenetv2_1.00_224/block_9_expand_relu/Relu6;mobilenetv2_1.00_224/block_9_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_expand/Conv2D]:35
	       DEPTHWISE_CONV_2D	          938.624	    0.386	    0.371	  0.031%	 79.318%	     0.000	        1	[mobilenetv2_1.00_224/block_9_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_9_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:36
	                 CONV_2D	          939.002	    4.853	    4.842	  0.409%	 79.728%	     0.000	        1	[mobilenetv2_1.00_224/block_9_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_project/Conv2D]:37
	                     ADD	          943.854	    1.194	    1.200	  0.101%	 79.829%	     0.000	        1	[mobilenetv2_1.00_224/block_9_add/add]:38
	                 CONV_2D	          945.061	   13.421	   13.179	  1.114%	 80.943%	     0.000	        1	[mobilenetv2_1.00_224/block_10_expand_relu/Relu6;mobilenetv2_1.00_224/block_10_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_expand/Conv2D]:39
	       DEPTHWISE_CONV_2D	          958.250	    0.379	    0.368	  0.031%	 80.974%	     0.000	        1	[mobilenetv2_1.00_224/block_10_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_depthwise/depthwise]:40
	                 CONV_2D	          958.625	    6.765	    6.736	  0.569%	 81.543%	     0.000	        1	[mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_project/Conv2D]:41
	                 CONV_2D	          965.370	   21.343	   20.562	  1.738%	 83.281%	     0.000	        1	[mobilenetv2_1.00_224/block_11_expand_relu/Relu6;mobilenetv2_1.00_224/block_11_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_expand/Conv2D]:42
	       DEPTHWISE_CONV_2D	          985.942	    0.569	    0.551	  0.047%	 83.327%	     0.000	        1	[mobilenetv2_1.00_224/block_11_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3]:43
	                 CONV_2D	          986.501	    8.335	    8.065	  0.682%	 84.009%	     0.000	        1	[mobilenetv2_1.00_224/block_11_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_project/Conv2D]:44
	                     ADD	          994.576	    1.859	    1.795	  0.152%	 84.160%	     0.000	        1	[mobilenetv2_1.00_224/block_11_add/add]:45
	                 CONV_2D	          996.379	   20.745	   20.533	  1.735%	 85.896%	     0.000	        1	[mobilenetv2_1.00_224/block_12_expand_relu/Relu6;mobilenetv2_1.00_224/block_12_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_expand/Conv2D]:46
	       DEPTHWISE_CONV_2D	         1016.922	    0.602	    0.535	  0.045%	 85.941%	     0.000	        1	[mobilenetv2_1.00_224/block_12_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_12_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3]:47
	                 CONV_2D	         1017.465	    7.979	    7.896	  0.667%	 86.608%	     0.000	        1	[mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_project/Conv2D]:48
	                     ADD	         1025.372	    1.775	    1.783	  0.151%	 86.759%	     0.000	        1	[mobilenetv2_1.00_224/block_12_add/add]:49
	                 CONV_2D	         1027.163	   20.848	   20.527	  1.735%	 88.493%	     0.000	        1	[mobilenetv2_1.00_224/block_13_expand_relu/Relu6;mobilenetv2_1.00_224/block_13_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_expand/Conv2D]:50
	                     PAD	         1047.699	    2.773	    2.751	  0.232%	 88.726%	     0.000	        1	[mobilenetv2_1.00_224/block_13_pad/Pad]:51
	       DEPTHWISE_CONV_2D	         1050.459	    0.234	    0.224	  0.019%	 88.745%	     0.000	        1	[mobilenetv2_1.00_224/block_13_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_depthwise/depthwise]:52
	                 CONV_2D	         1050.692	    3.572	    3.543	  0.299%	 89.044%	     0.000	        1	[mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_project/Conv2D]:53
	                 CONV_2D	         1054.244	   11.020	   10.946	  0.925%	 89.969%	     0.000	        1	[mobilenetv2_1.00_224/block_14_expand_relu/Relu6;mobilenetv2_1.00_224/block_14_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_expand/Conv2D]:54
	       DEPTHWISE_CONV_2D	         1065.200	    0.302	    0.282	  0.024%	 89.993%	     0.000	        1	[mobilenetv2_1.00_224/block_14_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3]:55
	                 CONV_2D	         1065.489	    5.036	    5.016	  0.424%	 90.417%	     0.000	        1	[mobilenetv2_1.00_224/block_14_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_project/Conv2D]:56
	                     ADD	         1070.515	    0.797	    0.760	  0.064%	 90.481%	     0.000	        1	[mobilenetv2_1.00_224/block_14_add/add]:57
	                 CONV_2D	         1071.282	   11.024	   10.956	  0.926%	 91.407%	     0.000	        1	[mobilenetv2_1.00_224/block_15_expand_relu/Relu6;mobilenetv2_1.00_224/block_15_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_expand/Conv2D]:58
	       DEPTHWISE_CONV_2D	         1082.249	    0.292	    0.282	  0.024%	 91.431%	     0.000	        1	[mobilenetv2_1.00_224/block_15_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_15_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3]:59
	                 CONV_2D	         1082.538	    5.108	    4.968	  0.420%	 91.851%	     0.000	        1	[mobilenetv2_1.00_224/block_15_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_project/Conv2D]:60
	                     ADD	         1087.516	    0.753	    0.755	  0.064%	 91.915%	     0.000	        1	[mobilenetv2_1.00_224/block_15_add/add]:61
	                 CONV_2D	         1088.278	   11.053	   10.934	  0.924%	 92.839%	     0.000	        1	[mobilenetv2_1.00_224/block_16_expand_relu/Relu6;mobilenetv2_1.00_224/block_16_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_expand/Conv2D]:62
	       DEPTHWISE_CONV_2D	         1099.222	    0.335	    0.279	  0.024%	 92.862%	     0.000	        1	[mobilenetv2_1.00_224/block_16_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_depthwise/depthwise]:63
	                 CONV_2D	         1099.508	    9.421	    9.311	  0.787%	 93.649%	     0.000	        1	[mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_project/Conv2D]:64
	                 CONV_2D	         1108.831	   18.729	   18.594	  1.571%	 95.220%	     0.000	        1	[mobilenetv2_1.00_224/out_relu/Relu6;mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3;mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv_1/Conv2D]:65
	                    MEAN	         1127.436	   10.891	   10.868	  0.918%	 96.139%	     0.000	        1	[mobilenetv2_1.00_224/global_average_pooling2d/Mean]:66
	         FULLY_CONNECTED	         1138.313	   45.699	   45.603	  3.854%	 99.992%	     0.000	        1	[mobilenetv2_1.00_224/predictions/MatMul;mobilenetv2_1.00_224/predictions/BiasAdd]:67
	                 SOFTMAX	         1183.926	    0.086	    0.091	  0.008%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:68

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          155.226	  275.842	  278.230	 23.512%	 23.512%	     0.000	        1	[mobilenetv2_1.00_224/block_1_expand_relu/Relu6;mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_expand/Conv2D]:3
	                 CONV_2D	          485.151	  106.377	  106.199	  8.974%	 32.486%	     0.000	        1	[mobilenetv2_1.00_224/block_2_expand_relu/Relu6;mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_expand/Conv2D]:7
	                 CONV_2D	          625.308	  109.155	  105.909	  8.950%	 41.436%	     0.000	        1	[mobilenetv2_1.00_224/block_3_expand_relu/Relu6;mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_expand/Conv2D]:11
	                 CONV_2D	            0.020	  100.516	  101.434	  8.572%	 50.008%	     0.000	        1	[mobilenetv2_1.00_224/Conv1_relu/Relu6;mobilenetv2_1.00_224/bn_Conv1/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv1/Conv2D]:0
	                 CONV_2D	          102.978	   51.647	   52.237	  4.414%	 54.422%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_project/Conv2D]:2
	         FULLY_CONNECTED	         1138.313	   45.699	   45.603	  3.854%	 58.276%	     0.000	        1	[mobilenetv2_1.00_224/predictions/MatMul;mobilenetv2_1.00_224/predictions/BiasAdd]:67
	                 CONV_2D	          796.672	   35.516	   35.051	  2.962%	 61.238%	     0.000	        1	[mobilenetv2_1.00_224/block_5_expand_relu/Relu6;mobilenetv2_1.00_224/block_5_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_expand/Conv2D]:19
	                 CONV_2D	          843.313	   35.724	   35.028	  2.960%	 64.198%	     0.000	        1	[mobilenetv2_1.00_224/block_6_expand_relu/Relu6;mobilenetv2_1.00_224/block_6_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_expand/Conv2D]:23
	                 CONV_2D	          750.135	   35.591	   34.968	  2.955%	 67.153%	     0.000	        1	[mobilenetv2_1.00_224/block_4_expand_relu/Relu6;mobilenetv2_1.00_224/block_4_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_expand/Conv2D]:15
	                     PAD	          433.468	   26.858	   26.920	  2.275%	 69.428%	     0.000	        1	[mobilenetv2_1.00_224/block_1_pad/Pad]:4

Number of nodes executed: 69
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       35	  1050.231	    88.753%	    88.753%	     0.000	       35
	         FULLY_CONNECTED	        1	    45.602	     3.854%	    92.606%	     0.000	        1
	                     PAD	        4	    43.341	     3.663%	    96.269%	     0.000	        4
	                     ADD	       10	    20.492	     1.732%	    98.001%	     0.000	       10
	       DEPTHWISE_CONV_2D	       17	    12.697	     1.073%	    99.074%	     0.000	       17
	                    MEAN	        1	    10.868	     0.918%	    99.992%	     0.000	        1
	                 SOFTMAX	        1	     0.091	     0.008%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=1194757 curr=1195625 min=1171212 max=1195625 avg=1.18335e+06 std=8402
Memory (bytes): count=0
69 nodes observed



[ perf record: Woken up 144 times to write data ]
[ perf record: Captured and wrote 36.209 MB /tmp/data.record (142147 samples) ]

36.528

