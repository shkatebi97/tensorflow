STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/EfficientNetV2L.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/EfficientNetV2L.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (230400, 3, ), and Output shape (57600, 32, ), and the ID is 0
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 16)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 1
	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
, and the ID is 2
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)
, and the ID is 3
	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 4	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)

	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
Applying Conv Low-Precision for Kernel shape (128, 288, ), Input shape (57600, 32, ), and Output shape (14400, 128, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (128, 80)
5
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (14400, 128, ), and Output shape (14400, 64, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
, and the ID is 6
Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
(256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 7
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
8
Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
(256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 9
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 10
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 11
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
(14400, 64, ), and the ID is 12
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 13
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
(14400, 256, ), and Output shape (14400, 64, ), and the ID is 14
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 15
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
, Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 16
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 17
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and Output shape (14400, 64, ), and the ID is 18
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (3600, 256, ), and the ID is 19
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 144)
Applying Conv Low-Precision for Kernel shape (96, 256, ), Input shape (3600, 256, ), and Output shape (3600, 96, ), and the ID is 20
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 64)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 64)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 21
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
(3600, 96, ), and the ID is 22
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 23
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
, and the ID is 24
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 25
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
(3600, 96, ), and the ID is 26
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 27
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
28
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 29
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
, and the ID is 30
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 31
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
(3600, 96, ), and the ID is 32
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 32)
Applying Conv Low-Precision for Kernel shape (384, 96, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 33
	Allocating LowPrecision Activations Tensors with Shape of (3600, 32)
The input model file size (MB): 127.361
Initialized session in 222.07ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
Applying Conv Low-Precision for Kernel shape (24, 384, ), Input shape (1, 384, ), and Output shape (1, 24, ), and the ID is 34
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (24, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 16)
Applying Conv Low-Precision for Kernel shape (384, 24, ), Input shape (1, 24, ), and Output shape (1, 384, ), and the ID is 35
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 384, ), Input shape (900, 384, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
(900, 192, ), and the ID is 36
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 37
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 38
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 39
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
40
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 41
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 42
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 43
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
44
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 45
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 46
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 47
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 48	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)

	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
49
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 50
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 51
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
(900, 192, ), and the ID is 52
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 53
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 54
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 55
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
, and the ID is 56
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
	Changing Input Shape
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 57
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 58
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 59
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 60
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 192, ), and Output shape (900, 768, ), and the ID is 61
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 62
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 63
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 64	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)

	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 65
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 66
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 67
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
, and Output shape (900, 192, ), and the ID is 68
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 69
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 70
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 71
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 72	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)

	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1152, 48)
Applying Conv Low-Precision for Kernel shape (1152, 192, ), Input shape (900, 192, ), and Output shape (900, 1152, ), and the ID is 73
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 1152, ), Input shape (1, 1152, ), and Output shape (1, 48, ), and the ID is 74
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1152, 48, ), Input shape (1, 48, ), and Output shape (1, 1152, ), and the ID is 75
	Allocating LowPrecision Weight Tensors with Shape of (1152, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1152, ), Input shape (900, 1152, ), and Output shape (900, 224, ), and the ID is 76	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 288)

	Allocating LowPrecision Activations Tensors with Shape of (900, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 77
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
78
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 79
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
, and the ID is 80
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 81
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 82
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 83
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
, and the ID is 84
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 85
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 86
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 87
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 88
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 89
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 90
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 91
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
, and Output shape (900, 224, ), and the ID is 92
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 93
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 94
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 95
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 96	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)

	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 97
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
, and the ID is 98
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 99
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 100
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 101
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 102
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 103
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
104
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 105	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)

	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 106
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 107
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
, and the ID is 108
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 109
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 110
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 111
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
(900, 224, ), and the ID is 112
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 113
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 114
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 115
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
(900, 224, ), and the ID is 116
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 117
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 118
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 119
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
, and the ID is 120
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 121
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 122
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 123
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 124
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 125
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
126
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 127
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 128
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 129
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 130
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 131
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 132
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 133
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 134
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 135
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 136
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 137
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 138
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 139
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 140
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 141
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 142
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 143
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
(900, 1344, ), and Output shape (900, 224, ), and the ID is 144
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 145
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 146
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 147
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 148
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 149
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 150
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 151
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 1344, ), Input shape (225, 1344, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 336)
152
	Allocating LowPrecision Activations Tensors with Shape of (228, 336)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
153
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 154
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 155
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and Output shape (225, 384, ), and the ID is 156
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 157
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 158
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 159
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
160
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
161
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 162
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 163	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 164	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)

	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 165
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 166
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 167	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 168
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 169	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 170
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 171
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 172	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)

	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 173
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
, and the ID is 174
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 175
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 176
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 177
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 178
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 179
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 180	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)

	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 181	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 182	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 183
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 184	Changing Input Shape
	Reserving LowPrecision Weight Tensors

	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 185
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 186
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
187
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 188	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)

	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
189
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 190
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 191
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and the ID is 192
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 193
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 194
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 195	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and Output shape (225, 384, ), and the ID is 196
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 197
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 198
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 199
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and the ID is 200
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 201
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 202
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 203
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 204
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 205	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 206
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
207
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
(225, 384, ), and the ID is 208
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 209
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 210
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 96, ), and Output shape (1, 2304, ), and the ID is 211
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and the ID is 212
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 213
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 214
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 215	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
216
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 217
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 218
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 219	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(225, 384, ), and the ID is 220
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 221	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 222
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 223
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and the ID is 224
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 225	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 226
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 227
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
228
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 229	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 230
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 231
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
232
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
233
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 234
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 235
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
(225, 384, ), and the ID is 236
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 237
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 238
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 239	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and Output shape (225, 384, ), and the ID is 240
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 241
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 242
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 243
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
, and the ID is 244
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 245
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 246
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 247
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
(225, 384, ), and the ID is 248
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
249
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 250
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
251
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 2304, ), Input shape (225, 2304, ), and Output shape (225, 640, ), and the ID is 252
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 253
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 254
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 255
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 256	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)

	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
257
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 258
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 259
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 260	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)

	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 261
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 262	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)

	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 263
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
(225, 640, ), and the ID is 264
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
265
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 266
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 267
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 268	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)

	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 269
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 270
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 271
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 272
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 273	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 274
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 275
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 276
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (1280, 640, ), Input shape (225, 640, ), and Output shape (225, 1280, ), and the ID is 277
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1280, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 7 Number of Temporaries Tensors
	Transformed Filter Shape: (1000, 320)
	Transformed Activation Shape From: (1, 1280) To: (1, 320)
count=6 first=29187866 curr=28702925 min=28683704 max=29187866 avg=2.87823e+07 std=181989

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=6 first=28706026 curr=28716851 min=28706026 max=28759570 avg=2.87278e+07 std=20747

Inference timings in us: Init: 222070, First inference: 29187866, Warmup (avg): 2.87823e+07, Inference (avg): 2.87278e+07
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=39.4102 overall=194.73
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   21.316	   21.316	100.000%	100.000%	  3388.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   21.316	   21.316	100.000%	100.000%	  3388.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    21.316	   100.000%	   100.000%	  3388.000	        1

Timings (microseconds): count=1 curr=21316
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	            0.031	   39.075	   38.855	  0.135%	  0.135%	     0.000	        1	[efficientnetv2-l/rescaling/mul]:0
	                     ADD	           38.897	   32.856	   32.709	  0.114%	  0.249%	     0.000	        1	[efficientnetv2-l/rescaling/add]:1
	                 CONV_2D	           71.616	   77.316	   76.922	  0.268%	  0.517%	     0.000	        1	[efficientnetv2-l/stem_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/stem_conv/Conv2D]:2
	                LOGISTIC	          148.552	   18.164	   18.001	  0.063%	  0.580%	     0.000	        1	[efficientnetv2-l/stem_activation/Sigmoid]:3
	                     MUL	          166.565	  130.131	  129.852	  0.452%	  1.032%	     0.000	        1	[efficientnetv2-l/stem_activation/mul_1]:4
	                 CONV_2D	          296.429	  102.557	  102.825	  0.358%	  1.390%	     0.000	        1	[efficientnetv2-l/block1a_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1a_project_conv/Conv2D]:5
	                LOGISTIC	          399.266	   18.135	   18.158	  0.063%	  1.453%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/Sigmoid]:6
	                     MUL	          417.435	  129.905	  129.827	  0.452%	  1.905%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/mul_1]:7
	                     ADD	          547.276	  171.558	  171.522	  0.597%	  2.503%	     0.000	        1	[efficientnetv2-l/block1a_add/add]:8
	                 CONV_2D	          718.808	  102.845	  102.719	  0.358%	  2.860%	     0.000	        1	[efficientnetv2-l/block1b_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1b_project_conv/Conv2D]:9
	                LOGISTIC	          821.540	   17.866	   17.956	  0.063%	  2.923%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/Sigmoid]:10
	                     MUL	          839.507	  128.905	  129.555	  0.451%	  3.374%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/mul_1]:11
	                     ADD	          969.073	  170.518	  171.293	  0.596%	  3.971%	     0.000	        1	[efficientnetv2-l/block1b_add/add]:12
	                 CONV_2D	         1140.378	  102.025	  102.015	  0.355%	  4.326%	     0.000	        1	[efficientnetv2-l/block1c_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1c_project_conv/Conv2D]:13
	                LOGISTIC	         1242.406	   18.167	   18.241	  0.064%	  4.389%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/Sigmoid]:14
	                     MUL	         1260.659	  128.871	  129.732	  0.452%	  4.841%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/mul_1]:15
	                     ADD	         1390.403	  170.551	  171.689	  0.598%	  5.439%	     0.000	        1	[efficientnetv2-l/block1c_add/add]:16
	                 CONV_2D	         1562.104	  100.683	  101.629	  0.354%	  5.793%	     0.000	        1	[efficientnetv2-l/block1d_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1d_project_conv/Conv2D]:17
	                LOGISTIC	         1663.745	   17.698	   17.857	  0.062%	  5.855%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/Sigmoid]:18
	                     MUL	         1681.614	  129.082	  129.627	  0.451%	  6.306%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/mul_1]:19
	                     ADD	         1811.252	  170.467	  171.225	  0.596%	  6.903%	     0.000	        1	[efficientnetv2-l/block1d_add/add]:20
	                 CONV_2D	         1982.491	   52.683	   53.178	  0.185%	  7.088%	     0.000	        1	[efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_expand_conv/Conv2D]:21
	                LOGISTIC	         2035.681	   18.044	   17.996	  0.063%	  7.151%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/Sigmoid]:22
	                     MUL	         2053.689	  129.128	  129.712	  0.452%	  7.602%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/mul_1]:23
	                 CONV_2D	         2183.413	   18.295	   18.253	  0.064%	  7.666%	     0.000	        1	[efficientnetv2-l/block2a_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_project_conv/Conv2D]:24
	                 CONV_2D	         2201.677	  127.329	  127.943	  0.446%	  8.111%	     0.000	        1	[efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_expand_conv/Conv2D]:25
	                LOGISTIC	         2329.631	   36.139	   35.775	  0.125%	  8.236%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/Sigmoid]:26
	                     MUL	         2365.417	  261.771	  259.429	  0.903%	  9.139%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                 CONV_2D	         2624.858	   10.788	   10.686	  0.037%	  9.177%	     0.000	        1	[efficientnetv2-l/block2b_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_project_conv/Conv2D]:28
	                     ADD	         2635.557	   86.060	   85.774	  0.299%	  9.475%	     0.000	        1	[efficientnetv2-l/block2b_add/add]:29
	                 CONV_2D	         2721.343	  128.903	  128.260	  0.447%	  9.922%	     0.000	        1	[efficientnetv2-l/block2c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_expand_conv/Conv2D]:30
	                LOGISTIC	         2849.616	   36.212	   35.877	  0.125%	 10.047%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/Sigmoid]:31
	                     MUL	         2885.505	  259.707	  259.322	  0.903%	 10.950%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                 CONV_2D	         3144.838	   10.659	   10.643	  0.037%	 10.987%	     0.000	        1	[efficientnetv2-l/block2c_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_project_conv/Conv2D]:33
	                     ADD	         3155.492	   85.962	   85.751	  0.299%	 11.286%	     0.000	        1	[efficientnetv2-l/block2c_add/add]:34
	                 CONV_2D	         3241.255	  129.251	  128.228	  0.447%	 11.732%	     0.000	        1	[efficientnetv2-l/block2d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_expand_conv/Conv2D]:35
	                LOGISTIC	         3369.494	   35.989	   35.999	  0.125%	 11.857%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/Sigmoid]:36
	                     MUL	         3405.505	  257.758	  259.149	  0.902%	 12.760%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                 CONV_2D	         3664.666	   10.692	   10.738	  0.037%	 12.797%	     0.000	        1	[efficientnetv2-l/block2d_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_project_conv/Conv2D]:38
	                     ADD	         3675.416	   85.196	   85.974	  0.299%	 13.097%	     0.000	        1	[efficientnetv2-l/block2d_add/add]:39
	                 CONV_2D	         3761.401	  129.228	  128.752	  0.448%	 13.545%	     0.000	        1	[efficientnetv2-l/block2e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_expand_conv/Conv2D]:40
	                LOGISTIC	         3890.164	   36.003	   36.085	  0.126%	 13.671%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/Sigmoid]:41
	                     MUL	         3926.262	  257.758	  259.370	  0.903%	 14.574%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                 CONV_2D	         4185.644	   10.654	   10.632	  0.037%	 14.611%	     0.000	        1	[efficientnetv2-l/block2e_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_project_conv/Conv2D]:43
	                     ADD	         4196.287	   85.234	   85.521	  0.298%	 14.909%	     0.000	        1	[efficientnetv2-l/block2e_add/add]:44
	                 CONV_2D	         4281.819	  128.396	  127.857	  0.445%	 15.354%	     0.000	        1	[efficientnetv2-l/block2f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_expand_conv/Conv2D]:45
	                LOGISTIC	         4409.688	   35.708	   35.849	  0.125%	 15.479%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/Sigmoid]:46
	                     MUL	         4445.551	  258.220	  259.393	  0.903%	 16.382%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                 CONV_2D	         4704.956	   10.675	   10.656	  0.037%	 16.419%	     0.000	        1	[efficientnetv2-l/block2f_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_project_conv/Conv2D]:48
	                     ADD	         4715.623	   85.609	   85.771	  0.299%	 16.718%	     0.000	        1	[efficientnetv2-l/block2f_add/add]:49
	                 CONV_2D	         4801.405	  129.489	  128.541	  0.448%	 17.166%	     0.000	        1	[efficientnetv2-l/block2g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_expand_conv/Conv2D]:50
	                LOGISTIC	         4929.960	   36.860	   35.936	  0.125%	 17.291%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/Sigmoid]:51
	                     MUL	         4965.908	  260.329	  259.647	  0.904%	 18.195%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                 CONV_2D	         5225.567	   10.657	   10.642	  0.037%	 18.232%	     0.000	        1	[efficientnetv2-l/block2g_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_project_conv/Conv2D]:53
	                     ADD	         5236.220	   85.805	   85.681	  0.298%	 18.530%	     0.000	        1	[efficientnetv2-l/block2g_add/add]:54
	                 CONV_2D	         5321.913	   32.134	   32.050	  0.112%	 18.642%	     0.000	        1	[efficientnetv2-l/block3a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_expand_conv/Conv2D]:55
	                LOGISTIC	         5353.978	    8.951	    8.939	  0.031%	 18.673%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/Sigmoid]:56
	                     MUL	         5362.929	   65.135	   65.031	  0.226%	 18.900%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/mul_1]:57
	                 CONV_2D	         5427.974	    3.990	    3.985	  0.014%	 18.913%	     0.000	        1	[efficientnetv2-l/block3a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_project_conv/Conv2D]:58
	                 CONV_2D	         5431.968	   58.744	   58.745	  0.205%	 19.118%	     0.000	        1	[efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_expand_conv/Conv2D]:59
	                LOGISTIC	         5490.725	   13.237	   13.378	  0.047%	 19.165%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/Sigmoid]:60
	                     MUL	         5504.117	   97.665	   97.828	  0.341%	 19.505%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/mul_1]:61
	                 CONV_2D	         5601.957	    9.149	    9.045	  0.031%	 19.537%	     0.000	        1	[efficientnetv2-l/block3b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_project_conv/Conv2D]:62
	                     ADD	         5611.012	   32.351	   32.298	  0.112%	 19.649%	     0.000	        1	[efficientnetv2-l/block3b_add/add]:63
	                 CONV_2D	         5643.322	   58.944	   58.574	  0.204%	 19.853%	     0.000	        1	[efficientnetv2-l/block3c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_expand_conv/Conv2D]:64
	                LOGISTIC	         5701.908	   13.287	   13.370	  0.047%	 19.900%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/Sigmoid]:65
	                     MUL	         5715.291	   97.608	   97.264	  0.339%	 20.238%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/mul_1]:66
	                 CONV_2D	         5812.566	    9.039	    8.982	  0.031%	 20.270%	     0.000	        1	[efficientnetv2-l/block3c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_project_conv/Conv2D]:67
	                     ADD	         5821.560	   32.119	   32.137	  0.112%	 20.382%	     0.000	        1	[efficientnetv2-l/block3c_add/add]:68
	                 CONV_2D	         5853.707	   58.291	   58.473	  0.204%	 20.585%	     0.000	        1	[efficientnetv2-l/block3d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_expand_conv/Conv2D]:69
	                LOGISTIC	         5912.192	   13.528	   13.448	  0.047%	 20.632%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/Sigmoid]:70
	                     MUL	         5925.652	   96.812	   97.290	  0.339%	 20.971%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/mul_1]:71
	                 CONV_2D	         6022.954	    9.027	    9.040	  0.031%	 21.002%	     0.000	        1	[efficientnetv2-l/block3d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_project_conv/Conv2D]:72
	                     ADD	         6032.007	   32.043	   32.197	  0.112%	 21.114%	     0.000	        1	[efficientnetv2-l/block3d_add/add]:73
	                 CONV_2D	         6064.216	   58.207	   58.340	  0.203%	 21.318%	     0.000	        1	[efficientnetv2-l/block3e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_expand_conv/Conv2D]:74
	                LOGISTIC	         6122.568	   13.437	   13.477	  0.047%	 21.365%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/Sigmoid]:75
	                     MUL	         6136.056	   96.845	   97.611	  0.340%	 21.704%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/mul_1]:76
	                 CONV_2D	         6233.680	    8.990	    9.018	  0.031%	 21.736%	     0.000	        1	[efficientnetv2-l/block3e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_project_conv/Conv2D]:77
	                     ADD	         6242.708	   31.966	   32.215	  0.112%	 21.848%	     0.000	        1	[efficientnetv2-l/block3e_add/add]:78
	                 CONV_2D	         6274.934	   58.407	   58.352	  0.203%	 22.051%	     0.000	        1	[efficientnetv2-l/block3f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_expand_conv/Conv2D]:79
	                LOGISTIC	         6333.297	   13.474	   13.440	  0.047%	 22.098%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/Sigmoid]:80
	                     MUL	         6346.748	   96.783	   97.219	  0.339%	 22.437%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/mul_1]:81
	                 CONV_2D	         6443.979	    9.084	    9.066	  0.032%	 22.468%	     0.000	        1	[efficientnetv2-l/block3f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_project_conv/Conv2D]:82
	                     ADD	         6453.055	   31.988	   32.103	  0.112%	 22.580%	     0.000	        1	[efficientnetv2-l/block3f_add/add]:83
	                 CONV_2D	         6485.169	   58.261	   58.334	  0.203%	 22.783%	     0.000	        1	[efficientnetv2-l/block3g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_expand_conv/Conv2D]:84
	                LOGISTIC	         6543.514	   13.500	   13.531	  0.047%	 22.830%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/Sigmoid]:85
	                     MUL	         6557.056	   96.753	   97.220	  0.339%	 23.169%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/mul_1]:86
	                 CONV_2D	         6654.288	    9.078	    9.100	  0.032%	 23.200%	     0.000	        1	[efficientnetv2-l/block3g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_project_conv/Conv2D]:87
	                     ADD	         6663.399	   32.044	   32.343	  0.113%	 23.313%	     0.000	        1	[efficientnetv2-l/block3g_add/add]:88
	                 CONV_2D	         6695.753	   17.180	   17.218	  0.060%	 23.373%	     0.000	        1	[efficientnetv2-l/block4a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_expand_conv/Conv2D]:89
	                LOGISTIC	         6712.983	   13.575	   13.534	  0.047%	 23.420%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/Sigmoid]:90
	                     MUL	         6726.527	   96.688	   97.188	  0.338%	 23.759%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/mul_1]:91
	       DEPTHWISE_CONV_2D	         6823.726	  122.692	  123.514	  0.430%	 24.189%	     0.000	        1	[efficientnetv2-l/block4a_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_dwconv2/depthwise;efficientnetv2-l/block6y_project_bn/FusedBatchNormV3]:92
	                LOGISTIC	         6947.251	    3.393	    3.404	  0.012%	 24.201%	     0.000	        1	[efficientnetv2-l/block4a_activation/Sigmoid]:93
	                     MUL	         6950.664	   24.226	   24.329	  0.085%	 24.285%	     0.000	        1	[efficientnetv2-l/block4a_activation/mul_1]:94
	                    MEAN	         6975.004	   58.321	   58.489	  0.204%	 24.489%	     0.000	        1	[efficientnetv2-l/block4a_se_squeeze/Mean]:95
	                   SHAPE	         7033.503	    0.008	    0.009	  0.000%	 24.489%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Shape]:96
	           STRIDED_SLICE	         7033.518	    0.021	    0.021	  0.000%	 24.489%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/strided_slice]:97
	                    PACK	         7033.546	    0.030	    0.038	  0.000%	 24.489%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape/shape]:98
	                 RESHAPE	         7033.590	    0.014	    0.014	  0.000%	 24.489%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape]:99
	                 CONV_2D	         7033.610	    0.060	    0.053	  0.000%	 24.489%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/BiasAdd;efficientnetv2-l/block4a_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4a_se_reduce/Conv2D]:100
	                LOGISTIC	         7033.671	    0.009	    0.009	  0.000%	 24.489%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/Sigmoid]:101
	                     MUL	         7033.688	    0.018	    0.024	  0.000%	 24.490%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/mul_1]:102
	                 CONV_2D	         7033.718	    0.025	    0.027	  0.000%	 24.490%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/BiasAdd;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_se_expand/Conv2D]:103
	                LOGISTIC	         7033.751	    0.011	    0.011	  0.000%	 24.490%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/Sigmoid]:104
	                     MUL	         7033.769	   24.222	   24.318	  0.085%	 24.574%	     0.000	        1	[efficientnetv2-l/block4a_se_excite/mul]:105
	                 CONV_2D	         7058.096	    3.976	    4.010	  0.014%	 24.588%	     0.000	        1	[efficientnetv2-l/block4a_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_project_conv/Conv2D]:106
	                 CONV_2D	         7062.115	    7.842	    7.875	  0.027%	 24.616%	     0.000	        1	[efficientnetv2-l/block4b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_expand_conv/Conv2D]:107
	                LOGISTIC	         7069.999	    6.669	    6.681	  0.023%	 24.639%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/Sigmoid]:108
	                     MUL	         7076.690	   48.444	   48.676	  0.170%	 24.809%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/mul_1]:109
	       DEPTHWISE_CONV_2D	         7125.378	    3.786	    3.699	  0.013%	 24.821%	     0.000	        1	[efficientnetv2-l/block4b_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:110
	                LOGISTIC	         7129.091	    6.702	    6.781	  0.024%	 24.845%	     0.000	        1	[efficientnetv2-l/block4b_activation/Sigmoid]:111
	                     MUL	         7135.882	   48.557	   48.846	  0.170%	 25.015%	     0.000	        1	[efficientnetv2-l/block4b_activation/mul_1]:112
	                    MEAN	         7184.739	  117.027	  116.766	  0.407%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_squeeze/Mean]:113
	                   SHAPE	         7301.517	    0.009	    0.009	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Shape]:114
	           STRIDED_SLICE	         7301.532	    0.022	    0.026	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/strided_slice]:115
	                    PACK	         7301.565	    0.030	    0.029	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape/shape]:116
	                 RESHAPE	         7301.601	    0.014	    0.013	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape]:117
	                 CONV_2D	         7301.621	    0.046	    0.046	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4b_se_reduce/Conv2D]:118
	                LOGISTIC	         7301.673	    0.009	    0.009	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/Sigmoid]:119
	                     MUL	         7301.689	    0.018	    0.018	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/mul_1]:120
	                 CONV_2D	         7301.712	    0.059	    0.035	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_se_expand/Conv2D]:121
	                LOGISTIC	         7301.754	    0.015	    0.015	  0.000%	 25.422%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/Sigmoid]:122
	                     MUL	         7301.775	   48.920	   48.570	  0.169%	 25.592%	     0.000	        1	[efficientnetv2-l/block4b_se_excite/mul]:123
	                 CONV_2D	         7350.356	    5.197	    5.173	  0.018%	 25.610%	     0.000	        1	[efficientnetv2-l/block4b_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_project_conv/Conv2D]:124
	                     ADD	         7355.540	   16.253	   16.079	  0.056%	 25.666%	     0.000	        1	[efficientnetv2-l/block4b_add/add]:125
	                 CONV_2D	         7371.630	    8.129	    7.918	  0.028%	 25.693%	     0.000	        1	[efficientnetv2-l/block4c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_expand_conv/Conv2D]:126
	                LOGISTIC	         7379.558	    6.761	    6.688	  0.023%	 25.716%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/Sigmoid]:127
	                     MUL	         7386.256	   48.997	   48.763	  0.170%	 25.886%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/mul_1]:128
	       DEPTHWISE_CONV_2D	         7435.030	    3.850	    3.579	  0.012%	 25.899%	     0.000	        1	[efficientnetv2-l/block4c_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:129
	                LOGISTIC	         7438.620	    6.752	    6.720	  0.023%	 25.922%	     0.000	        1	[efficientnetv2-l/block4c_activation/Sigmoid]:130
	                     MUL	         7445.350	   49.043	   48.717	  0.170%	 26.092%	     0.000	        1	[efficientnetv2-l/block4c_activation/mul_1]:131
	                    MEAN	         7494.079	  117.842	  117.421	  0.409%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_squeeze/Mean]:132
	                   SHAPE	         7611.511	    0.010	    0.009	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Shape]:133
	           STRIDED_SLICE	         7611.526	    0.023	    0.022	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/strided_slice]:134
	                    PACK	         7611.555	    0.030	    0.033	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape/shape]:135
	                 RESHAPE	         7611.594	    0.014	    0.014	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape]:136
	                 CONV_2D	         7611.614	    0.079	    0.051	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4c_se_reduce/Conv2D]:137
	                LOGISTIC	         7611.671	    0.011	    0.010	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/Sigmoid]:138
	                     MUL	         7611.686	    0.017	    0.020	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/mul_1]:139
	                 CONV_2D	         7611.713	    0.030	    0.040	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_se_expand/Conv2D]:140
	                LOGISTIC	         7611.758	    0.015	    0.015	  0.000%	 26.501%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/Sigmoid]:141
	                     MUL	         7611.783	   48.944	   48.673	  0.169%	 26.671%	     0.000	        1	[efficientnetv2-l/block4c_se_excite/mul]:142
	                 CONV_2D	         7660.468	    5.165	    5.194	  0.018%	 26.689%	     0.000	        1	[efficientnetv2-l/block4c_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_project_conv/Conv2D]:143
	                     ADD	         7665.672	   16.252	   16.104	  0.056%	 26.745%	     0.000	        1	[efficientnetv2-l/block4c_add/add]:144
	                 CONV_2D	         7681.785	    7.970	    7.959	  0.028%	 26.773%	     0.000	        1	[efficientnetv2-l/block4d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_expand_conv/Conv2D]:145
	                LOGISTIC	         7689.755	    6.703	    6.715	  0.023%	 26.796%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/Sigmoid]:146
	                     MUL	         7696.480	   48.787	   48.682	  0.170%	 26.966%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/mul_1]:147
	       DEPTHWISE_CONV_2D	         7745.173	    3.658	    3.631	  0.013%	 26.978%	     0.000	        1	[efficientnetv2-l/block4d_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:148
	                LOGISTIC	         7748.814	    6.677	    6.708	  0.023%	 27.002%	     0.000	        1	[efficientnetv2-l/block4d_activation/Sigmoid]:149
	                     MUL	         7755.533	   48.729	   48.674	  0.170%	 27.171%	     0.000	        1	[efficientnetv2-l/block4d_activation/mul_1]:150
	                    MEAN	         7804.218	  117.257	  117.083	  0.408%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_squeeze/Mean]:151
	                   SHAPE	         7921.313	    0.009	    0.009	  0.000%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Shape]:152
	           STRIDED_SLICE	         7921.328	    0.034	    0.024	  0.000%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/strided_slice]:153
	                    PACK	         7921.358	    0.030	    0.030	  0.000%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape/shape]:154
	                 RESHAPE	         7921.395	    0.014	    0.018	  0.000%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape]:155
	                 CONV_2D	         7921.419	    0.045	    0.046	  0.000%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4d_se_reduce/Conv2D]:156
	                LOGISTIC	         7921.472	    0.009	    0.009	  0.000%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/Sigmoid]:157
	                     MUL	         7921.488	    0.018	    0.018	  0.000%	 27.579%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/mul_1]:158
	                 CONV_2D	         7921.511	    0.031	    0.030	  0.000%	 27.580%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_se_expand/Conv2D]:159
	                LOGISTIC	         7921.548	    0.015	    0.015	  0.000%	 27.580%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/Sigmoid]:160
	                     MUL	         7921.569	   48.811	   48.641	  0.169%	 27.749%	     0.000	        1	[efficientnetv2-l/block4d_se_excite/mul]:161
	                 CONV_2D	         7970.220	    5.202	    5.177	  0.018%	 27.767%	     0.000	        1	[efficientnetv2-l/block4d_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_project_conv/Conv2D]:162
	                     ADD	         7975.406	   16.241	   16.102	  0.056%	 27.823%	     0.000	        1	[efficientnetv2-l/block4d_add/add]:163
	                 CONV_2D	         7991.518	    7.968	    7.912	  0.028%	 27.851%	     0.000	        1	[efficientnetv2-l/block4e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_expand_conv/Conv2D]:164
	                LOGISTIC	         7999.439	    6.599	    6.630	  0.023%	 27.874%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/Sigmoid]:165
	                     MUL	         8006.079	   48.759	   48.660	  0.169%	 28.043%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/mul_1]:166
	       DEPTHWISE_CONV_2D	         8054.751	    3.612	    3.596	  0.013%	 28.056%	     0.000	        1	[efficientnetv2-l/block4e_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:167
	                LOGISTIC	         8058.358	    6.643	    6.720	  0.023%	 28.079%	     0.000	        1	[efficientnetv2-l/block4e_activation/Sigmoid]:168
	                     MUL	         8065.088	   48.575	   48.640	  0.169%	 28.249%	     0.000	        1	[efficientnetv2-l/block4e_activation/mul_1]:169
	                    MEAN	         8113.739	  116.595	  117.042	  0.408%	 28.656%	     0.000	        1	[efficientnetv2-l/block4e_se_squeeze/Mean]:170
	                   SHAPE	         8230.792	    0.009	    0.008	  0.000%	 28.656%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Shape]:171
	           STRIDED_SLICE	         8230.807	    0.022	    0.022	  0.000%	 28.656%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/strided_slice]:172
	                    PACK	         8230.835	    0.046	    0.034	  0.000%	 28.656%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape/shape]:173
	                 RESHAPE	         8230.876	    0.014	    0.013	  0.000%	 28.656%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape]:174
	                 CONV_2D	         8230.895	    0.044	    0.060	  0.000%	 28.657%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4e_se_reduce/Conv2D]:175
	                LOGISTIC	         8230.962	    0.010	    0.009	  0.000%	 28.657%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/Sigmoid]:176
	                     MUL	         8230.977	    0.017	    0.017	  0.000%	 28.657%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/mul_1]:177
	                 CONV_2D	         8231.001	    0.027	    0.028	  0.000%	 28.657%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_se_expand/Conv2D]:178
	                LOGISTIC	         8231.035	    0.014	    0.015	  0.000%	 28.657%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/Sigmoid]:179
	                     MUL	         8231.055	   48.439	   48.507	  0.169%	 28.826%	     0.000	        1	[efficientnetv2-l/block4e_se_excite/mul]:180
	                 CONV_2D	         8279.574	    5.196	    5.194	  0.018%	 28.844%	     0.000	        1	[efficientnetv2-l/block4e_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_project_conv/Conv2D]:181
	                     ADD	         8284.775	   15.966	   16.030	  0.056%	 28.900%	     0.000	        1	[efficientnetv2-l/block4e_add/add]:182
	                 CONV_2D	         8300.815	    7.876	    7.897	  0.028%	 28.927%	     0.000	        1	[efficientnetv2-l/block4f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_expand_conv/Conv2D]:183
	                LOGISTIC	         8308.728	    6.646	    6.660	  0.023%	 28.950%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/Sigmoid]:184
	                     MUL	         8315.399	   48.360	   48.569	  0.169%	 29.119%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/mul_1]:185
	       DEPTHWISE_CONV_2D	         8363.979	    3.508	    3.514	  0.012%	 29.132%	     0.000	        1	[efficientnetv2-l/block4f_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:186
	                LOGISTIC	         8367.503	    6.687	    6.702	  0.023%	 29.155%	     0.000	        1	[efficientnetv2-l/block4f_activation/Sigmoid]:187
	                     MUL	         8374.216	   48.364	   48.628	  0.169%	 29.324%	     0.000	        1	[efficientnetv2-l/block4f_activation/mul_1]:188
	                    MEAN	         8422.855	  116.647	  117.089	  0.408%	 29.732%	     0.000	        1	[efficientnetv2-l/block4f_se_squeeze/Mean]:189
	                   SHAPE	         8539.954	    0.008	    0.009	  0.000%	 29.732%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Shape]:190
	           STRIDED_SLICE	         8539.969	    0.021	    0.022	  0.000%	 29.732%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/strided_slice]:191
	                    PACK	         8539.997	    0.042	    0.032	  0.000%	 29.732%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape/shape]:192
	                 RESHAPE	         8540.036	    0.013	    0.013	  0.000%	 29.732%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape]:193
	                 CONV_2D	         8540.056	    0.043	    0.057	  0.000%	 29.733%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4f_se_reduce/Conv2D]:194
	                LOGISTIC	         8540.120	    0.009	    0.009	  0.000%	 29.733%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/Sigmoid]:195
	                     MUL	         8540.136	    0.017	    0.018	  0.000%	 29.733%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/mul_1]:196
	                 CONV_2D	         8540.159	    0.029	    0.029	  0.000%	 29.733%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_se_expand/Conv2D]:197
	                LOGISTIC	         8540.195	    0.015	    0.015	  0.000%	 29.733%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/Sigmoid]:198
	                     MUL	         8540.216	   48.426	   48.553	  0.169%	 29.902%	     0.000	        1	[efficientnetv2-l/block4f_se_excite/mul]:199
	                 CONV_2D	         8588.781	    5.180	    5.171	  0.018%	 29.920%	     0.000	        1	[efficientnetv2-l/block4f_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_project_conv/Conv2D]:200
	                     ADD	         8593.960	   15.979	   16.064	  0.056%	 29.976%	     0.000	        1	[efficientnetv2-l/block4f_add/add]:201
	                 CONV_2D	         8610.032	    7.852	    7.885	  0.027%	 30.003%	     0.000	        1	[efficientnetv2-l/block4g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_expand_conv/Conv2D]:202
	                LOGISTIC	         8617.926	    6.689	    6.753	  0.024%	 30.027%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/Sigmoid]:203
	                     MUL	         8624.690	   48.414	   48.931	  0.170%	 30.197%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/mul_1]:204
	       DEPTHWISE_CONV_2D	         8673.632	    3.531	    3.550	  0.012%	 30.210%	     0.000	        1	[efficientnetv2-l/block4g_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:205
	                LOGISTIC	         8677.194	    6.683	    6.766	  0.024%	 30.233%	     0.000	        1	[efficientnetv2-l/block4g_activation/Sigmoid]:206
	                     MUL	         8683.971	   48.461	   48.727	  0.170%	 30.403%	     0.000	        1	[efficientnetv2-l/block4g_activation/mul_1]:207
	                    MEAN	         8732.711	  116.568	  117.003	  0.407%	 30.810%	     0.000	        1	[efficientnetv2-l/block4g_se_squeeze/Mean]:208
	                   SHAPE	         8849.725	    0.009	    0.011	  0.000%	 30.810%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Shape]:209
	           STRIDED_SLICE	         8849.742	    0.021	    0.024	  0.000%	 30.810%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/strided_slice]:210
	                    PACK	         8849.772	    0.030	    0.031	  0.000%	 30.811%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape/shape]:211
	                 RESHAPE	         8849.809	    0.014	    0.019	  0.000%	 30.811%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape]:212
	                 CONV_2D	         8849.834	    0.040	    0.044	  0.000%	 30.811%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4g_se_reduce/Conv2D]:213
	                LOGISTIC	         8849.884	    0.009	    0.009	  0.000%	 30.811%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/Sigmoid]:214
	                     MUL	         8849.900	    0.017	    0.018	  0.000%	 30.811%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/mul_1]:215
	                 CONV_2D	         8849.923	    0.030	    0.033	  0.000%	 30.811%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_se_expand/Conv2D]:216
	                LOGISTIC	         8849.962	    0.014	    0.015	  0.000%	 30.811%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/Sigmoid]:217
	                     MUL	         8849.983	   48.337	   48.606	  0.169%	 30.980%	     0.000	        1	[efficientnetv2-l/block4g_se_excite/mul]:218
	                 CONV_2D	         8898.601	    5.191	    5.197	  0.018%	 30.998%	     0.000	        1	[efficientnetv2-l/block4g_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_project_conv/Conv2D]:219
	                     ADD	         8903.807	   15.988	   16.044	  0.056%	 31.054%	     0.000	        1	[efficientnetv2-l/block4g_add/add]:220
	                 CONV_2D	         8919.861	    7.883	    7.950	  0.028%	 31.082%	     0.000	        1	[efficientnetv2-l/block4h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_expand_conv/Conv2D]:221
	                LOGISTIC	         8927.820	    6.682	    6.689	  0.023%	 31.105%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/Sigmoid]:222
	                     MUL	         8934.520	   48.320	   48.616	  0.169%	 31.274%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/mul_1]:223
	       DEPTHWISE_CONV_2D	         8983.147	    3.523	    3.540	  0.012%	 31.287%	     0.000	        1	[efficientnetv2-l/block4h_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:224
	                LOGISTIC	         8986.697	    6.655	    6.704	  0.023%	 31.310%	     0.000	        1	[efficientnetv2-l/block4h_activation/Sigmoid]:225
	                     MUL	         8993.411	   48.446	   48.628	  0.169%	 31.480%	     0.000	        1	[efficientnetv2-l/block4h_activation/mul_1]:226
	                    MEAN	         9042.050	  116.461	  116.804	  0.407%	 31.886%	     0.000	        1	[efficientnetv2-l/block4h_se_squeeze/Mean]:227
	                   SHAPE	         9158.866	    0.008	    0.009	  0.000%	 31.886%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Shape]:228
	           STRIDED_SLICE	         9158.881	    0.020	    0.022	  0.000%	 31.886%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/strided_slice]:229
	                    PACK	         9158.909	    0.029	    0.041	  0.000%	 31.887%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape/shape]:230
	                 RESHAPE	         9158.960	    0.013	    0.014	  0.000%	 31.887%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape]:231
	                 CONV_2D	         9158.980	    0.042	    0.043	  0.000%	 31.887%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4h_se_reduce/Conv2D]:232
	                LOGISTIC	         9159.030	    0.010	    0.009	  0.000%	 31.887%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/Sigmoid]:233
	                     MUL	         9159.045	    0.018	    0.018	  0.000%	 31.887%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/mul_1]:234
	                 CONV_2D	         9159.069	    0.030	    0.030	  0.000%	 31.887%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_se_expand/Conv2D]:235
	                LOGISTIC	         9159.105	    0.014	    0.015	  0.000%	 31.887%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/Sigmoid]:236
	                     MUL	         9159.126	   48.348	   48.658	  0.169%	 32.056%	     0.000	        1	[efficientnetv2-l/block4h_se_excite/mul]:237
	                 CONV_2D	         9207.794	    5.168	    5.167	  0.018%	 32.074%	     0.000	        1	[efficientnetv2-l/block4h_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_project_conv/Conv2D]:238
	                     ADD	         9212.972	   15.994	   16.056	  0.056%	 32.130%	     0.000	        1	[efficientnetv2-l/block4h_add/add]:239
	                 CONV_2D	         9229.037	    7.865	    7.918	  0.028%	 32.158%	     0.000	        1	[efficientnetv2-l/block4i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_expand_conv/Conv2D]:240
	                LOGISTIC	         9236.965	    6.663	    6.677	  0.023%	 32.181%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/Sigmoid]:241
	                     MUL	         9243.652	   48.447	   48.709	  0.170%	 32.351%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/mul_1]:242
	       DEPTHWISE_CONV_2D	         9292.372	    3.524	    3.540	  0.012%	 32.363%	     0.000	        1	[efficientnetv2-l/block4i_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:243
	                LOGISTIC	         9295.922	    6.694	    6.706	  0.023%	 32.386%	     0.000	        1	[efficientnetv2-l/block4i_activation/Sigmoid]:244
	                     MUL	         9302.644	   48.338	   48.675	  0.170%	 32.556%	     0.000	        1	[efficientnetv2-l/block4i_activation/mul_1]:245
	                    MEAN	         9351.329	  116.632	  117.174	  0.408%	 32.964%	     0.000	        1	[efficientnetv2-l/block4i_se_squeeze/Mean]:246
	                   SHAPE	         9468.517	    0.009	    0.009	  0.000%	 32.964%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Shape]:247
	           STRIDED_SLICE	         9468.532	    0.021	    0.024	  0.000%	 32.964%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/strided_slice]:248
	                    PACK	         9468.562	    0.030	    0.033	  0.000%	 32.964%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape/shape]:249
	                 RESHAPE	         9468.602	    0.013	    0.014	  0.000%	 32.964%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape]:250
	                 CONV_2D	         9468.621	    0.044	    0.046	  0.000%	 32.964%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4i_se_reduce/Conv2D]:251
	                LOGISTIC	         9468.674	    0.010	    0.009	  0.000%	 32.964%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/Sigmoid]:252
	                     MUL	         9468.690	    0.018	    0.018	  0.000%	 32.965%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/mul_1]:253
	                 CONV_2D	         9468.715	    0.029	    0.029	  0.000%	 32.965%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_se_expand/Conv2D]:254
	                LOGISTIC	         9468.750	    0.015	    0.015	  0.000%	 32.965%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/Sigmoid]:255
	                     MUL	         9468.771	   48.379	   48.593	  0.169%	 33.134%	     0.000	        1	[efficientnetv2-l/block4i_se_excite/mul]:256
	                 CONV_2D	         9517.375	    5.172	    5.186	  0.018%	 33.152%	     0.000	        1	[efficientnetv2-l/block4i_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_project_conv/Conv2D]:257
	                     ADD	         9522.571	   16.049	   16.071	  0.056%	 33.208%	     0.000	        1	[efficientnetv2-l/block4i_add/add]:258
	                 CONV_2D	         9538.651	    7.870	    7.916	  0.028%	 33.235%	     0.000	        1	[efficientnetv2-l/block4j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_expand_conv/Conv2D]:259
	                LOGISTIC	         9546.576	    6.680	    6.701	  0.023%	 33.259%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/Sigmoid]:260
	                     MUL	         9553.288	   48.385	   48.681	  0.170%	 33.428%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/mul_1]:261
	       DEPTHWISE_CONV_2D	         9601.979	    3.733	    3.589	  0.012%	 33.441%	     0.000	        1	[efficientnetv2-l/block4j_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_dwconv2/depthwise]:262
	                LOGISTIC	         9605.579	    6.697	    6.696	  0.023%	 33.464%	     0.000	        1	[efficientnetv2-l/block4j_activation/Sigmoid]:263
	                     MUL	         9612.286	   48.669	   48.801	  0.170%	 33.634%	     0.000	        1	[efficientnetv2-l/block4j_activation/mul_1]:264
	                    MEAN	         9661.098	  117.095	  116.743	  0.407%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_squeeze/Mean]:265
	                   SHAPE	         9777.852	    0.010	    0.009	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Shape]:266
	           STRIDED_SLICE	         9777.867	    0.023	    0.023	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/strided_slice]:267
	                    PACK	         9777.896	    0.034	    0.030	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape/shape]:268
	                 RESHAPE	         9777.933	    0.014	    0.014	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape]:269
	                 CONV_2D	         9777.953	    0.072	    0.051	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4j_se_reduce/Conv2D]:270
	                LOGISTIC	         9778.016	    0.011	    0.010	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/Sigmoid]:271
	                     MUL	         9778.032	    0.018	    0.018	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/mul_1]:272
	                 CONV_2D	         9778.056	    0.032	    0.035	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_se_expand/Conv2D]:273
	                LOGISTIC	         9778.097	    0.015	    0.015	  0.000%	 34.041%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/Sigmoid]:274
	                     MUL	         9778.119	   49.006	   48.562	  0.169%	 34.210%	     0.000	        1	[efficientnetv2-l/block4j_se_excite/mul]:275
	                 CONV_2D	         9826.691	    5.239	    5.177	  0.018%	 34.228%	     0.000	        1	[efficientnetv2-l/block4j_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_project_conv/Conv2D]:276
	                     ADD	         9831.876	   16.222	   16.092	  0.056%	 34.285%	     0.000	        1	[efficientnetv2-l/block4j_add/add]:277
	                 CONV_2D	         9847.978	   11.842	   11.748	  0.041%	 34.325%	     0.000	        1	[efficientnetv2-l/block5a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_expand_conv/Conv2D]:278
	                LOGISTIC	         9859.736	   10.089	   10.175	  0.035%	 34.361%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/Sigmoid]:279
	                     MUL	         9869.922	   73.567	   73.100	  0.255%	 34.615%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/mul_1]:280
	       DEPTHWISE_CONV_2D	         9943.032	    5.717	    5.482	  0.019%	 34.634%	     0.000	        1	[efficientnetv2-l/block5a_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_dwconv2/depthwise]:281
	                LOGISTIC	         9948.525	   10.082	   10.110	  0.035%	 34.670%	     0.000	        1	[efficientnetv2-l/block5a_activation/Sigmoid]:282
	                     MUL	         9958.645	   73.361	   73.048	  0.254%	 34.924%	     0.000	        1	[efficientnetv2-l/block5a_activation/mul_1]:283
	                    MEAN	        10031.705	  176.368	  176.096	  0.613%	 35.537%	     0.000	        1	[efficientnetv2-l/block5a_se_squeeze/Mean]:284
	                   SHAPE	        10207.812	    0.009	    0.009	  0.000%	 35.537%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Shape]:285
	           STRIDED_SLICE	        10207.828	    0.023	    0.023	  0.000%	 35.537%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/strided_slice]:286
	                    PACK	        10207.857	    0.048	    0.034	  0.000%	 35.538%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape/shape]:287
	                 RESHAPE	        10207.898	    0.014	    0.014	  0.000%	 35.538%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape]:288
	                 CONV_2D	        10207.918	    0.047	    0.055	  0.000%	 35.538%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5a_se_reduce/Conv2D]:289
	                LOGISTIC	        10207.980	    0.010	    0.010	  0.000%	 35.538%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/Sigmoid]:290
	                     MUL	        10207.995	    0.018	    0.018	  0.000%	 35.538%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/mul_1]:291
	                 CONV_2D	        10208.020	    0.035	    0.044	  0.000%	 35.538%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/BiasAdd;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_se_expand/Conv2D]:292
	                LOGISTIC	        10208.071	    0.018	    0.019	  0.000%	 35.538%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/Sigmoid]:293
	                     MUL	        10208.095	   73.097	   73.052	  0.254%	 35.792%	     0.000	        1	[efficientnetv2-l/block5a_se_excite/mul]:294
	                 CONV_2D	        10281.159	   10.428	   10.264	  0.036%	 35.828%	     0.000	        1	[efficientnetv2-l/block5a_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_project_conv/Conv2D]:295
	                 CONV_2D	        10291.433	   13.470	   13.408	  0.047%	 35.875%	     0.000	        1	[efficientnetv2-l/block5b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_expand_conv/Conv2D]:296
	                LOGISTIC	        10304.854	   11.718	   11.698	  0.041%	 35.916%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/Sigmoid]:297
	                     MUL	        10316.565	   85.297	   85.374	  0.297%	 36.213%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/mul_1]:298
	       DEPTHWISE_CONV_2D	        10401.951	    6.318	    6.389	  0.022%	 36.235%	     0.000	        1	[efficientnetv2-l/block5b_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:299
	                LOGISTIC	        10408.352	   11.806	   11.831	  0.041%	 36.276%	     0.000	        1	[efficientnetv2-l/block5b_activation/Sigmoid]:300
	                     MUL	        10420.193	   85.341	   85.201	  0.297%	 36.573%	     0.000	        1	[efficientnetv2-l/block5b_activation/mul_1]:301
	                    MEAN	        10505.405	  204.415	  204.732	  0.713%	 37.286%	     0.000	        1	[efficientnetv2-l/block5b_se_squeeze/Mean]:302
	                   SHAPE	        10710.148	    0.009	    0.011	  0.000%	 37.286%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Shape]:303
	           STRIDED_SLICE	        10710.165	    0.031	    0.024	  0.000%	 37.286%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/strided_slice]:304
	                    PACK	        10710.195	    0.030	    0.029	  0.000%	 37.286%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape/shape]:305
	                 RESHAPE	        10710.231	    0.014	    0.014	  0.000%	 37.286%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape]:306
	                 CONV_2D	        10710.251	    0.048	    0.059	  0.000%	 37.287%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5b_se_reduce/Conv2D]:307
	                LOGISTIC	        10710.317	    0.009	    0.010	  0.000%	 37.287%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/Sigmoid]:308
	                     MUL	        10710.333	    0.021	    0.021	  0.000%	 37.287%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/mul_1]:309
	                 CONV_2D	        10710.360	    0.034	    0.035	  0.000%	 37.287%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_se_expand/Conv2D]:310
	                LOGISTIC	        10710.402	    0.020	    0.023	  0.000%	 37.287%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/Sigmoid]:311
	                     MUL	        10710.431	   84.658	   84.706	  0.295%	 37.582%	     0.000	        1	[efficientnetv2-l/block5b_se_excite/mul]:312
	                 CONV_2D	        10795.148	   12.288	   12.276	  0.043%	 37.625%	     0.000	        1	[efficientnetv2-l/block5b_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_project_conv/Conv2D]:313
	                     ADD	        10807.435	   18.635	   18.699	  0.065%	 37.690%	     0.000	        1	[efficientnetv2-l/block5b_add/add]:314
	                 CONV_2D	        10826.144	   13.251	   13.286	  0.046%	 37.736%	     0.000	        1	[efficientnetv2-l/block5c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_expand_conv/Conv2D]:315
	                LOGISTIC	        10839.440	   11.921	   11.855	  0.041%	 37.777%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/Sigmoid]:316
	                     MUL	        10851.306	   84.653	   85.103	  0.296%	 38.074%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/mul_1]:317
	       DEPTHWISE_CONV_2D	        10936.423	    6.058	    6.227	  0.022%	 38.095%	     0.000	        1	[efficientnetv2-l/block5c_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:318
	                LOGISTIC	        10942.661	   11.846	   11.817	  0.041%	 38.136%	     0.000	        1	[efficientnetv2-l/block5c_activation/Sigmoid]:319
	                     MUL	        10954.489	   84.641	   85.004	  0.296%	 38.432%	     0.000	        1	[efficientnetv2-l/block5c_activation/mul_1]:320
	                    MEAN	        11039.504	  204.156	  205.403	  0.715%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_squeeze/Mean]:321
	                   SHAPE	        11244.921	    0.008	    0.009	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Shape]:322
	           STRIDED_SLICE	        11244.936	    0.022	    0.022	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/strided_slice]:323
	                    PACK	        11244.964	    0.030	    0.029	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape/shape]:324
	                 RESHAPE	        11245.000	    0.014	    0.014	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape]:325
	                 CONV_2D	        11245.020	    0.047	    0.048	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5c_se_reduce/Conv2D]:326
	                LOGISTIC	        11245.074	    0.028	    0.012	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/Sigmoid]:327
	                     MUL	        11245.093	    0.037	    0.024	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/mul_1]:328
	                 CONV_2D	        11245.123	    0.038	    0.044	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_se_expand/Conv2D]:329
	                LOGISTIC	        11245.173	    0.021	    0.020	  0.000%	 39.148%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/Sigmoid]:330
	                     MUL	        11245.199	   84.574	   84.832	  0.295%	 39.444%	     0.000	        1	[efficientnetv2-l/block5c_se_excite/mul]:331
	                 CONV_2D	        11330.043	   12.180	   12.248	  0.043%	 39.487%	     0.000	        1	[efficientnetv2-l/block5c_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_project_conv/Conv2D]:332
	                     ADD	        11342.301	   18.657	   18.735	  0.065%	 39.552%	     0.000	        1	[efficientnetv2-l/block5c_add/add]:333
	                 CONV_2D	        11361.045	   13.268	   13.342	  0.046%	 39.598%	     0.000	        1	[efficientnetv2-l/block5d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_expand_conv/Conv2D]:334
	                LOGISTIC	        11374.398	   11.666	   11.686	  0.041%	 39.639%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/Sigmoid]:335
	                     MUL	        11386.098	   84.644	   84.994	  0.296%	 39.935%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/mul_1]:336
	       DEPTHWISE_CONV_2D	        11471.103	    6.120	    6.202	  0.022%	 39.957%	     0.000	        1	[efficientnetv2-l/block5d_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:337
	                LOGISTIC	        11477.316	   11.772	   11.795	  0.041%	 39.998%	     0.000	        1	[efficientnetv2-l/block5d_activation/Sigmoid]:338
	                     MUL	        11489.123	   84.669	   84.933	  0.296%	 40.293%	     0.000	        1	[efficientnetv2-l/block5d_activation/mul_1]:339
	                    MEAN	        11574.072	  203.957	  204.470	  0.712%	 41.005%	     0.000	        1	[efficientnetv2-l/block5d_se_squeeze/Mean]:340
	                   SHAPE	        11778.553	    0.009	    0.009	  0.000%	 41.005%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Shape]:341
	           STRIDED_SLICE	        11778.568	    0.032	    0.024	  0.000%	 41.005%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/strided_slice]:342
	                    PACK	        11778.598	    0.029	    0.029	  0.000%	 41.006%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape/shape]:343
	                 RESHAPE	        11778.634	    0.014	    0.022	  0.000%	 41.006%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape]:344
	                 CONV_2D	        11778.662	    0.048	    0.055	  0.000%	 41.006%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5d_se_reduce/Conv2D]:345
	                LOGISTIC	        11778.724	    0.010	    0.010	  0.000%	 41.006%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/Sigmoid]:346
	                     MUL	        11778.739	    0.021	    0.022	  0.000%	 41.006%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/mul_1]:347
	                 CONV_2D	        11778.767	    0.056	    0.039	  0.000%	 41.006%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_se_expand/Conv2D]:348
	                LOGISTIC	        11778.818	    0.021	    0.024	  0.000%	 41.006%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/Sigmoid]:349
	                     MUL	        11778.848	   84.674	   84.815	  0.295%	 41.302%	     0.000	        1	[efficientnetv2-l/block5d_se_excite/mul]:350
	                 CONV_2D	        11863.674	   12.157	   12.261	  0.043%	 41.344%	     0.000	        1	[efficientnetv2-l/block5d_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_project_conv/Conv2D]:351
	                     ADD	        11875.948	   18.659	   18.747	  0.065%	 41.410%	     0.000	        1	[efficientnetv2-l/block5d_add/add]:352
	                 CONV_2D	        11894.706	   13.264	   13.335	  0.046%	 41.456%	     0.000	        1	[efficientnetv2-l/block5e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_expand_conv/Conv2D]:353
	                LOGISTIC	        11908.051	   11.737	   11.759	  0.041%	 41.497%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/Sigmoid]:354
	                     MUL	        11919.821	   84.702	   85.086	  0.296%	 41.793%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/mul_1]:355
	       DEPTHWISE_CONV_2D	        12004.919	    6.121	    6.277	  0.022%	 41.815%	     0.000	        1	[efficientnetv2-l/block5e_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:356
	                LOGISTIC	        12011.208	   11.809	   11.763	  0.041%	 41.856%	     0.000	        1	[efficientnetv2-l/block5e_activation/Sigmoid]:357
	                     MUL	        12022.984	   84.998	   85.237	  0.297%	 42.153%	     0.000	        1	[efficientnetv2-l/block5e_activation/mul_1]:358
	                    MEAN	        12108.233	  205.251	  204.832	  0.713%	 42.866%	     0.000	        1	[efficientnetv2-l/block5e_se_squeeze/Mean]:359
	                   SHAPE	        12313.077	    0.010	    0.011	  0.000%	 42.866%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Shape]:360
	           STRIDED_SLICE	        12313.094	    0.025	    0.024	  0.000%	 42.866%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/strided_slice]:361
	                    PACK	        12313.124	    0.032	    0.029	  0.000%	 42.866%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape/shape]:362
	                 RESHAPE	        12313.159	    0.015	    0.014	  0.000%	 42.866%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape]:363
	                 CONV_2D	        12313.180	    0.051	    0.051	  0.000%	 42.867%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5e_se_reduce/Conv2D]:364
	                LOGISTIC	        12313.237	    0.010	    0.009	  0.000%	 42.867%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/Sigmoid]:365
	                     MUL	        12313.253	    0.023	    0.021	  0.000%	 42.867%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/mul_1]:366
	                 CONV_2D	        12313.281	    0.038	    0.043	  0.000%	 42.867%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_se_expand/Conv2D]:367
	                LOGISTIC	        12313.330	    0.021	    0.020	  0.000%	 42.867%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/Sigmoid]:368
	                     MUL	        12313.356	   87.055	   85.476	  0.298%	 43.165%	     0.000	        1	[efficientnetv2-l/block5e_se_excite/mul]:369
	                 CONV_2D	        12398.845	   12.461	   12.334	  0.043%	 43.208%	     0.000	        1	[efficientnetv2-l/block5e_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_project_conv/Conv2D]:370
	                     ADD	        12411.190	   18.878	   18.848	  0.066%	 43.273%	     0.000	        1	[efficientnetv2-l/block5e_add/add]:371
	                 CONV_2D	        12430.049	   13.505	   13.490	  0.047%	 43.320%	     0.000	        1	[efficientnetv2-l/block5f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_expand_conv/Conv2D]:372
	                LOGISTIC	        12443.550	   11.833	   11.963	  0.042%	 43.362%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/Sigmoid]:373
	                     MUL	        12455.524	   85.880	   85.265	  0.297%	 43.659%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/mul_1]:374
	       DEPTHWISE_CONV_2D	        12540.801	    6.519	    6.322	  0.022%	 43.681%	     0.000	        1	[efficientnetv2-l/block5f_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:375
	                LOGISTIC	        12547.136	   11.767	   12.205	  0.043%	 43.723%	     0.000	        1	[efficientnetv2-l/block5f_activation/Sigmoid]:376
	                     MUL	        12559.352	   85.555	   85.126	  0.296%	 44.020%	     0.000	        1	[efficientnetv2-l/block5f_activation/mul_1]:377
	                    MEAN	        12644.489	  205.613	  204.794	  0.713%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_squeeze/Mean]:378
	                   SHAPE	        12849.294	    0.010	    0.009	  0.000%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Shape]:379
	           STRIDED_SLICE	        12849.310	    0.022	    0.024	  0.000%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/strided_slice]:380
	                    PACK	        12849.341	    0.029	    0.028	  0.000%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape/shape]:381
	                 RESHAPE	        12849.375	    0.013	    0.017	  0.000%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape]:382
	                 CONV_2D	        12849.399	    0.048	    0.051	  0.000%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5f_se_reduce/Conv2D]:383
	                LOGISTIC	        12849.457	    0.009	    0.009	  0.000%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/Sigmoid]:384
	                     MUL	        12849.475	    0.021	    0.021	  0.000%	 44.733%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/mul_1]:385
	                 CONV_2D	        12849.503	    0.036	    0.036	  0.000%	 44.734%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_se_expand/Conv2D]:386
	                LOGISTIC	        12849.545	    0.020	    0.020	  0.000%	 44.734%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/Sigmoid]:387
	                     MUL	        12849.571	   85.236	   84.972	  0.296%	 45.029%	     0.000	        1	[efficientnetv2-l/block5f_se_excite/mul]:388
	                 CONV_2D	        12934.554	   12.336	   12.317	  0.043%	 45.072%	     0.000	        1	[efficientnetv2-l/block5f_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_project_conv/Conv2D]:389
	                     ADD	        12946.881	   18.878	   18.803	  0.065%	 45.138%	     0.000	        1	[efficientnetv2-l/block5f_add/add]:390
	                 CONV_2D	        12965.696	   13.362	   13.336	  0.046%	 45.184%	     0.000	        1	[efficientnetv2-l/block5g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_expand_conv/Conv2D]:391
	                LOGISTIC	        12979.042	   11.680	   11.725	  0.041%	 45.225%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/Sigmoid]:392
	                     MUL	        12990.778	   84.948	   85.090	  0.296%	 45.521%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/mul_1]:393
	       DEPTHWISE_CONV_2D	        13075.880	    6.104	    6.311	  0.022%	 45.543%	     0.000	        1	[efficientnetv2-l/block5g_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:394
	                LOGISTIC	        13082.202	   11.912	   11.887	  0.041%	 45.585%	     0.000	        1	[efficientnetv2-l/block5g_activation/Sigmoid]:395
	                     MUL	        13094.102	   84.693	   85.059	  0.296%	 45.881%	     0.000	        1	[efficientnetv2-l/block5g_activation/mul_1]:396
	                    MEAN	        13179.173	  204.165	  205.109	  0.714%	 46.595%	     0.000	        1	[efficientnetv2-l/block5g_se_squeeze/Mean]:397
	                   SHAPE	        13384.293	    0.009	    0.013	  0.000%	 46.595%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Shape]:398
	           STRIDED_SLICE	        13384.313	    0.022	    0.024	  0.000%	 46.595%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/strided_slice]:399
	                    PACK	        13384.344	    0.041	    0.036	  0.000%	 46.596%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape/shape]:400
	                 RESHAPE	        13384.386	    0.014	    0.017	  0.000%	 46.596%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape]:401
	                 CONV_2D	        13384.410	    0.047	    0.048	  0.000%	 46.596%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5g_se_reduce/Conv2D]:402
	                LOGISTIC	        13384.465	    0.010	    0.010	  0.000%	 46.596%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/Sigmoid]:403
	                     MUL	        13384.481	    0.020	    0.021	  0.000%	 46.596%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/mul_1]:404
	                 CONV_2D	        13384.508	    0.037	    0.042	  0.000%	 46.596%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_se_expand/Conv2D]:405
	                LOGISTIC	        13384.556	    0.020	    0.024	  0.000%	 46.596%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/Sigmoid]:406
	                     MUL	        13384.586	   84.554	   85.031	  0.296%	 46.892%	     0.000	        1	[efficientnetv2-l/block5g_se_excite/mul]:407
	                 CONV_2D	        13469.628	   12.225	   12.317	  0.043%	 46.935%	     0.000	        1	[efficientnetv2-l/block5g_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_project_conv/Conv2D]:408
	                     ADD	        13481.956	   18.653	   18.762	  0.065%	 47.000%	     0.000	        1	[efficientnetv2-l/block5g_add/add]:409
	                 CONV_2D	        13500.728	   13.236	   13.358	  0.047%	 47.047%	     0.000	        1	[efficientnetv2-l/block5h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_expand_conv/Conv2D]:410
	                LOGISTIC	        13514.097	   11.708	   11.698	  0.041%	 47.088%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/Sigmoid]:411
	                     MUL	        13525.807	   84.750	   85.192	  0.297%	 47.384%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/mul_1]:412
	       DEPTHWISE_CONV_2D	        13611.010	    6.179	    6.225	  0.022%	 47.406%	     0.000	        1	[efficientnetv2-l/block5h_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:413
	                LOGISTIC	        13617.257	   11.751	   11.833	  0.041%	 47.447%	     0.000	        1	[efficientnetv2-l/block5h_activation/Sigmoid]:414
	                     MUL	        13629.101	   84.607	   85.084	  0.296%	 47.744%	     0.000	        1	[efficientnetv2-l/block5h_activation/mul_1]:415
	                    MEAN	        13714.196	  204.187	  204.577	  0.712%	 48.456%	     0.000	        1	[efficientnetv2-l/block5h_se_squeeze/Mean]:416
	                   SHAPE	        13918.785	    0.009	    0.009	  0.000%	 48.456%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Shape]:417
	           STRIDED_SLICE	        13918.800	    0.021	    0.023	  0.000%	 48.456%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/strided_slice]:418
	                    PACK	        13918.830	    0.046	    0.031	  0.000%	 48.456%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape/shape]:419
	                 RESHAPE	        13918.867	    0.014	    0.014	  0.000%	 48.456%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape]:420
	                 CONV_2D	        13918.888	    0.049	    0.059	  0.000%	 48.456%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5h_se_reduce/Conv2D]:421
	                LOGISTIC	        13918.953	    0.009	    0.009	  0.000%	 48.456%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/Sigmoid]:422
	                     MUL	        13918.969	    0.021	    0.021	  0.000%	 48.457%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/mul_1]:423
	                 CONV_2D	        13918.996	    0.036	    0.039	  0.000%	 48.457%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_se_expand/Conv2D]:424
	                LOGISTIC	        13919.042	    0.020	    0.020	  0.000%	 48.457%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/Sigmoid]:425
	                     MUL	        13919.068	   84.593	   84.908	  0.296%	 48.752%	     0.000	        1	[efficientnetv2-l/block5h_se_excite/mul]:426
	                 CONV_2D	        14003.987	   12.160	   12.265	  0.043%	 48.795%	     0.000	        1	[efficientnetv2-l/block5h_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_project_conv/Conv2D]:427
	                     ADD	        14016.262	   18.684	   18.755	  0.065%	 48.860%	     0.000	        1	[efficientnetv2-l/block5h_add/add]:428
	                 CONV_2D	        14035.027	   13.243	   13.326	  0.046%	 48.907%	     0.000	        1	[efficientnetv2-l/block5i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_expand_conv/Conv2D]:429
	                LOGISTIC	        14048.363	   11.803	   11.752	  0.041%	 48.948%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/Sigmoid]:430
	                     MUL	        14060.126	   84.731	   85.151	  0.297%	 49.244%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/mul_1]:431
	       DEPTHWISE_CONV_2D	        14145.288	    6.210	    6.391	  0.022%	 49.267%	     0.000	        1	[efficientnetv2-l/block5i_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:432
	                LOGISTIC	        14151.691	   11.889	   11.805	  0.041%	 49.308%	     0.000	        1	[efficientnetv2-l/block5i_activation/Sigmoid]:433
	                     MUL	        14163.507	   84.653	   85.050	  0.296%	 49.604%	     0.000	        1	[efficientnetv2-l/block5i_activation/mul_1]:434
	                    MEAN	        14248.568	  204.274	  205.381	  0.715%	 50.319%	     0.000	        1	[efficientnetv2-l/block5i_se_squeeze/Mean]:435
	                   SHAPE	        14453.960	    0.008	    0.011	  0.000%	 50.319%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Shape]:436
	           STRIDED_SLICE	        14453.978	    0.022	    0.022	  0.000%	 50.319%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/strided_slice]:437
	                    PACK	        14454.005	    0.030	    0.029	  0.000%	 50.319%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape/shape]:438
	                 RESHAPE	        14454.041	    0.013	    0.014	  0.000%	 50.319%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape]:439
	                 CONV_2D	        14454.061	    0.047	    0.054	  0.000%	 50.319%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5i_se_reduce/Conv2D]:440
	                LOGISTIC	        14454.122	    0.010	    0.010	  0.000%	 50.320%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/Sigmoid]:441
	                     MUL	        14454.138	    0.037	    0.029	  0.000%	 50.320%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/mul_1]:442
	                 CONV_2D	        14454.174	    0.038	    0.038	  0.000%	 50.320%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_se_expand/Conv2D]:443
	                LOGISTIC	        14454.218	    0.020	    0.035	  0.000%	 50.320%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/Sigmoid]:444
	                     MUL	        14454.260	   84.592	   85.139	  0.296%	 50.616%	     0.000	        1	[efficientnetv2-l/block5i_se_excite/mul]:445
	                 CONV_2D	        14539.411	   12.154	   12.271	  0.043%	 50.659%	     0.000	        1	[efficientnetv2-l/block5i_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_project_conv/Conv2D]:446
	                     ADD	        14551.692	   18.744	   18.859	  0.066%	 50.725%	     0.000	        1	[efficientnetv2-l/block5i_add/add]:447
	                 CONV_2D	        14570.561	   13.412	   13.372	  0.047%	 50.771%	     0.000	        1	[efficientnetv2-l/block5j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_expand_conv/Conv2D]:448
	                LOGISTIC	        14583.944	   11.791	   11.761	  0.041%	 50.812%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/Sigmoid]:449
	                     MUL	        14595.715	   84.732	   84.913	  0.296%	 51.108%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/mul_1]:450
	       DEPTHWISE_CONV_2D	        14680.639	    6.069	    6.145	  0.021%	 51.129%	     0.000	        1	[efficientnetv2-l/block5j_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:451
	                LOGISTIC	        14686.796	   11.737	   11.773	  0.041%	 51.170%	     0.000	        1	[efficientnetv2-l/block5j_activation/Sigmoid]:452
	                     MUL	        14698.580	   85.535	   85.113	  0.296%	 51.467%	     0.000	        1	[efficientnetv2-l/block5j_activation/mul_1]:453
	                    MEAN	        14783.705	  209.587	  205.597	  0.716%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_squeeze/Mean]:454
	                   SHAPE	        14989.316	    0.009	    0.009	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Shape]:455
	           STRIDED_SLICE	        14989.331	    0.021	    0.022	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/strided_slice]:456
	                    PACK	        14989.360	    0.030	    0.029	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape/shape]:457
	                 RESHAPE	        14989.395	    0.014	    0.014	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape]:458
	                 CONV_2D	        14989.418	    0.049	    0.050	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5j_se_reduce/Conv2D]:459
	                LOGISTIC	        14989.474	    0.009	    0.009	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/Sigmoid]:460
	                     MUL	        14989.489	    0.022	    0.021	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/mul_1]:461
	                 CONV_2D	        14989.517	    0.035	    0.047	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_se_expand/Conv2D]:462
	                LOGISTIC	        14989.571	    0.020	    0.021	  0.000%	 52.183%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/Sigmoid]:463
	                     MUL	        14989.598	   85.923	   85.106	  0.296%	 52.480%	     0.000	        1	[efficientnetv2-l/block5j_se_excite/mul]:464
	                 CONV_2D	        15074.716	   12.331	   12.248	  0.043%	 52.523%	     0.000	        1	[efficientnetv2-l/block5j_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_project_conv/Conv2D]:465
	                     ADD	        15086.974	   18.810	   18.733	  0.065%	 52.588%	     0.000	        1	[efficientnetv2-l/block5j_add/add]:466
	                 CONV_2D	        15105.717	   13.424	   13.340	  0.046%	 52.634%	     0.000	        1	[efficientnetv2-l/block5k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_expand_conv/Conv2D]:467
	                LOGISTIC	        15119.069	   11.687	   11.716	  0.041%	 52.675%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/Sigmoid]:468
	                     MUL	        15130.795	   85.388	   85.204	  0.297%	 52.972%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/mul_1]:469
	       DEPTHWISE_CONV_2D	        15216.010	    6.530	    6.296	  0.022%	 52.994%	     0.000	        1	[efficientnetv2-l/block5k_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:470
	                LOGISTIC	        15222.324	   11.616	   11.746	  0.041%	 53.035%	     0.000	        1	[efficientnetv2-l/block5k_activation/Sigmoid]:471
	                     MUL	        15234.082	   85.409	   85.227	  0.297%	 53.331%	     0.000	        1	[efficientnetv2-l/block5k_activation/mul_1]:472
	                    MEAN	        15319.320	  205.432	  205.296	  0.715%	 54.046%	     0.000	        1	[efficientnetv2-l/block5k_se_squeeze/Mean]:473
	                   SHAPE	        15524.627	    0.009	    0.009	  0.000%	 54.046%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Shape]:474
	           STRIDED_SLICE	        15524.642	    0.021	    0.023	  0.000%	 54.046%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/strided_slice]:475
	                    PACK	        15524.672	    0.030	    0.035	  0.000%	 54.046%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape/shape]:476
	                 RESHAPE	        15524.716	    0.014	    0.018	  0.000%	 54.047%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape]:477
	                 CONV_2D	        15524.740	    0.048	    0.054	  0.000%	 54.047%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5k_se_reduce/Conv2D]:478
	                LOGISTIC	        15524.801	    0.010	    0.010	  0.000%	 54.047%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/Sigmoid]:479
	                     MUL	        15524.817	    0.021	    0.031	  0.000%	 54.047%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/mul_1]:480
	                 CONV_2D	        15524.854	    0.037	    0.037	  0.000%	 54.047%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_se_expand/Conv2D]:481
	                LOGISTIC	        15524.897	    0.020	    0.020	  0.000%	 54.047%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/Sigmoid]:482
	                     MUL	        15524.923	   84.568	   84.968	  0.296%	 54.343%	     0.000	        1	[efficientnetv2-l/block5k_se_excite/mul]:483
	                 CONV_2D	        15609.903	   12.237	   12.230	  0.043%	 54.386%	     0.000	        1	[efficientnetv2-l/block5k_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_project_conv/Conv2D]:484
	                     ADD	        15622.146	   18.656	   18.767	  0.065%	 54.451%	     0.000	        1	[efficientnetv2-l/block5k_add/add]:485
	                 CONV_2D	        15640.922	   13.339	   13.366	  0.047%	 54.497%	     0.000	        1	[efficientnetv2-l/block5l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_expand_conv/Conv2D]:486
	                LOGISTIC	        15654.301	   11.628	   11.633	  0.041%	 54.538%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/Sigmoid]:487
	                     MUL	        15665.951	   84.791	   84.989	  0.296%	 54.834%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/mul_1]:488
	       DEPTHWISE_CONV_2D	        15750.952	    6.106	    6.192	  0.022%	 54.855%	     0.000	        1	[efficientnetv2-l/block5l_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:489
	                LOGISTIC	        15757.156	   11.760	   11.757	  0.041%	 54.896%	     0.000	        1	[efficientnetv2-l/block5l_activation/Sigmoid]:490
	                     MUL	        15768.924	   84.632	   85.049	  0.296%	 55.193%	     0.000	        1	[efficientnetv2-l/block5l_activation/mul_1]:491
	                    MEAN	        15853.984	  204.245	  204.689	  0.713%	 55.905%	     0.000	        1	[efficientnetv2-l/block5l_se_squeeze/Mean]:492
	                   SHAPE	        16058.686	    0.009	    0.009	  0.000%	 55.905%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Shape]:493
	           STRIDED_SLICE	        16058.701	    0.022	    0.035	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/strided_slice]:494
	                    PACK	        16058.743	    0.027	    0.029	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape/shape]:495
	                 RESHAPE	        16058.778	    0.014	    0.015	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape]:496
	                 CONV_2D	        16058.799	    0.049	    0.050	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5l_se_reduce/Conv2D]:497
	                LOGISTIC	        16058.855	    0.010	    0.009	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/Sigmoid]:498
	                     MUL	        16058.871	    0.020	    0.021	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/mul_1]:499
	                 CONV_2D	        16058.898	    0.037	    0.043	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_se_expand/Conv2D]:500
	                LOGISTIC	        16058.947	    0.039	    0.024	  0.000%	 55.906%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/Sigmoid]:501
	                     MUL	        16058.976	   84.513	   85.141	  0.296%	 56.203%	     0.000	        1	[efficientnetv2-l/block5l_se_excite/mul]:502
	                 CONV_2D	        16144.128	   12.234	   12.267	  0.043%	 56.245%	     0.000	        1	[efficientnetv2-l/block5l_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_project_conv/Conv2D]:503
	                     ADD	        16156.405	   18.674	   18.853	  0.066%	 56.311%	     0.000	        1	[efficientnetv2-l/block5l_add/add]:504
	                 CONV_2D	        16175.268	   13.315	   13.352	  0.046%	 56.358%	     0.000	        1	[efficientnetv2-l/block5m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_expand_conv/Conv2D]:505
	                LOGISTIC	        16188.630	   11.757	   11.797	  0.041%	 56.399%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/Sigmoid]:506
	                     MUL	        16200.437	   84.655	   84.957	  0.296%	 56.694%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/mul_1]:507
	       DEPTHWISE_CONV_2D	        16285.408	    6.202	    6.319	  0.022%	 56.716%	     0.000	        1	[efficientnetv2-l/block5m_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:508
	                LOGISTIC	        16291.740	   11.760	   11.782	  0.041%	 56.758%	     0.000	        1	[efficientnetv2-l/block5m_activation/Sigmoid]:509
	                     MUL	        16303.533	   84.691	   85.091	  0.296%	 57.054%	     0.000	        1	[efficientnetv2-l/block5m_activation/mul_1]:510
	                    MEAN	        16388.635	  204.239	  205.380	  0.715%	 57.769%	     0.000	        1	[efficientnetv2-l/block5m_se_squeeze/Mean]:511
	                   SHAPE	        16594.027	    0.008	    0.009	  0.000%	 57.769%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Shape]:512
	           STRIDED_SLICE	        16594.042	    0.022	    0.024	  0.000%	 57.769%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/strided_slice]:513
	                    PACK	        16594.072	    0.028	    0.029	  0.000%	 57.769%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape/shape]:514
	                 RESHAPE	        16594.107	    0.013	    0.014	  0.000%	 57.769%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape]:515
	                 CONV_2D	        16594.128	    0.065	    0.062	  0.000%	 57.770%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5m_se_reduce/Conv2D]:516
	                LOGISTIC	        16594.196	    0.010	    0.010	  0.000%	 57.770%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/Sigmoid]:517
	                     MUL	        16594.212	    0.021	    0.021	  0.000%	 57.770%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/mul_1]:518
	                 CONV_2D	        16594.240	    0.037	    0.042	  0.000%	 57.770%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_se_expand/Conv2D]:519
	                LOGISTIC	        16594.288	    0.020	    0.020	  0.000%	 57.770%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/Sigmoid]:520
	                     MUL	        16594.315	   84.523	   85.004	  0.296%	 58.066%	     0.000	        1	[efficientnetv2-l/block5m_se_excite/mul]:521
	                 CONV_2D	        16679.331	   12.285	   12.230	  0.043%	 58.108%	     0.000	        1	[efficientnetv2-l/block5m_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_project_conv/Conv2D]:522
	                     ADD	        16691.570	   18.702	   18.741	  0.065%	 58.174%	     0.000	        1	[efficientnetv2-l/block5m_add/add]:523
	                 CONV_2D	        16710.321	   13.326	   13.364	  0.047%	 58.220%	     0.000	        1	[efficientnetv2-l/block5n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_expand_conv/Conv2D]:524
	                LOGISTIC	        16723.695	   11.893	   11.904	  0.041%	 58.262%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/Sigmoid]:525
	                     MUL	        16735.610	   84.734	   85.141	  0.296%	 58.558%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/mul_1]:526
	       DEPTHWISE_CONV_2D	        16820.764	    6.016	    6.214	  0.022%	 58.580%	     0.000	        1	[efficientnetv2-l/block5n_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:527
	                LOGISTIC	        16826.991	   11.813	   11.746	  0.041%	 58.621%	     0.000	        1	[efficientnetv2-l/block5n_activation/Sigmoid]:528
	                     MUL	        16838.749	   84.746	   85.075	  0.296%	 58.917%	     0.000	        1	[efficientnetv2-l/block5n_activation/mul_1]:529
	                    MEAN	        16923.836	  204.714	  204.750	  0.713%	 59.630%	     0.000	        1	[efficientnetv2-l/block5n_se_squeeze/Mean]:530
	                   SHAPE	        17128.596	    0.009	    0.009	  0.000%	 59.630%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Shape]:531
	           STRIDED_SLICE	        17128.613	    0.022	    0.022	  0.000%	 59.630%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/strided_slice]:532
	                    PACK	        17128.642	    0.027	    0.030	  0.000%	 59.630%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape/shape]:533
	                 RESHAPE	        17128.679	    0.014	    0.014	  0.000%	 59.630%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape]:534
	                 CONV_2D	        17128.699	    0.048	    0.049	  0.000%	 59.630%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5n_se_reduce/Conv2D]:535
	                LOGISTIC	        17128.754	    0.009	    0.010	  0.000%	 59.630%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/Sigmoid]:536
	                     MUL	        17128.770	    0.038	    0.023	  0.000%	 59.631%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/mul_1]:537
	                 CONV_2D	        17128.800	    0.038	    0.041	  0.000%	 59.631%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_se_expand/Conv2D]:538
	                LOGISTIC	        17128.846	    0.020	    0.020	  0.000%	 59.631%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/Sigmoid]:539
	                     MUL	        17128.873	   84.918	   84.833	  0.295%	 59.926%	     0.000	        1	[efficientnetv2-l/block5n_se_excite/mul]:540
	                 CONV_2D	        17213.717	   12.359	   12.258	  0.043%	 59.969%	     0.000	        1	[efficientnetv2-l/block5n_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_project_conv/Conv2D]:541
	                     ADD	        17225.985	   18.972	   18.812	  0.066%	 60.034%	     0.000	        1	[efficientnetv2-l/block5n_add/add]:542
	                 CONV_2D	        17244.808	   13.494	   13.320	  0.046%	 60.081%	     0.000	        1	[efficientnetv2-l/block5o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_expand_conv/Conv2D]:543
	                LOGISTIC	        17258.139	   11.637	   11.727	  0.041%	 60.122%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/Sigmoid]:544
	                     MUL	        17269.877	   86.930	   85.352	  0.297%	 60.419%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/mul_1]:545
	       DEPTHWISE_CONV_2D	        17355.241	    6.751	    6.292	  0.022%	 60.441%	     0.000	        1	[efficientnetv2-l/block5o_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:546
	                LOGISTIC	        17361.545	   11.757	   11.852	  0.041%	 60.482%	     0.000	        1	[efficientnetv2-l/block5o_activation/Sigmoid]:547
	                     MUL	        17373.408	   86.105	   85.611	  0.298%	 60.780%	     0.000	        1	[efficientnetv2-l/block5o_activation/mul_1]:548
	                    MEAN	        17459.033	  206.153	  205.394	  0.715%	 61.495%	     0.000	        1	[efficientnetv2-l/block5o_se_squeeze/Mean]:549
	                   SHAPE	        17664.438	    0.009	    0.008	  0.000%	 61.495%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Shape]:550
	           STRIDED_SLICE	        17664.453	    0.021	    0.023	  0.000%	 61.495%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/strided_slice]:551
	                    PACK	        17664.483	    0.029	    0.028	  0.000%	 61.496%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape/shape]:552
	                 RESHAPE	        17664.517	    0.015	    0.016	  0.000%	 61.496%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape]:553
	                 CONV_2D	        17664.540	    0.049	    0.056	  0.000%	 61.496%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5o_se_reduce/Conv2D]:554
	                LOGISTIC	        17664.603	    0.010	    0.012	  0.000%	 61.496%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/Sigmoid]:555
	                     MUL	        17664.622	    0.021	    0.020	  0.000%	 61.496%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/mul_1]:556
	                 CONV_2D	        17664.648	    0.036	    0.044	  0.000%	 61.496%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_se_expand/Conv2D]:557
	                LOGISTIC	        17664.698	    0.019	    0.020	  0.000%	 61.496%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/Sigmoid]:558
	                     MUL	        17664.725	   85.368	   84.936	  0.296%	 61.792%	     0.000	        1	[efficientnetv2-l/block5o_se_excite/mul]:559
	                 CONV_2D	        17749.672	   12.278	   12.230	  0.043%	 61.835%	     0.000	        1	[efficientnetv2-l/block5o_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_project_conv/Conv2D]:560
	                     ADD	        17761.913	   18.890	   18.751	  0.065%	 61.900%	     0.000	        1	[efficientnetv2-l/block5o_add/add]:561
	                 CONV_2D	        17780.673	   13.390	   13.371	  0.047%	 61.946%	     0.000	        1	[efficientnetv2-l/block5p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_expand_conv/Conv2D]:562
	                LOGISTIC	        17794.054	   11.710	   11.725	  0.041%	 61.987%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/Sigmoid]:563
	                     MUL	        17805.790	   85.342	   85.242	  0.297%	 62.284%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/mul_1]:564
	       DEPTHWISE_CONV_2D	        17891.044	    6.354	    6.258	  0.022%	 62.306%	     0.000	        1	[efficientnetv2-l/block5p_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:565
	                LOGISTIC	        17897.314	   11.725	   11.761	  0.041%	 62.347%	     0.000	        1	[efficientnetv2-l/block5p_activation/Sigmoid]:566
	                     MUL	        17909.086	   85.610	   85.197	  0.297%	 62.643%	     0.000	        1	[efficientnetv2-l/block5p_activation/mul_1]:567
	                    MEAN	        17994.295	  204.257	  204.565	  0.712%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_squeeze/Mean]:568
	                   SHAPE	        18198.871	    0.010	    0.009	  0.000%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Shape]:569
	           STRIDED_SLICE	        18198.886	    0.033	    0.024	  0.000%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/strided_slice]:570
	                    PACK	        18198.916	    0.028	    0.032	  0.000%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape/shape]:571
	                 RESHAPE	        18198.954	    0.014	    0.019	  0.000%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape]:572
	                 CONV_2D	        18198.980	    0.050	    0.050	  0.000%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5p_se_reduce/Conv2D]:573
	                LOGISTIC	        18199.035	    0.009	    0.009	  0.000%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/Sigmoid]:574
	                     MUL	        18199.051	    0.021	    0.021	  0.000%	 63.356%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/mul_1]:575
	                 CONV_2D	        18199.078	    0.057	    0.039	  0.000%	 63.357%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_se_expand/Conv2D]:576
	                LOGISTIC	        18199.124	    0.020	    0.020	  0.000%	 63.357%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/Sigmoid]:577
	                     MUL	        18199.150	   84.576	   84.818	  0.295%	 63.652%	     0.000	        1	[efficientnetv2-l/block5p_se_excite/mul]:578
	                 CONV_2D	        18283.982	   12.172	   12.284	  0.043%	 63.695%	     0.000	        1	[efficientnetv2-l/block5p_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_project_conv/Conv2D]:579
	                     ADD	        18296.277	   18.648	   18.741	  0.065%	 63.760%	     0.000	        1	[efficientnetv2-l/block5p_add/add]:580
	                 CONV_2D	        18315.027	   13.281	   13.356	  0.047%	 63.807%	     0.000	        1	[efficientnetv2-l/block5q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_expand_conv/Conv2D]:581
	                LOGISTIC	        18328.393	   11.821	   11.819	  0.041%	 63.848%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/Sigmoid]:582
	                     MUL	        18340.223	   84.654	   85.118	  0.296%	 64.144%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/mul_1]:583
	       DEPTHWISE_CONV_2D	        18425.355	    6.138	    6.314	  0.022%	 64.166%	     0.000	        1	[efficientnetv2-l/block5q_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:584
	                LOGISTIC	        18431.689	   11.834	   11.814	  0.041%	 64.207%	     0.000	        1	[efficientnetv2-l/block5q_activation/Sigmoid]:585
	                     MUL	        18443.515	   84.706	   84.984	  0.296%	 64.503%	     0.000	        1	[efficientnetv2-l/block5q_activation/mul_1]:586
	                    MEAN	        18528.510	  204.287	  205.297	  0.715%	 65.218%	     0.000	        1	[efficientnetv2-l/block5q_se_squeeze/Mean]:587
	                   SHAPE	        18733.820	    0.009	    0.013	  0.000%	 65.218%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Shape]:588
	           STRIDED_SLICE	        18733.838	    0.022	    0.022	  0.000%	 65.218%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/strided_slice]:589
	                    PACK	        18733.867	    0.028	    0.032	  0.000%	 65.218%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape/shape]:590
	                 RESHAPE	        18733.905	    0.013	    0.014	  0.000%	 65.218%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape]:591
	                 CONV_2D	        18733.926	    0.046	    0.048	  0.000%	 65.219%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5q_se_reduce/Conv2D]:592
	                LOGISTIC	        18733.980	    0.010	    0.010	  0.000%	 65.219%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/Sigmoid]:593
	                     MUL	        18733.996	    0.020	    0.021	  0.000%	 65.219%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/mul_1]:594
	                 CONV_2D	        18734.023	    0.036	    0.039	  0.000%	 65.219%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_se_expand/Conv2D]:595
	                LOGISTIC	        18734.068	    0.021	    0.020	  0.000%	 65.219%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/Sigmoid]:596
	                     MUL	        18734.094	   84.636	   85.005	  0.296%	 65.515%	     0.000	        1	[efficientnetv2-l/block5q_se_excite/mul]:597
	                 CONV_2D	        18819.111	   12.174	   12.266	  0.043%	 65.558%	     0.000	        1	[efficientnetv2-l/block5q_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_project_conv/Conv2D]:598
	                     ADD	        18831.387	   18.652	   18.786	  0.065%	 65.623%	     0.000	        1	[efficientnetv2-l/block5q_add/add]:599
	                 CONV_2D	        18850.184	   13.267	   13.345	  0.046%	 65.669%	     0.000	        1	[efficientnetv2-l/block5r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_expand_conv/Conv2D]:600
	                LOGISTIC	        18863.539	   11.735	   11.707	  0.041%	 65.710%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/Sigmoid]:601
	                     MUL	        18875.256	   84.931	   85.296	  0.297%	 66.007%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/mul_1]:602
	       DEPTHWISE_CONV_2D	        18960.565	    6.092	    6.260	  0.022%	 66.029%	     0.000	        1	[efficientnetv2-l/block5r_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:603
	                LOGISTIC	        18966.836	   11.821	   11.802	  0.041%	 66.070%	     0.000	        1	[efficientnetv2-l/block5r_activation/Sigmoid]:604
	                     MUL	        18978.649	   84.714	   85.088	  0.296%	 66.366%	     0.000	        1	[efficientnetv2-l/block5r_activation/mul_1]:605
	                    MEAN	        19063.749	  204.078	  204.921	  0.714%	 67.080%	     0.000	        1	[efficientnetv2-l/block5r_se_squeeze/Mean]:606
	                   SHAPE	        19268.682	    0.009	    0.015	  0.000%	 67.080%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Shape]:607
	           STRIDED_SLICE	        19268.703	    0.023	    0.022	  0.000%	 67.080%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/strided_slice]:608
	                    PACK	        19268.732	    0.028	    0.029	  0.000%	 67.080%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape/shape]:609
	                 RESHAPE	        19268.767	    0.015	    0.014	  0.000%	 67.080%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape]:610
	                 CONV_2D	        19268.787	    0.065	    0.063	  0.000%	 67.081%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5r_se_reduce/Conv2D]:611
	                LOGISTIC	        19268.857	    0.009	    0.009	  0.000%	 67.081%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/Sigmoid]:612
	                     MUL	        19268.873	    0.020	    0.025	  0.000%	 67.081%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/mul_1]:613
	                 CONV_2D	        19268.904	    0.039	    0.041	  0.000%	 67.081%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_se_expand/Conv2D]:614
	                LOGISTIC	        19268.952	    0.021	    0.020	  0.000%	 67.081%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/Sigmoid]:615
	                     MUL	        19268.978	   84.586	   85.013	  0.296%	 67.377%	     0.000	        1	[efficientnetv2-l/block5r_se_excite/mul]:616
	                 CONV_2D	        19354.004	   12.176	   12.296	  0.043%	 67.420%	     0.000	        1	[efficientnetv2-l/block5r_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_project_conv/Conv2D]:617
	                     ADD	        19366.310	   18.728	   18.787	  0.065%	 67.485%	     0.000	        1	[efficientnetv2-l/block5r_add/add]:618
	                 CONV_2D	        19385.107	   13.297	   13.348	  0.046%	 67.532%	     0.000	        1	[efficientnetv2-l/block5s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_expand_conv/Conv2D]:619
	                LOGISTIC	        19398.468	   11.856	   11.854	  0.041%	 67.573%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/Sigmoid]:620
	                     MUL	        19410.333	   84.701	   85.169	  0.297%	 67.870%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/mul_1]:621
	       DEPTHWISE_CONV_2D	        19495.514	    6.190	    6.234	  0.022%	 67.891%	     0.000	        1	[efficientnetv2-l/block5s_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:622
	                LOGISTIC	        19501.760	   11.956	   11.902	  0.041%	 67.933%	     0.000	        1	[efficientnetv2-l/block5s_activation/Sigmoid]:623
	                     MUL	        19513.673	   85.094	   85.290	  0.297%	 68.230%	     0.000	        1	[efficientnetv2-l/block5s_activation/mul_1]:624
	                    MEAN	        19598.977	  206.192	  205.446	  0.715%	 68.945%	     0.000	        1	[efficientnetv2-l/block5s_se_squeeze/Mean]:625
	                   SHAPE	        19804.433	    0.009	    0.009	  0.000%	 68.945%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Shape]:626
	           STRIDED_SLICE	        19804.449	    0.022	    0.026	  0.000%	 68.945%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/strided_slice]:627
	                    PACK	        19804.481	    0.028	    0.029	  0.000%	 68.945%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape/shape]:628
	                 RESHAPE	        19804.516	    0.014	    0.014	  0.000%	 68.945%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape]:629
	                 CONV_2D	        19804.537	    0.052	    0.054	  0.000%	 68.946%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5s_se_reduce/Conv2D]:630
	                LOGISTIC	        19804.597	    0.010	    0.013	  0.000%	 68.946%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/Sigmoid]:631
	                     MUL	        19804.616	    0.024	    0.025	  0.000%	 68.946%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/mul_1]:632
	                 CONV_2D	        19804.648	    0.041	    0.045	  0.000%	 68.946%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_se_expand/Conv2D]:633
	                LOGISTIC	        19804.698	    0.046	    0.025	  0.000%	 68.946%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/Sigmoid]:634
	                     MUL	        19804.729	   86.145	   85.269	  0.297%	 69.243%	     0.000	        1	[efficientnetv2-l/block5s_se_excite/mul]:635
	                 CONV_2D	        19890.009	   12.358	   12.271	  0.043%	 69.286%	     0.000	        1	[efficientnetv2-l/block5s_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_project_conv/Conv2D]:636
	                     ADD	        19902.290	   18.939	   18.793	  0.065%	 69.351%	     0.000	        1	[efficientnetv2-l/block5s_add/add]:637
	                 CONV_2D	        19921.093	   13.429	   13.407	  0.047%	 69.398%	     0.000	        1	[efficientnetv2-l/block6a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_expand_conv/Conv2D]:638
	                LOGISTIC	        19934.511	   11.637	   11.823	  0.041%	 69.439%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/Sigmoid]:639
	                     MUL	        19946.345	   86.039	   85.371	  0.297%	 69.736%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/mul_1]:640
	       DEPTHWISE_CONV_2D	        20031.728	  109.463	  108.586	  0.378%	 70.114%	     0.000	        1	[efficientnetv2-l/block6a_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_dwconv2/depthwise]:641
	                LOGISTIC	        20140.325	    2.947	    2.960	  0.010%	 70.125%	     0.000	        1	[efficientnetv2-l/block6a_activation/Sigmoid]:642
	                     MUL	        20143.294	   21.458	   21.310	  0.074%	 70.199%	     0.000	        1	[efficientnetv2-l/block6a_activation/mul_1]:643
	                    MEAN	        20164.614	   51.449	   51.311	  0.179%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_squeeze/Mean]:644
	                   SHAPE	        20215.935	    0.008	    0.008	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Shape]:645
	           STRIDED_SLICE	        20215.950	    0.021	    0.021	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/strided_slice]:646
	                    PACK	        20215.978	    0.047	    0.036	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape/shape]:647
	                 RESHAPE	        20216.020	    0.013	    0.015	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape]:648
	                 CONV_2D	        20216.042	    0.049	    0.067	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block6a_se_reduce/Conv2D]:649
	                LOGISTIC	        20216.115	    0.010	    0.010	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/Sigmoid]:650
	                     MUL	        20216.131	    0.020	    0.021	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/mul_1]:651
	                 CONV_2D	        20216.157	    0.036	    0.037	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_se_expand/Conv2D]:652
	                LOGISTIC	        20216.201	    0.019	    0.020	  0.000%	 70.378%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/Sigmoid]:653
	                     MUL	        20216.227	   21.382	   21.273	  0.074%	 70.452%	     0.000	        1	[efficientnetv2-l/block6a_se_excite/mul]:654
	                 CONV_2D	        20237.510	    5.219	    5.207	  0.018%	 70.471%	     0.000	        1	[efficientnetv2-l/block6a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_project_conv/Conv2D]:655
	                 CONV_2D	        20242.726	   10.805	   10.711	  0.037%	 70.508%	     0.000	        1	[efficientnetv2-l/block6b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_expand_conv/Conv2D]:656
	                LOGISTIC	        20253.447	    5.028	    5.017	  0.017%	 70.525%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/Sigmoid]:657
	                     MUL	        20258.475	   36.682	   36.528	  0.127%	 70.653%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/mul_1]:658
	       DEPTHWISE_CONV_2D	        20295.014	    3.256	    3.020	  0.011%	 70.663%	     0.000	        1	[efficientnetv2-l/block6b_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:659
	                LOGISTIC	        20298.047	    5.050	    5.036	  0.018%	 70.681%	     0.000	        1	[efficientnetv2-l/block6b_activation/Sigmoid]:660
	                     MUL	        20303.093	   36.587	   36.574	  0.127%	 70.808%	     0.000	        1	[efficientnetv2-l/block6b_activation/mul_1]:661
	                    MEAN	        20339.678	   88.172	   88.231	  0.307%	 71.115%	     0.000	        1	[efficientnetv2-l/block6b_se_squeeze/Mean]:662
	                   SHAPE	        20427.919	    0.008	    0.008	  0.000%	 71.115%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Shape]:663
	           STRIDED_SLICE	        20427.933	    0.021	    0.030	  0.000%	 71.115%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/strided_slice]:664
	                    PACK	        20427.969	    0.028	    0.029	  0.000%	 71.115%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape/shape]:665
	                 RESHAPE	        20428.005	    0.014	    0.015	  0.000%	 71.116%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape]:666
	                 CONV_2D	        20428.026	    0.052	    0.057	  0.000%	 71.116%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_reduce/Conv2D]:667
	                LOGISTIC	        20428.089	    0.010	    0.010	  0.000%	 71.116%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/Sigmoid]:668
	                     MUL	        20428.105	    0.046	    0.025	  0.000%	 71.116%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/mul_1]:669
	                 CONV_2D	        20428.137	    0.051	    0.052	  0.000%	 71.116%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_expand/Conv2D]:670
	                LOGISTIC	        20428.195	    0.029	    0.038	  0.000%	 71.116%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/Sigmoid]:671
	                     MUL	        20428.239	   36.460	   36.440	  0.127%	 71.243%	     0.000	        1	[efficientnetv2-l/block6b_se_excite/mul]:672
	                 CONV_2D	        20464.690	    7.573	    7.521	  0.026%	 71.269%	     0.000	        1	[efficientnetv2-l/block6b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_project_conv/Conv2D]:673
	                     ADD	        20472.220	    8.087	    8.065	  0.028%	 71.297%	     0.000	        1	[efficientnetv2-l/block6b_add/add]:674
	                 CONV_2D	        20480.294	   10.793	   10.695	  0.037%	 71.335%	     0.000	        1	[efficientnetv2-l/block6c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_expand_conv/Conv2D]:675
	                LOGISTIC	        20490.998	    5.001	    5.016	  0.017%	 71.352%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/Sigmoid]:676
	                     MUL	        20496.024	   36.637	   36.563	  0.127%	 71.479%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/mul_1]:677
	       DEPTHWISE_CONV_2D	        20532.598	    3.143	    3.048	  0.011%	 71.490%	     0.000	        1	[efficientnetv2-l/block6c_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:678
	                LOGISTIC	        20535.657	    5.059	    5.071	  0.018%	 71.508%	     0.000	        1	[efficientnetv2-l/block6c_activation/Sigmoid]:679
	                     MUL	        20540.738	   36.555	   36.599	  0.127%	 71.635%	     0.000	        1	[efficientnetv2-l/block6c_activation/mul_1]:680
	                    MEAN	        20577.349	   88.360	   88.156	  0.307%	 71.942%	     0.000	        1	[efficientnetv2-l/block6c_se_squeeze/Mean]:681
	                   SHAPE	        20665.519	    0.009	    0.009	  0.000%	 71.942%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Shape]:682
	           STRIDED_SLICE	        20665.534	    0.022	    0.026	  0.000%	 71.942%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/strided_slice]:683
	                    PACK	        20665.566	    0.029	    0.029	  0.000%	 71.942%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape/shape]:684
	                 RESHAPE	        20665.602	    0.014	    0.015	  0.000%	 71.942%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape]:685
	                 CONV_2D	        20665.623	    0.051	    0.056	  0.000%	 71.943%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_reduce/Conv2D]:686
	                LOGISTIC	        20665.684	    0.010	    0.010	  0.000%	 71.943%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/Sigmoid]:687
	                     MUL	        20665.700	    0.021	    0.021	  0.000%	 71.943%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/mul_1]:688
	                 CONV_2D	        20665.727	    0.051	    0.050	  0.000%	 71.943%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_expand/Conv2D]:689
	                LOGISTIC	        20665.784	    0.028	    0.029	  0.000%	 71.943%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/Sigmoid]:690
	                     MUL	        20665.819	   36.551	   36.409	  0.127%	 72.070%	     0.000	        1	[efficientnetv2-l/block6c_se_excite/mul]:691
	                 CONV_2D	        20702.238	    7.518	    7.490	  0.026%	 72.096%	     0.000	        1	[efficientnetv2-l/block6c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_project_conv/Conv2D]:692
	                     ADD	        20709.739	    8.155	    8.076	  0.028%	 72.124%	     0.000	        1	[efficientnetv2-l/block6c_add/add]:693
	                 CONV_2D	        20717.826	   10.797	   10.684	  0.037%	 72.161%	     0.000	        1	[efficientnetv2-l/block6d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_expand_conv/Conv2D]:694
	                LOGISTIC	        20728.519	    5.034	    5.048	  0.018%	 72.179%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/Sigmoid]:695
	                     MUL	        20733.578	   36.518	   36.524	  0.127%	 72.306%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/mul_1]:696
	       DEPTHWISE_CONV_2D	        20770.113	    2.889	    2.956	  0.010%	 72.316%	     0.000	        1	[efficientnetv2-l/block6d_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:697
	                LOGISTIC	        20773.080	    5.085	    5.059	  0.018%	 72.334%	     0.000	        1	[efficientnetv2-l/block6d_activation/Sigmoid]:698
	                     MUL	        20778.151	   36.356	   36.518	  0.127%	 72.461%	     0.000	        1	[efficientnetv2-l/block6d_activation/mul_1]:699
	                    MEAN	        20814.679	   87.681	   88.101	  0.307%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_squeeze/Mean]:700
	                   SHAPE	        20902.799	    0.009	    0.009	  0.000%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Shape]:701
	           STRIDED_SLICE	        20902.814	    0.021	    0.023	  0.000%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/strided_slice]:702
	                    PACK	        20902.843	    0.030	    0.030	  0.000%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape/shape]:703
	                 RESHAPE	        20902.879	    0.014	    0.014	  0.000%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape]:704
	                 CONV_2D	        20902.900	    0.068	    0.060	  0.000%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_reduce/Conv2D]:705
	                LOGISTIC	        20902.967	    0.010	    0.010	  0.000%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/Sigmoid]:706
	                     MUL	        20902.983	    0.021	    0.021	  0.000%	 72.768%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/mul_1]:707
	                 CONV_2D	        20903.010	    0.050	    0.056	  0.000%	 72.769%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_expand/Conv2D]:708
	                LOGISTIC	        20903.072	    0.029	    0.029	  0.000%	 72.769%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/Sigmoid]:709
	                     MUL	        20903.107	   36.249	   36.411	  0.127%	 72.895%	     0.000	        1	[efficientnetv2-l/block6d_se_excite/mul]:710
	                 CONV_2D	        20939.529	    7.446	    7.501	  0.026%	 72.922%	     0.000	        1	[efficientnetv2-l/block6d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_project_conv/Conv2D]:711
	                     ADD	        20947.038	    7.996	    8.050	  0.028%	 72.950%	     0.000	        1	[efficientnetv2-l/block6d_add/add]:712
	                 CONV_2D	        20955.097	   10.590	   10.674	  0.037%	 72.987%	     0.000	        1	[efficientnetv2-l/block6e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_expand_conv/Conv2D]:713
	                LOGISTIC	        20965.780	    5.037	    5.020	  0.017%	 73.004%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/Sigmoid]:714
	                     MUL	        20970.810	   36.321	   36.492	  0.127%	 73.131%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/mul_1]:715
	       DEPTHWISE_CONV_2D	        21007.313	    2.878	    2.954	  0.010%	 73.142%	     0.000	        1	[efficientnetv2-l/block6e_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:716
	                LOGISTIC	        21010.285	    5.081	    5.085	  0.018%	 73.159%	     0.000	        1	[efficientnetv2-l/block6e_activation/Sigmoid]:717
	                     MUL	        21015.380	   36.408	   36.501	  0.127%	 73.286%	     0.000	        1	[efficientnetv2-l/block6e_activation/mul_1]:718
	                    MEAN	        21051.891	   87.588	   88.368	  0.308%	 73.594%	     0.000	        1	[efficientnetv2-l/block6e_se_squeeze/Mean]:719
	                   SHAPE	        21140.269	    0.008	    0.009	  0.000%	 73.594%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Shape]:720
	           STRIDED_SLICE	        21140.284	    0.021	    0.022	  0.000%	 73.594%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/strided_slice]:721
	                    PACK	        21140.312	    0.029	    0.032	  0.000%	 73.594%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape/shape]:722
	                 RESHAPE	        21140.351	    0.014	    0.016	  0.000%	 73.594%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape]:723
	                 CONV_2D	        21140.373	    0.047	    0.059	  0.000%	 73.595%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_reduce/Conv2D]:724
	                LOGISTIC	        21140.438	    0.010	    0.010	  0.000%	 73.595%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/Sigmoid]:725
	                     MUL	        21140.454	    0.020	    0.021	  0.000%	 73.595%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/mul_1]:726
	                 CONV_2D	        21140.481	    0.069	    0.059	  0.000%	 73.595%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_expand/Conv2D]:727
	                LOGISTIC	        21140.547	    0.030	    0.029	  0.000%	 73.595%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/Sigmoid]:728
	                     MUL	        21140.582	   36.200	   36.564	  0.127%	 73.722%	     0.000	        1	[efficientnetv2-l/block6e_se_excite/mul]:729
	                 CONV_2D	        21177.157	    7.499	    7.499	  0.026%	 73.748%	     0.000	        1	[efficientnetv2-l/block6e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_project_conv/Conv2D]:730
	                     ADD	        21184.665	    8.023	    8.052	  0.028%	 73.777%	     0.000	        1	[efficientnetv2-l/block6e_add/add]:731
	                 CONV_2D	        21192.725	   10.581	   10.648	  0.037%	 73.814%	     0.000	        1	[efficientnetv2-l/block6f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_expand_conv/Conv2D]:732
	                LOGISTIC	        21203.381	    5.040	    5.069	  0.018%	 73.831%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/Sigmoid]:733
	                     MUL	        21208.461	   36.300	   36.466	  0.127%	 73.958%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/mul_1]:734
	       DEPTHWISE_CONV_2D	        21244.937	    2.820	    3.028	  0.011%	 73.969%	     0.000	        1	[efficientnetv2-l/block6f_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:735
	                LOGISTIC	        21247.975	    5.017	    5.046	  0.018%	 73.986%	     0.000	        1	[efficientnetv2-l/block6f_activation/Sigmoid]:736
	                     MUL	        21253.032	   36.277	   36.516	  0.127%	 74.114%	     0.000	        1	[efficientnetv2-l/block6f_activation/mul_1]:737
	                    MEAN	        21289.558	   87.577	   88.061	  0.307%	 74.420%	     0.000	        1	[efficientnetv2-l/block6f_se_squeeze/Mean]:738
	                   SHAPE	        21377.630	    0.008	    0.008	  0.000%	 74.420%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Shape]:739
	           STRIDED_SLICE	        21377.645	    0.022	    0.022	  0.000%	 74.420%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/strided_slice]:740
	                    PACK	        21377.673	    0.031	    0.034	  0.000%	 74.420%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape/shape]:741
	                 RESHAPE	        21377.714	    0.014	    0.014	  0.000%	 74.420%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape]:742
	                 CONV_2D	        21377.734	    0.052	    0.057	  0.000%	 74.421%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_reduce/Conv2D]:743
	                LOGISTIC	        21377.796	    0.010	    0.010	  0.000%	 74.421%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/Sigmoid]:744
	                     MUL	        21377.813	    0.021	    0.021	  0.000%	 74.421%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/mul_1]:745
	                 CONV_2D	        21377.839	    0.051	    0.051	  0.000%	 74.421%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_expand/Conv2D]:746
	                LOGISTIC	        21377.897	    0.049	    0.046	  0.000%	 74.421%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/Sigmoid]:747
	                     MUL	        21377.950	   36.207	   36.430	  0.127%	 74.548%	     0.000	        1	[efficientnetv2-l/block6f_se_excite/mul]:748
	                 CONV_2D	        21414.391	    7.426	    7.528	  0.026%	 74.574%	     0.000	        1	[efficientnetv2-l/block6f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_project_conv/Conv2D]:749
	                     ADD	        21421.929	    8.035	    8.053	  0.028%	 74.602%	     0.000	        1	[efficientnetv2-l/block6f_add/add]:750
	                 CONV_2D	        21429.991	   10.576	   10.691	  0.037%	 74.639%	     0.000	        1	[efficientnetv2-l/block6g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_expand_conv/Conv2D]:751
	                LOGISTIC	        21440.692	    4.973	    5.023	  0.017%	 74.657%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/Sigmoid]:752
	                     MUL	        21445.726	   36.312	   36.486	  0.127%	 74.784%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/mul_1]:753
	       DEPTHWISE_CONV_2D	        21482.225	    2.932	    2.980	  0.010%	 74.794%	     0.000	        1	[efficientnetv2-l/block6g_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:754
	                LOGISTIC	        21485.215	    5.050	    5.049	  0.018%	 74.812%	     0.000	        1	[efficientnetv2-l/block6g_activation/Sigmoid]:755
	                     MUL	        21490.276	   36.289	   36.477	  0.127%	 74.939%	     0.000	        1	[efficientnetv2-l/block6g_activation/mul_1]:756
	                    MEAN	        21526.764	   87.660	   88.218	  0.307%	 75.246%	     0.000	        1	[efficientnetv2-l/block6g_se_squeeze/Mean]:757
	                   SHAPE	        21614.993	    0.008	    0.009	  0.000%	 75.246%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Shape]:758
	           STRIDED_SLICE	        21615.008	    0.021	    0.024	  0.000%	 75.246%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/strided_slice]:759
	                    PACK	        21615.038	    0.029	    0.032	  0.000%	 75.246%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape/shape]:760
	                 RESHAPE	        21615.076	    0.014	    0.014	  0.000%	 75.246%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape]:761
	                 CONV_2D	        21615.096	    0.050	    0.051	  0.000%	 75.247%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_reduce/Conv2D]:762
	                LOGISTIC	        21615.154	    0.010	    0.010	  0.000%	 75.247%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/Sigmoid]:763
	                     MUL	        21615.170	    0.036	    0.024	  0.000%	 75.247%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/mul_1]:764
	                 CONV_2D	        21615.200	    0.052	    0.061	  0.000%	 75.247%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_expand/Conv2D]:765
	                LOGISTIC	        21615.267	    0.028	    0.029	  0.000%	 75.247%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/Sigmoid]:766
	                     MUL	        21615.303	   36.298	   36.408	  0.127%	 75.374%	     0.000	        1	[efficientnetv2-l/block6g_se_excite/mul]:767
	                 CONV_2D	        21651.721	    7.447	    7.483	  0.026%	 75.400%	     0.000	        1	[efficientnetv2-l/block6g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_project_conv/Conv2D]:768
	                     ADD	        21659.214	    8.000	    8.044	  0.028%	 75.428%	     0.000	        1	[efficientnetv2-l/block6g_add/add]:769
	                 CONV_2D	        21667.267	   10.699	   10.710	  0.037%	 75.465%	     0.000	        1	[efficientnetv2-l/block6h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_expand_conv/Conv2D]:770
	                LOGISTIC	        21677.987	    5.010	    5.034	  0.018%	 75.483%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/Sigmoid]:771
	                     MUL	        21683.031	   36.323	   36.567	  0.127%	 75.610%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/mul_1]:772
	       DEPTHWISE_CONV_2D	        21719.609	    2.769	    3.002	  0.010%	 75.621%	     0.000	        1	[efficientnetv2-l/block6h_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:773
	                LOGISTIC	        21722.628	    5.037	    5.027	  0.018%	 75.638%	     0.000	        1	[efficientnetv2-l/block6h_activation/Sigmoid]:774
	                     MUL	        21727.665	   36.336	   36.671	  0.128%	 75.766%	     0.000	        1	[efficientnetv2-l/block6h_activation/mul_1]:775
	                    MEAN	        21764.355	   87.583	   88.218	  0.307%	 76.073%	     0.000	        1	[efficientnetv2-l/block6h_se_squeeze/Mean]:776
	                   SHAPE	        21852.583	    0.008	    0.008	  0.000%	 76.073%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Shape]:777
	           STRIDED_SLICE	        21852.597	    0.021	    0.025	  0.000%	 76.073%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/strided_slice]:778
	                    PACK	        21852.628	    0.042	    0.041	  0.000%	 76.073%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape/shape]:779
	                 RESHAPE	        21852.676	    0.014	    0.015	  0.000%	 76.073%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape]:780
	                 CONV_2D	        21852.697	    0.049	    0.051	  0.000%	 76.073%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_reduce/Conv2D]:781
	                LOGISTIC	        21852.755	    0.010	    0.010	  0.000%	 76.073%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/Sigmoid]:782
	                     MUL	        21852.771	    0.020	    0.025	  0.000%	 76.074%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/mul_1]:783
	                 CONV_2D	        21852.803	    0.050	    0.054	  0.000%	 76.074%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_expand/Conv2D]:784
	                LOGISTIC	        21852.864	    0.029	    0.029	  0.000%	 76.074%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/Sigmoid]:785
	                     MUL	        21852.899	   36.190	   36.416	  0.127%	 76.201%	     0.000	        1	[efficientnetv2-l/block6h_se_excite/mul]:786
	                 CONV_2D	        21889.326	    7.456	    7.513	  0.026%	 76.227%	     0.000	        1	[efficientnetv2-l/block6h_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_project_conv/Conv2D]:787
	                     ADD	        21896.848	    8.007	    8.049	  0.028%	 76.255%	     0.000	        1	[efficientnetv2-l/block6h_add/add]:788
	                 CONV_2D	        21904.906	   10.576	   10.684	  0.037%	 76.292%	     0.000	        1	[efficientnetv2-l/block6i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_expand_conv/Conv2D]:789
	                LOGISTIC	        21915.600	    5.084	    5.081	  0.018%	 76.310%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/Sigmoid]:790
	                     MUL	        21920.691	   36.237	   36.510	  0.127%	 76.437%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/mul_1]:791
	       DEPTHWISE_CONV_2D	        21957.211	    2.816	    3.002	  0.010%	 76.447%	     0.000	        1	[efficientnetv2-l/block6i_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:792
	                LOGISTIC	        21960.223	    5.093	    5.090	  0.018%	 76.465%	     0.000	        1	[efficientnetv2-l/block6i_activation/Sigmoid]:793
	                     MUL	        21965.323	   36.360	   36.634	  0.128%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_activation/mul_1]:794
	                    MEAN	        22001.968	   88.038	   88.051	  0.307%	 76.899%	     0.000	        1	[efficientnetv2-l/block6i_se_squeeze/Mean]:795
	                   SHAPE	        22090.030	    0.009	    0.008	  0.000%	 76.899%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Shape]:796
	           STRIDED_SLICE	        22090.045	    0.021	    0.021	  0.000%	 76.899%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/strided_slice]:797
	                    PACK	        22090.072	    0.030	    0.029	  0.000%	 76.899%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape/shape]:798
	                 RESHAPE	        22090.110	    0.014	    0.015	  0.000%	 76.900%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape]:799
	                 CONV_2D	        22090.132	    0.053	    0.056	  0.000%	 76.900%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_reduce/Conv2D]:800
	                LOGISTIC	        22090.194	    0.010	    0.010	  0.000%	 76.900%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/Sigmoid]:801
	                     MUL	        22090.210	    0.038	    0.024	  0.000%	 76.900%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/mul_1]:802
	                 CONV_2D	        22090.240	    0.050	    0.057	  0.000%	 76.900%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_expand/Conv2D]:803
	                LOGISTIC	        22090.303	    0.030	    0.029	  0.000%	 76.900%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/Sigmoid]:804
	                     MUL	        22090.338	   36.222	   36.289	  0.126%	 77.026%	     0.000	        1	[efficientnetv2-l/block6i_se_excite/mul]:805
	                 CONV_2D	        22126.637	    7.467	    7.467	  0.026%	 77.052%	     0.000	        1	[efficientnetv2-l/block6i_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_project_conv/Conv2D]:806
	                     ADD	        22134.112	    8.010	    8.037	  0.028%	 77.080%	     0.000	        1	[efficientnetv2-l/block6i_add/add]:807
	                 CONV_2D	        22142.157	   10.611	   10.666	  0.037%	 77.118%	     0.000	        1	[efficientnetv2-l/block6j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_expand_conv/Conv2D]:808
	                LOGISTIC	        22152.835	    5.009	    5.026	  0.018%	 77.135%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/Sigmoid]:809
	                     MUL	        22157.871	   36.427	   36.470	  0.127%	 77.262%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/mul_1]:810
	       DEPTHWISE_CONV_2D	        22194.352	    3.250	    2.941	  0.010%	 77.272%	     0.000	        1	[efficientnetv2-l/block6j_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:811
	                LOGISTIC	        22197.303	    5.012	    5.024	  0.017%	 77.290%	     0.000	        1	[efficientnetv2-l/block6j_activation/Sigmoid]:812
	                     MUL	        22202.337	   36.658	   36.480	  0.127%	 77.417%	     0.000	        1	[efficientnetv2-l/block6j_activation/mul_1]:813
	                    MEAN	        22238.827	   88.794	   88.055	  0.307%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_squeeze/Mean]:814
	                   SHAPE	        22326.892	    0.009	    0.009	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Shape]:815
	           STRIDED_SLICE	        22326.907	    0.069	    0.032	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/strided_slice]:816
	                    PACK	        22326.945	    0.031	    0.033	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape/shape]:817
	                 RESHAPE	        22326.985	    0.016	    0.015	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape]:818
	                 CONV_2D	        22327.006	    0.081	    0.060	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_reduce/Conv2D]:819
	                LOGISTIC	        22327.072	    0.012	    0.012	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/Sigmoid]:820
	                     MUL	        22327.091	    0.023	    0.021	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/mul_1]:821
	                 CONV_2D	        22327.129	    0.065	    0.057	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_expand/Conv2D]:822
	                LOGISTIC	        22327.197	    0.029	    0.029	  0.000%	 77.724%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/Sigmoid]:823
	                     MUL	        22327.232	   36.856	   36.542	  0.127%	 77.852%	     0.000	        1	[efficientnetv2-l/block6j_se_excite/mul]:824
	                 CONV_2D	        22363.785	    7.577	    7.506	  0.026%	 77.878%	     0.000	        1	[efficientnetv2-l/block6j_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_project_conv/Conv2D]:825
	                     ADD	        22371.301	    8.106	    8.065	  0.028%	 77.906%	     0.000	        1	[efficientnetv2-l/block6j_add/add]:826
	                 CONV_2D	        22379.375	   10.899	   10.713	  0.037%	 77.943%	     0.000	        1	[efficientnetv2-l/block6k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_expand_conv/Conv2D]:827
	                LOGISTIC	        22390.097	    5.091	    5.023	  0.017%	 77.961%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/Sigmoid]:828
	                     MUL	        22395.131	   36.600	   36.553	  0.127%	 78.088%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/mul_1]:829
	       DEPTHWISE_CONV_2D	        22431.695	    3.408	    3.081	  0.011%	 78.099%	     0.000	        1	[efficientnetv2-l/block6k_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:830
	                LOGISTIC	        22434.787	    5.005	    5.046	  0.018%	 78.116%	     0.000	        1	[efficientnetv2-l/block6k_activation/Sigmoid]:831
	                     MUL	        22439.845	   36.636	   36.589	  0.127%	 78.244%	     0.000	        1	[efficientnetv2-l/block6k_activation/mul_1]:832
	                    MEAN	        22476.445	   88.477	   88.171	  0.307%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_squeeze/Mean]:833
	                   SHAPE	        22564.628	    0.008	    0.009	  0.000%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Shape]:834
	           STRIDED_SLICE	        22564.643	    0.022	    0.023	  0.000%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/strided_slice]:835
	                    PACK	        22564.673	    0.030	    0.033	  0.000%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape/shape]:836
	                 RESHAPE	        22564.712	    0.015	    0.015	  0.000%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape]:837
	                 CONV_2D	        22564.733	    0.051	    0.055	  0.000%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_reduce/Conv2D]:838
	                LOGISTIC	        22564.795	    0.010	    0.010	  0.000%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/Sigmoid]:839
	                     MUL	        22564.811	    0.021	    0.022	  0.000%	 78.551%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/mul_1]:840
	                 CONV_2D	        22564.839	    0.077	    0.054	  0.000%	 78.552%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_expand/Conv2D]:841
	                LOGISTIC	        22564.899	    0.030	    0.039	  0.000%	 78.552%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/Sigmoid]:842
	                     MUL	        22564.945	   36.624	   36.415	  0.127%	 78.679%	     0.000	        1	[efficientnetv2-l/block6k_se_excite/mul]:843
	                 CONV_2D	        22601.373	    7.568	    7.503	  0.026%	 78.705%	     0.000	        1	[efficientnetv2-l/block6k_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_project_conv/Conv2D]:844
	                     ADD	        22608.885	    8.102	    8.059	  0.028%	 78.733%	     0.000	        1	[efficientnetv2-l/block6k_add/add]:845
	                 CONV_2D	        22616.952	   10.743	   10.693	  0.037%	 78.770%	     0.000	        1	[efficientnetv2-l/block6l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_expand_conv/Conv2D]:846
	                LOGISTIC	        22627.655	    5.016	    5.022	  0.017%	 78.787%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/Sigmoid]:847
	                     MUL	        22632.688	   36.536	   36.544	  0.127%	 78.915%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/mul_1]:848
	       DEPTHWISE_CONV_2D	        22669.244	    3.113	    2.944	  0.010%	 78.925%	     0.000	        1	[efficientnetv2-l/block6l_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:849
	                LOGISTIC	        22672.201	    5.072	    5.031	  0.018%	 78.942%	     0.000	        1	[efficientnetv2-l/block6l_activation/Sigmoid]:850
	                     MUL	        22677.243	   36.704	   36.551	  0.127%	 79.070%	     0.000	        1	[efficientnetv2-l/block6l_activation/mul_1]:851
	                    MEAN	        22713.804	   88.375	   88.168	  0.307%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_squeeze/Mean]:852
	                   SHAPE	        22801.984	    0.009	    0.009	  0.000%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Shape]:853
	           STRIDED_SLICE	        22801.999	    0.022	    0.025	  0.000%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/strided_slice]:854
	                    PACK	        22802.031	    0.030	    0.030	  0.000%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape/shape]:855
	                 RESHAPE	        22802.067	    0.014	    0.015	  0.000%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape]:856
	                 CONV_2D	        22802.088	    0.059	    0.065	  0.000%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_reduce/Conv2D]:857
	                LOGISTIC	        22802.162	    0.032	    0.014	  0.000%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/Sigmoid]:858
	                     MUL	        22802.183	    0.021	    0.021	  0.000%	 79.377%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/mul_1]:859
	                 CONV_2D	        22802.210	    0.051	    0.050	  0.000%	 79.378%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_expand/Conv2D]:860
	                LOGISTIC	        22802.266	    0.028	    0.028	  0.000%	 79.378%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/Sigmoid]:861
	                     MUL	        22802.301	   36.536	   36.455	  0.127%	 79.505%	     0.000	        1	[efficientnetv2-l/block6l_se_excite/mul]:862
	                 CONV_2D	        22838.767	    7.545	    7.520	  0.026%	 79.531%	     0.000	        1	[efficientnetv2-l/block6l_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_project_conv/Conv2D]:863
	                     ADD	        22846.298	    8.090	    8.070	  0.028%	 79.559%	     0.000	        1	[efficientnetv2-l/block6l_add/add]:864
	                 CONV_2D	        22854.377	   10.747	   10.697	  0.037%	 79.596%	     0.000	        1	[efficientnetv2-l/block6m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_expand_conv/Conv2D]:865
	                LOGISTIC	        22865.084	    5.006	    5.053	  0.018%	 79.614%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/Sigmoid]:866
	                     MUL	        22870.148	   36.565	   36.507	  0.127%	 79.741%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/mul_1]:867
	       DEPTHWISE_CONV_2D	        22906.665	    3.073	    3.002	  0.010%	 79.751%	     0.000	        1	[efficientnetv2-l/block6m_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:868
	                LOGISTIC	        22909.686	    5.023	    5.035	  0.018%	 79.769%	     0.000	        1	[efficientnetv2-l/block6m_activation/Sigmoid]:869
	                     MUL	        22914.743	   36.601	   36.524	  0.127%	 79.896%	     0.000	        1	[efficientnetv2-l/block6m_activation/mul_1]:870
	                    MEAN	        22951.277	   88.125	   88.090	  0.307%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_squeeze/Mean]:871
	                   SHAPE	        23039.378	    0.008	    0.009	  0.000%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Shape]:872
	           STRIDED_SLICE	        23039.393	    0.022	    0.024	  0.000%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/strided_slice]:873
	                    PACK	        23039.423	    0.029	    0.032	  0.000%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape/shape]:874
	                 RESHAPE	        23039.462	    0.015	    0.015	  0.000%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape]:875
	                 CONV_2D	        23039.483	    0.049	    0.054	  0.000%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_reduce/Conv2D]:876
	                LOGISTIC	        23039.543	    0.010	    0.010	  0.000%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/Sigmoid]:877
	                     MUL	        23039.559	    0.021	    0.025	  0.000%	 80.203%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/mul_1]:878
	                 CONV_2D	        23039.593	    0.048	    0.051	  0.000%	 80.204%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_expand/Conv2D]:879
	                LOGISTIC	        23039.650	    0.029	    0.029	  0.000%	 80.204%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/Sigmoid]:880
	                     MUL	        23039.686	   36.590	   36.446	  0.127%	 80.331%	     0.000	        1	[efficientnetv2-l/block6m_se_excite/mul]:881
	                 CONV_2D	        23076.143	    7.506	    7.499	  0.026%	 80.357%	     0.000	        1	[efficientnetv2-l/block6m_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_project_conv/Conv2D]:882
	                     ADD	        23083.652	    8.155	    8.088	  0.028%	 80.385%	     0.000	        1	[efficientnetv2-l/block6m_add/add]:883
	                 CONV_2D	        23091.749	   10.814	   10.730	  0.037%	 80.422%	     0.000	        1	[efficientnetv2-l/block6n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_expand_conv/Conv2D]:884
	                LOGISTIC	        23102.489	    4.986	    5.013	  0.017%	 80.440%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/Sigmoid]:885
	                     MUL	        23107.513	   36.599	   36.493	  0.127%	 80.567%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/mul_1]:886
	       DEPTHWISE_CONV_2D	        23144.022	    3.068	    2.952	  0.010%	 80.577%	     0.000	        1	[efficientnetv2-l/block6n_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:887
	                LOGISTIC	        23146.984	    5.057	    5.052	  0.018%	 80.595%	     0.000	        1	[efficientnetv2-l/block6n_activation/Sigmoid]:888
	                     MUL	        23152.047	   36.705	   36.534	  0.127%	 80.722%	     0.000	        1	[efficientnetv2-l/block6n_activation/mul_1]:889
	                    MEAN	        23188.591	   87.860	   88.091	  0.307%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_squeeze/Mean]:890
	                   SHAPE	        23276.693	    0.009	    0.009	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Shape]:891
	           STRIDED_SLICE	        23276.708	    0.022	    0.025	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/strided_slice]:892
	                    PACK	        23276.739	    0.029	    0.033	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape/shape]:893
	                 RESHAPE	        23276.779	    0.014	    0.014	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape]:894
	                 CONV_2D	        23276.799	    0.051	    0.055	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_reduce/Conv2D]:895
	                LOGISTIC	        23276.861	    0.010	    0.011	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/Sigmoid]:896
	                     MUL	        23276.877	    0.021	    0.021	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/mul_1]:897
	                 CONV_2D	        23276.905	    0.069	    0.056	  0.000%	 81.029%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_expand/Conv2D]:898
	                LOGISTIC	        23276.967	    0.029	    0.029	  0.000%	 81.030%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/Sigmoid]:899
	                     MUL	        23277.002	   36.227	   36.410	  0.127%	 81.156%	     0.000	        1	[efficientnetv2-l/block6n_se_excite/mul]:900
	                 CONV_2D	        23313.422	    7.462	    7.495	  0.026%	 81.182%	     0.000	        1	[efficientnetv2-l/block6n_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_project_conv/Conv2D]:901
	                     ADD	        23320.927	    8.012	    8.059	  0.028%	 81.210%	     0.000	        1	[efficientnetv2-l/block6n_add/add]:902
	                 CONV_2D	        23328.994	   10.606	   10.718	  0.037%	 81.248%	     0.000	        1	[efficientnetv2-l/block6o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_expand_conv/Conv2D]:903
	                LOGISTIC	        23339.724	    5.030	    5.114	  0.018%	 81.266%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/Sigmoid]:904
	                     MUL	        23344.847	   36.414	   36.582	  0.127%	 81.393%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/mul_1]:905
	       DEPTHWISE_CONV_2D	        23381.440	    2.854	    3.055	  0.011%	 81.404%	     0.000	        1	[efficientnetv2-l/block6o_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:906
	                LOGISTIC	        23384.506	    5.040	    5.031	  0.018%	 81.421%	     0.000	        1	[efficientnetv2-l/block6o_activation/Sigmoid]:907
	                     MUL	        23389.547	   36.304	   36.486	  0.127%	 81.548%	     0.000	        1	[efficientnetv2-l/block6o_activation/mul_1]:908
	                    MEAN	        23426.044	   87.678	   88.126	  0.307%	 81.855%	     0.000	        1	[efficientnetv2-l/block6o_se_squeeze/Mean]:909
	                   SHAPE	        23514.181	    0.008	    0.010	  0.000%	 81.855%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Shape]:910
	           STRIDED_SLICE	        23514.197	    0.066	    0.029	  0.000%	 81.855%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/strided_slice]:911
	                    PACK	        23514.235	    0.029	    0.030	  0.000%	 81.855%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape/shape]:912
	                 RESHAPE	        23514.273	    0.014	    0.014	  0.000%	 81.855%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape]:913
	                 CONV_2D	        23514.294	    0.052	    0.052	  0.000%	 81.856%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_reduce/Conv2D]:914
	                LOGISTIC	        23514.352	    0.010	    0.010	  0.000%	 81.856%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/Sigmoid]:915
	                     MUL	        23514.368	    0.037	    0.027	  0.000%	 81.856%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/mul_1]:916
	                 CONV_2D	        23514.401	    0.051	    0.051	  0.000%	 81.856%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_expand/Conv2D]:917
	                LOGISTIC	        23514.459	    0.028	    0.029	  0.000%	 81.856%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/Sigmoid]:918
	                     MUL	        23514.494	   36.214	   36.571	  0.127%	 81.983%	     0.000	        1	[efficientnetv2-l/block6o_se_excite/mul]:919
	                 CONV_2D	        23551.075	    7.465	    7.563	  0.026%	 82.010%	     0.000	        1	[efficientnetv2-l/block6o_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_project_conv/Conv2D]:920
	                     ADD	        23558.646	    8.018	    8.086	  0.028%	 82.038%	     0.000	        1	[efficientnetv2-l/block6o_add/add]:921
	                 CONV_2D	        23566.740	   10.588	   10.695	  0.037%	 82.075%	     0.000	        1	[efficientnetv2-l/block6p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_expand_conv/Conv2D]:922
	                LOGISTIC	        23577.445	    5.025	    5.046	  0.018%	 82.093%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/Sigmoid]:923
	                     MUL	        23582.500	   36.397	   36.445	  0.127%	 82.220%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/mul_1]:924
	       DEPTHWISE_CONV_2D	        23618.956	    2.752	    2.909	  0.010%	 82.230%	     0.000	        1	[efficientnetv2-l/block6p_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:925
	                LOGISTIC	        23621.876	    5.047	    5.059	  0.018%	 82.247%	     0.000	        1	[efficientnetv2-l/block6p_activation/Sigmoid]:926
	                     MUL	        23626.946	   36.472	   36.577	  0.127%	 82.375%	     0.000	        1	[efficientnetv2-l/block6p_activation/mul_1]:927
	                    MEAN	        23663.533	   87.805	   87.932	  0.306%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_squeeze/Mean]:928
	                   SHAPE	        23751.476	    0.009	    0.009	  0.000%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Shape]:929
	           STRIDED_SLICE	        23751.491	    0.021	    0.026	  0.000%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/strided_slice]:930
	                    PACK	        23751.524	    0.028	    0.030	  0.000%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape/shape]:931
	                 RESHAPE	        23751.560	    0.014	    0.014	  0.000%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape]:932
	                 CONV_2D	        23751.582	    0.053	    0.052	  0.000%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_reduce/Conv2D]:933
	                LOGISTIC	        23751.641	    0.010	    0.010	  0.000%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/Sigmoid]:934
	                     MUL	        23751.657	    0.021	    0.023	  0.000%	 82.681%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/mul_1]:935
	                 CONV_2D	        23751.686	    0.070	    0.059	  0.000%	 82.682%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_expand/Conv2D]:936
	                LOGISTIC	        23751.751	    0.030	    0.029	  0.000%	 82.682%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/Sigmoid]:937
	                     MUL	        23751.786	   36.186	   36.365	  0.127%	 82.808%	     0.000	        1	[efficientnetv2-l/block6p_se_excite/mul]:938
	                 CONV_2D	        23788.161	    7.466	    7.493	  0.026%	 82.834%	     0.000	        1	[efficientnetv2-l/block6p_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_project_conv/Conv2D]:939
	                     ADD	        23795.664	    8.004	    8.250	  0.029%	 82.863%	     0.000	        1	[efficientnetv2-l/block6p_add/add]:940
	                 CONV_2D	        23803.923	   10.577	   10.716	  0.037%	 82.901%	     0.000	        1	[efficientnetv2-l/block6q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_expand_conv/Conv2D]:941
	                LOGISTIC	        23814.649	    5.082	    5.062	  0.018%	 82.918%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/Sigmoid]:942
	                     MUL	        23819.721	   36.269	   36.514	  0.127%	 83.045%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/mul_1]:943
	       DEPTHWISE_CONV_2D	        23856.245	    2.797	    3.009	  0.010%	 83.056%	     0.000	        1	[efficientnetv2-l/block6q_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:944
	                LOGISTIC	        23859.265	    5.174	    5.078	  0.018%	 83.073%	     0.000	        1	[efficientnetv2-l/block6q_activation/Sigmoid]:945
	                     MUL	        23864.354	   36.311	   36.503	  0.127%	 83.201%	     0.000	        1	[efficientnetv2-l/block6q_activation/mul_1]:946
	                    MEAN	        23900.867	   87.656	   88.124	  0.307%	 83.507%	     0.000	        1	[efficientnetv2-l/block6q_se_squeeze/Mean]:947
	                   SHAPE	        23989.003	    0.008	    0.009	  0.000%	 83.507%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Shape]:948
	           STRIDED_SLICE	        23989.018	    0.021	    0.022	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/strided_slice]:949
	                    PACK	        23989.046	    0.040	    0.035	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape/shape]:950
	                 RESHAPE	        23989.088	    0.014	    0.014	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape]:951
	                 CONV_2D	        23989.108	    0.050	    0.054	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_reduce/Conv2D]:952
	                LOGISTIC	        23989.168	    0.009	    0.010	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/Sigmoid]:953
	                     MUL	        23989.184	    0.021	    0.021	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/mul_1]:954
	                 CONV_2D	        23989.211	    0.049	    0.052	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_expand/Conv2D]:955
	                LOGISTIC	        23989.270	    0.028	    0.032	  0.000%	 83.508%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/Sigmoid]:956
	                     MUL	        23989.308	   36.189	   36.442	  0.127%	 83.635%	     0.000	        1	[efficientnetv2-l/block6q_se_excite/mul]:957
	                 CONV_2D	        24025.762	    7.452	    7.496	  0.026%	 83.661%	     0.000	        1	[efficientnetv2-l/block6q_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_project_conv/Conv2D]:958
	                     ADD	        24033.267	    7.996	    8.074	  0.028%	 83.689%	     0.000	        1	[efficientnetv2-l/block6q_add/add]:959
	                 CONV_2D	        24041.350	   10.569	   10.659	  0.037%	 83.727%	     0.000	        1	[efficientnetv2-l/block6r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_expand_conv/Conv2D]:960
	                LOGISTIC	        24052.018	    4.989	    4.986	  0.017%	 83.744%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/Sigmoid]:961
	                     MUL	        24057.016	   36.318	   36.557	  0.127%	 83.871%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/mul_1]:962
	       DEPTHWISE_CONV_2D	        24093.583	    2.786	    2.882	  0.010%	 83.881%	     0.000	        1	[efficientnetv2-l/block6r_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:963
	                LOGISTIC	        24096.476	    5.093	    5.059	  0.018%	 83.899%	     0.000	        1	[efficientnetv2-l/block6r_activation/Sigmoid]:964
	                     MUL	        24101.546	   36.343	   36.487	  0.127%	 84.026%	     0.000	        1	[efficientnetv2-l/block6r_activation/mul_1]:965
	                    MEAN	        24138.044	   87.665	   88.028	  0.307%	 84.332%	     0.000	        1	[efficientnetv2-l/block6r_se_squeeze/Mean]:966
	                   SHAPE	        24226.084	    0.009	    0.009	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Shape]:967
	           STRIDED_SLICE	        24226.099	    0.022	    0.024	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/strided_slice]:968
	                    PACK	        24226.129	    0.028	    0.033	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape/shape]:969
	                 RESHAPE	        24226.169	    0.013	    0.019	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape]:970
	                 CONV_2D	        24226.194	    0.052	    0.053	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_reduce/Conv2D]:971
	                LOGISTIC	        24226.254	    0.009	    0.010	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/Sigmoid]:972
	                     MUL	        24226.270	    0.021	    0.021	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/mul_1]:973
	                 CONV_2D	        24226.298	    0.073	    0.056	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_expand/Conv2D]:974
	                LOGISTIC	        24226.359	    0.030	    0.033	  0.000%	 84.333%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/Sigmoid]:975
	                     MUL	        24226.398	   36.212	   36.407	  0.127%	 84.460%	     0.000	        1	[efficientnetv2-l/block6r_se_excite/mul]:976
	                 CONV_2D	        24262.817	    7.449	    7.490	  0.026%	 84.486%	     0.000	        1	[efficientnetv2-l/block6r_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_project_conv/Conv2D]:977
	                     ADD	        24270.315	    8.025	    8.040	  0.028%	 84.514%	     0.000	        1	[efficientnetv2-l/block6r_add/add]:978
	                 CONV_2D	        24278.365	   10.615	   10.693	  0.037%	 84.551%	     0.000	        1	[efficientnetv2-l/block6s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_expand_conv/Conv2D]:979
	                LOGISTIC	        24289.068	    5.034	    5.017	  0.017%	 84.569%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/Sigmoid]:980
	                     MUL	        24294.095	   36.293	   36.480	  0.127%	 84.696%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/mul_1]:981
	       DEPTHWISE_CONV_2D	        24330.585	    2.811	    2.988	  0.010%	 84.706%	     0.000	        1	[efficientnetv2-l/block6s_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:982
	                LOGISTIC	        24333.584	    5.082	    5.077	  0.018%	 84.724%	     0.000	        1	[efficientnetv2-l/block6s_activation/Sigmoid]:983
	                     MUL	        24338.672	   36.251	   36.456	  0.127%	 84.851%	     0.000	        1	[efficientnetv2-l/block6s_activation/mul_1]:984
	                    MEAN	        24375.139	   87.801	   88.194	  0.307%	 85.158%	     0.000	        1	[efficientnetv2-l/block6s_se_squeeze/Mean]:985
	                   SHAPE	        24463.343	    0.008	    0.009	  0.000%	 85.158%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Shape]:986
	           STRIDED_SLICE	        24463.358	    0.022	    0.022	  0.000%	 85.158%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/strided_slice]:987
	                    PACK	        24463.386	    0.029	    0.035	  0.000%	 85.158%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape/shape]:988
	                 RESHAPE	        24463.427	    0.015	    0.014	  0.000%	 85.158%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape]:989
	                 CONV_2D	        24463.448	    0.053	    0.056	  0.000%	 85.159%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_reduce/Conv2D]:990
	                LOGISTIC	        24463.510	    0.009	    0.010	  0.000%	 85.159%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/Sigmoid]:991
	                     MUL	        24463.526	    0.021	    0.021	  0.000%	 85.159%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/mul_1]:992
	                 CONV_2D	        24463.553	    0.050	    0.056	  0.000%	 85.159%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_expand/Conv2D]:993
	                LOGISTIC	        24463.615	    0.028	    0.028	  0.000%	 85.159%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/Sigmoid]:994
	                     MUL	        24463.649	   36.195	   36.410	  0.127%	 85.286%	     0.000	        1	[efficientnetv2-l/block6s_se_excite/mul]:995
	                 CONV_2D	        24500.071	    7.452	    7.489	  0.026%	 85.312%	     0.000	        1	[efficientnetv2-l/block6s_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_project_conv/Conv2D]:996
	                     ADD	        24507.569	    8.017	    8.056	  0.028%	 85.340%	     0.000	        1	[efficientnetv2-l/block6s_add/add]:997
	                 CONV_2D	        24515.632	   10.689	   10.676	  0.037%	 85.377%	     0.000	        1	[efficientnetv2-l/block6t_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_expand_conv/Conv2D]:998
	                LOGISTIC	        24526.319	    5.063	    5.210	  0.018%	 85.395%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/Sigmoid]:999
	                     MUL	        24531.540	   36.529	   36.461	  0.127%	 85.522%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/mul_1]:1000
	       DEPTHWISE_CONV_2D	        24568.012	    2.774	    2.845	  0.010%	 85.532%	     0.000	        1	[efficientnetv2-l/block6t_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1001
	                LOGISTIC	        24570.866	    5.036	    5.034	  0.018%	 85.550%	     0.000	        1	[efficientnetv2-l/block6t_activation/Sigmoid]:1002
	                     MUL	        24575.910	   36.406	   36.457	  0.127%	 85.677%	     0.000	        1	[efficientnetv2-l/block6t_activation/mul_1]:1003
	                    MEAN	        24612.378	   88.099	   87.921	  0.306%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_squeeze/Mean]:1004
	                   SHAPE	        24700.310	    0.009	    0.010	  0.000%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Shape]:1005
	           STRIDED_SLICE	        24700.326	    0.022	    0.022	  0.000%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/strided_slice]:1006
	                    PACK	        24700.355	    0.030	    0.029	  0.000%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape/shape]:1007
	                 RESHAPE	        24700.390	    0.014	    0.014	  0.000%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape]:1008
	                 CONV_2D	        24700.411	    0.074	    0.061	  0.000%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_reduce/Conv2D]:1009
	                LOGISTIC	        24700.479	    0.010	    0.010	  0.000%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/Sigmoid]:1010
	                     MUL	        24700.497	    0.021	    0.021	  0.000%	 85.983%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/mul_1]:1011
	                 CONV_2D	        24700.524	    0.050	    0.051	  0.000%	 85.984%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_expand/Conv2D]:1012
	                LOGISTIC	        24700.582	    0.028	    0.032	  0.000%	 85.984%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/Sigmoid]:1013
	                     MUL	        24700.624	   36.678	   36.383	  0.127%	 86.110%	     0.000	        1	[efficientnetv2-l/block6t_se_excite/mul]:1014
	                 CONV_2D	        24737.018	    7.573	    7.491	  0.026%	 86.136%	     0.000	        1	[efficientnetv2-l/block6t_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_project_conv/Conv2D]:1015
	                     ADD	        24744.518	    8.118	    8.069	  0.028%	 86.165%	     0.000	        1	[efficientnetv2-l/block6t_add/add]:1016
	                 CONV_2D	        24752.596	   11.004	   10.722	  0.037%	 86.202%	     0.000	        1	[efficientnetv2-l/block6u_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_expand_conv/Conv2D]:1017
	                LOGISTIC	        24763.329	    5.053	    5.027	  0.018%	 86.219%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/Sigmoid]:1018
	                     MUL	        24768.366	   36.727	   36.533	  0.127%	 86.347%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/mul_1]:1019
	       DEPTHWISE_CONV_2D	        24804.910	    3.351	    3.070	  0.011%	 86.357%	     0.000	        1	[efficientnetv2-l/block6u_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1020
	                LOGISTIC	        24807.991	    5.037	    5.048	  0.018%	 86.375%	     0.000	        1	[efficientnetv2-l/block6u_activation/Sigmoid]:1021
	                     MUL	        24813.049	   36.695	   36.570	  0.127%	 86.502%	     0.000	        1	[efficientnetv2-l/block6u_activation/mul_1]:1022
	                    MEAN	        24849.630	   90.527	   88.547	  0.308%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_squeeze/Mean]:1023
	                   SHAPE	        24938.187	    0.010	    0.009	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Shape]:1024
	           STRIDED_SLICE	        24938.202	    0.024	    0.022	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/strided_slice]:1025
	                    PACK	        24938.230	    0.031	    0.030	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape/shape]:1026
	                 RESHAPE	        24938.266	    0.014	    0.014	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape]:1027
	                 CONV_2D	        24938.287	    0.080	    0.062	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_reduce/Conv2D]:1028
	                LOGISTIC	        24938.355	    0.012	    0.010	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/Sigmoid]:1029
	                     MUL	        24938.371	    0.022	    0.021	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/mul_1]:1030
	                 CONV_2D	        24938.399	    0.054	    0.059	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_expand/Conv2D]:1031
	                LOGISTIC	        24938.464	    0.031	    0.030	  0.000%	 86.811%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/Sigmoid]:1032
	                     MUL	        24938.500	   38.027	   36.741	  0.128%	 86.939%	     0.000	        1	[efficientnetv2-l/block6u_se_excite/mul]:1033
	                 CONV_2D	        24975.252	    7.628	    7.510	  0.026%	 86.966%	     0.000	        1	[efficientnetv2-l/block6u_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_project_conv/Conv2D]:1034
	                     ADD	        24982.772	    8.540	    8.137	  0.028%	 86.994%	     0.000	        1	[efficientnetv2-l/block6u_add/add]:1035
	                 CONV_2D	        24990.921	   11.063	   10.724	  0.037%	 87.031%	     0.000	        1	[efficientnetv2-l/block6v_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_expand_conv/Conv2D]:1036
	                LOGISTIC	        25001.654	    5.114	    5.043	  0.018%	 87.049%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/Sigmoid]:1037
	                     MUL	        25006.707	   36.640	   36.517	  0.127%	 87.176%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/mul_1]:1038
	       DEPTHWISE_CONV_2D	        25043.235	    3.185	    2.962	  0.010%	 87.186%	     0.000	        1	[efficientnetv2-l/block6v_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1039
	                LOGISTIC	        25046.207	    5.014	    5.078	  0.018%	 87.204%	     0.000	        1	[efficientnetv2-l/block6v_activation/Sigmoid]:1040
	                     MUL	        25051.296	   37.385	   36.644	  0.128%	 87.332%	     0.000	        1	[efficientnetv2-l/block6v_activation/mul_1]:1041
	                    MEAN	        25087.951	   89.805	   88.656	  0.309%	 87.640%	     0.000	        1	[efficientnetv2-l/block6v_se_squeeze/Mean]:1042
	                   SHAPE	        25176.618	    0.010	    0.009	  0.000%	 87.640%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Shape]:1043
	           STRIDED_SLICE	        25176.633	    0.022	    0.021	  0.000%	 87.640%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/strided_slice]:1044
	                    PACK	        25176.661	    0.030	    0.032	  0.000%	 87.641%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape/shape]:1045
	                 RESHAPE	        25176.700	    0.034	    0.022	  0.000%	 87.641%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape]:1046
	                 CONV_2D	        25176.729	    0.054	    0.060	  0.000%	 87.641%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_reduce/Conv2D]:1047
	                LOGISTIC	        25176.796	    0.009	    0.010	  0.000%	 87.641%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/Sigmoid]:1048
	                     MUL	        25176.812	    0.021	    0.021	  0.000%	 87.641%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/mul_1]:1049
	                 CONV_2D	        25176.839	    0.051	    0.054	  0.000%	 87.641%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_expand/Conv2D]:1050
	                LOGISTIC	        25176.899	    0.030	    0.029	  0.000%	 87.641%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/Sigmoid]:1051
	                     MUL	        25176.934	   36.587	   36.383	  0.127%	 87.768%	     0.000	        1	[efficientnetv2-l/block6v_se_excite/mul]:1052
	                 CONV_2D	        25213.328	    7.532	    7.503	  0.026%	 87.794%	     0.000	        1	[efficientnetv2-l/block6v_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_project_conv/Conv2D]:1053
	                     ADD	        25220.842	    8.177	    8.075	  0.028%	 87.822%	     0.000	        1	[efficientnetv2-l/block6v_add/add]:1054
	                 CONV_2D	        25228.926	   10.844	   10.760	  0.037%	 87.860%	     0.000	        1	[efficientnetv2-l/block6w_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_expand_conv/Conv2D]:1055
	                LOGISTIC	        25239.696	    5.000	    5.018	  0.017%	 87.877%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/Sigmoid]:1056
	                     MUL	        25244.724	   36.725	   36.661	  0.128%	 88.005%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/mul_1]:1057
	       DEPTHWISE_CONV_2D	        25281.414	    3.116	    3.068	  0.011%	 88.015%	     0.000	        1	[efficientnetv2-l/block6w_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1058
	                LOGISTIC	        25284.493	    5.015	    5.029	  0.018%	 88.033%	     0.000	        1	[efficientnetv2-l/block6w_activation/Sigmoid]:1059
	                     MUL	        25289.532	   36.576	   36.498	  0.127%	 88.160%	     0.000	        1	[efficientnetv2-l/block6w_activation/mul_1]:1060
	                    MEAN	        25326.041	   88.386	   88.156	  0.307%	 88.467%	     0.000	        1	[efficientnetv2-l/block6w_se_squeeze/Mean]:1061
	                   SHAPE	        25414.208	    0.009	    0.009	  0.000%	 88.467%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Shape]:1062
	           STRIDED_SLICE	        25414.222	    0.021	    0.022	  0.000%	 88.467%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/strided_slice]:1063
	                    PACK	        25414.250	    0.030	    0.032	  0.000%	 88.467%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape/shape]:1064
	                 RESHAPE	        25414.289	    0.015	    0.015	  0.000%	 88.467%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape]:1065
	                 CONV_2D	        25414.310	    0.054	    0.057	  0.000%	 88.468%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_reduce/Conv2D]:1066
	                LOGISTIC	        25414.381	    0.014	    0.011	  0.000%	 88.468%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/Sigmoid]:1067
	                     MUL	        25414.398	    0.042	    0.025	  0.000%	 88.468%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/mul_1]:1068
	                 CONV_2D	        25414.429	    0.056	    0.059	  0.000%	 88.468%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_expand/Conv2D]:1069
	                LOGISTIC	        25414.494	    0.029	    0.029	  0.000%	 88.468%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/Sigmoid]:1070
	                     MUL	        25414.532	   36.555	   36.441	  0.127%	 88.595%	     0.000	        1	[efficientnetv2-l/block6w_se_excite/mul]:1071
	                 CONV_2D	        25450.984	    7.595	    7.537	  0.026%	 88.621%	     0.000	        1	[efficientnetv2-l/block6w_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_project_conv/Conv2D]:1072
	                     ADD	        25458.539	    8.096	    8.068	  0.028%	 88.649%	     0.000	        1	[efficientnetv2-l/block6w_add/add]:1073
	                 CONV_2D	        25466.618	   10.741	   10.716	  0.037%	 88.687%	     0.000	        1	[efficientnetv2-l/block6x_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_expand_conv/Conv2D]:1074
	                LOGISTIC	        25477.345	    5.011	    5.061	  0.018%	 88.704%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/Sigmoid]:1075
	                     MUL	        25482.417	   36.585	   36.505	  0.127%	 88.831%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/mul_1]:1076
	       DEPTHWISE_CONV_2D	        25518.935	    3.354	    3.029	  0.011%	 88.842%	     0.000	        1	[efficientnetv2-l/block6x_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1077
	                LOGISTIC	        25521.974	    5.016	    5.049	  0.018%	 88.859%	     0.000	        1	[efficientnetv2-l/block6x_activation/Sigmoid]:1078
	                     MUL	        25527.033	   36.589	   36.606	  0.127%	 88.987%	     0.000	        1	[efficientnetv2-l/block6x_activation/mul_1]:1079
	                    MEAN	        25563.651	   88.340	   87.990	  0.306%	 89.293%	     0.000	        1	[efficientnetv2-l/block6x_se_squeeze/Mean]:1080
	                   SHAPE	        25651.652	    0.009	    0.010	  0.000%	 89.293%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Shape]:1081
	           STRIDED_SLICE	        25651.668	    0.022	    0.021	  0.000%	 89.293%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/strided_slice]:1082
	                    PACK	        25651.696	    0.029	    0.029	  0.000%	 89.293%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape/shape]:1083
	                 RESHAPE	        25651.731	    0.014	    0.014	  0.000%	 89.294%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape]:1084
	                 CONV_2D	        25651.751	    0.049	    0.057	  0.000%	 89.294%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_reduce/Conv2D]:1085
	                LOGISTIC	        25651.815	    0.010	    0.010	  0.000%	 89.294%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/Sigmoid]:1086
	                     MUL	        25651.831	    0.021	    0.021	  0.000%	 89.294%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/mul_1]:1087
	                 CONV_2D	        25651.858	    0.079	    0.056	  0.000%	 89.294%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_expand/Conv2D]:1088
	                LOGISTIC	        25651.920	    0.029	    0.035	  0.000%	 89.294%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/Sigmoid]:1089
	                     MUL	        25651.961	   36.596	   36.374	  0.127%	 89.421%	     0.000	        1	[efficientnetv2-l/block6x_se_excite/mul]:1090
	                 CONV_2D	        25688.345	    7.533	    7.487	  0.026%	 89.447%	     0.000	        1	[efficientnetv2-l/block6x_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_project_conv/Conv2D]:1091
	                     ADD	        25695.844	    8.085	    8.056	  0.028%	 89.475%	     0.000	        1	[efficientnetv2-l/block6x_add/add]:1092
	                 CONV_2D	        25703.909	   10.705	   10.701	  0.037%	 89.512%	     0.000	        1	[efficientnetv2-l/block6y_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_expand_conv/Conv2D]:1093
	                LOGISTIC	        25714.620	    5.050	    5.026	  0.018%	 89.530%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/Sigmoid]:1094
	                     MUL	        25719.656	   36.338	   36.498	  0.127%	 89.657%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/mul_1]:1095
	       DEPTHWISE_CONV_2D	        25756.170	    2.804	    2.969	  0.010%	 89.667%	     0.000	        1	[efficientnetv2-l/block6y_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1096
	                LOGISTIC	        25759.149	    5.039	    5.054	  0.018%	 89.685%	     0.000	        1	[efficientnetv2-l/block6y_activation/Sigmoid]:1097
	                     MUL	        25764.213	   36.304	   36.900	  0.128%	 89.813%	     0.000	        1	[efficientnetv2-l/block6y_activation/mul_1]:1098
	                    MEAN	        25801.124	   87.708	   88.161	  0.307%	 90.120%	     0.000	        1	[efficientnetv2-l/block6y_se_squeeze/Mean]:1099
	                   SHAPE	        25889.296	    0.008	    0.009	  0.000%	 90.120%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Shape]:1100
	           STRIDED_SLICE	        25889.311	    0.020	    0.022	  0.000%	 90.120%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/strided_slice]:1101
	                    PACK	        25889.340	    0.028	    0.030	  0.000%	 90.120%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape/shape]:1102
	                 RESHAPE	        25889.376	    0.014	    0.018	  0.000%	 90.121%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape]:1103
	                 CONV_2D	        25889.401	    0.052	    0.054	  0.000%	 90.121%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_reduce/Conv2D]:1104
	                LOGISTIC	        25889.462	    0.056	    0.018	  0.000%	 90.121%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/Sigmoid]:1105
	                     MUL	        25889.486	    0.020	    0.025	  0.000%	 90.121%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/mul_1]:1106
	                 CONV_2D	        25889.517	    0.051	    0.052	  0.000%	 90.121%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_expand/Conv2D]:1107
	                LOGISTIC	        25889.575	    0.028	    0.032	  0.000%	 90.121%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/Sigmoid]:1108
	                     MUL	        25889.614	   36.250	   36.393	  0.127%	 90.248%	     0.000	        1	[efficientnetv2-l/block6y_se_excite/mul]:1109
	                 CONV_2D	        25926.018	    7.475	    7.499	  0.026%	 90.274%	     0.000	        1	[efficientnetv2-l/block6y_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_project_conv/Conv2D]:1110
	                     ADD	        25933.527	    8.074	    8.057	  0.028%	 90.302%	     0.000	        1	[efficientnetv2-l/block6y_add/add]:1111
	                 CONV_2D	        25941.593	   10.624	   10.653	  0.037%	 90.339%	     0.000	        1	[efficientnetv2-l/block7a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_expand_conv/Conv2D]:1112
	                LOGISTIC	        25952.255	    4.974	    4.997	  0.017%	 90.357%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/Sigmoid]:1113
	                     MUL	        25957.262	   36.434	   36.627	  0.128%	 90.484%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/mul_1]:1114
	       DEPTHWISE_CONV_2D	        25993.902	    2.787	    2.900	  0.010%	 90.494%	     0.000	        1	[efficientnetv2-l/block7a_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_dwconv2/depthwise]:1115
	                LOGISTIC	        25996.813	    5.010	    5.117	  0.018%	 90.512%	     0.000	        1	[efficientnetv2-l/block7a_activation/Sigmoid]:1116
	                     MUL	        26001.940	   36.310	   36.651	  0.128%	 90.640%	     0.000	        1	[efficientnetv2-l/block7a_activation/mul_1]:1117
	                    MEAN	        26038.602	   87.577	   88.097	  0.307%	 90.946%	     0.000	        1	[efficientnetv2-l/block7a_se_squeeze/Mean]:1118
	                   SHAPE	        26126.710	    0.010	    0.009	  0.000%	 90.946%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Shape]:1119
	           STRIDED_SLICE	        26126.726	    0.021	    0.021	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/strided_slice]:1120
	                    PACK	        26126.753	    0.029	    0.028	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape/shape]:1121
	                 RESHAPE	        26126.787	    0.014	    0.014	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape]:1122
	                 CONV_2D	        26126.808	    0.051	    0.060	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_reduce/Conv2D]:1123
	                LOGISTIC	        26126.874	    0.010	    0.010	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/Sigmoid]:1124
	                     MUL	        26126.890	    0.020	    0.024	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/mul_1]:1125
	                 CONV_2D	        26126.920	    0.051	    0.054	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_expand/Conv2D]:1126
	                LOGISTIC	        26126.980	    0.030	    0.032	  0.000%	 90.947%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/Sigmoid]:1127
	                     MUL	        26127.018	   36.185	   36.290	  0.126%	 91.074%	     0.000	        1	[efficientnetv2-l/block7a_se_excite/mul]:1128
	                 CONV_2D	        26163.319	   12.306	   12.351	  0.043%	 91.117%	     0.000	        1	[efficientnetv2-l/block7a_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_project_conv/Conv2D]:1129
	                 CONV_2D	        26175.678	   25.475	   25.593	  0.089%	 91.206%	     0.000	        1	[efficientnetv2-l/block7b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_expand_conv/Conv2D]:1130
	                LOGISTIC	        26201.281	    8.316	    8.335	  0.029%	 91.235%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/Sigmoid]:1131
	                     MUL	        26209.627	   60.608	   60.975	  0.212%	 91.447%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/mul_1]:1132
	       DEPTHWISE_CONV_2D	        26270.614	    5.047	    5.335	  0.019%	 91.466%	     0.000	        1	[efficientnetv2-l/block7b_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1133
	                LOGISTIC	        26275.960	    8.354	    8.359	  0.029%	 91.495%	     0.000	        1	[efficientnetv2-l/block7b_activation/Sigmoid]:1134
	                     MUL	        26284.330	   60.530	   60.825	  0.212%	 91.707%	     0.000	        1	[efficientnetv2-l/block7b_activation/mul_1]:1135
	                    MEAN	        26345.169	  146.270	  146.963	  0.512%	 92.218%	     0.000	        1	[efficientnetv2-l/block7b_se_squeeze/Mean]:1136
	                   SHAPE	        26492.144	    0.008	    0.009	  0.000%	 92.218%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Shape]:1137
	           STRIDED_SLICE	        26492.159	    0.021	    0.022	  0.000%	 92.219%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/strided_slice]:1138
	                    PACK	        26492.188	    0.029	    0.030	  0.000%	 92.219%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape/shape]:1139
	                 RESHAPE	        26492.224	    0.015	    0.015	  0.000%	 92.219%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape]:1140
	                 CONV_2D	        26492.245	    0.088	    0.080	  0.000%	 92.219%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7b_se_reduce/Conv2D]:1141
	                LOGISTIC	        26492.331	    0.011	    0.010	  0.000%	 92.219%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/Sigmoid]:1142
	                     MUL	        26492.347	    0.025	    0.025	  0.000%	 92.219%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/mul_1]:1143
	                 CONV_2D	        26492.379	    0.073	    0.082	  0.000%	 92.219%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_se_expand/Conv2D]:1144
	                LOGISTIC	        26492.468	    0.042	    0.051	  0.000%	 92.220%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/Sigmoid]:1145
	                     MUL	        26492.525	   60.350	   60.744	  0.212%	 92.431%	     0.000	        1	[efficientnetv2-l/block7b_se_excite/mul]:1146
	                 CONV_2D	        26553.280	   20.238	   20.414	  0.071%	 92.502%	     0.000	        1	[efficientnetv2-l/block7b_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_project_conv/Conv2D]:1147
	                     ADD	        26573.704	   13.336	   13.407	  0.047%	 92.549%	     0.000	        1	[efficientnetv2-l/block7b_add/add]:1148
	                 CONV_2D	        26587.120	   25.442	   25.722	  0.090%	 92.638%	     0.000	        1	[efficientnetv2-l/block7c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_expand_conv/Conv2D]:1149
	                LOGISTIC	        26612.853	    8.297	    8.307	  0.029%	 92.667%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/Sigmoid]:1150
	                     MUL	        26621.170	   60.539	   60.924	  0.212%	 92.880%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/mul_1]:1151
	       DEPTHWISE_CONV_2D	        26682.105	    5.180	    5.415	  0.019%	 92.898%	     0.000	        1	[efficientnetv2-l/block7c_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1152
	                LOGISTIC	        26687.539	    8.333	    8.361	  0.029%	 92.928%	     0.000	        1	[efficientnetv2-l/block7c_activation/Sigmoid]:1153
	                     MUL	        26695.913	   60.545	   60.827	  0.212%	 93.139%	     0.000	        1	[efficientnetv2-l/block7c_activation/mul_1]:1154
	                    MEAN	        26756.750	  146.833	  147.379	  0.513%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_squeeze/Mean]:1155
	                   SHAPE	        26904.140	    0.008	    0.009	  0.000%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Shape]:1156
	           STRIDED_SLICE	        26904.155	    0.021	    0.024	  0.000%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/strided_slice]:1157
	                    PACK	        26904.185	    0.029	    0.036	  0.000%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape/shape]:1158
	                 RESHAPE	        26904.227	    0.014	    0.015	  0.000%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape]:1159
	                 CONV_2D	        26904.249	    0.103	    0.089	  0.000%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7c_se_reduce/Conv2D]:1160
	                LOGISTIC	        26904.345	    0.011	    0.011	  0.000%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/Sigmoid]:1161
	                     MUL	        26904.362	    0.025	    0.025	  0.000%	 93.653%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/mul_1]:1162
	                 CONV_2D	        26904.394	    0.071	    0.073	  0.000%	 93.654%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_se_expand/Conv2D]:1163
	                LOGISTIC	        26904.473	    0.044	    0.049	  0.000%	 93.654%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/Sigmoid]:1164
	                     MUL	        26904.529	   60.424	   60.748	  0.212%	 93.865%	     0.000	        1	[efficientnetv2-l/block7c_se_excite/mul]:1165
	                 CONV_2D	        26965.288	   20.279	   20.426	  0.071%	 93.936%	     0.000	        1	[efficientnetv2-l/block7c_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_project_conv/Conv2D]:1166
	                     ADD	        26985.724	   13.509	   13.424	  0.047%	 93.983%	     0.000	        1	[efficientnetv2-l/block7c_add/add]:1167
	                 CONV_2D	        26999.158	   25.800	   25.634	  0.089%	 94.072%	     0.000	        1	[efficientnetv2-l/block7d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_expand_conv/Conv2D]:1168
	                LOGISTIC	        27024.804	    8.390	    8.329	  0.029%	 94.101%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/Sigmoid]:1169
	                     MUL	        27033.143	   60.549	   60.694	  0.211%	 94.313%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/mul_1]:1170
	       DEPTHWISE_CONV_2D	        27093.848	    5.168	    5.210	  0.018%	 94.331%	     0.000	        1	[efficientnetv2-l/block7d_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1171
	                LOGISTIC	        27099.070	    8.343	    8.352	  0.029%	 94.360%	     0.000	        1	[efficientnetv2-l/block7d_activation/Sigmoid]:1172
	                     MUL	        27107.434	   60.846	   60.818	  0.212%	 94.572%	     0.000	        1	[efficientnetv2-l/block7d_activation/mul_1]:1173
	                    MEAN	        27168.263	  148.249	  147.185	  0.513%	 95.084%	     0.000	        1	[efficientnetv2-l/block7d_se_squeeze/Mean]:1174
	                   SHAPE	        27315.459	    0.010	    0.016	  0.000%	 95.084%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Shape]:1175
	           STRIDED_SLICE	        27315.481	    0.023	    0.023	  0.000%	 95.084%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/strided_slice]:1176
	                    PACK	        27315.510	    0.074	    0.037	  0.000%	 95.085%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape/shape]:1177
	                 RESHAPE	        27315.554	    0.016	    0.015	  0.000%	 95.085%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape]:1178
	                 CONV_2D	        27315.575	    0.091	    0.082	  0.000%	 95.085%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7d_se_reduce/Conv2D]:1179
	                LOGISTIC	        27315.663	    0.012	    0.011	  0.000%	 95.085%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/Sigmoid]:1180
	                     MUL	        27315.681	    0.025	    0.026	  0.000%	 95.085%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/mul_1]:1181
	                 CONV_2D	        27315.713	    0.074	    0.084	  0.000%	 95.085%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_se_expand/Conv2D]:1182
	                LOGISTIC	        27315.803	    0.046	    0.047	  0.000%	 95.086%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/Sigmoid]:1183
	                     MUL	        27315.856	   61.040	   60.835	  0.212%	 95.297%	     0.000	        1	[efficientnetv2-l/block7d_se_excite/mul]:1184
	                 CONV_2D	        27376.702	   20.642	   20.485	  0.071%	 95.369%	     0.000	        1	[efficientnetv2-l/block7d_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_project_conv/Conv2D]:1185
	                     ADD	        27397.197	   13.439	   13.430	  0.047%	 95.415%	     0.000	        1	[efficientnetv2-l/block7d_add/add]:1186
	                 CONV_2D	        27410.637	   27.101	   25.860	  0.090%	 95.506%	     0.000	        1	[efficientnetv2-l/block7e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_expand_conv/Conv2D]:1187
	                LOGISTIC	        27436.508	    8.449	    8.377	  0.029%	 95.535%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/Sigmoid]:1188
	                     MUL	        27444.897	   63.184	   61.194	  0.213%	 95.748%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/mul_1]:1189
	       DEPTHWISE_CONV_2D	        27506.101	    6.055	    5.429	  0.019%	 95.767%	     0.000	        1	[efficientnetv2-l/block7e_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1190
	                LOGISTIC	        27511.546	    8.699	    8.439	  0.029%	 95.796%	     0.000	        1	[efficientnetv2-l/block7e_activation/Sigmoid]:1191
	                     MUL	        27519.997	   60.906	   60.891	  0.212%	 96.008%	     0.000	        1	[efficientnetv2-l/block7e_activation/mul_1]:1192
	                    MEAN	        27580.899	  147.773	  147.368	  0.513%	 96.521%	     0.000	        1	[efficientnetv2-l/block7e_se_squeeze/Mean]:1193
	                   SHAPE	        27728.278	    0.008	    0.009	  0.000%	 96.521%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Shape]:1194
	           STRIDED_SLICE	        27728.293	    0.023	    0.022	  0.000%	 96.521%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/strided_slice]:1195
	                    PACK	        27728.321	    0.029	    0.032	  0.000%	 96.522%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape/shape]:1196
	                 RESHAPE	        27728.360	    0.014	    0.014	  0.000%	 96.522%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape]:1197
	                 CONV_2D	        27728.381	    0.069	    0.073	  0.000%	 96.522%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7e_se_reduce/Conv2D]:1198
	                LOGISTIC	        27728.461	    0.011	    0.011	  0.000%	 96.522%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/Sigmoid]:1199
	                     MUL	        27728.478	    0.025	    0.025	  0.000%	 96.522%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/mul_1]:1200
	                 CONV_2D	        27728.509	    0.092	    0.090	  0.000%	 96.522%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_se_expand/Conv2D]:1201
	                LOGISTIC	        27728.605	    0.044	    0.046	  0.000%	 96.522%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/Sigmoid]:1202
	                     MUL	        27728.658	   60.363	   60.727	  0.211%	 96.734%	     0.000	        1	[efficientnetv2-l/block7e_se_excite/mul]:1203
	                 CONV_2D	        27789.396	   20.219	   20.520	  0.071%	 96.805%	     0.000	        1	[efficientnetv2-l/block7e_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_project_conv/Conv2D]:1204
	                     ADD	        27809.926	   13.362	   13.411	  0.047%	 96.852%	     0.000	        1	[efficientnetv2-l/block7e_add/add]:1205
	                 CONV_2D	        27823.346	   25.433	   25.618	  0.089%	 96.941%	     0.000	        1	[efficientnetv2-l/block7f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_expand_conv/Conv2D]:1206
	                LOGISTIC	        27848.975	    8.306	    8.323	  0.029%	 96.970%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/Sigmoid]:1207
	                     MUL	        27857.308	   60.592	   60.783	  0.212%	 97.182%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/mul_1]:1208
	       DEPTHWISE_CONV_2D	        27918.103	    5.071	    5.170	  0.018%	 97.200%	     0.000	        1	[efficientnetv2-l/block7f_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1209
	                LOGISTIC	        27923.284	    8.486	    8.473	  0.030%	 97.229%	     0.000	        1	[efficientnetv2-l/block7f_activation/Sigmoid]:1210
	                     MUL	        27931.768	   60.659	   60.794	  0.212%	 97.441%	     0.000	        1	[efficientnetv2-l/block7f_activation/mul_1]:1211
	                    MEAN	        27992.574	  146.508	  146.662	  0.511%	 97.952%	     0.000	        1	[efficientnetv2-l/block7f_se_squeeze/Mean]:1212
	                   SHAPE	        28139.248	    0.009	    0.009	  0.000%	 97.952%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Shape]:1213
	           STRIDED_SLICE	        28139.264	    0.021	    0.021	  0.000%	 97.952%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/strided_slice]:1214
	                    PACK	        28139.291	    0.045	    0.033	  0.000%	 97.952%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape/shape]:1215
	                 RESHAPE	        28139.331	    0.014	    0.021	  0.000%	 97.952%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape]:1216
	                 CONV_2D	        28139.358	    0.071	    0.072	  0.000%	 97.952%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7f_se_reduce/Conv2D]:1217
	                LOGISTIC	        28139.436	    0.011	    0.013	  0.000%	 97.952%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/Sigmoid]:1218
	                     MUL	        28139.456	    0.025	    0.027	  0.000%	 97.953%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/mul_1]:1219
	                 CONV_2D	        28139.489	    0.072	    0.087	  0.000%	 97.953%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_se_expand/Conv2D]:1220
	                LOGISTIC	        28139.586	    0.044	    0.043	  0.000%	 97.953%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/Sigmoid]:1221
	                     MUL	        28139.635	   60.364	   60.604	  0.211%	 98.164%	     0.000	        1	[efficientnetv2-l/block7f_se_excite/mul]:1222
	                 CONV_2D	        28200.250	   20.244	   20.402	  0.071%	 98.235%	     0.000	        1	[efficientnetv2-l/block7f_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_project_conv/Conv2D]:1223
	                     ADD	        28220.662	   13.416	   13.431	  0.047%	 98.282%	     0.000	        1	[efficientnetv2-l/block7f_add/add]:1224
	                 CONV_2D	        28234.102	   25.480	   25.675	  0.089%	 98.371%	     0.000	        1	[efficientnetv2-l/block7g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_expand_conv/Conv2D]:1225
	                LOGISTIC	        28259.787	    8.325	    8.314	  0.029%	 98.400%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/Sigmoid]:1226
	                     MUL	        28268.111	   60.502	   61.322	  0.214%	 98.614%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/mul_1]:1227
	       DEPTHWISE_CONV_2D	        28329.445	    5.182	    5.383	  0.019%	 98.633%	     0.000	        1	[efficientnetv2-l/block7g_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_dwconv2/depthwise]:1228
	                LOGISTIC	        28334.839	    8.294	    8.359	  0.029%	 98.662%	     0.000	        1	[efficientnetv2-l/block7g_activation/Sigmoid]:1229
	                     MUL	        28343.209	   60.535	   61.027	  0.213%	 98.874%	     0.000	        1	[efficientnetv2-l/block7g_activation/mul_1]:1230
	                    MEAN	        28404.246	  146.891	  147.693	  0.514%	 99.388%	     0.000	        1	[efficientnetv2-l/block7g_se_squeeze/Mean]:1231
	                   SHAPE	        28551.955	    0.009	    0.009	  0.000%	 99.388%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Shape]:1232
	           STRIDED_SLICE	        28551.970	    0.021	    0.025	  0.000%	 99.389%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/strided_slice]:1233
	                    PACK	        28552.001	    0.029	    0.032	  0.000%	 99.389%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape/shape]:1234
	                 RESHAPE	        28552.039	    0.014	    0.015	  0.000%	 99.389%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape]:1235
	                 CONV_2D	        28552.059	    0.068	    0.070	  0.000%	 99.389%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7g_se_reduce/Conv2D]:1236
	                LOGISTIC	        28552.136	    0.010	    0.010	  0.000%	 99.389%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/Sigmoid]:1237
	                     MUL	        28552.152	    0.025	    0.034	  0.000%	 99.389%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/mul_1]:1238
	                 CONV_2D	        28552.193	    0.088	    0.081	  0.000%	 99.389%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_se_expand/Conv2D]:1239
	                LOGISTIC	        28552.280	    0.043	    0.054	  0.000%	 99.390%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/Sigmoid]:1240
	                     MUL	        28552.341	   60.325	   60.611	  0.211%	 99.601%	     0.000	        1	[efficientnetv2-l/block7g_se_excite/mul]:1241
	                 CONV_2D	        28612.964	   20.202	   20.343	  0.071%	 99.672%	     0.000	        1	[efficientnetv2-l/block7g_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_project_conv/Conv2D]:1242
	                     ADD	        28633.317	   13.338	   13.401	  0.047%	 99.718%	     0.000	        1	[efficientnetv2-l/block7g_add/add]:1243
	                 CONV_2D	        28646.728	    8.610	    8.667	  0.030%	 99.748%	     0.000	        1	[efficientnetv2-l/top_bn/FusedBatchNormV3;efficientnetv2-l/top_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/top_conv/Conv2D]:1244
	                LOGISTIC	        28655.405	    2.787	    2.812	  0.010%	 99.758%	     0.000	        1	[efficientnetv2-l/top_activation/Sigmoid]:1245
	                     MUL	        28658.226	   20.106	   20.263	  0.071%	 99.829%	     0.000	        1	[efficientnetv2-l/top_activation/mul_1]:1246
	                    MEAN	        28678.502	   48.666	   48.787	  0.170%	 99.999%	     0.000	        1	[efficientnetv2-l/avg_pool/Mean]:1247
	         FULLY_CONNECTED	        28727.301	    0.319	    0.312	  0.001%	100.000%	     0.000	        1	[efficientnetv2-l/predictions/MatMul;efficientnetv2-l/predictions/BiasAdd]:1248
	                 SOFTMAX	        28727.621	    0.082	    0.086	  0.000%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:1249

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	         4965.908	  260.329	  259.647	  0.904%	  0.904%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                     MUL	         2365.417	  261.771	  259.429	  0.903%	  1.808%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                     MUL	         4445.551	  258.220	  259.393	  0.903%	  2.711%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                     MUL	         3926.262	  257.758	  259.370	  0.903%	  3.614%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                     MUL	         2885.505	  259.707	  259.322	  0.903%	  4.517%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                     MUL	         3405.505	  257.758	  259.149	  0.902%	  5.420%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                    MEAN	        14783.705	  209.587	  205.597	  0.716%	  6.136%	     0.000	        1	[efficientnetv2-l/block5j_se_squeeze/Mean]:454
	                    MEAN	        19598.977	  206.192	  205.446	  0.715%	  6.851%	     0.000	        1	[efficientnetv2-l/block5s_se_squeeze/Mean]:625
	                    MEAN	        11039.504	  204.156	  205.403	  0.715%	  7.566%	     0.000	        1	[efficientnetv2-l/block5c_se_squeeze/Mean]:321
	                    MEAN	        17459.033	  206.153	  205.394	  0.715%	  8.282%	     0.000	        1	[efficientnetv2-l/block5o_se_squeeze/Mean]:549

Number of nodes executed: 1250
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                     MUL	      265	 13279.704	    46.245%	    46.245%	     0.000	      265
	                    MEAN	       62	  8165.579	    28.436%	    74.681%	     0.000	       62
	                 CONV_2D	      278	  3224.781	    11.230%	    85.911%	     0.000	      278
	                     ADD	       74	  2183.019	     7.602%	    93.513%	     0.000	       74
	                LOGISTIC	      264	  1368.396	     4.765%	    98.278%	     0.000	      264
	       DEPTHWISE_CONV_2D	       61	   489.199	     1.704%	    99.982%	     0.000	       61
	                    PACK	       61	     1.908	     0.007%	    99.989%	     0.000	       61
	           STRIDED_SLICE	       61	     1.407	     0.005%	    99.994%	     0.000	       61
	                 RESHAPE	       61	     0.902	     0.003%	    99.997%	     0.000	       61
	                   SHAPE	       61	     0.538	     0.002%	    99.999%	     0.000	       61
	         FULLY_CONNECTED	        1	     0.312	     0.001%	   100.000%	     0.000	        1
	                 SOFTMAX	        1	     0.086	     0.000%	   100.000%	     0.000	        1

Timings (microseconds): count=6 first=28694611 curr=28705512 min=28694611 max=28747938 avg=2.87164e+07 std=20618
Memory (bytes): count=0
1250 nodes observed



[ perf record: Woken up 968 times to write data ]
[ perf record: Captured and wrote 242.072 MB /tmp/data.record (1380708 samples) ]

348.092

