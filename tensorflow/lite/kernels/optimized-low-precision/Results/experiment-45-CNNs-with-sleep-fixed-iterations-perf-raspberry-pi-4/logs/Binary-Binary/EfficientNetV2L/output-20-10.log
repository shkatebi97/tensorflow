STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/EfficientNetV2L.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/EfficientNetV2L.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (230400, 3, ), and Output shape (57600, 32, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 16)
, and the ID is 0
	Allocating LowPrecision Activations Tensors with Shape of (57600, 16)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
(57600, 32, ), and the ID is 1
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 2
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 3
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 4
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (128, 48)
Applying Conv Low-Precision for Kernel shape (128, 288, ), Input shape (57600, 32, ), and Output shape (14400, 128, ), and the ID is 5
	Allocating LowPrecision Activations Tensors with Shape of (14400, 48)
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (14400, 128, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 16)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
(14400, 64, ), and the ID is 6
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 7
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
(14400, 256, ), and Output shape (14400, 64, ), and the ID is 8
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 9
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
10
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 11
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
, and the ID is 12
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 13
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 14
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 15	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)

	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(14400, 256, ), and Output shape (14400, 64, ), and the ID is 16
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 17
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 18	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)

Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (3600, 256, ), and the ID is 19
	Allocating LowPrecision Activations Tensors with Shape of (3600, 80)
Applying Conv Low-Precision for Kernel shape (96, 256, ), Input shape (3600, 256, ), and Output shape (3600, 96, ), and the ID is 20
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 32)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 32)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 21
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 22
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 23
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 24	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)

	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 25
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 26
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 27
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
28
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 29
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 30
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 31
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 32
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
Applying Conv Low-Precision for Kernel shape (384, 96, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 33	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 16)

	Allocating LowPrecision Activations Tensors with Shape of (3600, 16)
The input model file size (MB): 127.361
Initialized session in 229.007ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
Applying Conv Low-Precision for Kernel shape (24, 384, ), Input shape (1, 384, ), and Output shape (1, 24, ), and the ID is 34
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (24, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 24, ), Input shape (1, 24, ), and Output shape (1, 384, ), and the ID is 35
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 384, ), Input shape (900, 384, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 48)
(900, 192, ), and the ID is 36
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 37
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 38
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 39
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
40
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 41
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 42
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 43
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
(900, 192, ), and the ID is 44
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
, and the ID is 45
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 46
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 47
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
, and the ID is 48
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 49
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
50
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 51
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
(900, 192, ), and the ID is 52
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 53
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 54
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 55
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 56	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 57	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)

	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 58
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 59
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 60	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)

	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 61
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 62
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 63
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
64
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 65
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 66	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)

	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 67
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
68
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 69
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 70
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 71
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 72
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (1152, 192, ), Input shape (900, 192, ), and Output shape (900, 1152, ), and the ID is 73
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1152, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 1152, ), Input shape (1, 1152, ), and Output shape (1, 48, ), and the ID is 74
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 144)
	Allocating LowPrecision Activations Tensors with Shape of (1, 144)
Applying Conv Low-Precision for Kernel shape (1152, 48, ), Input shape (1, 48, ), and Output shape (1, 1152, ), and the ID is 75
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1152, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1152, ), Input shape (900, 1152, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 144)
	Allocating LowPrecision Activations Tensors with Shape of (900, 144)
, and the ID is 76
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 77
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 78
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 79
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
, and the ID is 80
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 81	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)

	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 82
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 83
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
84
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 85
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
, and the ID is 86
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 87
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
88
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 89
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 90
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 91
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 92
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 93
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 94
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 95
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
96
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 97
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
98
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 99
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
, and the ID is 100
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 101
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 102
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 103
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 104	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)

	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 105
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 106
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 107
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 108
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 109
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 110
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 1344, ), and the ID is 111
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 112	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)

	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 113
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 114
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 115
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 116	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)

	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 117
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 118
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 119
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
, and the ID is 120
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 121
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 122
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 123	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
(900, 224, ), and the ID is 124
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 125
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
(1, 56, ), and the ID is 126
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 127
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
128
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 129
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 130
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 131
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 132	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)

	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 133
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 134
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 135
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
, and Output shape (900, 224, ), and the ID is 136
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 137
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
138
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 139
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
, and the ID is 140
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 141	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)

	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 142
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 143
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
144
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 145
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 146
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 147
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
148
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
149
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 150
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 151
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 1344, ), Input shape (225, 1344, ), and Output shape (225, 384, ), and the ID is 152	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 176)

	Allocating LowPrecision Activations Tensors with Shape of (228, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 153
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 154
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 155
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 156
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 157
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 158
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
159
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
(225, 384, ), and the ID is 160
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 161	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 162
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 163
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
164
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
165
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 166
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 167
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 168	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)

	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 169
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 170
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 171
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
(225, 384, ), and the ID is 172
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 173	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 174
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 175
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 176	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
177
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 178
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 179
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 180
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 181
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 182
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 183
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 184
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 185
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 186
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
187
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 188
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
189
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 190
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 191
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 192
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 193
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 194
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
195
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
(225, 2304, ), and Output shape (225, 384, ), and the ID is 196
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 197	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 198	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)

	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 199
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and Output shape (225, 384, ), and the ID is 200
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 201	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 202
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and Output shape (1, 2304, ), and the ID is 203
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
204
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 205
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 206
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 207
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
(225, 384, ), and the ID is 208
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 209
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 210
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 211
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
(225, 2304, ), and Output shape (225, 384, ), and the ID is 212
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
213
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 214
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and Output shape (1, 2304, ), and the ID is 215
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 216
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 217	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
, and the ID is 218
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 219
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and Output shape (225, 384, ), and the ID is 220
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 221
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 222
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 223
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 224
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 225
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 226
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 227
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 228
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 229
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 230
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 231
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 232
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 233
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 234
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 235
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 236
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 237
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
, and the ID is 238
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 239
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
240
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 241
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 242
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 243
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 244	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)

	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 245	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 246
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 247
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 248
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 249
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
250
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 251
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (640, 2304, ), Input shape (225, 2304, ), and Output shape (225, 640, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 288)
, and the ID is 252
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 253
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 254
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 255
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
, and the ID is 256
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 257
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 258
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 259
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 260	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)

	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 261
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 262
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 263
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
(225, 3840, ), and Output shape (225, 640, ), and the ID is 264
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 265
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 266
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 267
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
, and the ID is 268
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 269
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 270
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 271
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 272
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 273
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
274
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 275
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 276
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1280, 80)
Applying Conv Low-Precision for Kernel shape (1280, 640, ), Input shape (225, 640, ), and Output shape (225, 1280, ), and the ID is 277
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 7 Number of Temporaries Tensors
	Transformed Filter Shape: (1000, 160)
	Transformed Activation Shape From: (1, 1280) To: (1, 160)
count=6 first=29639018 curr=29161726 min=29154975 max=29639018 avg=2.92494e+07 std=174565

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=6 first=29191285 curr=29193850 min=29191285 max=29240367 avg=2.92116e+07 std=16261

Inference timings in us: Init: 229007, First inference: 29639018, Warmup (avg): 2.92494e+07, Inference (avg): 2.92116e+07
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=38.5273 overall=345.219
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   27.941	   27.941	100.000%	100.000%	  2812.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   27.941	   27.941	100.000%	100.000%	  2812.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    27.941	   100.000%	   100.000%	  2812.000	        1

Timings (microseconds): count=1 curr=27941
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	            0.045	   38.580	   38.788	  0.133%	  0.133%	     0.000	        1	[efficientnetv2-l/rescaling/mul]:0
	                     ADD	           38.844	   31.754	   31.853	  0.109%	  0.242%	     0.000	        1	[efficientnetv2-l/rescaling/add]:1
	                 CONV_2D	           70.710	  165.671	  166.647	  0.571%	  0.813%	     0.000	        1	[efficientnetv2-l/stem_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/stem_conv/Conv2D]:2
	                LOGISTIC	          237.369	   17.790	   17.918	  0.061%	  0.874%	     0.000	        1	[efficientnetv2-l/stem_activation/Sigmoid]:3
	                     MUL	          255.299	  129.297	  130.209	  0.446%	  1.320%	     0.000	        1	[efficientnetv2-l/stem_activation/mul_1]:4
	                 CONV_2D	          385.520	  135.185	  134.010	  0.459%	  1.779%	     0.000	        1	[efficientnetv2-l/block1a_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1a_project_conv/Conv2D]:5
	                LOGISTIC	          519.542	   18.132	   18.015	  0.062%	  1.841%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/Sigmoid]:6
	                     MUL	          537.569	  131.501	  130.225	  0.446%	  2.287%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/mul_1]:7
	                     ADD	          667.806	  177.503	  176.405	  0.604%	  2.891%	     0.000	        1	[efficientnetv2-l/block1a_add/add]:8
	                 CONV_2D	          844.222	  134.822	  133.917	  0.459%	  3.349%	     0.000	        1	[efficientnetv2-l/block1b_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1b_project_conv/Conv2D]:9
	                LOGISTIC	          978.152	   18.081	   18.000	  0.062%	  3.411%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/Sigmoid]:10
	                     MUL	          996.164	  129.799	  129.514	  0.444%	  3.854%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/mul_1]:11
	                     ADD	         1125.690	  176.898	  176.209	  0.603%	  4.458%	     0.000	        1	[efficientnetv2-l/block1b_add/add]:12
	                 CONV_2D	         1301.911	  133.989	  133.005	  0.455%	  4.913%	     0.000	        1	[efficientnetv2-l/block1c_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1c_project_conv/Conv2D]:13
	                LOGISTIC	         1434.928	   18.056	   17.981	  0.062%	  4.975%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/Sigmoid]:14
	                     MUL	         1452.923	  129.606	  129.470	  0.443%	  5.418%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/mul_1]:15
	                     ADD	         1582.405	  175.617	  176.403	  0.604%	  6.022%	     0.000	        1	[efficientnetv2-l/block1c_add/add]:16
	                 CONV_2D	         1758.820	  132.274	  132.189	  0.453%	  6.475%	     0.000	        1	[efficientnetv2-l/block1d_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1d_project_conv/Conv2D]:17
	                LOGISTIC	         1891.021	   17.860	   17.940	  0.061%	  6.537%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/Sigmoid]:18
	                     MUL	         1908.972	  128.948	  129.230	  0.443%	  6.979%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/mul_1]:19
	                     ADD	         2038.213	  175.362	  176.212	  0.603%	  7.583%	     0.000	        1	[efficientnetv2-l/block1d_add/add]:20
	                 CONV_2D	         2214.438	   63.534	   63.614	  0.218%	  7.800%	     0.000	        1	[efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_expand_conv/Conv2D]:21
	                LOGISTIC	         2278.064	   17.878	   17.862	  0.061%	  7.862%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/Sigmoid]:22
	                     MUL	         2295.938	  128.925	  130.052	  0.445%	  8.307%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/mul_1]:23
	                 CONV_2D	         2426.003	   44.990	   45.146	  0.155%	  8.462%	     0.000	        1	[efficientnetv2-l/block2a_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_project_conv/Conv2D]:24
	                 CONV_2D	         2471.161	  102.267	  103.116	  0.353%	  8.815%	     0.000	        1	[efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_expand_conv/Conv2D]:25
	                LOGISTIC	         2574.289	   35.664	   35.827	  0.123%	  8.937%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/Sigmoid]:26
	                     MUL	         2610.128	  257.910	  261.056	  0.894%	  9.831%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                 CONV_2D	         2871.196	   41.794	   41.877	  0.143%	  9.975%	     0.000	        1	[efficientnetv2-l/block2b_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_project_conv/Conv2D]:28
	                     ADD	         2913.086	   88.403	   87.938	  0.301%	 10.276%	     0.000	        1	[efficientnetv2-l/block2b_add/add]:29
	                 CONV_2D	         3001.036	  104.053	  102.551	  0.351%	 10.627%	     0.000	        1	[efficientnetv2-l/block2c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_expand_conv/Conv2D]:30
	                LOGISTIC	         3103.599	   36.054	   35.765	  0.122%	 10.750%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/Sigmoid]:31
	                     MUL	         3139.375	  260.838	  259.711	  0.889%	 11.639%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                 CONV_2D	         3399.098	   41.932	   41.975	  0.144%	 11.783%	     0.000	        1	[efficientnetv2-l/block2c_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_project_conv/Conv2D]:33
	                     ADD	         3441.085	   88.287	   88.039	  0.302%	 12.084%	     0.000	        1	[efficientnetv2-l/block2c_add/add]:34
	                 CONV_2D	         3529.135	  103.414	  103.011	  0.353%	 12.437%	     0.000	        1	[efficientnetv2-l/block2d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_expand_conv/Conv2D]:35
	                LOGISTIC	         3632.159	   36.061	   36.035	  0.123%	 12.561%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/Sigmoid]:36
	                     MUL	         3668.205	  258.665	  259.143	  0.887%	 13.448%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                 CONV_2D	         3927.360	   41.805	   41.943	  0.144%	 13.592%	     0.000	        1	[efficientnetv2-l/block2d_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_project_conv/Conv2D]:38
	                     ADD	         3969.322	   87.739	   87.912	  0.301%	 13.893%	     0.000	        1	[efficientnetv2-l/block2d_add/add]:39
	                 CONV_2D	         4057.246	  101.757	  102.375	  0.351%	 14.243%	     0.000	        1	[efficientnetv2-l/block2e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_expand_conv/Conv2D]:40
	                LOGISTIC	         4159.633	   35.748	   35.822	  0.123%	 14.366%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/Sigmoid]:41
	                     MUL	         4195.474	  257.727	  258.705	  0.886%	 15.252%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                 CONV_2D	         4454.191	   41.838	   41.871	  0.143%	 15.395%	     0.000	        1	[efficientnetv2-l/block2e_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_project_conv/Conv2D]:43
	                     ADD	         4496.074	   87.734	   87.864	  0.301%	 15.696%	     0.000	        1	[efficientnetv2-l/block2e_add/add]:44
	                 CONV_2D	         4583.950	  102.192	  102.478	  0.351%	 16.047%	     0.000	        1	[efficientnetv2-l/block2f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_expand_conv/Conv2D]:45
	                LOGISTIC	         4686.440	   35.776	   35.883	  0.123%	 16.170%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/Sigmoid]:46
	                     MUL	         4722.336	  257.704	  259.295	  0.888%	 17.058%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                 CONV_2D	         4981.643	   42.255	   42.473	  0.145%	 17.204%	     0.000	        1	[efficientnetv2-l/block2f_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_project_conv/Conv2D]:48
	                     ADD	         5024.127	   87.669	   88.143	  0.302%	 17.505%	     0.000	        1	[efficientnetv2-l/block2f_add/add]:49
	                 CONV_2D	         5112.281	  102.701	  103.139	  0.353%	 17.859%	     0.000	        1	[efficientnetv2-l/block2g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_expand_conv/Conv2D]:50
	                LOGISTIC	         5215.435	   35.781	   35.862	  0.123%	 17.981%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/Sigmoid]:51
	                     MUL	         5251.308	  258.666	  258.548	  0.885%	 18.867%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                 CONV_2D	         5509.868	   42.702	   42.484	  0.145%	 19.012%	     0.000	        1	[efficientnetv2-l/block2g_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_project_conv/Conv2D]:53
	                     ADD	         5552.365	   88.911	   88.153	  0.302%	 19.314%	     0.000	        1	[efficientnetv2-l/block2g_add/add]:54
	                 CONV_2D	         5640.529	   25.985	   25.662	  0.088%	 19.402%	     0.000	        1	[efficientnetv2-l/block3a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_expand_conv/Conv2D]:55
	                LOGISTIC	         5666.203	    8.867	    8.918	  0.031%	 19.433%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/Sigmoid]:56
	                     MUL	         5675.132	   65.154	   64.843	  0.222%	 19.655%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/mul_1]:57
	                 CONV_2D	         5739.987	   13.389	   13.086	  0.045%	 19.700%	     0.000	        1	[efficientnetv2-l/block3a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_project_conv/Conv2D]:58
	                 CONV_2D	         5753.084	   35.713	   35.553	  0.122%	 19.821%	     0.000	        1	[efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_expand_conv/Conv2D]:59
	                LOGISTIC	         5788.650	   21.574	   14.765	  0.051%	 19.872%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/Sigmoid]:60
	                     MUL	         5803.426	   97.346	   97.088	  0.332%	 20.204%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/mul_1]:61
	                 CONV_2D	         5900.529	   12.343	   12.265	  0.042%	 20.246%	     0.000	        1	[efficientnetv2-l/block3b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_project_conv/Conv2D]:62
	                     ADD	         5912.804	   33.193	   33.002	  0.113%	 20.359%	     0.000	        1	[efficientnetv2-l/block3b_add/add]:63
	                 CONV_2D	         5945.818	   35.377	   35.157	  0.120%	 20.480%	     0.000	        1	[efficientnetv2-l/block3c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_expand_conv/Conv2D]:64
	                LOGISTIC	         5980.988	   13.423	   13.373	  0.046%	 20.526%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/Sigmoid]:65
	                     MUL	         5994.373	   97.408	   97.177	  0.333%	 20.858%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/mul_1]:66
	                 CONV_2D	         6091.561	   12.355	   12.307	  0.042%	 20.901%	     0.000	        1	[efficientnetv2-l/block3c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_project_conv/Conv2D]:67
	                     ADD	         6103.880	   33.244	   33.191	  0.114%	 21.014%	     0.000	        1	[efficientnetv2-l/block3c_add/add]:68
	                 CONV_2D	         6137.082	   35.461	   35.261	  0.121%	 21.135%	     0.000	        1	[efficientnetv2-l/block3d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_expand_conv/Conv2D]:69
	                LOGISTIC	         6172.354	   13.434	   13.432	  0.046%	 21.181%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/Sigmoid]:70
	                     MUL	         6185.802	   97.229	   97.147	  0.333%	 21.514%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/mul_1]:71
	                 CONV_2D	         6282.961	   12.148	   12.297	  0.042%	 21.556%	     0.000	        1	[efficientnetv2-l/block3d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_project_conv/Conv2D]:72
	                     ADD	         6295.271	   32.972	   33.000	  0.113%	 21.669%	     0.000	        1	[efficientnetv2-l/block3d_add/add]:73
	                 CONV_2D	         6328.283	   35.105	   35.187	  0.121%	 21.789%	     0.000	        1	[efficientnetv2-l/block3e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_expand_conv/Conv2D]:74
	                LOGISTIC	         6363.485	   13.372	   13.385	  0.046%	 21.835%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/Sigmoid]:75
	                     MUL	         6376.882	   96.606	   97.037	  0.332%	 22.167%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/mul_1]:76
	                 CONV_2D	         6473.930	   12.134	   12.201	  0.042%	 22.209%	     0.000	        1	[efficientnetv2-l/block3e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_project_conv/Conv2D]:77
	                     ADD	         6486.142	   32.815	   33.028	  0.113%	 22.322%	     0.000	        1	[efficientnetv2-l/block3e_add/add]:78
	                 CONV_2D	         6519.183	   35.175	   35.158	  0.120%	 22.443%	     0.000	        1	[efficientnetv2-l/block3f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_expand_conv/Conv2D]:79
	                LOGISTIC	         6554.353	   13.478	   13.428	  0.046%	 22.489%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/Sigmoid]:80
	                     MUL	         6567.796	   96.770	   97.210	  0.333%	 22.822%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/mul_1]:81
	                 CONV_2D	         6665.018	   12.160	   12.235	  0.042%	 22.864%	     0.000	        1	[efficientnetv2-l/block3f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_project_conv/Conv2D]:82
	                     ADD	         6677.265	   32.921	   33.019	  0.113%	 22.977%	     0.000	        1	[efficientnetv2-l/block3f_add/add]:83
	                 CONV_2D	         6710.295	   35.157	   35.155	  0.120%	 23.097%	     0.000	        1	[efficientnetv2-l/block3g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_expand_conv/Conv2D]:84
	                LOGISTIC	         6745.462	   13.356	   13.393	  0.046%	 23.143%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/Sigmoid]:85
	                     MUL	         6758.867	   96.781	   97.647	  0.334%	 23.477%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/mul_1]:86
	                 CONV_2D	         6856.526	   12.179	   12.238	  0.042%	 23.519%	     0.000	        1	[efficientnetv2-l/block3g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_project_conv/Conv2D]:87
	                     ADD	         6868.775	   32.829	   33.036	  0.113%	 23.632%	     0.000	        1	[efficientnetv2-l/block3g_add/add]:88
	                 CONV_2D	         6901.822	   36.730	   36.863	  0.126%	 23.759%	     0.000	        1	[efficientnetv2-l/block4a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_expand_conv/Conv2D]:89
	                LOGISTIC	         6938.697	   13.498	   13.433	  0.046%	 23.805%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/Sigmoid]:90
	                     MUL	         6952.141	   96.650	   96.938	  0.332%	 24.137%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/mul_1]:91
	       DEPTHWISE_CONV_2D	         7049.090	  123.061	  123.630	  0.423%	 24.560%	     0.000	        1	[efficientnetv2-l/block4a_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_dwconv2/depthwise;efficientnetv2-l/block6y_project_bn/FusedBatchNormV3]:92
	                LOGISTIC	         7172.731	    3.332	    3.366	  0.012%	 24.571%	     0.000	        1	[efficientnetv2-l/block4a_activation/Sigmoid]:93
	                     MUL	         7176.106	   24.255	   24.292	  0.083%	 24.655%	     0.000	        1	[efficientnetv2-l/block4a_activation/mul_1]:94
	                    MEAN	         7200.408	   58.213	   58.534	  0.200%	 24.855%	     0.000	        1	[efficientnetv2-l/block4a_se_squeeze/Mean]:95
	                   SHAPE	         7258.953	    0.008	    0.010	  0.000%	 24.855%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Shape]:96
	           STRIDED_SLICE	         7258.969	    0.019	    0.023	  0.000%	 24.855%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/strided_slice]:97
	                    PACK	         7258.998	    0.029	    0.029	  0.000%	 24.855%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape/shape]:98
	                 RESHAPE	         7259.034	    0.014	    0.016	  0.000%	 24.855%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape]:99
	                 CONV_2D	         7259.057	    0.043	    0.046	  0.000%	 24.856%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/BiasAdd;efficientnetv2-l/block4a_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4a_se_reduce/Conv2D]:100
	                LOGISTIC	         7259.109	    0.009	    0.009	  0.000%	 24.856%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/Sigmoid]:101
	                     MUL	         7259.124	    0.018	    0.018	  0.000%	 24.856%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/mul_1]:102
	                 CONV_2D	         7259.149	    0.030	    0.031	  0.000%	 24.856%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/BiasAdd;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_se_expand/Conv2D]:103
	                LOGISTIC	         7259.186	    0.011	    0.011	  0.000%	 24.856%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/Sigmoid]:104
	                     MUL	         7259.203	   24.256	   24.340	  0.083%	 24.939%	     0.000	        1	[efficientnetv2-l/block4a_se_excite/mul]:105
	                 CONV_2D	         7283.553	    4.984	    5.002	  0.017%	 24.956%	     0.000	        1	[efficientnetv2-l/block4a_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_project_conv/Conv2D]:106
	                 CONV_2D	         7288.564	   16.704	   16.747	  0.057%	 25.014%	     0.000	        1	[efficientnetv2-l/block4b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_expand_conv/Conv2D]:107
	                LOGISTIC	         7305.323	    6.674	    6.719	  0.023%	 25.037%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/Sigmoid]:108
	                     MUL	         7312.055	   48.368	   48.705	  0.167%	 25.203%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/mul_1]:109
	       DEPTHWISE_CONV_2D	         7360.773	    3.530	    3.614	  0.012%	 25.216%	     0.000	        1	[efficientnetv2-l/block4b_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:110
	                LOGISTIC	         7364.398	    6.704	    6.781	  0.023%	 25.239%	     0.000	        1	[efficientnetv2-l/block4b_activation/Sigmoid]:111
	                     MUL	         7371.190	   48.399	   48.461	  0.166%	 25.405%	     0.000	        1	[efficientnetv2-l/block4b_activation/mul_1]:112
	                    MEAN	         7419.661	  116.557	  116.956	  0.401%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_squeeze/Mean]:113
	                   SHAPE	         7536.628	    0.018	    0.010	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Shape]:114
	           STRIDED_SLICE	         7536.644	    0.022	    0.021	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/strided_slice]:115
	                    PACK	         7536.672	    0.030	    0.030	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape/shape]:116
	                 RESHAPE	         7536.708	    0.014	    0.014	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape]:117
	                 CONV_2D	         7536.728	    0.043	    0.053	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4b_se_reduce/Conv2D]:118
	                LOGISTIC	         7536.788	    0.009	    0.010	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/Sigmoid]:119
	                     MUL	         7536.804	    0.017	    0.017	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/mul_1]:120
	                 CONV_2D	         7536.827	    0.042	    0.047	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_se_expand/Conv2D]:121
	                LOGISTIC	         7536.880	    0.015	    0.015	  0.000%	 25.806%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/Sigmoid]:122
	                     MUL	         7536.901	   48.461	   48.840	  0.167%	 25.974%	     0.000	        1	[efficientnetv2-l/block4b_se_excite/mul]:123
	                 CONV_2D	         7585.752	    4.403	    4.473	  0.015%	 25.989%	     0.000	        1	[efficientnetv2-l/block4b_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_project_conv/Conv2D]:124
	                     ADD	         7590.234	   16.490	   16.499	  0.057%	 26.045%	     0.000	        1	[efficientnetv2-l/block4b_add/add]:125
	                 CONV_2D	         7606.743	   16.638	   16.725	  0.057%	 26.103%	     0.000	        1	[efficientnetv2-l/block4c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_expand_conv/Conv2D]:126
	                LOGISTIC	         7623.480	    6.670	    6.710	  0.023%	 26.126%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/Sigmoid]:127
	                     MUL	         7630.201	   48.350	   48.530	  0.166%	 26.292%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/mul_1]:128
	       DEPTHWISE_CONV_2D	         7678.742	    3.438	    3.541	  0.012%	 26.304%	     0.000	        1	[efficientnetv2-l/block4c_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:129
	                LOGISTIC	         7682.293	    6.730	    6.723	  0.023%	 26.327%	     0.000	        1	[efficientnetv2-l/block4c_activation/Sigmoid]:130
	                     MUL	         7689.027	   48.297	   48.548	  0.166%	 26.493%	     0.000	        1	[efficientnetv2-l/block4c_activation/mul_1]:131
	                    MEAN	         7737.587	  117.093	  117.062	  0.401%	 26.894%	     0.000	        1	[efficientnetv2-l/block4c_se_squeeze/Mean]:132
	                   SHAPE	         7854.661	    0.010	    0.009	  0.000%	 26.894%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Shape]:133
	           STRIDED_SLICE	         7854.676	    0.021	    0.021	  0.000%	 26.894%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/strided_slice]:134
	                    PACK	         7854.704	    0.029	    0.032	  0.000%	 26.894%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape/shape]:135
	                 RESHAPE	         7854.742	    0.014	    0.014	  0.000%	 26.894%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape]:136
	                 CONV_2D	         7854.762	    0.067	    0.050	  0.000%	 26.895%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4c_se_reduce/Conv2D]:137
	                LOGISTIC	         7854.819	    0.009	    0.009	  0.000%	 26.895%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/Sigmoid]:138
	                     MUL	         7854.834	    0.017	    0.018	  0.000%	 26.895%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/mul_1]:139
	                 CONV_2D	         7854.858	    0.043	    0.044	  0.000%	 26.895%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_se_expand/Conv2D]:140
	                LOGISTIC	         7854.908	    0.015	    0.019	  0.000%	 26.895%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/Sigmoid]:141
	                     MUL	         7854.934	   48.562	   48.542	  0.166%	 27.061%	     0.000	        1	[efficientnetv2-l/block4c_se_excite/mul]:142
	                 CONV_2D	         7903.487	    4.414	    4.408	  0.015%	 27.076%	     0.000	        1	[efficientnetv2-l/block4c_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_project_conv/Conv2D]:143
	                     ADD	         7907.904	   16.571	   16.523	  0.057%	 27.133%	     0.000	        1	[efficientnetv2-l/block4c_add/add]:144
	                 CONV_2D	         7924.438	   16.824	   16.752	  0.057%	 27.190%	     0.000	        1	[efficientnetv2-l/block4d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_expand_conv/Conv2D]:145
	                LOGISTIC	         7941.201	    6.797	    6.681	  0.023%	 27.213%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/Sigmoid]:146
	                     MUL	         7947.894	   49.022	   48.571	  0.166%	 27.379%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/mul_1]:147
	       DEPTHWISE_CONV_2D	         7996.476	    3.798	    3.554	  0.012%	 27.392%	     0.000	        1	[efficientnetv2-l/block4d_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:148
	                LOGISTIC	         8000.042	    6.805	    6.729	  0.023%	 27.415%	     0.000	        1	[efficientnetv2-l/block4d_activation/Sigmoid]:149
	                     MUL	         8006.782	   48.945	   48.593	  0.166%	 27.581%	     0.000	        1	[efficientnetv2-l/block4d_activation/mul_1]:150
	                    MEAN	         8055.386	  118.072	  117.381	  0.402%	 27.983%	     0.000	        1	[efficientnetv2-l/block4d_se_squeeze/Mean]:151
	                   SHAPE	         8172.778	    0.009	    0.009	  0.000%	 27.983%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Shape]:152
	           STRIDED_SLICE	         8172.793	    0.021	    0.024	  0.000%	 27.983%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/strided_slice]:153
	                    PACK	         8172.824	    0.030	    0.030	  0.000%	 27.983%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape/shape]:154
	                 RESHAPE	         8172.860	    0.014	    0.014	  0.000%	 27.983%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape]:155
	                 CONV_2D	         8172.881	    0.042	    0.051	  0.000%	 27.983%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4d_se_reduce/Conv2D]:156
	                LOGISTIC	         8172.939	    0.009	    0.012	  0.000%	 27.983%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/Sigmoid]:157
	                     MUL	         8172.958	    0.018	    0.018	  0.000%	 27.984%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/mul_1]:158
	                 CONV_2D	         8172.981	    0.043	    0.048	  0.000%	 27.984%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_se_expand/Conv2D]:159
	                LOGISTIC	         8173.036	    0.015	    0.015	  0.000%	 27.984%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/Sigmoid]:160
	                     MUL	         8173.057	   49.207	   48.727	  0.167%	 28.151%	     0.000	        1	[efficientnetv2-l/block4d_se_excite/mul]:161
	                 CONV_2D	         8221.794	    4.449	    4.421	  0.015%	 28.166%	     0.000	        1	[efficientnetv2-l/block4d_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_project_conv/Conv2D]:162
	                     ADD	         8226.227	   16.566	   16.527	  0.057%	 28.222%	     0.000	        1	[efficientnetv2-l/block4d_add/add]:163
	                 CONV_2D	         8242.764	   16.826	   16.746	  0.057%	 28.280%	     0.000	        1	[efficientnetv2-l/block4e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_expand_conv/Conv2D]:164
	                LOGISTIC	         8259.521	    6.822	    6.740	  0.023%	 28.303%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/Sigmoid]:165
	                     MUL	         8266.271	   48.757	   48.558	  0.166%	 28.469%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/mul_1]:166
	       DEPTHWISE_CONV_2D	         8314.840	    3.593	    3.563	  0.012%	 28.481%	     0.000	        1	[efficientnetv2-l/block4e_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:167
	                LOGISTIC	         8318.415	    6.694	    6.748	  0.023%	 28.504%	     0.000	        1	[efficientnetv2-l/block4e_activation/Sigmoid]:168
	                     MUL	         8325.174	   48.699	   48.583	  0.166%	 28.671%	     0.000	        1	[efficientnetv2-l/block4e_activation/mul_1]:169
	                    MEAN	         8373.769	  117.509	  117.081	  0.401%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_squeeze/Mean]:170
	                   SHAPE	         8490.861	    0.010	    0.009	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Shape]:171
	           STRIDED_SLICE	         8490.876	    0.023	    0.022	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/strided_slice]:172
	                    PACK	         8490.905	    0.030	    0.029	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape/shape]:173
	                 RESHAPE	         8490.940	    0.015	    0.017	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape]:174
	                 CONV_2D	         8490.963	    0.048	    0.046	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4e_se_reduce/Conv2D]:175
	                LOGISTIC	         8491.016	    0.010	    0.010	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/Sigmoid]:176
	                     MUL	         8491.032	    0.018	    0.018	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/mul_1]:177
	                 CONV_2D	         8491.056	    0.045	    0.048	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_se_expand/Conv2D]:178
	                LOGISTIC	         8491.110	    0.015	    0.018	  0.000%	 29.072%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/Sigmoid]:179
	                     MUL	         8491.133	   48.809	   48.674	  0.167%	 29.239%	     0.000	        1	[efficientnetv2-l/block4e_se_excite/mul]:180
	                 CONV_2D	         8539.820	    4.431	    4.409	  0.015%	 29.254%	     0.000	        1	[efficientnetv2-l/block4e_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_project_conv/Conv2D]:181
	                     ADD	         8544.238	   16.644	   16.867	  0.058%	 29.312%	     0.000	        1	[efficientnetv2-l/block4e_add/add]:182
	                 CONV_2D	         8561.117	   16.852	   16.819	  0.058%	 29.370%	     0.000	        1	[efficientnetv2-l/block4f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_expand_conv/Conv2D]:183
	                LOGISTIC	         8577.946	    6.839	    6.756	  0.023%	 29.393%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/Sigmoid]:184
	                     MUL	         8584.713	   48.820	   48.667	  0.167%	 29.559%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/mul_1]:185
	       DEPTHWISE_CONV_2D	         8633.391	    3.655	    3.566	  0.012%	 29.572%	     0.000	        1	[efficientnetv2-l/block4f_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:186
	                LOGISTIC	         8636.971	    6.674	    6.709	  0.023%	 29.595%	     0.000	        1	[efficientnetv2-l/block4f_activation/Sigmoid]:187
	                     MUL	         8643.691	   48.674	   48.579	  0.166%	 29.761%	     0.000	        1	[efficientnetv2-l/block4f_activation/mul_1]:188
	                    MEAN	         8692.280	  117.022	  117.278	  0.402%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_squeeze/Mean]:189
	                   SHAPE	         8809.569	    0.009	    0.009	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Shape]:190
	           STRIDED_SLICE	         8809.584	    0.022	    0.021	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/strided_slice]:191
	                    PACK	         8809.612	    0.030	    0.030	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape/shape]:192
	                 RESHAPE	         8809.648	    0.014	    0.014	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape]:193
	                 CONV_2D	         8809.668	    0.044	    0.052	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4f_se_reduce/Conv2D]:194
	                LOGISTIC	         8809.728	    0.010	    0.010	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/Sigmoid]:195
	                     MUL	         8809.743	    0.017	    0.017	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/mul_1]:196
	                 CONV_2D	         8809.767	    0.065	    0.055	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_se_expand/Conv2D]:197
	                LOGISTIC	         8809.828	    0.014	    0.015	  0.000%	 30.163%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/Sigmoid]:198
	                     MUL	         8809.850	   48.411	   48.592	  0.166%	 30.330%	     0.000	        1	[efficientnetv2-l/block4f_se_excite/mul]:199
	                 CONV_2D	         8858.455	    4.376	    4.402	  0.015%	 30.345%	     0.000	        1	[efficientnetv2-l/block4f_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_project_conv/Conv2D]:200
	                     ADD	         8862.867	   16.488	   16.482	  0.056%	 30.401%	     0.000	        1	[efficientnetv2-l/block4f_add/add]:201
	                 CONV_2D	         8879.358	   16.644	   16.711	  0.057%	 30.459%	     0.000	        1	[efficientnetv2-l/block4g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_expand_conv/Conv2D]:202
	                LOGISTIC	         8896.079	    6.634	    6.684	  0.023%	 30.481%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/Sigmoid]:203
	                     MUL	         8902.774	   48.299	   48.456	  0.166%	 30.647%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/mul_1]:204
	       DEPTHWISE_CONV_2D	         8951.241	    3.464	    3.500	  0.012%	 30.659%	     0.000	        1	[efficientnetv2-l/block4g_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:205
	                LOGISTIC	         8954.752	    6.725	    6.720	  0.023%	 30.682%	     0.000	        1	[efficientnetv2-l/block4g_activation/Sigmoid]:206
	                     MUL	         8961.483	   48.417	   48.543	  0.166%	 30.849%	     0.000	        1	[efficientnetv2-l/block4g_activation/mul_1]:207
	                    MEAN	         9010.039	  116.735	  117.109	  0.401%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_squeeze/Mean]:208
	                   SHAPE	         9127.159	    0.008	    0.009	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Shape]:209
	           STRIDED_SLICE	         9127.174	    0.021	    0.024	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/strided_slice]:210
	                    PACK	         9127.204	    0.030	    0.032	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape/shape]:211
	                 RESHAPE	         9127.243	    0.014	    0.014	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape]:212
	                 CONV_2D	         9127.263	    0.043	    0.050	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4g_se_reduce/Conv2D]:213
	                LOGISTIC	         9127.320	    0.009	    0.009	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/Sigmoid]:214
	                     MUL	         9127.335	    0.017	    0.018	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/mul_1]:215
	                 CONV_2D	         9127.359	    0.059	    0.049	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_se_expand/Conv2D]:216
	                LOGISTIC	         9127.414	    0.016	    0.015	  0.000%	 31.250%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/Sigmoid]:217
	                     MUL	         9127.436	   48.410	   48.641	  0.167%	 31.417%	     0.000	        1	[efficientnetv2-l/block4g_se_excite/mul]:218
	                 CONV_2D	         9176.087	    4.386	    4.405	  0.015%	 31.432%	     0.000	        1	[efficientnetv2-l/block4g_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_project_conv/Conv2D]:219
	                     ADD	         9180.502	   16.473	   16.495	  0.056%	 31.489%	     0.000	        1	[efficientnetv2-l/block4g_add/add]:220
	                 CONV_2D	         9197.007	   16.680	   16.762	  0.057%	 31.546%	     0.000	        1	[efficientnetv2-l/block4h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_expand_conv/Conv2D]:221
	                LOGISTIC	         9213.780	    6.687	    6.709	  0.023%	 31.569%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/Sigmoid]:222
	                     MUL	         9220.500	   48.328	   48.595	  0.166%	 31.735%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/mul_1]:223
	       DEPTHWISE_CONV_2D	         9269.106	    3.493	    3.592	  0.012%	 31.748%	     0.000	        1	[efficientnetv2-l/block4h_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:224
	                LOGISTIC	         9272.710	    6.703	    6.718	  0.023%	 31.771%	     0.000	        1	[efficientnetv2-l/block4h_activation/Sigmoid]:225
	                     MUL	         9279.439	   48.462	   48.626	  0.167%	 31.937%	     0.000	        1	[efficientnetv2-l/block4h_activation/mul_1]:226
	                    MEAN	         9328.077	  116.678	  117.079	  0.401%	 32.338%	     0.000	        1	[efficientnetv2-l/block4h_se_squeeze/Mean]:227
	                   SHAPE	         9445.167	    0.008	    0.009	  0.000%	 32.338%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Shape]:228
	           STRIDED_SLICE	         9445.182	    0.021	    0.022	  0.000%	 32.338%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/strided_slice]:229
	                    PACK	         9445.212	    0.029	    0.030	  0.000%	 32.338%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape/shape]:230
	                 RESHAPE	         9445.248	    0.013	    0.014	  0.000%	 32.338%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape]:231
	                 CONV_2D	         9445.268	    0.044	    0.044	  0.000%	 32.339%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4h_se_reduce/Conv2D]:232
	                LOGISTIC	         9445.319	    0.009	    0.009	  0.000%	 32.339%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/Sigmoid]:233
	                     MUL	         9445.334	    0.018	    0.020	  0.000%	 32.339%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/mul_1]:234
	                 CONV_2D	         9445.361	    0.040	    0.046	  0.000%	 32.339%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_se_expand/Conv2D]:235
	                LOGISTIC	         9445.413	    0.014	    0.015	  0.000%	 32.339%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/Sigmoid]:236
	                     MUL	         9445.434	   48.459	   48.614	  0.166%	 32.505%	     0.000	        1	[efficientnetv2-l/block4h_se_excite/mul]:237
	                 CONV_2D	         9494.059	    4.399	    4.418	  0.015%	 32.520%	     0.000	        1	[efficientnetv2-l/block4h_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_project_conv/Conv2D]:238
	                     ADD	         9498.486	   16.424	   16.544	  0.057%	 32.577%	     0.000	        1	[efficientnetv2-l/block4h_add/add]:239
	                 CONV_2D	         9515.041	   16.673	   16.788	  0.057%	 32.635%	     0.000	        1	[efficientnetv2-l/block4i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_expand_conv/Conv2D]:240
	                LOGISTIC	         9531.841	    6.717	    6.679	  0.023%	 32.658%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/Sigmoid]:241
	                     MUL	         9538.530	   48.347	   48.629	  0.167%	 32.824%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/mul_1]:242
	       DEPTHWISE_CONV_2D	         9587.171	    3.458	    3.568	  0.012%	 32.836%	     0.000	        1	[efficientnetv2-l/block4i_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:243
	                LOGISTIC	         9590.750	    6.681	    6.699	  0.023%	 32.859%	     0.000	        1	[efficientnetv2-l/block4i_activation/Sigmoid]:244
	                     MUL	         9597.460	   48.404	   48.586	  0.166%	 33.026%	     0.000	        1	[efficientnetv2-l/block4i_activation/mul_1]:245
	                    MEAN	         9646.059	  116.703	  117.104	  0.401%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_squeeze/Mean]:246
	                   SHAPE	         9763.174	    0.008	    0.009	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Shape]:247
	           STRIDED_SLICE	         9763.190	    0.020	    0.022	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/strided_slice]:248
	                    PACK	         9763.218	    0.029	    0.031	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape/shape]:249
	                 RESHAPE	         9763.256	    0.013	    0.018	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape]:250
	                 CONV_2D	         9763.281	    0.043	    0.046	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4i_se_reduce/Conv2D]:251
	                LOGISTIC	         9763.333	    0.009	    0.009	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/Sigmoid]:252
	                     MUL	         9763.349	    0.018	    0.018	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/mul_1]:253
	                 CONV_2D	         9763.373	    0.040	    0.048	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_se_expand/Conv2D]:254
	                LOGISTIC	         9763.427	    0.015	    0.015	  0.000%	 33.427%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/Sigmoid]:255
	                     MUL	         9763.448	   48.448	   48.842	  0.167%	 33.595%	     0.000	        1	[efficientnetv2-l/block4i_se_excite/mul]:256
	                 CONV_2D	         9812.302	    4.375	    4.444	  0.015%	 33.610%	     0.000	        1	[efficientnetv2-l/block4i_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_project_conv/Conv2D]:257
	                     ADD	         9816.756	   16.438	   16.659	  0.057%	 33.667%	     0.000	        1	[efficientnetv2-l/block4i_add/add]:258
	                 CONV_2D	         9833.425	   16.607	   16.827	  0.058%	 33.725%	     0.000	        1	[efficientnetv2-l/block4j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_expand_conv/Conv2D]:259
	                LOGISTIC	         9850.264	    6.689	    6.742	  0.023%	 33.748%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/Sigmoid]:260
	                     MUL	         9857.017	   48.427	   48.648	  0.167%	 33.914%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/mul_1]:261
	       DEPTHWISE_CONV_2D	         9905.676	    3.532	    3.563	  0.012%	 33.926%	     0.000	        1	[efficientnetv2-l/block4j_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_dwconv2/depthwise]:262
	                LOGISTIC	         9909.251	    6.669	    6.744	  0.023%	 33.950%	     0.000	        1	[efficientnetv2-l/block4j_activation/Sigmoid]:263
	                     MUL	         9916.006	   48.427	   48.551	  0.166%	 34.116%	     0.000	        1	[efficientnetv2-l/block4j_activation/mul_1]:264
	                    MEAN	         9964.568	  116.591	  117.138	  0.401%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_squeeze/Mean]:265
	                   SHAPE	        10081.719	    0.009	    0.009	  0.000%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Shape]:266
	           STRIDED_SLICE	        10081.736	    0.021	    0.024	  0.000%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/strided_slice]:267
	                    PACK	        10081.765	    0.029	    0.035	  0.000%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape/shape]:268
	                 RESHAPE	        10081.807	    0.013	    0.014	  0.000%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape]:269
	                 CONV_2D	        10081.826	    0.044	    0.049	  0.000%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4j_se_reduce/Conv2D]:270
	                LOGISTIC	        10081.882	    0.009	    0.009	  0.000%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/Sigmoid]:271
	                     MUL	        10081.898	    0.017	    0.018	  0.000%	 34.517%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/mul_1]:272
	                 CONV_2D	        10081.927	    0.057	    0.046	  0.000%	 34.518%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_se_expand/Conv2D]:273
	                LOGISTIC	        10081.980	    0.015	    0.015	  0.000%	 34.518%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/Sigmoid]:274
	                     MUL	        10082.001	   48.406	   48.593	  0.166%	 34.684%	     0.000	        1	[efficientnetv2-l/block4j_se_excite/mul]:275
	                 CONV_2D	        10130.604	    4.462	    4.511	  0.015%	 34.700%	     0.000	        1	[efficientnetv2-l/block4j_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_project_conv/Conv2D]:276
	                     ADD	        10135.125	   16.426	   16.495	  0.056%	 34.756%	     0.000	        1	[efficientnetv2-l/block4j_add/add]:277
	                 CONV_2D	        10151.629	   24.370	   24.472	  0.084%	 34.840%	     0.000	        1	[efficientnetv2-l/block5a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_expand_conv/Conv2D]:278
	                LOGISTIC	        10176.112	   10.100	   10.122	  0.035%	 34.875%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/Sigmoid]:279
	                     MUL	        10186.245	   72.767	   72.814	  0.249%	 35.124%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/mul_1]:280
	       DEPTHWISE_CONV_2D	        10259.069	    5.479	    5.516	  0.019%	 35.143%	     0.000	        1	[efficientnetv2-l/block5a_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_dwconv2/depthwise]:281
	                LOGISTIC	        10264.596	   10.162	   10.116	  0.035%	 35.177%	     0.000	        1	[efficientnetv2-l/block5a_activation/Sigmoid]:282
	                     MUL	        10274.724	   72.728	   72.820	  0.249%	 35.427%	     0.000	        1	[efficientnetv2-l/block5a_activation/mul_1]:283
	                    MEAN	        10347.554	  177.499	  176.073	  0.603%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_squeeze/Mean]:284
	                   SHAPE	        10523.638	    0.010	    0.009	  0.000%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Shape]:285
	           STRIDED_SLICE	        10523.654	    0.023	    0.022	  0.000%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/strided_slice]:286
	                    PACK	        10523.682	    0.030	    0.035	  0.000%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape/shape]:287
	                 RESHAPE	        10523.724	    0.015	    0.014	  0.000%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape]:288
	                 CONV_2D	        10523.744	    0.054	    0.050	  0.000%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5a_se_reduce/Conv2D]:289
	                LOGISTIC	        10523.800	    0.010	    0.012	  0.000%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/Sigmoid]:290
	                     MUL	        10523.818	    0.018	    0.018	  0.000%	 36.030%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/mul_1]:291
	                 CONV_2D	        10523.843	    0.057	    0.062	  0.000%	 36.031%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/BiasAdd;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_se_expand/Conv2D]:292
	                LOGISTIC	        10523.911	    0.018	    0.018	  0.000%	 36.031%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/Sigmoid]:293
	                     MUL	        10523.936	   73.737	   73.007	  0.250%	 36.281%	     0.000	        1	[efficientnetv2-l/block5a_se_excite/mul]:294
	                 CONV_2D	        10596.954	   10.856	   10.648	  0.036%	 36.317%	     0.000	        1	[efficientnetv2-l/block5a_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_project_conv/Conv2D]:295
	                 CONV_2D	        10607.613	   28.361	   28.280	  0.097%	 36.414%	     0.000	        1	[efficientnetv2-l/block5b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_expand_conv/Conv2D]:296
	                LOGISTIC	        10635.905	   11.719	   11.713	  0.040%	 36.454%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/Sigmoid]:297
	                     MUL	        10647.630	   85.952	   85.146	  0.292%	 36.746%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/mul_1]:298
	       DEPTHWISE_CONV_2D	        10732.787	    7.058	    6.409	  0.022%	 36.768%	     0.000	        1	[efficientnetv2-l/block5b_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:299
	                LOGISTIC	        10739.207	   11.724	   11.738	  0.040%	 36.808%	     0.000	        1	[efficientnetv2-l/block5b_activation/Sigmoid]:300
	                     MUL	        10750.958	   85.353	   85.076	  0.291%	 37.099%	     0.000	        1	[efficientnetv2-l/block5b_activation/mul_1]:301
	                    MEAN	        10836.047	  206.120	  205.493	  0.704%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_squeeze/Mean]:302
	                   SHAPE	        11041.551	    0.008	    0.009	  0.000%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Shape]:303
	           STRIDED_SLICE	        11041.566	    0.022	    0.022	  0.000%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/strided_slice]:304
	                    PACK	        11041.595	    0.029	    0.030	  0.000%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape/shape]:305
	                 RESHAPE	        11041.631	    0.014	    0.014	  0.000%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape]:306
	                 CONV_2D	        11041.652	    0.047	    0.056	  0.000%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5b_se_reduce/Conv2D]:307
	                LOGISTIC	        11041.714	    0.028	    0.013	  0.000%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/Sigmoid]:308
	                     MUL	        11041.733	    0.020	    0.021	  0.000%	 37.803%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/mul_1]:309
	                 CONV_2D	        11041.760	    0.064	    0.067	  0.000%	 37.804%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_se_expand/Conv2D]:310
	                LOGISTIC	        11041.834	    0.021	    0.020	  0.000%	 37.804%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/Sigmoid]:311
	                     MUL	        11041.860	   85.343	   85.116	  0.291%	 38.095%	     0.000	        1	[efficientnetv2-l/block5b_se_excite/mul]:312
	                 CONV_2D	        11126.988	    9.901	    9.808	  0.034%	 38.129%	     0.000	        1	[efficientnetv2-l/block5b_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_project_conv/Conv2D]:313
	                     ADD	        11136.806	   19.335	   19.309	  0.066%	 38.195%	     0.000	        1	[efficientnetv2-l/block5b_add/add]:314
	                 CONV_2D	        11156.126	   28.380	   28.288	  0.097%	 38.292%	     0.000	        1	[efficientnetv2-l/block5c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_expand_conv/Conv2D]:315
	                LOGISTIC	        11184.425	   11.718	   11.759	  0.040%	 38.332%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/Sigmoid]:316
	                     MUL	        11196.195	   84.688	   84.961	  0.291%	 38.623%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/mul_1]:317
	       DEPTHWISE_CONV_2D	        11281.168	    6.218	    6.357	  0.022%	 38.645%	     0.000	        1	[efficientnetv2-l/block5c_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:318
	                LOGISTIC	        11287.537	   11.774	   11.767	  0.040%	 38.685%	     0.000	        1	[efficientnetv2-l/block5c_activation/Sigmoid]:319
	                     MUL	        11299.315	   84.708	   85.104	  0.291%	 38.977%	     0.000	        1	[efficientnetv2-l/block5c_activation/mul_1]:320
	                    MEAN	        11384.431	  204.282	  205.008	  0.702%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_squeeze/Mean]:321
	                   SHAPE	        11589.451	    0.008	    0.009	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Shape]:322
	           STRIDED_SLICE	        11589.466	    0.021	    0.022	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/strided_slice]:323
	                    PACK	        11589.494	    0.040	    0.037	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape/shape]:324
	                 RESHAPE	        11589.538	    0.014	    0.014	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape]:325
	                 CONV_2D	        11589.558	    0.049	    0.059	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5c_se_reduce/Conv2D]:326
	                LOGISTIC	        11589.623	    0.010	    0.010	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/Sigmoid]:327
	                     MUL	        11589.639	    0.020	    0.021	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/mul_1]:328
	                 CONV_2D	        11589.666	    0.062	    0.066	  0.000%	 39.679%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_se_expand/Conv2D]:329
	                LOGISTIC	        11589.738	    0.021	    0.020	  0.000%	 39.680%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/Sigmoid]:330
	                     MUL	        11589.765	   84.658	   84.992	  0.291%	 39.971%	     0.000	        1	[efficientnetv2-l/block5c_se_excite/mul]:331
	                 CONV_2D	        11674.768	   10.245	   10.223	  0.035%	 40.006%	     0.000	        1	[efficientnetv2-l/block5c_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_project_conv/Conv2D]:332
	                     ADD	        11685.003	   19.161	   19.240	  0.066%	 40.072%	     0.000	        1	[efficientnetv2-l/block5c_add/add]:333
	                 CONV_2D	        11704.253	   28.175	   28.260	  0.097%	 40.168%	     0.000	        1	[efficientnetv2-l/block5d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_expand_conv/Conv2D]:334
	                LOGISTIC	        11732.524	   11.950	   11.962	  0.041%	 40.209%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/Sigmoid]:335
	                     MUL	        11744.497	   84.867	   84.952	  0.291%	 40.500%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/mul_1]:336
	       DEPTHWISE_CONV_2D	        11829.460	    6.315	    6.321	  0.022%	 40.522%	     0.000	        1	[efficientnetv2-l/block5d_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:337
	                LOGISTIC	        11835.793	   11.813	   11.817	  0.040%	 40.562%	     0.000	        1	[efficientnetv2-l/block5d_activation/Sigmoid]:338
	                     MUL	        11847.621	   84.850	   84.860	  0.291%	 40.853%	     0.000	        1	[efficientnetv2-l/block5d_activation/mul_1]:339
	                    MEAN	        11932.493	  204.982	  205.558	  0.704%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_squeeze/Mean]:340
	                   SHAPE	        12138.061	    0.008	    0.009	  0.000%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Shape]:341
	           STRIDED_SLICE	        12138.076	    0.022	    0.022	  0.000%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/strided_slice]:342
	                    PACK	        12138.105	    0.029	    0.031	  0.000%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape/shape]:343
	                 RESHAPE	        12138.143	    0.015	    0.014	  0.000%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape]:344
	                 CONV_2D	        12138.164	    0.047	    0.054	  0.000%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5d_se_reduce/Conv2D]:345
	                LOGISTIC	        12138.225	    0.009	    0.010	  0.000%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/Sigmoid]:346
	                     MUL	        12138.240	    0.020	    0.021	  0.000%	 41.557%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/mul_1]:347
	                 CONV_2D	        12138.267	    0.081	    0.067	  0.000%	 41.558%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_se_expand/Conv2D]:348
	                LOGISTIC	        12138.341	    0.019	    0.025	  0.000%	 41.558%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/Sigmoid]:349
	                     MUL	        12138.371	   84.638	   84.945	  0.291%	 41.849%	     0.000	        1	[efficientnetv2-l/block5d_se_excite/mul]:350
	                 CONV_2D	        12223.327	    9.669	    9.757	  0.033%	 41.882%	     0.000	        1	[efficientnetv2-l/block5d_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_project_conv/Conv2D]:351
	                     ADD	        12233.096	   19.209	   19.364	  0.066%	 41.948%	     0.000	        1	[efficientnetv2-l/block5d_add/add]:352
	                 CONV_2D	        12252.470	   28.141	   28.278	  0.097%	 42.045%	     0.000	        1	[efficientnetv2-l/block5e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_expand_conv/Conv2D]:353
	                LOGISTIC	        12280.759	   11.616	   11.803	  0.040%	 42.086%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/Sigmoid]:354
	                     MUL	        12292.573	   84.776	   85.445	  0.293%	 42.378%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/mul_1]:355
	       DEPTHWISE_CONV_2D	        12378.033	    6.212	    6.299	  0.022%	 42.400%	     0.000	        1	[efficientnetv2-l/block5e_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:356
	                LOGISTIC	        12384.344	   11.680	   11.719	  0.040%	 42.440%	     0.000	        1	[efficientnetv2-l/block5e_activation/Sigmoid]:357
	                     MUL	        12396.074	   84.743	   85.013	  0.291%	 42.731%	     0.000	        1	[efficientnetv2-l/block5e_activation/mul_1]:358
	                    MEAN	        12481.099	  204.309	  205.143	  0.703%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_squeeze/Mean]:359
	                   SHAPE	        12686.253	    0.008	    0.009	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Shape]:360
	           STRIDED_SLICE	        12686.268	    0.022	    0.024	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/strided_slice]:361
	                    PACK	        12686.298	    0.029	    0.030	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape/shape]:362
	                 RESHAPE	        12686.335	    0.014	    0.014	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape]:363
	                 CONV_2D	        12686.355	    0.048	    0.051	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5e_se_reduce/Conv2D]:364
	                LOGISTIC	        12686.412	    0.009	    0.010	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/Sigmoid]:365
	                     MUL	        12686.428	    0.020	    0.021	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/mul_1]:366
	                 CONV_2D	        12686.455	    0.081	    0.073	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_se_expand/Conv2D]:367
	                LOGISTIC	        12686.534	    0.020	    0.020	  0.000%	 43.434%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/Sigmoid]:368
	                     MUL	        12686.560	   85.062	   85.001	  0.291%	 43.726%	     0.000	        1	[efficientnetv2-l/block5e_se_excite/mul]:369
	                 CONV_2D	        12771.573	    9.736	    9.746	  0.033%	 43.759%	     0.000	        1	[efficientnetv2-l/block5e_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_project_conv/Conv2D]:370
	                     ADD	        12781.330	   19.263	   19.251	  0.066%	 43.825%	     0.000	        1	[efficientnetv2-l/block5e_add/add]:371
	                 CONV_2D	        12800.591	   28.177	   28.235	  0.097%	 43.922%	     0.000	        1	[efficientnetv2-l/block5f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_expand_conv/Conv2D]:372
	                LOGISTIC	        12828.837	   11.899	   11.787	  0.040%	 43.962%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/Sigmoid]:373
	                     MUL	        12840.635	   85.513	   85.002	  0.291%	 44.253%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/mul_1]:374
	       DEPTHWISE_CONV_2D	        12925.649	    6.661	    6.242	  0.021%	 44.274%	     0.000	        1	[efficientnetv2-l/block5f_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:375
	                LOGISTIC	        12931.903	   11.803	   11.765	  0.040%	 44.315%	     0.000	        1	[efficientnetv2-l/block5f_activation/Sigmoid]:376
	                     MUL	        12943.680	   90.201	   85.831	  0.294%	 44.609%	     0.000	        1	[efficientnetv2-l/block5f_activation/mul_1]:377
	                    MEAN	        13029.522	  207.456	  206.357	  0.707%	 45.315%	     0.000	        1	[efficientnetv2-l/block5f_se_squeeze/Mean]:378
	                   SHAPE	        13235.890	    0.010	    0.009	  0.000%	 45.315%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Shape]:379
	           STRIDED_SLICE	        13235.906	    0.021	    0.024	  0.000%	 45.315%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/strided_slice]:380
	                    PACK	        13235.936	    0.050	    0.036	  0.000%	 45.316%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape/shape]:381
	                 RESHAPE	        13235.979	    0.015	    0.014	  0.000%	 45.316%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape]:382
	                 CONV_2D	        13235.999	    0.049	    0.049	  0.000%	 45.316%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5f_se_reduce/Conv2D]:383
	                LOGISTIC	        13236.056	    0.009	    0.009	  0.000%	 45.316%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/Sigmoid]:384
	                     MUL	        13236.071	    0.022	    0.021	  0.000%	 45.316%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/mul_1]:385
	                 CONV_2D	        13236.098	    0.065	    0.068	  0.000%	 45.316%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_se_expand/Conv2D]:386
	                LOGISTIC	        13236.176	    0.020	    0.020	  0.000%	 45.316%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/Sigmoid]:387
	                     MUL	        13236.210	   85.289	   85.121	  0.292%	 45.608%	     0.000	        1	[efficientnetv2-l/block5f_se_excite/mul]:388
	                 CONV_2D	        13321.343	   10.342	   10.228	  0.035%	 45.643%	     0.000	        1	[efficientnetv2-l/block5f_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_project_conv/Conv2D]:389
	                     ADD	        13331.581	   19.349	   19.322	  0.066%	 45.709%	     0.000	        1	[efficientnetv2-l/block5f_add/add]:390
	                 CONV_2D	        13350.914	   28.409	   28.297	  0.097%	 45.806%	     0.000	        1	[efficientnetv2-l/block5g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_expand_conv/Conv2D]:391
	                LOGISTIC	        13379.222	   11.723	   11.801	  0.040%	 45.846%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/Sigmoid]:392
	                     MUL	        13391.034	   85.385	   85.161	  0.292%	 46.138%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/mul_1]:393
	       DEPTHWISE_CONV_2D	        13476.207	    6.484	    6.509	  0.022%	 46.160%	     0.000	        1	[efficientnetv2-l/block5g_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:394
	                LOGISTIC	        13482.727	   11.664	   11.777	  0.040%	 46.201%	     0.000	        1	[efficientnetv2-l/block5g_activation/Sigmoid]:395
	                     MUL	        13494.515	   85.360	   85.050	  0.291%	 46.492%	     0.000	        1	[efficientnetv2-l/block5g_activation/mul_1]:396
	                    MEAN	        13579.577	  205.450	  205.116	  0.702%	 47.194%	     0.000	        1	[efficientnetv2-l/block5g_se_squeeze/Mean]:397
	                   SHAPE	        13784.704	    0.008	    0.009	  0.000%	 47.194%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Shape]:398
	           STRIDED_SLICE	        13784.719	    0.021	    0.021	  0.000%	 47.194%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/strided_slice]:399
	                    PACK	        13784.747	    0.031	    0.030	  0.000%	 47.194%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape/shape]:400
	                 RESHAPE	        13784.783	    0.014	    0.014	  0.000%	 47.194%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape]:401
	                 CONV_2D	        13784.804	    0.048	    0.052	  0.000%	 47.195%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5g_se_reduce/Conv2D]:402
	                LOGISTIC	        13784.862	    0.009	    0.009	  0.000%	 47.195%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/Sigmoid]:403
	                     MUL	        13784.877	    0.021	    0.021	  0.000%	 47.195%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/mul_1]:404
	                 CONV_2D	        13784.904	    0.088	    0.074	  0.000%	 47.195%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_se_expand/Conv2D]:405
	                LOGISTIC	        13784.985	    0.020	    0.020	  0.000%	 47.195%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/Sigmoid]:406
	                     MUL	        13785.012	   85.412	   85.115	  0.291%	 47.487%	     0.000	        1	[efficientnetv2-l/block5g_se_excite/mul]:407
	                 CONV_2D	        13870.141	    9.832	    9.773	  0.033%	 47.520%	     0.000	        1	[efficientnetv2-l/block5g_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_project_conv/Conv2D]:408
	                     ADD	        13879.926	   19.304	   19.254	  0.066%	 47.586%	     0.000	        1	[efficientnetv2-l/block5g_add/add]:409
	                 CONV_2D	        13899.190	   28.358	   28.314	  0.097%	 47.683%	     0.000	        1	[efficientnetv2-l/block5h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_expand_conv/Conv2D]:410
	                LOGISTIC	        13927.515	   11.762	   11.782	  0.040%	 47.723%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/Sigmoid]:411
	                     MUL	        13939.308	   84.609	   84.990	  0.291%	 48.014%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/mul_1]:412
	       DEPTHWISE_CONV_2D	        14024.309	    6.165	    6.368	  0.022%	 48.036%	     0.000	        1	[efficientnetv2-l/block5h_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:413
	                LOGISTIC	        14030.689	   11.710	   11.730	  0.040%	 48.076%	     0.000	        1	[efficientnetv2-l/block5h_activation/Sigmoid]:414
	                     MUL	        14042.430	   84.585	   85.246	  0.292%	 48.368%	     0.000	        1	[efficientnetv2-l/block5h_activation/mul_1]:415
	                    MEAN	        14127.688	  204.627	  205.732	  0.705%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_squeeze/Mean]:416
	                   SHAPE	        14333.430	    0.008	    0.009	  0.000%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Shape]:417
	           STRIDED_SLICE	        14333.445	    0.022	    0.028	  0.000%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/strided_slice]:418
	                    PACK	        14333.480	    0.043	    0.032	  0.000%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape/shape]:419
	                 RESHAPE	        14333.519	    0.014	    0.014	  0.000%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape]:420
	                 CONV_2D	        14333.539	    0.047	    0.048	  0.000%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5h_se_reduce/Conv2D]:421
	                LOGISTIC	        14333.593	    0.009	    0.009	  0.000%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/Sigmoid]:422
	                     MUL	        14333.608	    0.021	    0.020	  0.000%	 49.073%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/mul_1]:423
	                 CONV_2D	        14333.635	    0.061	    0.068	  0.000%	 49.074%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_se_expand/Conv2D]:424
	                LOGISTIC	        14333.709	    0.021	    0.020	  0.000%	 49.074%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/Sigmoid]:425
	                     MUL	        14333.736	   84.508	   84.881	  0.291%	 49.364%	     0.000	        1	[efficientnetv2-l/block5h_se_excite/mul]:426
	                 CONV_2D	        14418.628	    9.701	    9.753	  0.033%	 49.398%	     0.000	        1	[efficientnetv2-l/block5h_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_project_conv/Conv2D]:427
	                     ADD	        14428.392	   19.176	   19.262	  0.066%	 49.464%	     0.000	        1	[efficientnetv2-l/block5h_add/add]:428
	                 CONV_2D	        14447.665	   28.124	   28.255	  0.097%	 49.560%	     0.000	        1	[efficientnetv2-l/block5i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_expand_conv/Conv2D]:429
	                LOGISTIC	        14475.931	   11.775	   11.763	  0.040%	 49.601%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/Sigmoid]:430
	                     MUL	        14487.705	   84.725	   85.150	  0.292%	 49.892%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/mul_1]:431
	       DEPTHWISE_CONV_2D	        14572.867	    6.281	    6.448	  0.022%	 49.914%	     0.000	        1	[efficientnetv2-l/block5i_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:432
	                LOGISTIC	        14579.326	   11.803	   11.802	  0.040%	 49.955%	     0.000	        1	[efficientnetv2-l/block5i_activation/Sigmoid]:433
	                     MUL	        14591.143	   84.607	   84.949	  0.291%	 50.246%	     0.000	        1	[efficientnetv2-l/block5i_activation/mul_1]:434
	                    MEAN	        14676.103	  204.049	  205.239	  0.703%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_squeeze/Mean]:435
	                   SHAPE	        14881.353	    0.009	    0.009	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Shape]:436
	           STRIDED_SLICE	        14881.368	    0.022	    0.024	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/strided_slice]:437
	                    PACK	        14881.398	    0.029	    0.029	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape/shape]:438
	                 RESHAPE	        14881.434	    0.014	    0.014	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape]:439
	                 CONV_2D	        14881.454	    0.048	    0.055	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5i_se_reduce/Conv2D]:440
	                LOGISTIC	        14881.516	    0.009	    0.009	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/Sigmoid]:441
	                     MUL	        14881.532	    0.020	    0.021	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/mul_1]:442
	                 CONV_2D	        14881.558	    0.061	    0.074	  0.000%	 50.949%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_se_expand/Conv2D]:443
	                LOGISTIC	        14881.639	    0.019	    0.020	  0.000%	 50.950%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/Sigmoid]:444
	                     MUL	        14881.665	   84.665	   84.846	  0.291%	 51.240%	     0.000	        1	[efficientnetv2-l/block5i_se_excite/mul]:445
	                 CONV_2D	        14966.522	   10.133	   10.227	  0.035%	 51.275%	     0.000	        1	[efficientnetv2-l/block5i_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_project_conv/Conv2D]:446
	                     ADD	        14976.765	   19.143	   19.250	  0.066%	 51.341%	     0.000	        1	[efficientnetv2-l/block5i_add/add]:447
	                 CONV_2D	        14996.024	   28.197	   28.351	  0.097%	 51.438%	     0.000	        1	[efficientnetv2-l/block5j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_expand_conv/Conv2D]:448
	                LOGISTIC	        15024.393	   11.769	   11.776	  0.040%	 51.478%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/Sigmoid]:449
	                     MUL	        15036.181	   84.579	   85.018	  0.291%	 51.770%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/mul_1]:450
	       DEPTHWISE_CONV_2D	        15121.210	    6.142	    6.308	  0.022%	 51.791%	     0.000	        1	[efficientnetv2-l/block5j_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:451
	                LOGISTIC	        15127.530	   11.777	   11.783	  0.040%	 51.832%	     0.000	        1	[efficientnetv2-l/block5j_activation/Sigmoid]:452
	                     MUL	        15139.326	   84.743	   84.932	  0.291%	 52.122%	     0.000	        1	[efficientnetv2-l/block5j_activation/mul_1]:453
	                    MEAN	        15224.270	  205.602	  205.346	  0.703%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_squeeze/Mean]:454
	                   SHAPE	        15429.628	    0.009	    0.009	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Shape]:455
	           STRIDED_SLICE	        15429.643	    0.022	    0.022	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/strided_slice]:456
	                    PACK	        15429.671	    0.031	    0.031	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape/shape]:457
	                 RESHAPE	        15429.709	    0.014	    0.016	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape]:458
	                 CONV_2D	        15429.731	    0.050	    0.052	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5j_se_reduce/Conv2D]:459
	                LOGISTIC	        15429.789	    0.010	    0.010	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/Sigmoid]:460
	                     MUL	        15429.805	    0.022	    0.025	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/mul_1]:461
	                 CONV_2D	        15429.836	    0.062	    0.071	  0.000%	 52.826%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_se_expand/Conv2D]:462
	                LOGISTIC	        15429.914	    0.021	    0.020	  0.000%	 52.827%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/Sigmoid]:463
	                     MUL	        15429.941	   85.486	   85.016	  0.291%	 53.118%	     0.000	        1	[efficientnetv2-l/block5j_se_excite/mul]:464
	                 CONV_2D	        15514.969	    9.929	    9.825	  0.034%	 53.151%	     0.000	        1	[efficientnetv2-l/block5j_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_project_conv/Conv2D]:465
	                     ADD	        15524.804	   19.490	   19.378	  0.066%	 53.218%	     0.000	        1	[efficientnetv2-l/block5j_add/add]:466
	                 CONV_2D	        15544.192	   28.569	   28.320	  0.097%	 53.315%	     0.000	        1	[efficientnetv2-l/block5k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_expand_conv/Conv2D]:467
	                LOGISTIC	        15572.524	   11.808	   11.829	  0.041%	 53.355%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/Sigmoid]:468
	                     MUL	        15584.364	   85.535	   85.083	  0.291%	 53.647%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/mul_1]:469
	       DEPTHWISE_CONV_2D	        15669.459	    7.004	    6.479	  0.022%	 53.669%	     0.000	        1	[efficientnetv2-l/block5k_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:470
	                LOGISTIC	        15675.950	   11.877	   11.786	  0.040%	 53.709%	     0.000	        1	[efficientnetv2-l/block5k_activation/Sigmoid]:471
	                     MUL	        15687.747	   85.441	   85.082	  0.291%	 54.001%	     0.000	        1	[efficientnetv2-l/block5k_activation/mul_1]:472
	                    MEAN	        15772.844	  205.732	  205.230	  0.703%	 54.703%	     0.000	        1	[efficientnetv2-l/block5k_se_squeeze/Mean]:473
	                   SHAPE	        15978.085	    0.009	    0.010	  0.000%	 54.703%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Shape]:474
	           STRIDED_SLICE	        15978.101	    0.022	    0.024	  0.000%	 54.703%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/strided_slice]:475
	                    PACK	        15978.131	    0.030	    0.034	  0.000%	 54.704%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape/shape]:476
	                 RESHAPE	        15978.172	    0.014	    0.014	  0.000%	 54.704%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape]:477
	                 CONV_2D	        15978.192	    0.048	    0.051	  0.000%	 54.704%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5k_se_reduce/Conv2D]:478
	                LOGISTIC	        15978.251	    0.010	    0.010	  0.000%	 54.704%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/Sigmoid]:479
	                     MUL	        15978.266	    0.021	    0.021	  0.000%	 54.704%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/mul_1]:480
	                 CONV_2D	        15978.293	    0.059	    0.067	  0.000%	 54.704%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_se_expand/Conv2D]:481
	                LOGISTIC	        15978.366	    0.020	    0.020	  0.000%	 54.704%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/Sigmoid]:482
	                     MUL	        15978.392	   85.304	   84.903	  0.291%	 54.995%	     0.000	        1	[efficientnetv2-l/block5k_se_excite/mul]:483
	                 CONV_2D	        16063.306	    9.827	    9.762	  0.033%	 55.028%	     0.000	        1	[efficientnetv2-l/block5k_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_project_conv/Conv2D]:484
	                     ADD	        16073.078	   19.319	   19.256	  0.066%	 55.094%	     0.000	        1	[efficientnetv2-l/block5k_add/add]:485
	                 CONV_2D	        16092.344	   28.444	   28.248	  0.097%	 55.191%	     0.000	        1	[efficientnetv2-l/block5l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_expand_conv/Conv2D]:486
	                LOGISTIC	        16120.604	   11.703	   11.694	  0.040%	 55.231%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/Sigmoid]:487
	                     MUL	        16132.309	   84.932	   84.900	  0.291%	 55.522%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/mul_1]:488
	       DEPTHWISE_CONV_2D	        16217.222	    6.103	    6.171	  0.021%	 55.543%	     0.000	        1	[efficientnetv2-l/block5l_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:489
	                LOGISTIC	        16223.406	   11.714	   11.767	  0.040%	 55.583%	     0.000	        1	[efficientnetv2-l/block5l_activation/Sigmoid]:490
	                     MUL	        16235.184	   84.727	   84.889	  0.291%	 55.874%	     0.000	        1	[efficientnetv2-l/block5l_activation/mul_1]:491
	                    MEAN	        16320.085	  204.590	  205.300	  0.703%	 56.577%	     0.000	        1	[efficientnetv2-l/block5l_se_squeeze/Mean]:492
	                   SHAPE	        16525.396	    0.009	    0.008	  0.000%	 56.577%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Shape]:493
	           STRIDED_SLICE	        16525.411	    0.021	    0.022	  0.000%	 56.577%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/strided_slice]:494
	                    PACK	        16525.439	    0.030	    0.033	  0.000%	 56.577%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape/shape]:495
	                 RESHAPE	        16525.479	    0.014	    0.018	  0.000%	 56.577%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape]:496
	                 CONV_2D	        16525.503	    0.065	    0.059	  0.000%	 56.578%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5l_se_reduce/Conv2D]:497
	                LOGISTIC	        16525.569	    0.010	    0.010	  0.000%	 56.578%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/Sigmoid]:498
	                     MUL	        16525.584	    0.021	    0.021	  0.000%	 56.578%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/mul_1]:499
	                 CONV_2D	        16525.611	    0.061	    0.062	  0.000%	 56.578%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_se_expand/Conv2D]:500
	                LOGISTIC	        16525.679	    0.020	    0.019	  0.000%	 56.578%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/Sigmoid]:501
	                     MUL	        16525.705	   84.676	   85.055	  0.291%	 56.869%	     0.000	        1	[efficientnetv2-l/block5l_se_excite/mul]:502
	                 CONV_2D	        16610.771	   10.148	   10.210	  0.035%	 56.904%	     0.000	        1	[efficientnetv2-l/block5l_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_project_conv/Conv2D]:503
	                     ADD	        16620.992	   19.212	   19.276	  0.066%	 56.970%	     0.000	        1	[efficientnetv2-l/block5l_add/add]:504
	                 CONV_2D	        16640.278	   28.108	   28.223	  0.097%	 57.067%	     0.000	        1	[efficientnetv2-l/block5m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_expand_conv/Conv2D]:505
	                LOGISTIC	        16668.512	   11.750	   11.778	  0.040%	 57.107%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/Sigmoid]:506
	                     MUL	        16680.301	   84.568	   85.031	  0.291%	 57.398%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/mul_1]:507
	       DEPTHWISE_CONV_2D	        16765.343	    6.244	    6.302	  0.022%	 57.420%	     0.000	        1	[efficientnetv2-l/block5m_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:508
	                LOGISTIC	        16771.657	   11.735	   11.769	  0.040%	 57.460%	     0.000	        1	[efficientnetv2-l/block5m_activation/Sigmoid]:509
	                     MUL	        16783.437	   84.704	   84.819	  0.290%	 57.751%	     0.000	        1	[efficientnetv2-l/block5m_activation/mul_1]:510
	                    MEAN	        16868.268	  204.249	  204.911	  0.702%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_squeeze/Mean]:511
	                   SHAPE	        17073.190	    0.009	    0.009	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Shape]:512
	           STRIDED_SLICE	        17073.205	    0.022	    0.023	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/strided_slice]:513
	                    PACK	        17073.235	    0.029	    0.037	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape/shape]:514
	                 RESHAPE	        17073.279	    0.014	    0.014	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape]:515
	                 CONV_2D	        17073.299	    0.047	    0.049	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5m_se_reduce/Conv2D]:516
	                LOGISTIC	        17073.354	    0.009	    0.009	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/Sigmoid]:517
	                     MUL	        17073.370	    0.020	    0.021	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/mul_1]:518
	                 CONV_2D	        17073.397	    0.059	    0.071	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_se_expand/Conv2D]:519
	                LOGISTIC	        17073.475	    0.019	    0.020	  0.000%	 58.453%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/Sigmoid]:520
	                     MUL	        17073.501	   84.506	   85.023	  0.291%	 58.745%	     0.000	        1	[efficientnetv2-l/block5m_se_excite/mul]:521
	                 CONV_2D	        17158.537	    9.857	    9.849	  0.034%	 58.778%	     0.000	        1	[efficientnetv2-l/block5m_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_project_conv/Conv2D]:522
	                     ADD	        17168.399	   19.136	   19.461	  0.067%	 58.845%	     0.000	        1	[efficientnetv2-l/block5m_add/add]:523
	                 CONV_2D	        17187.873	   28.212	   29.738	  0.102%	 58.947%	     0.000	        1	[efficientnetv2-l/block5n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_expand_conv/Conv2D]:524
	                LOGISTIC	        17217.624	   11.698	   11.748	  0.040%	 58.987%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/Sigmoid]:525
	                     MUL	        17229.383	   84.630	   85.002	  0.291%	 59.278%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/mul_1]:526
	       DEPTHWISE_CONV_2D	        17314.396	    6.229	    6.239	  0.021%	 59.299%	     0.000	        1	[efficientnetv2-l/block5n_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:527
	                LOGISTIC	        17320.647	   11.985	   11.932	  0.041%	 59.340%	     0.000	        1	[efficientnetv2-l/block5n_activation/Sigmoid]:528
	                     MUL	        17332.591	   84.609	   84.811	  0.290%	 59.631%	     0.000	        1	[efficientnetv2-l/block5n_activation/mul_1]:529
	                    MEAN	        17417.412	  204.724	  205.398	  0.703%	 60.334%	     0.000	        1	[efficientnetv2-l/block5n_se_squeeze/Mean]:530
	                   SHAPE	        17622.823	    0.009	    0.009	  0.000%	 60.334%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Shape]:531
	           STRIDED_SLICE	        17622.838	    0.021	    0.022	  0.000%	 60.334%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/strided_slice]:532
	                    PACK	        17622.866	    0.030	    0.030	  0.000%	 60.334%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape/shape]:533
	                 RESHAPE	        17622.903	    0.014	    0.014	  0.000%	 60.334%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape]:534
	                 CONV_2D	        17622.926	    0.048	    0.053	  0.000%	 60.335%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5n_se_reduce/Conv2D]:535
	                LOGISTIC	        17622.986	    0.009	    0.010	  0.000%	 60.335%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/Sigmoid]:536
	                     MUL	        17623.002	    0.019	    0.025	  0.000%	 60.335%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/mul_1]:537
	                 CONV_2D	        17623.034	    0.062	    0.066	  0.000%	 60.335%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_se_expand/Conv2D]:538
	                LOGISTIC	        17623.106	    0.020	    0.022	  0.000%	 60.335%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/Sigmoid]:539
	                     MUL	        17623.134	   84.680	   84.882	  0.291%	 60.626%	     0.000	        1	[efficientnetv2-l/block5n_se_excite/mul]:540
	                 CONV_2D	        17708.029	    9.920	    9.795	  0.034%	 60.659%	     0.000	        1	[efficientnetv2-l/block5n_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_project_conv/Conv2D]:541
	                     ADD	        17717.835	   19.250	   19.265	  0.066%	 60.725%	     0.000	        1	[efficientnetv2-l/block5n_add/add]:542
	                 CONV_2D	        17737.110	   28.127	   28.258	  0.097%	 60.822%	     0.000	        1	[efficientnetv2-l/block5o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_expand_conv/Conv2D]:543
	                LOGISTIC	        17765.378	   11.685	   11.712	  0.040%	 60.862%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/Sigmoid]:544
	                     MUL	        17777.101	   84.909	   84.842	  0.291%	 61.153%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/mul_1]:545
	       DEPTHWISE_CONV_2D	        17861.954	    6.544	    6.356	  0.022%	 61.174%	     0.000	        1	[efficientnetv2-l/block5o_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:546
	                LOGISTIC	        17868.322	   11.800	   11.735	  0.040%	 61.215%	     0.000	        1	[efficientnetv2-l/block5o_activation/Sigmoid]:547
	                     MUL	        17880.067	   85.768	   85.096	  0.291%	 61.506%	     0.000	        1	[efficientnetv2-l/block5o_activation/mul_1]:548
	                    MEAN	        17965.174	  206.972	  205.605	  0.704%	 62.210%	     0.000	        1	[efficientnetv2-l/block5o_se_squeeze/Mean]:549
	                   SHAPE	        18170.790	    0.010	    0.009	  0.000%	 62.210%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Shape]:550
	           STRIDED_SLICE	        18170.808	    0.038	    0.025	  0.000%	 62.210%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/strided_slice]:551
	                    PACK	        18170.840	    0.030	    0.031	  0.000%	 62.210%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape/shape]:552
	                 RESHAPE	        18170.877	    0.014	    0.014	  0.000%	 62.210%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape]:553
	                 CONV_2D	        18170.897	    0.049	    0.049	  0.000%	 62.211%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5o_se_reduce/Conv2D]:554
	                LOGISTIC	        18170.952	    0.009	    0.010	  0.000%	 62.211%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/Sigmoid]:555
	                     MUL	        18170.968	    0.021	    0.021	  0.000%	 62.211%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/mul_1]:556
	                 CONV_2D	        18170.995	    0.060	    0.075	  0.000%	 62.211%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_se_expand/Conv2D]:557
	                LOGISTIC	        18171.076	    0.020	    0.021	  0.000%	 62.211%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/Sigmoid]:558
	                     MUL	        18171.103	   85.321	   85.028	  0.291%	 62.502%	     0.000	        1	[efficientnetv2-l/block5o_se_excite/mul]:559
	                 CONV_2D	        18256.150	   10.279	   10.233	  0.035%	 62.537%	     0.000	        1	[efficientnetv2-l/block5o_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_project_conv/Conv2D]:560
	                     ADD	        18266.394	   19.358	   19.259	  0.066%	 62.603%	     0.000	        1	[efficientnetv2-l/block5o_add/add]:561
	                 CONV_2D	        18285.663	   28.500	   28.274	  0.097%	 62.700%	     0.000	        1	[efficientnetv2-l/block5p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_expand_conv/Conv2D]:562
	                LOGISTIC	        18313.948	   11.749	   11.795	  0.040%	 62.740%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/Sigmoid]:563
	                     MUL	        18325.754	   85.314	   84.889	  0.291%	 63.031%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/mul_1]:564
	       DEPTHWISE_CONV_2D	        18410.655	    6.509	    6.287	  0.022%	 63.053%	     0.000	        1	[efficientnetv2-l/block5p_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:565
	                LOGISTIC	        18416.954	   11.743	   11.752	  0.040%	 63.093%	     0.000	        1	[efficientnetv2-l/block5p_activation/Sigmoid]:566
	                     MUL	        18428.716	   85.140	   85.005	  0.291%	 63.384%	     0.000	        1	[efficientnetv2-l/block5p_activation/mul_1]:567
	                    MEAN	        18513.733	  205.397	  205.548	  0.704%	 64.088%	     0.000	        1	[efficientnetv2-l/block5p_se_squeeze/Mean]:568
	                   SHAPE	        18719.294	    0.009	    0.009	  0.000%	 64.088%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Shape]:569
	           STRIDED_SLICE	        18719.309	    0.022	    0.022	  0.000%	 64.088%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/strided_slice]:570
	                    PACK	        18719.338	    0.030	    0.032	  0.000%	 64.088%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape/shape]:571
	                 RESHAPE	        18719.376	    0.014	    0.013	  0.000%	 64.088%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape]:572
	                 CONV_2D	        18719.396	    0.049	    0.053	  0.000%	 64.088%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5p_se_reduce/Conv2D]:573
	                LOGISTIC	        18719.456	    0.009	    0.009	  0.000%	 64.088%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/Sigmoid]:574
	                     MUL	        18719.471	    0.020	    0.021	  0.000%	 64.089%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/mul_1]:575
	                 CONV_2D	        18719.499	    0.059	    0.066	  0.000%	 64.089%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_se_expand/Conv2D]:576
	                LOGISTIC	        18719.572	    0.041	    0.026	  0.000%	 64.089%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/Sigmoid]:577
	                     MUL	        18719.605	   84.551	   84.846	  0.291%	 64.379%	     0.000	        1	[efficientnetv2-l/block5p_se_excite/mul]:578
	                 CONV_2D	        18804.463	    9.677	    9.740	  0.033%	 64.413%	     0.000	        1	[efficientnetv2-l/block5p_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_project_conv/Conv2D]:579
	                     ADD	        18814.212	   19.134	   19.229	  0.066%	 64.479%	     0.000	        1	[efficientnetv2-l/block5p_add/add]:580
	                 CONV_2D	        18833.450	   28.197	   28.221	  0.097%	 64.575%	     0.000	        1	[efficientnetv2-l/block5q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_expand_conv/Conv2D]:581
	                LOGISTIC	        18861.683	   11.713	   11.771	  0.040%	 64.616%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/Sigmoid]:582
	                     MUL	        18873.465	   84.622	   84.891	  0.291%	 64.906%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/mul_1]:583
	       DEPTHWISE_CONV_2D	        18958.367	    6.255	    6.377	  0.022%	 64.928%	     0.000	        1	[efficientnetv2-l/block5q_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:584
	                LOGISTIC	        18964.757	   11.726	   11.758	  0.040%	 64.968%	     0.000	        1	[efficientnetv2-l/block5q_activation/Sigmoid]:585
	                     MUL	        18976.525	   84.686	   84.968	  0.291%	 65.259%	     0.000	        1	[efficientnetv2-l/block5q_activation/mul_1]:586
	                    MEAN	        19061.505	  204.204	  205.404	  0.703%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_squeeze/Mean]:587
	                   SHAPE	        19266.920	    0.009	    0.009	  0.000%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Shape]:588
	           STRIDED_SLICE	        19266.935	    0.022	    0.022	  0.000%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/strided_slice]:589
	                    PACK	        19266.963	    0.030	    0.030	  0.000%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape/shape]:590
	                 RESHAPE	        19266.999	    0.014	    0.014	  0.000%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape]:591
	                 CONV_2D	        19267.019	    0.051	    0.052	  0.000%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5q_se_reduce/Conv2D]:592
	                LOGISTIC	        19267.077	    0.009	    0.010	  0.000%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/Sigmoid]:593
	                     MUL	        19267.093	    0.019	    0.026	  0.000%	 65.963%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/mul_1]:594
	                 CONV_2D	        19267.126	    0.060	    0.072	  0.000%	 65.964%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_se_expand/Conv2D]:595
	                LOGISTIC	        19267.205	    0.035	    0.023	  0.000%	 65.964%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/Sigmoid]:596
	                     MUL	        19267.235	   84.592	   84.907	  0.291%	 66.255%	     0.000	        1	[efficientnetv2-l/block5q_se_excite/mul]:597
	                 CONV_2D	        19352.155	    9.727	    9.765	  0.033%	 66.288%	     0.000	        1	[efficientnetv2-l/block5q_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_project_conv/Conv2D]:598
	                     ADD	        19361.930	   19.236	   19.280	  0.066%	 66.354%	     0.000	        1	[efficientnetv2-l/block5q_add/add]:599
	                 CONV_2D	        19381.221	   28.159	   28.267	  0.097%	 66.451%	     0.000	        1	[efficientnetv2-l/block5r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_expand_conv/Conv2D]:600
	                LOGISTIC	        19409.499	   11.619	   11.679	  0.040%	 66.491%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/Sigmoid]:601
	                     MUL	        19421.189	   84.636	   84.915	  0.291%	 66.782%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/mul_1]:602
	       DEPTHWISE_CONV_2D	        19506.114	    6.118	    6.253	  0.021%	 66.803%	     0.000	        1	[efficientnetv2-l/block5r_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:603
	                LOGISTIC	        19512.379	   11.661	   11.708	  0.040%	 66.843%	     0.000	        1	[efficientnetv2-l/block5r_activation/Sigmoid]:604
	                     MUL	        19524.098	   84.698	   84.972	  0.291%	 67.134%	     0.000	        1	[efficientnetv2-l/block5r_activation/mul_1]:605
	                    MEAN	        19609.082	  204.476	  205.617	  0.704%	 67.838%	     0.000	        1	[efficientnetv2-l/block5r_se_squeeze/Mean]:606
	                   SHAPE	        19814.709	    0.008	    0.009	  0.000%	 67.838%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Shape]:607
	           STRIDED_SLICE	        19814.728	    0.022	    0.024	  0.000%	 67.838%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/strided_slice]:608
	                    PACK	        19814.759	    0.030	    0.033	  0.000%	 67.838%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape/shape]:609
	                 RESHAPE	        19814.798	    0.014	    0.015	  0.000%	 67.839%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape]:610
	                 CONV_2D	        19814.819	    0.047	    0.055	  0.000%	 67.839%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5r_se_reduce/Conv2D]:611
	                LOGISTIC	        19814.880	    0.009	    0.010	  0.000%	 67.839%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/Sigmoid]:612
	                     MUL	        19814.896	    0.021	    0.021	  0.000%	 67.839%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/mul_1]:613
	                 CONV_2D	        19814.924	    0.061	    0.065	  0.000%	 67.839%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_se_expand/Conv2D]:614
	                LOGISTIC	        19814.995	    0.021	    0.022	  0.000%	 67.839%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/Sigmoid]:615
	                     MUL	        19815.024	   84.646	   84.781	  0.290%	 68.129%	     0.000	        1	[efficientnetv2-l/block5r_se_excite/mul]:616
	                 CONV_2D	        19899.817	   10.138	   10.186	  0.035%	 68.164%	     0.000	        1	[efficientnetv2-l/block5r_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_project_conv/Conv2D]:617
	                     ADD	        19910.013	   19.137	   19.239	  0.066%	 68.230%	     0.000	        1	[efficientnetv2-l/block5r_add/add]:618
	                 CONV_2D	        19929.262	   28.197	   28.289	  0.097%	 68.327%	     0.000	        1	[efficientnetv2-l/block5s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_expand_conv/Conv2D]:619
	                LOGISTIC	        19957.562	   11.697	   11.735	  0.040%	 68.367%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/Sigmoid]:620
	                     MUL	        19969.308	   84.538	   84.947	  0.291%	 68.658%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/mul_1]:621
	       DEPTHWISE_CONV_2D	        20054.266	    6.143	    6.301	  0.022%	 68.680%	     0.000	        1	[efficientnetv2-l/block5s_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:622
	                LOGISTIC	        20060.579	   11.739	   11.785	  0.040%	 68.720%	     0.000	        1	[efficientnetv2-l/block5s_activation/Sigmoid]:623
	                     MUL	        20072.382	   84.681	   84.949	  0.291%	 69.011%	     0.000	        1	[efficientnetv2-l/block5s_activation/mul_1]:624
	                    MEAN	        20157.342	  205.171	  205.307	  0.703%	 69.714%	     0.000	        1	[efficientnetv2-l/block5s_se_squeeze/Mean]:625
	                   SHAPE	        20362.661	    0.009	    0.009	  0.000%	 69.714%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Shape]:626
	           STRIDED_SLICE	        20362.676	    0.023	    0.022	  0.000%	 69.714%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/strided_slice]:627
	                    PACK	        20362.705	    0.034	    0.033	  0.000%	 69.714%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape/shape]:628
	                 RESHAPE	        20362.745	    0.014	    0.014	  0.000%	 69.714%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape]:629
	                 CONV_2D	        20362.765	    0.058	    0.053	  0.000%	 69.715%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5s_se_reduce/Conv2D]:630
	                LOGISTIC	        20362.824	    0.009	    0.009	  0.000%	 69.715%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/Sigmoid]:631
	                     MUL	        20362.840	    0.023	    0.022	  0.000%	 69.715%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/mul_1]:632
	                 CONV_2D	        20362.868	    0.061	    0.064	  0.000%	 69.715%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_se_expand/Conv2D]:633
	                LOGISTIC	        20362.938	    0.020	    0.020	  0.000%	 69.715%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/Sigmoid]:634
	                     MUL	        20362.965	   85.638	   85.042	  0.291%	 70.006%	     0.000	        1	[efficientnetv2-l/block5s_se_excite/mul]:635
	                 CONV_2D	        20448.019	    9.860	    9.793	  0.034%	 70.040%	     0.000	        1	[efficientnetv2-l/block5s_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_project_conv/Conv2D]:636
	                     ADD	        20457.823	   19.322	   19.338	  0.066%	 70.106%	     0.000	        1	[efficientnetv2-l/block5s_add/add]:637
	                 CONV_2D	        20477.171	   28.609	   28.350	  0.097%	 70.203%	     0.000	        1	[efficientnetv2-l/block6a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_expand_conv/Conv2D]:638
	                LOGISTIC	        20505.532	   11.859	   11.879	  0.041%	 70.244%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/Sigmoid]:639
	                     MUL	        20517.422	   85.447	   85.090	  0.291%	 70.535%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/mul_1]:640
	       DEPTHWISE_CONV_2D	        20602.523	  109.801	  109.230	  0.374%	 70.909%	     0.000	        1	[efficientnetv2-l/block6a_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_dwconv2/depthwise]:641
	                LOGISTIC	        20711.765	    2.945	    2.945	  0.010%	 70.919%	     0.000	        1	[efficientnetv2-l/block6a_activation/Sigmoid]:642
	                     MUL	        20714.718	   21.350	   21.193	  0.073%	 70.992%	     0.000	        1	[efficientnetv2-l/block6a_activation/mul_1]:643
	                    MEAN	        20735.922	   51.546	   51.423	  0.176%	 71.168%	     0.000	        1	[efficientnetv2-l/block6a_se_squeeze/Mean]:644
	                   SHAPE	        20787.355	    0.009	    0.009	  0.000%	 71.168%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Shape]:645
	           STRIDED_SLICE	        20787.370	    0.021	    0.023	  0.000%	 71.168%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/strided_slice]:646
	                    PACK	        20787.399	    0.052	    0.034	  0.000%	 71.168%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape/shape]:647
	                 RESHAPE	        20787.440	    0.014	    0.014	  0.000%	 71.168%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape]:648
	                 CONV_2D	        20787.460	    0.048	    0.048	  0.000%	 71.168%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block6a_se_reduce/Conv2D]:649
	                LOGISTIC	        20787.514	    0.010	    0.009	  0.000%	 71.169%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/Sigmoid]:650
	                     MUL	        20787.530	    0.021	    0.020	  0.000%	 71.169%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/mul_1]:651
	                 CONV_2D	        20787.555	    0.058	    0.066	  0.000%	 71.169%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_se_expand/Conv2D]:652
	                LOGISTIC	        20787.627	    0.020	    0.020	  0.000%	 71.169%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/Sigmoid]:653
	                     MUL	        20787.654	   21.426	   21.241	  0.073%	 71.242%	     0.000	        1	[efficientnetv2-l/block6a_se_excite/mul]:654
	                 CONV_2D	        20808.913	    4.042	    4.026	  0.014%	 71.255%	     0.000	        1	[efficientnetv2-l/block6a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_project_conv/Conv2D]:655
	                 CONV_2D	        20812.950	   12.096	   11.980	  0.041%	 71.296%	     0.000	        1	[efficientnetv2-l/block6b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_expand_conv/Conv2D]:656
	                LOGISTIC	        20824.939	    5.027	    5.017	  0.017%	 71.314%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/Sigmoid]:657
	                     MUL	        20829.966	   36.529	   36.430	  0.125%	 71.438%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/mul_1]:658
	       DEPTHWISE_CONV_2D	        20866.408	    3.325	    2.946	  0.010%	 71.448%	     0.000	        1	[efficientnetv2-l/block6b_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:659
	                LOGISTIC	        20869.364	    5.072	    5.041	  0.017%	 71.466%	     0.000	        1	[efficientnetv2-l/block6b_activation/Sigmoid]:660
	                     MUL	        20874.418	   36.772	   36.444	  0.125%	 71.591%	     0.000	        1	[efficientnetv2-l/block6b_activation/mul_1]:661
	                    MEAN	        20910.873	   88.697	   88.402	  0.303%	 71.893%	     0.000	        1	[efficientnetv2-l/block6b_se_squeeze/Mean]:662
	                   SHAPE	        20999.286	    0.009	    0.009	  0.000%	 71.893%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Shape]:663
	           STRIDED_SLICE	        20999.301	    0.025	    0.026	  0.000%	 71.893%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/strided_slice]:664
	                    PACK	        20999.334	    0.034	    0.048	  0.000%	 71.894%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape/shape]:665
	                 RESHAPE	        20999.389	    0.016	    0.015	  0.000%	 71.894%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape]:666
	                 CONV_2D	        20999.409	    0.087	    0.064	  0.000%	 71.894%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_reduce/Conv2D]:667
	                LOGISTIC	        20999.480	    0.012	    0.010	  0.000%	 71.894%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/Sigmoid]:668
	                     MUL	        20999.496	    0.029	    0.022	  0.000%	 71.894%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/mul_1]:669
	                 CONV_2D	        20999.524	    0.093	    0.091	  0.000%	 71.894%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_expand/Conv2D]:670
	                LOGISTIC	        20999.622	    0.029	    0.032	  0.000%	 71.894%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/Sigmoid]:671
	                     MUL	        20999.660	   36.544	   36.438	  0.125%	 72.019%	     0.000	        1	[efficientnetv2-l/block6b_se_excite/mul]:672
	                 CONV_2D	        21036.109	    5.859	    5.854	  0.020%	 72.039%	     0.000	        1	[efficientnetv2-l/block6b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_project_conv/Conv2D]:673
	                     ADD	        21041.973	    8.323	    8.283	  0.028%	 72.068%	     0.000	        1	[efficientnetv2-l/block6b_add/add]:674
	                 CONV_2D	        21050.264	   12.067	   12.029	  0.041%	 72.109%	     0.000	        1	[efficientnetv2-l/block6c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_expand_conv/Conv2D]:675
	                LOGISTIC	        21062.303	    5.023	    5.078	  0.017%	 72.126%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/Sigmoid]:676
	                     MUL	        21067.392	   36.628	   36.471	  0.125%	 72.251%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/mul_1]:677
	       DEPTHWISE_CONV_2D	        21103.874	    3.141	    3.001	  0.010%	 72.261%	     0.000	        1	[efficientnetv2-l/block6c_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:678
	                LOGISTIC	        21106.886	    5.034	    5.060	  0.017%	 72.279%	     0.000	        1	[efficientnetv2-l/block6c_activation/Sigmoid]:679
	                     MUL	        21111.956	   36.323	   36.423	  0.125%	 72.403%	     0.000	        1	[efficientnetv2-l/block6c_activation/mul_1]:680
	                    MEAN	        21148.390	   87.861	   88.117	  0.302%	 72.705%	     0.000	        1	[efficientnetv2-l/block6c_se_squeeze/Mean]:681
	                   SHAPE	        21236.518	    0.007	    0.008	  0.000%	 72.705%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Shape]:682
	           STRIDED_SLICE	        21236.532	    0.020	    0.023	  0.000%	 72.705%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/strided_slice]:683
	                    PACK	        21236.561	    0.029	    0.029	  0.000%	 72.705%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape/shape]:684
	                 RESHAPE	        21236.597	    0.014	    0.016	  0.000%	 72.705%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape]:685
	                 CONV_2D	        21236.620	    0.053	    0.057	  0.000%	 72.706%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_reduce/Conv2D]:686
	                LOGISTIC	        21236.683	    0.009	    0.009	  0.000%	 72.706%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/Sigmoid]:687
	                     MUL	        21236.699	    0.020	    0.021	  0.000%	 72.706%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/mul_1]:688
	                 CONV_2D	        21236.725	    0.106	    0.100	  0.000%	 72.706%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_expand/Conv2D]:689
	                LOGISTIC	        21236.831	    0.031	    0.030	  0.000%	 72.706%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/Sigmoid]:690
	                     MUL	        21236.867	   36.242	   36.391	  0.125%	 72.831%	     0.000	        1	[efficientnetv2-l/block6c_se_excite/mul]:691
	                 CONV_2D	        21273.269	    5.778	    5.795	  0.020%	 72.851%	     0.000	        1	[efficientnetv2-l/block6c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_project_conv/Conv2D]:692
	                     ADD	        21279.072	    8.213	    8.231	  0.028%	 72.879%	     0.000	        1	[efficientnetv2-l/block6c_add/add]:693
	                 CONV_2D	        21287.310	   11.956	   12.008	  0.041%	 72.920%	     0.000	        1	[efficientnetv2-l/block6d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_expand_conv/Conv2D]:694
	                LOGISTIC	        21299.329	    5.008	    5.013	  0.017%	 72.937%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/Sigmoid]:695
	                     MUL	        21304.352	   36.380	   36.362	  0.125%	 73.062%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/mul_1]:696
	       DEPTHWISE_CONV_2D	        21340.725	    2.830	    2.940	  0.010%	 73.072%	     0.000	        1	[efficientnetv2-l/block6d_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:697
	                LOGISTIC	        21343.676	    5.010	    5.050	  0.017%	 73.089%	     0.000	        1	[efficientnetv2-l/block6d_activation/Sigmoid]:698
	                     MUL	        21348.735	   36.264	   36.372	  0.125%	 73.214%	     0.000	        1	[efficientnetv2-l/block6d_activation/mul_1]:699
	                    MEAN	        21385.118	   88.010	   88.250	  0.302%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_squeeze/Mean]:700
	                   SHAPE	        21473.379	    0.008	    0.009	  0.000%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Shape]:701
	           STRIDED_SLICE	        21473.394	    0.020	    0.023	  0.000%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/strided_slice]:702
	                    PACK	        21473.424	    0.029	    0.037	  0.000%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape/shape]:703
	                 RESHAPE	        21473.468	    0.015	    0.014	  0.000%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape]:704
	                 CONV_2D	        21473.488	    0.070	    0.060	  0.000%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_reduce/Conv2D]:705
	                LOGISTIC	        21473.555	    0.010	    0.010	  0.000%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/Sigmoid]:706
	                     MUL	        21473.572	    0.020	    0.020	  0.000%	 73.516%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/mul_1]:707
	                 CONV_2D	        21473.598	    0.096	    0.100	  0.000%	 73.517%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_expand/Conv2D]:708
	                LOGISTIC	        21473.705	    0.028	    0.029	  0.000%	 73.517%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/Sigmoid]:709
	                     MUL	        21473.740	   36.144	   36.360	  0.125%	 73.641%	     0.000	        1	[efficientnetv2-l/block6d_se_excite/mul]:710
	                 CONV_2D	        21510.110	    5.775	    5.796	  0.020%	 73.661%	     0.000	        1	[efficientnetv2-l/block6d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_project_conv/Conv2D]:711
	                     ADD	        21515.915	    8.314	    8.277	  0.028%	 73.690%	     0.000	        1	[efficientnetv2-l/block6d_add/add]:712
	                 CONV_2D	        21524.201	   11.947	   12.021	  0.041%	 73.731%	     0.000	        1	[efficientnetv2-l/block6e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_expand_conv/Conv2D]:713
	                LOGISTIC	        21536.232	    4.960	    4.999	  0.017%	 73.748%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/Sigmoid]:714
	                     MUL	        21541.242	   36.312	   36.427	  0.125%	 73.873%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/mul_1]:715
	       DEPTHWISE_CONV_2D	        21577.681	    2.816	    2.914	  0.010%	 73.883%	     0.000	        1	[efficientnetv2-l/block6e_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:716
	                LOGISTIC	        21580.608	    5.106	    5.057	  0.017%	 73.900%	     0.000	        1	[efficientnetv2-l/block6e_activation/Sigmoid]:717
	                     MUL	        21585.676	   36.267	   36.410	  0.125%	 74.025%	     0.000	        1	[efficientnetv2-l/block6e_activation/mul_1]:718
	                    MEAN	        21622.097	   87.883	   88.586	  0.303%	 74.328%	     0.000	        1	[efficientnetv2-l/block6e_se_squeeze/Mean]:719
	                   SHAPE	        21710.694	    0.008	    0.009	  0.000%	 74.328%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Shape]:720
	           STRIDED_SLICE	        21710.709	    0.021	    0.033	  0.000%	 74.328%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/strided_slice]:721
	                    PACK	        21710.748	    0.030	    0.032	  0.000%	 74.328%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape/shape]:722
	                 RESHAPE	        21710.787	    0.014	    0.014	  0.000%	 74.328%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape]:723
	                 CONV_2D	        21710.807	    0.053	    0.058	  0.000%	 74.328%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_reduce/Conv2D]:724
	                LOGISTIC	        21710.872	    0.010	    0.010	  0.000%	 74.328%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/Sigmoid]:725
	                     MUL	        21710.888	    0.020	    0.023	  0.000%	 74.329%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/mul_1]:726
	                 CONV_2D	        21710.917	    0.109	    0.094	  0.000%	 74.329%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_expand/Conv2D]:727
	                LOGISTIC	        21711.018	    0.030	    0.033	  0.000%	 74.329%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/Sigmoid]:728
	                     MUL	        21711.057	   36.180	   36.447	  0.125%	 74.454%	     0.000	        1	[efficientnetv2-l/block6e_se_excite/mul]:729
	                 CONV_2D	        21747.515	    5.782	    5.801	  0.020%	 74.474%	     0.000	        1	[efficientnetv2-l/block6e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_project_conv/Conv2D]:730
	                     ADD	        21753.325	    8.214	    8.328	  0.029%	 74.502%	     0.000	        1	[efficientnetv2-l/block6e_add/add]:731
	                 CONV_2D	        21761.663	   11.946	   12.032	  0.041%	 74.543%	     0.000	        1	[efficientnetv2-l/block6f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_expand_conv/Conv2D]:732
	                LOGISTIC	        21773.704	    4.997	    5.022	  0.017%	 74.561%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/Sigmoid]:733
	                     MUL	        21778.736	   36.343	   36.433	  0.125%	 74.685%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/mul_1]:734
	       DEPTHWISE_CONV_2D	        21815.181	    2.837	    2.956	  0.010%	 74.695%	     0.000	        1	[efficientnetv2-l/block6f_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:735
	                LOGISTIC	        21818.148	    5.046	    5.046	  0.017%	 74.713%	     0.000	        1	[efficientnetv2-l/block6f_activation/Sigmoid]:736
	                     MUL	        21823.205	   36.235	   36.389	  0.125%	 74.837%	     0.000	        1	[efficientnetv2-l/block6f_activation/mul_1]:737
	                    MEAN	        21859.605	   87.997	   88.360	  0.303%	 75.140%	     0.000	        1	[efficientnetv2-l/block6f_se_squeeze/Mean]:738
	                   SHAPE	        21947.976	    0.009	    0.009	  0.000%	 75.140%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Shape]:739
	           STRIDED_SLICE	        21947.990	    0.021	    0.022	  0.000%	 75.140%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/strided_slice]:740
	                    PACK	        21948.018	    0.029	    0.030	  0.000%	 75.140%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape/shape]:741
	                 RESHAPE	        21948.055	    0.014	    0.015	  0.000%	 75.140%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape]:742
	                 CONV_2D	        21948.082	    0.052	    0.057	  0.000%	 75.140%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_reduce/Conv2D]:743
	                LOGISTIC	        21948.146	    0.010	    0.010	  0.000%	 75.140%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/Sigmoid]:744
	                     MUL	        21948.162	    0.021	    0.021	  0.000%	 75.141%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/mul_1]:745
	                 CONV_2D	        21948.189	    0.090	    0.097	  0.000%	 75.141%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_expand/Conv2D]:746
	                LOGISTIC	        21948.293	    0.045	    0.036	  0.000%	 75.141%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/Sigmoid]:747
	                     MUL	        21948.335	   36.336	   36.396	  0.125%	 75.266%	     0.000	        1	[efficientnetv2-l/block6f_se_excite/mul]:748
	                 CONV_2D	        21984.742	    5.792	    5.801	  0.020%	 75.286%	     0.000	        1	[efficientnetv2-l/block6f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_project_conv/Conv2D]:749
	                     ADD	        21990.552	    8.221	    8.256	  0.028%	 75.314%	     0.000	        1	[efficientnetv2-l/block6f_add/add]:750
	                 CONV_2D	        21998.816	   11.965	   11.998	  0.041%	 75.355%	     0.000	        1	[efficientnetv2-l/block6g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_expand_conv/Conv2D]:751
	                LOGISTIC	        22010.823	    5.098	    5.085	  0.017%	 75.372%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/Sigmoid]:752
	                     MUL	        22015.919	   36.259	   36.369	  0.125%	 75.497%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/mul_1]:753
	       DEPTHWISE_CONV_2D	        22052.298	    2.844	    3.071	  0.011%	 75.507%	     0.000	        1	[efficientnetv2-l/block6g_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:754
	                LOGISTIC	        22055.381	    5.018	    5.045	  0.017%	 75.525%	     0.000	        1	[efficientnetv2-l/block6g_activation/Sigmoid]:755
	                     MUL	        22060.436	   36.288	   36.618	  0.125%	 75.650%	     0.000	        1	[efficientnetv2-l/block6g_activation/mul_1]:756
	                    MEAN	        22097.065	   87.963	   88.446	  0.303%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_squeeze/Mean]:757
	                   SHAPE	        22185.521	    0.009	    0.010	  0.000%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Shape]:758
	           STRIDED_SLICE	        22185.538	    0.021	    0.021	  0.000%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/strided_slice]:759
	                    PACK	        22185.565	    0.029	    0.031	  0.000%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape/shape]:760
	                 RESHAPE	        22185.602	    0.014	    0.014	  0.000%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape]:761
	                 CONV_2D	        22185.623	    0.067	    0.057	  0.000%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_reduce/Conv2D]:762
	                LOGISTIC	        22185.686	    0.010	    0.010	  0.000%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/Sigmoid]:763
	                     MUL	        22185.702	    0.020	    0.020	  0.000%	 75.953%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/mul_1]:764
	                 CONV_2D	        22185.728	    0.090	    0.097	  0.000%	 75.954%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_expand/Conv2D]:765
	                LOGISTIC	        22185.832	    0.028	    0.035	  0.000%	 75.954%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/Sigmoid]:766
	                     MUL	        22185.873	   36.278	   36.372	  0.125%	 76.078%	     0.000	        1	[efficientnetv2-l/block6g_se_excite/mul]:767
	                 CONV_2D	        22222.255	    5.783	    5.848	  0.020%	 76.099%	     0.000	        1	[efficientnetv2-l/block6g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_project_conv/Conv2D]:768
	                     ADD	        22228.111	    8.223	    8.302	  0.028%	 76.127%	     0.000	        1	[efficientnetv2-l/block6g_add/add]:769
	                 CONV_2D	        22236.421	   11.925	   11.999	  0.041%	 76.168%	     0.000	        1	[efficientnetv2-l/block6h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_expand_conv/Conv2D]:770
	                LOGISTIC	        22248.431	    5.007	    5.005	  0.017%	 76.185%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/Sigmoid]:771
	                     MUL	        22253.445	   36.254	   36.368	  0.125%	 76.310%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/mul_1]:772
	       DEPTHWISE_CONV_2D	        22289.824	    2.844	    2.864	  0.010%	 76.320%	     0.000	        1	[efficientnetv2-l/block6h_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:773
	                LOGISTIC	        22292.698	    5.020	    5.026	  0.017%	 76.337%	     0.000	        1	[efficientnetv2-l/block6h_activation/Sigmoid]:774
	                     MUL	        22297.735	   36.379	   36.356	  0.125%	 76.461%	     0.000	        1	[efficientnetv2-l/block6h_activation/mul_1]:775
	                    MEAN	        22334.103	   88.025	   88.314	  0.302%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_squeeze/Mean]:776
	                   SHAPE	        22422.427	    0.009	    0.009	  0.000%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Shape]:777
	           STRIDED_SLICE	        22422.442	    0.021	    0.021	  0.000%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/strided_slice]:778
	                    PACK	        22422.470	    0.031	    0.043	  0.000%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape/shape]:779
	                 RESHAPE	        22422.520	    0.014	    0.014	  0.000%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape]:780
	                 CONV_2D	        22422.540	    0.054	    0.059	  0.000%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_reduce/Conv2D]:781
	                LOGISTIC	        22422.607	    0.010	    0.010	  0.000%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/Sigmoid]:782
	                     MUL	        22422.623	    0.021	    0.025	  0.000%	 76.764%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/mul_1]:783
	                 CONV_2D	        22422.653	    0.109	    0.099	  0.000%	 76.765%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_expand/Conv2D]:784
	                LOGISTIC	        22422.759	    0.029	    0.030	  0.000%	 76.765%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/Sigmoid]:785
	                     MUL	        22422.795	   36.257	   36.375	  0.125%	 76.889%	     0.000	        1	[efficientnetv2-l/block6h_se_excite/mul]:786
	                 CONV_2D	        22459.182	    5.800	    5.829	  0.020%	 76.909%	     0.000	        1	[efficientnetv2-l/block6h_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_project_conv/Conv2D]:787
	                     ADD	        22465.020	    8.225	    8.274	  0.028%	 76.938%	     0.000	        1	[efficientnetv2-l/block6h_add/add]:788
	                 CONV_2D	        22473.303	   11.932	   12.089	  0.041%	 76.979%	     0.000	        1	[efficientnetv2-l/block6i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_expand_conv/Conv2D]:789
	                LOGISTIC	        22485.402	    5.013	    5.114	  0.018%	 76.997%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/Sigmoid]:790
	                     MUL	        22490.525	   36.257	   36.654	  0.126%	 77.122%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/mul_1]:791
	       DEPTHWISE_CONV_2D	        22527.191	    2.777	    2.934	  0.010%	 77.132%	     0.000	        1	[efficientnetv2-l/block6i_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:792
	                LOGISTIC	        22530.135	    5.021	    5.049	  0.017%	 77.149%	     0.000	        1	[efficientnetv2-l/block6i_activation/Sigmoid]:793
	                     MUL	        22535.193	   36.328	   36.396	  0.125%	 77.274%	     0.000	        1	[efficientnetv2-l/block6i_activation/mul_1]:794
	                    MEAN	        22571.602	   88.042	   88.564	  0.303%	 77.577%	     0.000	        1	[efficientnetv2-l/block6i_se_squeeze/Mean]:795
	                   SHAPE	        22660.176	    0.008	    0.009	  0.000%	 77.577%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Shape]:796
	           STRIDED_SLICE	        22660.191	    0.021	    0.022	  0.000%	 77.577%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/strided_slice]:797
	                    PACK	        22660.220	    0.029	    0.040	  0.000%	 77.578%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape/shape]:798
	                 RESHAPE	        22660.267	    0.014	    0.015	  0.000%	 77.578%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape]:799
	                 CONV_2D	        22660.288	    0.054	    0.056	  0.000%	 77.578%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_reduce/Conv2D]:800
	                LOGISTIC	        22660.351	    0.010	    0.010	  0.000%	 77.578%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/Sigmoid]:801
	                     MUL	        22660.366	    0.021	    0.021	  0.000%	 77.578%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/mul_1]:802
	                 CONV_2D	        22660.393	    0.119	    0.118	  0.000%	 77.578%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_expand/Conv2D]:803
	                LOGISTIC	        22660.518	    0.029	    0.029	  0.000%	 77.578%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/Sigmoid]:804
	                     MUL	        22660.554	   36.436	   36.782	  0.126%	 77.704%	     0.000	        1	[efficientnetv2-l/block6i_se_excite/mul]:805
	                 CONV_2D	        22697.347	    5.909	    5.834	  0.020%	 77.724%	     0.000	        1	[efficientnetv2-l/block6i_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_project_conv/Conv2D]:806
	                     ADD	        22703.190	    8.246	    8.272	  0.028%	 77.753%	     0.000	        1	[efficientnetv2-l/block6i_add/add]:807
	                 CONV_2D	        22711.471	   11.948	   12.049	  0.041%	 77.794%	     0.000	        1	[efficientnetv2-l/block6j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_expand_conv/Conv2D]:808
	                LOGISTIC	        22723.530	    5.052	    5.063	  0.017%	 77.811%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/Sigmoid]:809
	                     MUL	        22728.604	   36.276	   36.420	  0.125%	 77.936%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/mul_1]:810
	       DEPTHWISE_CONV_2D	        22765.035	    2.784	    2.976	  0.010%	 77.946%	     0.000	        1	[efficientnetv2-l/block6j_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:811
	                LOGISTIC	        22768.022	    5.069	    5.057	  0.017%	 77.964%	     0.000	        1	[efficientnetv2-l/block6j_activation/Sigmoid]:812
	                     MUL	        22773.089	   36.493	   36.392	  0.125%	 78.088%	     0.000	        1	[efficientnetv2-l/block6j_activation/mul_1]:813
	                    MEAN	        22809.491	   88.939	   88.418	  0.303%	 78.391%	     0.000	        1	[efficientnetv2-l/block6j_se_squeeze/Mean]:814
	                   SHAPE	        22897.920	    0.009	    0.009	  0.000%	 78.391%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Shape]:815
	           STRIDED_SLICE	        22897.935	    0.023	    0.021	  0.000%	 78.391%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/strided_slice]:816
	                    PACK	        22897.963	    0.033	    0.029	  0.000%	 78.391%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape/shape]:817
	                 RESHAPE	        22897.999	    0.014	    0.014	  0.000%	 78.391%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape]:818
	                 CONV_2D	        22898.019	    0.100	    0.066	  0.000%	 78.391%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_reduce/Conv2D]:819
	                LOGISTIC	        22898.092	    0.010	    0.010	  0.000%	 78.392%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/Sigmoid]:820
	                     MUL	        22898.108	    0.021	    0.034	  0.000%	 78.392%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/mul_1]:821
	                 CONV_2D	        22898.149	    0.119	    0.099	  0.000%	 78.392%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_expand/Conv2D]:822
	                LOGISTIC	        22898.254	    0.031	    0.029	  0.000%	 78.392%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/Sigmoid]:823
	                     MUL	        22898.289	   36.667	   36.427	  0.125%	 78.517%	     0.000	        1	[efficientnetv2-l/block6j_se_excite/mul]:824
	                 CONV_2D	        22934.726	    5.866	    5.835	  0.020%	 78.537%	     0.000	        1	[efficientnetv2-l/block6j_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_project_conv/Conv2D]:825
	                     ADD	        22940.571	    8.331	    8.296	  0.028%	 78.565%	     0.000	        1	[efficientnetv2-l/block6j_add/add]:826
	                 CONV_2D	        22948.876	   12.285	   12.061	  0.041%	 78.606%	     0.000	        1	[efficientnetv2-l/block6k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_expand_conv/Conv2D]:827
	                LOGISTIC	        22960.947	    5.010	    5.035	  0.017%	 78.624%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/Sigmoid]:828
	                     MUL	        22965.992	   36.655	   37.006	  0.127%	 78.750%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/mul_1]:829
	       DEPTHWISE_CONV_2D	        23003.009	    3.629	    3.126	  0.011%	 78.761%	     0.000	        1	[efficientnetv2-l/block6k_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:830
	                LOGISTIC	        23006.146	    5.037	    5.022	  0.017%	 78.778%	     0.000	        1	[efficientnetv2-l/block6k_activation/Sigmoid]:831
	                     MUL	        23011.179	   36.764	   36.506	  0.125%	 78.903%	     0.000	        1	[efficientnetv2-l/block6k_activation/mul_1]:832
	                    MEAN	        23047.696	   88.798	   88.308	  0.302%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_squeeze/Mean]:833
	                   SHAPE	        23136.015	    0.008	    0.009	  0.000%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Shape]:834
	           STRIDED_SLICE	        23136.030	    0.021	    0.022	  0.000%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/strided_slice]:835
	                    PACK	        23136.058	    0.032	    0.036	  0.000%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape/shape]:836
	                 RESHAPE	        23136.100	    0.016	    0.015	  0.000%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape]:837
	                 CONV_2D	        23136.122	    0.084	    0.064	  0.000%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_reduce/Conv2D]:838
	                LOGISTIC	        23136.192	    0.010	    0.013	  0.000%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/Sigmoid]:839
	                     MUL	        23136.211	    0.022	    0.021	  0.000%	 79.206%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/mul_1]:840
	                 CONV_2D	        23136.238	    0.107	    0.097	  0.000%	 79.207%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_expand/Conv2D]:841
	                LOGISTIC	        23136.344	    0.034	    0.033	  0.000%	 79.207%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/Sigmoid]:842
	                     MUL	        23136.383	   36.713	   36.460	  0.125%	 79.332%	     0.000	        1	[efficientnetv2-l/block6k_se_excite/mul]:843
	                 CONV_2D	        23172.854	    5.844	    5.845	  0.020%	 79.352%	     0.000	        1	[efficientnetv2-l/block6k_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_project_conv/Conv2D]:844
	                     ADD	        23178.708	    8.273	    8.280	  0.028%	 79.380%	     0.000	        1	[efficientnetv2-l/block6k_add/add]:845
	                 CONV_2D	        23186.996	   12.094	   12.021	  0.041%	 79.421%	     0.000	        1	[efficientnetv2-l/block6l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_expand_conv/Conv2D]:846
	                LOGISTIC	        23199.027	    5.108	    5.054	  0.017%	 79.439%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/Sigmoid]:847
	                     MUL	        23204.091	   36.704	   36.421	  0.125%	 79.563%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/mul_1]:848
	       DEPTHWISE_CONV_2D	        23240.523	    3.197	    2.975	  0.010%	 79.574%	     0.000	        1	[efficientnetv2-l/block6l_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:849
	                LOGISTIC	        23243.511	    5.053	    5.021	  0.017%	 79.591%	     0.000	        1	[efficientnetv2-l/block6l_activation/Sigmoid]:850
	                     MUL	        23248.542	   36.560	   36.396	  0.125%	 79.715%	     0.000	        1	[efficientnetv2-l/block6l_activation/mul_1]:851
	                    MEAN	        23284.949	   88.576	   88.251	  0.302%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_squeeze/Mean]:852
	                   SHAPE	        23373.210	    0.008	    0.008	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Shape]:853
	           STRIDED_SLICE	        23373.225	    0.021	    0.024	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/strided_slice]:854
	                    PACK	        23373.256	    0.050	    0.032	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape/shape]:855
	                 RESHAPE	        23373.295	    0.015	    0.015	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape]:856
	                 CONV_2D	        23373.316	    0.051	    0.052	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_reduce/Conv2D]:857
	                LOGISTIC	        23373.374	    0.010	    0.010	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/Sigmoid]:858
	                     MUL	        23373.390	    0.020	    0.020	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/mul_1]:859
	                 CONV_2D	        23373.416	    0.089	    0.099	  0.000%	 80.018%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_expand/Conv2D]:860
	                LOGISTIC	        23373.521	    0.029	    0.032	  0.000%	 80.019%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/Sigmoid]:861
	                     MUL	        23373.559	   36.322	   36.348	  0.124%	 80.143%	     0.000	        1	[efficientnetv2-l/block6l_se_excite/mul]:862
	                 CONV_2D	        23409.918	    5.783	    5.794	  0.020%	 80.163%	     0.000	        1	[efficientnetv2-l/block6l_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_project_conv/Conv2D]:863
	                     ADD	        23415.720	    8.222	    8.259	  0.028%	 80.191%	     0.000	        1	[efficientnetv2-l/block6l_add/add]:864
	                 CONV_2D	        23423.988	   11.938	   11.991	  0.041%	 80.232%	     0.000	        1	[efficientnetv2-l/block6m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_expand_conv/Conv2D]:865
	                LOGISTIC	        23435.988	    5.000	    5.026	  0.017%	 80.249%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/Sigmoid]:866
	                     MUL	        23441.023	   36.317	   36.406	  0.125%	 80.374%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/mul_1]:867
	       DEPTHWISE_CONV_2D	        23477.440	    2.825	    2.985	  0.010%	 80.384%	     0.000	        1	[efficientnetv2-l/block6m_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:868
	                LOGISTIC	        23480.437	    5.057	    5.065	  0.017%	 80.402%	     0.000	        1	[efficientnetv2-l/block6m_activation/Sigmoid]:869
	                     MUL	        23485.513	   36.242	   36.381	  0.125%	 80.526%	     0.000	        1	[efficientnetv2-l/block6m_activation/mul_1]:870
	                    MEAN	        23521.906	   88.063	   88.311	  0.302%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_squeeze/Mean]:871
	                   SHAPE	        23610.227	    0.009	    0.009	  0.000%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Shape]:872
	           STRIDED_SLICE	        23610.242	    0.022	    0.021	  0.000%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/strided_slice]:873
	                    PACK	        23610.269	    0.028	    0.029	  0.000%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape/shape]:874
	                 RESHAPE	        23610.305	    0.014	    0.014	  0.000%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape]:875
	                 CONV_2D	        23610.325	    0.113	    0.077	  0.000%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_reduce/Conv2D]:876
	                LOGISTIC	        23610.409	    0.010	    0.010	  0.000%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/Sigmoid]:877
	                     MUL	        23610.425	    0.020	    0.020	  0.000%	 80.829%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/mul_1]:878
	                 CONV_2D	        23610.452	    0.092	    0.100	  0.000%	 80.830%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_expand/Conv2D]:879
	                LOGISTIC	        23610.558	    0.029	    0.029	  0.000%	 80.830%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/Sigmoid]:880
	                     MUL	        23610.593	   36.252	   36.348	  0.124%	 80.954%	     0.000	        1	[efficientnetv2-l/block6m_se_excite/mul]:881
	                 CONV_2D	        23646.955	    5.789	    5.816	  0.020%	 80.974%	     0.000	        1	[efficientnetv2-l/block6m_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_project_conv/Conv2D]:882
	                     ADD	        23652.779	    8.280	    8.255	  0.028%	 81.002%	     0.000	        1	[efficientnetv2-l/block6m_add/add]:883
	                 CONV_2D	        23661.044	   11.953	   11.984	  0.041%	 81.043%	     0.000	        1	[efficientnetv2-l/block6n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_expand_conv/Conv2D]:884
	                LOGISTIC	        23673.039	    5.022	    5.030	  0.017%	 81.061%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/Sigmoid]:885
	                     MUL	        23678.079	   36.228	   36.387	  0.125%	 81.185%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/mul_1]:886
	       DEPTHWISE_CONV_2D	        23714.477	    2.747	    2.923	  0.010%	 81.195%	     0.000	        1	[efficientnetv2-l/block6n_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:887
	                LOGISTIC	        23717.411	    5.043	    5.037	  0.017%	 81.213%	     0.000	        1	[efficientnetv2-l/block6n_activation/Sigmoid]:888
	                     MUL	        23722.457	   36.412	   36.363	  0.125%	 81.337%	     0.000	        1	[efficientnetv2-l/block6n_activation/mul_1]:889
	                    MEAN	        23758.832	   88.117	   88.162	  0.302%	 81.639%	     0.000	        1	[efficientnetv2-l/block6n_se_squeeze/Mean]:890
	                   SHAPE	        23847.007	    0.009	    0.009	  0.000%	 81.639%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Shape]:891
	           STRIDED_SLICE	        23847.022	    0.021	    0.021	  0.000%	 81.639%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/strided_slice]:892
	                    PACK	        23847.050	    0.030	    0.033	  0.000%	 81.639%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape/shape]:893
	                 RESHAPE	        23847.089	    0.013	    0.016	  0.000%	 81.639%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape]:894
	                 CONV_2D	        23847.111	    0.071	    0.058	  0.000%	 81.640%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_reduce/Conv2D]:895
	                LOGISTIC	        23847.176	    0.010	    0.010	  0.000%	 81.640%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/Sigmoid]:896
	                     MUL	        23847.192	    0.021	    0.021	  0.000%	 81.640%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/mul_1]:897
	                 CONV_2D	        23847.218	    0.091	    0.096	  0.000%	 81.640%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_expand/Conv2D]:898
	                LOGISTIC	        23847.321	    0.028	    0.034	  0.000%	 81.640%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/Sigmoid]:899
	                     MUL	        23847.362	   36.214	   36.365	  0.125%	 81.765%	     0.000	        1	[efficientnetv2-l/block6n_se_excite/mul]:900
	                 CONV_2D	        23883.738	    5.796	    5.824	  0.020%	 81.785%	     0.000	        1	[efficientnetv2-l/block6n_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_project_conv/Conv2D]:901
	                     ADD	        23889.571	    8.214	    8.259	  0.028%	 81.813%	     0.000	        1	[efficientnetv2-l/block6n_add/add]:902
	                 CONV_2D	        23897.838	   11.936	   12.003	  0.041%	 81.854%	     0.000	        1	[efficientnetv2-l/block6o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_expand_conv/Conv2D]:903
	                LOGISTIC	        23909.851	    4.967	    4.995	  0.017%	 81.871%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/Sigmoid]:904
	                     MUL	        23914.855	   36.229	   36.389	  0.125%	 81.996%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/mul_1]:905
	       DEPTHWISE_CONV_2D	        23951.262	    2.837	    2.958	  0.010%	 82.006%	     0.000	        1	[efficientnetv2-l/block6o_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:906
	                LOGISTIC	        23954.231	    5.092	    5.051	  0.017%	 82.023%	     0.000	        1	[efficientnetv2-l/block6o_activation/Sigmoid]:907
	                     MUL	        23959.292	   36.315	   36.406	  0.125%	 82.148%	     0.000	        1	[efficientnetv2-l/block6o_activation/mul_1]:908
	                    MEAN	        23995.710	   87.830	   88.133	  0.302%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_squeeze/Mean]:909
	                   SHAPE	        24083.855	    0.008	    0.009	  0.000%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Shape]:910
	           STRIDED_SLICE	        24083.870	    0.020	    0.021	  0.000%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/strided_slice]:911
	                    PACK	        24083.897	    0.043	    0.042	  0.000%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape/shape]:912
	                 RESHAPE	        24083.945	    0.014	    0.014	  0.000%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape]:913
	                 CONV_2D	        24083.965	    0.052	    0.056	  0.000%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_reduce/Conv2D]:914
	                LOGISTIC	        24084.028	    0.009	    0.010	  0.000%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/Sigmoid]:915
	                     MUL	        24084.044	    0.020	    0.023	  0.000%	 82.450%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/mul_1]:916
	                 CONV_2D	        24084.073	    0.088	    0.093	  0.000%	 82.451%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_expand/Conv2D]:917
	                LOGISTIC	        24084.173	    0.030	    0.031	  0.000%	 82.451%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/Sigmoid]:918
	                     MUL	        24084.212	   36.279	   36.424	  0.125%	 82.575%	     0.000	        1	[efficientnetv2-l/block6o_se_excite/mul]:919
	                 CONV_2D	        24120.647	    5.848	    5.832	  0.020%	 82.595%	     0.000	        1	[efficientnetv2-l/block6o_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_project_conv/Conv2D]:920
	                     ADD	        24126.489	    8.216	    8.272	  0.028%	 82.624%	     0.000	        1	[efficientnetv2-l/block6o_add/add]:921
	                 CONV_2D	        24134.770	   11.941	   12.097	  0.041%	 82.665%	     0.000	        1	[efficientnetv2-l/block6p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_expand_conv/Conv2D]:922
	                LOGISTIC	        24146.877	    5.005	    5.048	  0.017%	 82.682%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/Sigmoid]:923
	                     MUL	        24151.936	   36.412	   36.540	  0.125%	 82.807%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/mul_1]:924
	       DEPTHWISE_CONV_2D	        24188.486	    2.816	    3.011	  0.010%	 82.818%	     0.000	        1	[efficientnetv2-l/block6p_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:925
	                LOGISTIC	        24191.508	    5.040	    5.051	  0.017%	 82.835%	     0.000	        1	[efficientnetv2-l/block6p_activation/Sigmoid]:926
	                     MUL	        24196.569	   36.252	   36.647	  0.126%	 82.961%	     0.000	        1	[efficientnetv2-l/block6p_activation/mul_1]:927
	                    MEAN	        24233.227	   88.126	   88.465	  0.303%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_squeeze/Mean]:928
	                   SHAPE	        24321.702	    0.008	    0.008	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Shape]:929
	           STRIDED_SLICE	        24321.720	    0.028	    0.025	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/strided_slice]:930
	                    PACK	        24321.752	    0.029	    0.029	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape/shape]:931
	                 RESHAPE	        24321.788	    0.014	    0.014	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape]:932
	                 CONV_2D	        24321.808	    0.054	    0.055	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_reduce/Conv2D]:933
	                LOGISTIC	        24321.870	    0.010	    0.010	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/Sigmoid]:934
	                     MUL	        24321.886	    0.020	    0.021	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/mul_1]:935
	                 CONV_2D	        24321.913	    0.091	    0.106	  0.000%	 83.264%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_expand/Conv2D]:936
	                LOGISTIC	        24322.025	    0.028	    0.032	  0.000%	 83.265%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/Sigmoid]:937
	                     MUL	        24322.064	   36.291	   36.426	  0.125%	 83.389%	     0.000	        1	[efficientnetv2-l/block6p_se_excite/mul]:938
	                 CONV_2D	        24358.501	    5.774	    5.824	  0.020%	 83.409%	     0.000	        1	[efficientnetv2-l/block6p_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_project_conv/Conv2D]:939
	                     ADD	        24364.335	    8.240	    8.282	  0.028%	 83.438%	     0.000	        1	[efficientnetv2-l/block6p_add/add]:940
	                 CONV_2D	        24372.626	   11.938	   12.039	  0.041%	 83.479%	     0.000	        1	[efficientnetv2-l/block6q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_expand_conv/Conv2D]:941
	                LOGISTIC	        24384.675	    5.003	    5.031	  0.017%	 83.496%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/Sigmoid]:942
	                     MUL	        24389.716	   36.285	   36.531	  0.125%	 83.621%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/mul_1]:943
	       DEPTHWISE_CONV_2D	        24426.259	    2.777	    2.992	  0.010%	 83.631%	     0.000	        1	[efficientnetv2-l/block6q_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:944
	                LOGISTIC	        24429.261	    5.023	    5.042	  0.017%	 83.649%	     0.000	        1	[efficientnetv2-l/block6q_activation/Sigmoid]:945
	                     MUL	        24434.312	   36.320	   36.419	  0.125%	 83.773%	     0.000	        1	[efficientnetv2-l/block6q_activation/mul_1]:946
	                    MEAN	        24470.743	   87.928	   88.243	  0.302%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_squeeze/Mean]:947
	                   SHAPE	        24558.997	    0.008	    0.009	  0.000%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Shape]:948
	           STRIDED_SLICE	        24559.011	    0.021	    0.021	  0.000%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/strided_slice]:949
	                    PACK	        24559.039	    0.029	    0.030	  0.000%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape/shape]:950
	                 RESHAPE	        24559.076	    0.028	    0.017	  0.000%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape]:951
	                 CONV_2D	        24559.099	    0.053	    0.056	  0.000%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_reduce/Conv2D]:952
	                LOGISTIC	        24559.161	    0.010	    0.010	  0.000%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/Sigmoid]:953
	                     MUL	        24559.178	    0.020	    0.024	  0.000%	 84.076%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/mul_1]:954
	                 CONV_2D	        24559.208	    0.088	    0.107	  0.000%	 84.077%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_expand/Conv2D]:955
	                LOGISTIC	        24559.322	    0.029	    0.030	  0.000%	 84.077%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/Sigmoid]:956
	                     MUL	        24559.358	   36.267	   36.566	  0.125%	 84.202%	     0.000	        1	[efficientnetv2-l/block6q_se_excite/mul]:957
	                 CONV_2D	        24595.935	    5.858	    5.909	  0.020%	 84.222%	     0.000	        1	[efficientnetv2-l/block6q_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_project_conv/Conv2D]:958
	                     ADD	        24601.853	    8.212	    8.261	  0.028%	 84.250%	     0.000	        1	[efficientnetv2-l/block6q_add/add]:959
	                 CONV_2D	        24610.123	   11.930	   12.020	  0.041%	 84.292%	     0.000	        1	[efficientnetv2-l/block6r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_expand_conv/Conv2D]:960
	                LOGISTIC	        24622.152	    4.983	    5.013	  0.017%	 84.309%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/Sigmoid]:961
	                     MUL	        24627.175	   36.410	   36.422	  0.125%	 84.434%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/mul_1]:962
	       DEPTHWISE_CONV_2D	        24663.610	    2.765	    2.956	  0.010%	 84.444%	     0.000	        1	[efficientnetv2-l/block6r_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:963
	                LOGISTIC	        24666.576	    5.021	    5.036	  0.017%	 84.461%	     0.000	        1	[efficientnetv2-l/block6r_activation/Sigmoid]:964
	                     MUL	        24671.624	   36.275	   36.443	  0.125%	 84.586%	     0.000	        1	[efficientnetv2-l/block6r_activation/mul_1]:965
	                    MEAN	        24708.078	   88.003	   88.325	  0.302%	 84.888%	     0.000	        1	[efficientnetv2-l/block6r_se_squeeze/Mean]:966
	                   SHAPE	        24796.416	    0.007	    0.008	  0.000%	 84.888%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Shape]:967
	           STRIDED_SLICE	        24796.430	    0.020	    0.021	  0.000%	 84.888%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/strided_slice]:968
	                    PACK	        24796.458	    0.029	    0.032	  0.000%	 84.888%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape/shape]:969
	                 RESHAPE	        24796.497	    0.014	    0.014	  0.000%	 84.888%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape]:970
	                 CONV_2D	        24796.517	    0.053	    0.053	  0.000%	 84.889%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_reduce/Conv2D]:971
	                LOGISTIC	        24796.577	    0.010	    0.010	  0.000%	 84.889%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/Sigmoid]:972
	                     MUL	        24796.593	    0.020	    0.035	  0.000%	 84.889%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/mul_1]:973
	                 CONV_2D	        24796.634	    0.120	    0.099	  0.000%	 84.889%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_expand/Conv2D]:974
	                LOGISTIC	        24796.739	    0.029	    0.033	  0.000%	 84.889%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/Sigmoid]:975
	                     MUL	        24796.778	   36.284	   36.404	  0.125%	 85.014%	     0.000	        1	[efficientnetv2-l/block6r_se_excite/mul]:976
	                 CONV_2D	        24833.193	    5.971	    6.012	  0.021%	 85.034%	     0.000	        1	[efficientnetv2-l/block6r_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_project_conv/Conv2D]:977
	                     ADD	        24839.214	    8.212	    8.280	  0.028%	 85.063%	     0.000	        1	[efficientnetv2-l/block6r_add/add]:978
	                 CONV_2D	        24847.504	   11.927	   11.994	  0.041%	 85.104%	     0.000	        1	[efficientnetv2-l/block6s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_expand_conv/Conv2D]:979
	                LOGISTIC	        24859.508	    5.018	    5.045	  0.017%	 85.121%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/Sigmoid]:980
	                     MUL	        24864.563	   36.278	   36.469	  0.125%	 85.246%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/mul_1]:981
	       DEPTHWISE_CONV_2D	        24901.043	    2.840	    3.106	  0.011%	 85.257%	     0.000	        1	[efficientnetv2-l/block6s_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:982
	                LOGISTIC	        24904.160	    5.027	    5.071	  0.017%	 85.274%	     0.000	        1	[efficientnetv2-l/block6s_activation/Sigmoid]:983
	                     MUL	        24909.242	   36.292	   36.393	  0.125%	 85.399%	     0.000	        1	[efficientnetv2-l/block6s_activation/mul_1]:984
	                    MEAN	        24945.646	   87.859	   88.171	  0.302%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_squeeze/Mean]:985
	                   SHAPE	        25033.827	    0.007	    0.008	  0.000%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Shape]:986
	           STRIDED_SLICE	        25033.841	    0.030	    0.024	  0.000%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/strided_slice]:987
	                    PACK	        25033.872	    0.028	    0.032	  0.000%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape/shape]:988
	                 RESHAPE	        25033.910	    0.014	    0.018	  0.000%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape]:989
	                 CONV_2D	        25033.936	    0.054	    0.057	  0.000%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_reduce/Conv2D]:990
	                LOGISTIC	        25034.000	    0.010	    0.017	  0.000%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/Sigmoid]:991
	                     MUL	        25034.023	    0.021	    0.021	  0.000%	 85.701%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/mul_1]:992
	                 CONV_2D	        25034.050	    0.094	    0.096	  0.000%	 85.702%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_expand/Conv2D]:993
	                LOGISTIC	        25034.152	    0.030	    0.029	  0.000%	 85.702%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/Sigmoid]:994
	                     MUL	        25034.187	   36.216	   36.341	  0.124%	 85.826%	     0.000	        1	[efficientnetv2-l/block6s_se_excite/mul]:995
	                 CONV_2D	        25070.540	    5.769	    5.808	  0.020%	 85.846%	     0.000	        1	[efficientnetv2-l/block6s_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_project_conv/Conv2D]:996
	                     ADD	        25076.356	    8.220	    8.246	  0.028%	 85.874%	     0.000	        1	[efficientnetv2-l/block6s_add/add]:997
	                 CONV_2D	        25084.610	   11.928	   11.959	  0.041%	 85.915%	     0.000	        1	[efficientnetv2-l/block6t_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_expand_conv/Conv2D]:998
	                LOGISTIC	        25096.579	    5.007	    5.023	  0.017%	 85.932%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/Sigmoid]:999
	                     MUL	        25101.612	   36.365	   36.471	  0.125%	 86.057%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/mul_1]:1000
	       DEPTHWISE_CONV_2D	        25138.093	    3.128	    3.022	  0.010%	 86.068%	     0.000	        1	[efficientnetv2-l/block6t_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1001
	                LOGISTIC	        25141.126	    5.076	    5.048	  0.017%	 86.085%	     0.000	        1	[efficientnetv2-l/block6t_activation/Sigmoid]:1002
	                     MUL	        25146.184	   36.403	   36.480	  0.125%	 86.210%	     0.000	        1	[efficientnetv2-l/block6t_activation/mul_1]:1003
	                    MEAN	        25182.676	   88.337	   88.256	  0.302%	 86.512%	     0.000	        1	[efficientnetv2-l/block6t_se_squeeze/Mean]:1004
	                   SHAPE	        25270.943	    0.009	    0.009	  0.000%	 86.512%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Shape]:1005
	           STRIDED_SLICE	        25270.957	    0.021	    0.022	  0.000%	 86.512%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/strided_slice]:1006
	                    PACK	        25270.986	    0.029	    0.032	  0.000%	 86.512%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape/shape]:1007
	                 RESHAPE	        25271.025	    0.014	    0.014	  0.000%	 86.512%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape]:1008
	                 CONV_2D	        25271.045	    0.051	    0.054	  0.000%	 86.513%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_reduce/Conv2D]:1009
	                LOGISTIC	        25271.105	    0.010	    0.010	  0.000%	 86.513%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/Sigmoid]:1010
	                     MUL	        25271.124	    0.034	    0.023	  0.000%	 86.513%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/mul_1]:1011
	                 CONV_2D	        25271.153	    0.129	    0.099	  0.000%	 86.513%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_expand/Conv2D]:1012
	                LOGISTIC	        25271.258	    0.029	    0.031	  0.000%	 86.513%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/Sigmoid]:1013
	                     MUL	        25271.296	   36.469	   36.364	  0.125%	 86.638%	     0.000	        1	[efficientnetv2-l/block6t_se_excite/mul]:1014
	                 CONV_2D	        25307.671	    5.954	    5.892	  0.020%	 86.658%	     0.000	        1	[efficientnetv2-l/block6t_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_project_conv/Conv2D]:1015
	                     ADD	        25313.573	    8.414	    8.284	  0.028%	 86.686%	     0.000	        1	[efficientnetv2-l/block6t_add/add]:1016
	                 CONV_2D	        25321.872	   12.162	   12.033	  0.041%	 86.727%	     0.000	        1	[efficientnetv2-l/block6u_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_expand_conv/Conv2D]:1017
	                LOGISTIC	        25333.915	    5.056	    4.997	  0.017%	 86.745%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/Sigmoid]:1018
	                     MUL	        25338.922	   36.747	   36.462	  0.125%	 86.869%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/mul_1]:1019
	       DEPTHWISE_CONV_2D	        25375.395	    3.446	    3.037	  0.010%	 86.880%	     0.000	        1	[efficientnetv2-l/block6u_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1020
	                LOGISTIC	        25378.444	    5.072	    5.066	  0.017%	 86.897%	     0.000	        1	[efficientnetv2-l/block6u_activation/Sigmoid]:1021
	                     MUL	        25383.520	   36.656	   36.525	  0.125%	 87.022%	     0.000	        1	[efficientnetv2-l/block6u_activation/mul_1]:1022
	                    MEAN	        25420.057	   88.881	   88.354	  0.303%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_squeeze/Mean]:1023
	                   SHAPE	        25508.421	    0.009	    0.008	  0.000%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Shape]:1024
	           STRIDED_SLICE	        25508.436	    0.028	    0.022	  0.000%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/strided_slice]:1025
	                    PACK	        25508.464	    0.036	    0.030	  0.000%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape/shape]:1026
	                 RESHAPE	        25508.502	    0.016	    0.014	  0.000%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape]:1027
	                 CONV_2D	        25508.522	    0.057	    0.059	  0.000%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_reduce/Conv2D]:1028
	                LOGISTIC	        25508.588	    0.012	    0.010	  0.000%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/Sigmoid]:1029
	                     MUL	        25508.605	    0.021	    0.024	  0.000%	 87.325%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/mul_1]:1030
	                 CONV_2D	        25508.635	    0.119	    0.107	  0.000%	 87.326%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_expand/Conv2D]:1031
	                LOGISTIC	        25508.748	    0.031	    0.029	  0.000%	 87.326%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/Sigmoid]:1032
	                     MUL	        25508.784	   36.690	   36.404	  0.125%	 87.451%	     0.000	        1	[efficientnetv2-l/block6u_se_excite/mul]:1033
	                 CONV_2D	        25545.200	    6.083	    6.051	  0.021%	 87.471%	     0.000	        1	[efficientnetv2-l/block6u_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_project_conv/Conv2D]:1034
	                     ADD	        25551.261	    8.414	    8.295	  0.028%	 87.500%	     0.000	        1	[efficientnetv2-l/block6u_add/add]:1035
	                 CONV_2D	        25559.565	   12.213	   12.041	  0.041%	 87.541%	     0.000	        1	[efficientnetv2-l/block6v_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_expand_conv/Conv2D]:1036
	                LOGISTIC	        25571.617	    5.087	    5.051	  0.017%	 87.558%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/Sigmoid]:1037
	                     MUL	        25576.677	   36.724	   36.548	  0.125%	 87.683%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/mul_1]:1038
	       DEPTHWISE_CONV_2D	        25613.236	    3.470	    3.068	  0.011%	 87.694%	     0.000	        1	[efficientnetv2-l/block6v_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1039
	                LOGISTIC	        25616.316	    5.067	    5.040	  0.017%	 87.711%	     0.000	        1	[efficientnetv2-l/block6v_activation/Sigmoid]:1040
	                     MUL	        25621.368	   36.652	   36.503	  0.125%	 87.836%	     0.000	        1	[efficientnetv2-l/block6v_activation/mul_1]:1041
	                    MEAN	        25657.882	   88.503	   88.228	  0.302%	 88.138%	     0.000	        1	[efficientnetv2-l/block6v_se_squeeze/Mean]:1042
	                   SHAPE	        25746.120	    0.021	    0.011	  0.000%	 88.138%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Shape]:1043
	           STRIDED_SLICE	        25746.137	    0.020	    0.021	  0.000%	 88.138%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/strided_slice]:1044
	                    PACK	        25746.164	    0.029	    0.037	  0.000%	 88.139%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape/shape]:1045
	                 RESHAPE	        25746.208	    0.013	    0.014	  0.000%	 88.139%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape]:1046
	                 CONV_2D	        25746.228	    0.054	    0.061	  0.000%	 88.139%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_reduce/Conv2D]:1047
	                LOGISTIC	        25746.296	    0.010	    0.010	  0.000%	 88.139%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/Sigmoid]:1048
	                     MUL	        25746.312	    0.021	    0.024	  0.000%	 88.139%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/mul_1]:1049
	                 CONV_2D	        25746.341	    0.088	    0.095	  0.000%	 88.139%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_expand/Conv2D]:1050
	                LOGISTIC	        25746.443	    0.029	    0.029	  0.000%	 88.139%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/Sigmoid]:1051
	                     MUL	        25746.478	   36.744	   36.360	  0.125%	 88.264%	     0.000	        1	[efficientnetv2-l/block6v_se_excite/mul]:1052
	                 CONV_2D	        25782.849	    5.843	    5.820	  0.020%	 88.284%	     0.000	        1	[efficientnetv2-l/block6v_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_project_conv/Conv2D]:1053
	                     ADD	        25788.678	    8.312	    8.268	  0.028%	 88.312%	     0.000	        1	[efficientnetv2-l/block6v_add/add]:1054
	                 CONV_2D	        25796.955	   12.073	   11.987	  0.041%	 88.353%	     0.000	        1	[efficientnetv2-l/block6w_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_expand_conv/Conv2D]:1055
	                LOGISTIC	        25808.952	    5.039	    5.027	  0.017%	 88.370%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/Sigmoid]:1056
	                     MUL	        25813.989	   36.741	   36.482	  0.125%	 88.495%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/mul_1]:1057
	       DEPTHWISE_CONV_2D	        25850.482	    3.044	    2.965	  0.010%	 88.505%	     0.000	        1	[efficientnetv2-l/block6w_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1058
	                LOGISTIC	        25853.459	    5.056	    5.061	  0.017%	 88.523%	     0.000	        1	[efficientnetv2-l/block6w_activation/Sigmoid]:1059
	                     MUL	        25858.530	   36.643	   36.424	  0.125%	 88.648%	     0.000	        1	[efficientnetv2-l/block6w_activation/mul_1]:1060
	                    MEAN	        25894.965	   88.567	   88.625	  0.304%	 88.951%	     0.000	        1	[efficientnetv2-l/block6w_se_squeeze/Mean]:1061
	                   SHAPE	        25983.602	    0.009	    0.009	  0.000%	 88.951%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Shape]:1062
	           STRIDED_SLICE	        25983.617	    0.023	    0.022	  0.000%	 88.951%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/strided_slice]:1063
	                    PACK	        25983.646	    0.031	    0.041	  0.000%	 88.951%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape/shape]:1064
	                 RESHAPE	        25983.694	    0.014	    0.015	  0.000%	 88.951%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape]:1065
	                 CONV_2D	        25983.715	    0.056	    0.056	  0.000%	 88.952%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_reduce/Conv2D]:1066
	                LOGISTIC	        25983.778	    0.010	    0.010	  0.000%	 88.952%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/Sigmoid]:1067
	                     MUL	        25983.794	    0.020	    0.030	  0.000%	 88.952%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/mul_1]:1068
	                 CONV_2D	        25983.830	    0.092	    0.102	  0.000%	 88.952%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_expand/Conv2D]:1069
	                LOGISTIC	        25983.939	    0.051	    0.033	  0.000%	 88.952%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/Sigmoid]:1070
	                     MUL	        25983.978	   36.506	   36.459	  0.125%	 89.077%	     0.000	        1	[efficientnetv2-l/block6w_se_excite/mul]:1071
	                 CONV_2D	        26020.450	    5.893	    5.861	  0.020%	 89.097%	     0.000	        1	[efficientnetv2-l/block6w_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_project_conv/Conv2D]:1072
	                     ADD	        26026.320	    8.358	    8.280	  0.028%	 89.125%	     0.000	        1	[efficientnetv2-l/block6w_add/add]:1073
	                 CONV_2D	        26034.608	   12.100	   12.078	  0.041%	 89.167%	     0.000	        1	[efficientnetv2-l/block6x_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_expand_conv/Conv2D]:1074
	                LOGISTIC	        26046.696	    5.036	    5.027	  0.017%	 89.184%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/Sigmoid]:1075
	                     MUL	        26051.733	   36.480	   36.467	  0.125%	 89.309%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/mul_1]:1076
	       DEPTHWISE_CONV_2D	        26088.210	    2.802	    2.884	  0.010%	 89.319%	     0.000	        1	[efficientnetv2-l/block6x_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1077
	                LOGISTIC	        26091.105	    5.058	    5.033	  0.017%	 89.336%	     0.000	        1	[efficientnetv2-l/block6x_activation/Sigmoid]:1078
	                     MUL	        26096.148	   36.279	   36.340	  0.124%	 89.460%	     0.000	        1	[efficientnetv2-l/block6x_activation/mul_1]:1079
	                    MEAN	        26132.498	   88.021	   88.424	  0.303%	 89.763%	     0.000	        1	[efficientnetv2-l/block6x_se_squeeze/Mean]:1080
	                   SHAPE	        26220.933	    0.008	    0.009	  0.000%	 89.763%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Shape]:1081
	           STRIDED_SLICE	        26220.948	    0.021	    0.022	  0.000%	 89.763%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/strided_slice]:1082
	                    PACK	        26220.976	    0.029	    0.030	  0.000%	 89.763%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape/shape]:1083
	                 RESHAPE	        26221.013	    0.014	    0.014	  0.000%	 89.764%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape]:1084
	                 CONV_2D	        26221.033	    0.115	    0.068	  0.000%	 89.764%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_reduce/Conv2D]:1085
	                LOGISTIC	        26221.108	    0.010	    0.010	  0.000%	 89.764%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/Sigmoid]:1086
	                     MUL	        26221.124	    0.020	    0.024	  0.000%	 89.764%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/mul_1]:1087
	                 CONV_2D	        26221.155	    0.091	    0.105	  0.000%	 89.764%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_expand/Conv2D]:1088
	                LOGISTIC	        26221.268	    0.028	    0.028	  0.000%	 89.764%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/Sigmoid]:1089
	                     MUL	        26221.302	   36.368	   36.323	  0.124%	 89.889%	     0.000	        1	[efficientnetv2-l/block6x_se_excite/mul]:1090
	                 CONV_2D	        26257.636	    6.033	    6.046	  0.021%	 89.909%	     0.000	        1	[efficientnetv2-l/block6x_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_project_conv/Conv2D]:1091
	                     ADD	        26263.691	    8.226	    8.317	  0.028%	 89.938%	     0.000	        1	[efficientnetv2-l/block6x_add/add]:1092
	                 CONV_2D	        26272.016	   11.936	   11.977	  0.041%	 89.979%	     0.000	        1	[efficientnetv2-l/block6y_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_expand_conv/Conv2D]:1093
	                LOGISTIC	        26284.004	    4.994	    5.018	  0.017%	 89.996%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/Sigmoid]:1094
	                     MUL	        26289.032	   36.319	   36.398	  0.125%	 90.121%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/mul_1]:1095
	       DEPTHWISE_CONV_2D	        26325.441	    2.847	    2.962	  0.010%	 90.131%	     0.000	        1	[efficientnetv2-l/block6y_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1096
	                LOGISTIC	        26328.413	    5.030	    5.042	  0.017%	 90.148%	     0.000	        1	[efficientnetv2-l/block6y_activation/Sigmoid]:1097
	                     MUL	        26333.465	   36.320	   36.420	  0.125%	 90.273%	     0.000	        1	[efficientnetv2-l/block6y_activation/mul_1]:1098
	                    MEAN	        26369.896	   87.955	   88.168	  0.302%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_squeeze/Mean]:1099
	                   SHAPE	        26458.075	    0.009	    0.009	  0.000%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Shape]:1100
	           STRIDED_SLICE	        26458.090	    0.020	    0.022	  0.000%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/strided_slice]:1101
	                    PACK	        26458.119	    0.039	    0.034	  0.000%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape/shape]:1102
	                 RESHAPE	        26458.159	    0.014	    0.017	  0.000%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape]:1103
	                 CONV_2D	        26458.183	    0.052	    0.056	  0.000%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_reduce/Conv2D]:1104
	                LOGISTIC	        26458.246	    0.010	    0.016	  0.000%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/Sigmoid]:1105
	                     MUL	        26458.267	    0.021	    0.021	  0.000%	 90.575%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/mul_1]:1106
	                 CONV_2D	        26458.294	    0.091	    0.098	  0.000%	 90.576%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_expand/Conv2D]:1107
	                LOGISTIC	        26458.399	    0.030	    0.029	  0.000%	 90.576%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/Sigmoid]:1108
	                     MUL	        26458.435	   36.230	   36.420	  0.125%	 90.701%	     0.000	        1	[efficientnetv2-l/block6y_se_excite/mul]:1109
	                 CONV_2D	        26494.866	    5.773	    5.840	  0.020%	 90.721%	     0.000	        1	[efficientnetv2-l/block6y_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_project_conv/Conv2D]:1110
	                     ADD	        26500.717	    8.233	    8.253	  0.028%	 90.749%	     0.000	        1	[efficientnetv2-l/block6y_add/add]:1111
	                 CONV_2D	        26508.979	   11.923	   12.002	  0.041%	 90.790%	     0.000	        1	[efficientnetv2-l/block7a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_expand_conv/Conv2D]:1112
	                LOGISTIC	        26520.990	    5.096	    5.078	  0.017%	 90.807%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/Sigmoid]:1113
	                     MUL	        26526.079	   36.346	   36.461	  0.125%	 90.932%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/mul_1]:1114
	       DEPTHWISE_CONV_2D	        26562.551	    2.828	    2.885	  0.010%	 90.942%	     0.000	        1	[efficientnetv2-l/block7a_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_dwconv2/depthwise]:1115
	                LOGISTIC	        26565.446	    5.070	    5.050	  0.017%	 90.959%	     0.000	        1	[efficientnetv2-l/block7a_activation/Sigmoid]:1116
	                     MUL	        26570.506	   36.379	   36.497	  0.125%	 91.084%	     0.000	        1	[efficientnetv2-l/block7a_activation/mul_1]:1117
	                    MEAN	        26607.015	   88.097	   88.812	  0.304%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_squeeze/Mean]:1118
	                   SHAPE	        26695.837	    0.009	    0.009	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Shape]:1119
	           STRIDED_SLICE	        26695.852	    0.022	    0.024	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/strided_slice]:1120
	                    PACK	        26695.885	    0.031	    0.032	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape/shape]:1121
	                 RESHAPE	        26695.924	    0.015	    0.014	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape]:1122
	                 CONV_2D	        26695.944	    0.054	    0.060	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_reduce/Conv2D]:1123
	                LOGISTIC	        26696.011	    0.010	    0.010	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/Sigmoid]:1124
	                     MUL	        26696.027	    0.021	    0.030	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/mul_1]:1125
	                 CONV_2D	        26696.063	    0.108	    0.097	  0.000%	 91.389%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_expand/Conv2D]:1126
	                LOGISTIC	        26696.166	    0.029	    0.029	  0.000%	 91.390%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/Sigmoid]:1127
	                     MUL	        26696.201	   36.191	   36.586	  0.125%	 91.515%	     0.000	        1	[efficientnetv2-l/block7a_se_excite/mul]:1128
	                 CONV_2D	        26732.798	    9.401	    9.445	  0.032%	 91.547%	     0.000	        1	[efficientnetv2-l/block7a_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_project_conv/Conv2D]:1129
	                 CONV_2D	        26742.253	   19.610	   19.706	  0.067%	 91.615%	     0.000	        1	[efficientnetv2-l/block7b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_expand_conv/Conv2D]:1130
	                LOGISTIC	        26761.969	    8.270	    8.344	  0.029%	 91.643%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/Sigmoid]:1131
	                     MUL	        26770.323	   60.496	   60.821	  0.208%	 91.852%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/mul_1]:1132
	       DEPTHWISE_CONV_2D	        26831.156	    4.932	    5.310	  0.018%	 91.870%	     0.000	        1	[efficientnetv2-l/block7b_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1133
	                LOGISTIC	        26836.478	    8.284	    8.312	  0.028%	 91.898%	     0.000	        1	[efficientnetv2-l/block7b_activation/Sigmoid]:1134
	                     MUL	        26844.800	   60.497	   60.714	  0.208%	 92.106%	     0.000	        1	[efficientnetv2-l/block7b_activation/mul_1]:1135
	                    MEAN	        26905.532	  146.652	  147.344	  0.505%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_squeeze/Mean]:1136
	                   SHAPE	        27052.886	    0.009	    0.009	  0.000%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Shape]:1137
	           STRIDED_SLICE	        27052.901	    0.021	    0.021	  0.000%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/strided_slice]:1138
	                    PACK	        27052.929	    0.029	    0.034	  0.000%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape/shape]:1139
	                 RESHAPE	        27052.970	    0.015	    0.015	  0.000%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape]:1140
	                 CONV_2D	        27052.991	    0.077	    0.070	  0.000%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7b_se_reduce/Conv2D]:1141
	                LOGISTIC	        27053.067	    0.011	    0.011	  0.000%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/Sigmoid]:1142
	                     MUL	        27053.084	    0.025	    0.025	  0.000%	 92.611%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/mul_1]:1143
	                 CONV_2D	        27053.115	    0.135	    0.147	  0.001%	 92.612%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_se_expand/Conv2D]:1144
	                LOGISTIC	        27053.269	    0.041	    0.046	  0.000%	 92.612%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/Sigmoid]:1145
	                     MUL	        27053.323	   60.417	   60.620	  0.208%	 92.820%	     0.000	        1	[efficientnetv2-l/block7b_se_excite/mul]:1146
	                 CONV_2D	        27113.956	   12.347	   12.464	  0.043%	 92.862%	     0.000	        1	[efficientnetv2-l/block7b_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_project_conv/Conv2D]:1147
	                     ADD	        27126.435	   13.706	   13.872	  0.048%	 92.910%	     0.000	        1	[efficientnetv2-l/block7b_add/add]:1148
	                 CONV_2D	        27140.317	   19.630	   19.782	  0.068%	 92.978%	     0.000	        1	[efficientnetv2-l/block7c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_expand_conv/Conv2D]:1149
	                LOGISTIC	        27160.111	    8.293	    8.406	  0.029%	 93.006%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/Sigmoid]:1150
	                     MUL	        27168.527	   60.466	   61.019	  0.209%	 93.215%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/mul_1]:1151
	       DEPTHWISE_CONV_2D	        27229.557	    5.137	    5.312	  0.018%	 93.234%	     0.000	        1	[efficientnetv2-l/block7c_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1152
	                LOGISTIC	        27234.883	    8.314	    8.350	  0.029%	 93.262%	     0.000	        1	[efficientnetv2-l/block7c_activation/Sigmoid]:1153
	                     MUL	        27243.244	   60.601	   60.825	  0.208%	 93.470%	     0.000	        1	[efficientnetv2-l/block7c_activation/mul_1]:1154
	                    MEAN	        27304.079	  146.615	  147.222	  0.504%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_squeeze/Mean]:1155
	                   SHAPE	        27451.313	    0.020	    0.011	  0.000%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Shape]:1156
	           STRIDED_SLICE	        27451.330	    0.021	    0.026	  0.000%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/strided_slice]:1157
	                    PACK	        27451.363	    0.030	    0.034	  0.000%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape/shape]:1158
	                 RESHAPE	        27451.403	    0.015	    0.018	  0.000%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape]:1159
	                 CONV_2D	        27451.433	    0.062	    0.064	  0.000%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7c_se_reduce/Conv2D]:1160
	                LOGISTIC	        27451.504	    0.010	    0.010	  0.000%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/Sigmoid]:1161
	                     MUL	        27451.520	    0.024	    0.027	  0.000%	 93.975%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/mul_1]:1162
	                 CONV_2D	        27451.554	    0.154	    0.149	  0.001%	 93.976%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_se_expand/Conv2D]:1163
	                LOGISTIC	        27451.713	    0.043	    0.043	  0.000%	 93.976%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/Sigmoid]:1164
	                     MUL	        27451.763	   60.358	   60.605	  0.208%	 94.183%	     0.000	        1	[efficientnetv2-l/block7c_se_excite/mul]:1165
	                 CONV_2D	        27512.379	   12.038	   12.095	  0.041%	 94.225%	     0.000	        1	[efficientnetv2-l/block7c_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_project_conv/Conv2D]:1166
	                     ADD	        27524.482	   13.703	   13.729	  0.047%	 94.272%	     0.000	        1	[efficientnetv2-l/block7c_add/add]:1167
	                 CONV_2D	        27538.221	   19.640	   19.666	  0.067%	 94.339%	     0.000	        1	[efficientnetv2-l/block7d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_expand_conv/Conv2D]:1168
	                LOGISTIC	        27557.897	    8.296	    8.309	  0.028%	 94.368%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/Sigmoid]:1169
	                     MUL	        27566.217	   60.757	   61.199	  0.210%	 94.577%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/mul_1]:1170
	       DEPTHWISE_CONV_2D	        27627.428	    5.551	    5.487	  0.019%	 94.596%	     0.000	        1	[efficientnetv2-l/block7d_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1171
	                LOGISTIC	        27632.926	    8.393	    8.415	  0.029%	 94.625%	     0.000	        1	[efficientnetv2-l/block7d_activation/Sigmoid]:1172
	                     MUL	        27641.352	   60.549	   60.651	  0.208%	 94.833%	     0.000	        1	[efficientnetv2-l/block7d_activation/mul_1]:1173
	                    MEAN	        27702.014	  147.823	  147.111	  0.504%	 95.336%	     0.000	        1	[efficientnetv2-l/block7d_se_squeeze/Mean]:1174
	                   SHAPE	        27849.136	    0.011	    0.009	  0.000%	 95.336%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Shape]:1175
	           STRIDED_SLICE	        27849.151	    0.023	    0.022	  0.000%	 95.337%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/strided_slice]:1176
	                    PACK	        27849.180	    0.032	    0.034	  0.000%	 95.337%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape/shape]:1177
	                 RESHAPE	        27849.220	    0.016	    0.015	  0.000%	 95.337%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape]:1178
	                 CONV_2D	        27849.242	    0.097	    0.075	  0.000%	 95.337%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7d_se_reduce/Conv2D]:1179
	                LOGISTIC	        27849.324	    0.011	    0.014	  0.000%	 95.337%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/Sigmoid]:1180
	                     MUL	        27849.344	    0.025	    0.028	  0.000%	 95.337%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/mul_1]:1181
	                 CONV_2D	        27849.378	    0.141	    0.147	  0.001%	 95.338%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_se_expand/Conv2D]:1182
	                LOGISTIC	        27849.531	    0.060	    0.046	  0.000%	 95.338%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/Sigmoid]:1183
	                     MUL	        27849.584	   61.105	   61.236	  0.210%	 95.547%	     0.000	        1	[efficientnetv2-l/block7d_se_excite/mul]:1184
	                 CONV_2D	        27910.831	   12.356	   12.205	  0.042%	 95.589%	     0.000	        1	[efficientnetv2-l/block7d_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_project_conv/Conv2D]:1185
	                     ADD	        27923.046	   13.859	   13.803	  0.047%	 95.637%	     0.000	        1	[efficientnetv2-l/block7d_add/add]:1186
	                 CONV_2D	        27936.858	   19.988	   19.855	  0.068%	 95.705%	     0.000	        1	[efficientnetv2-l/block7e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_expand_conv/Conv2D]:1187
	                LOGISTIC	        27956.725	    8.445	    8.347	  0.029%	 95.733%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/Sigmoid]:1188
	                     MUL	        27965.083	   60.993	   60.910	  0.209%	 95.942%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/mul_1]:1189
	       DEPTHWISE_CONV_2D	        28026.004	    5.895	    5.356	  0.018%	 95.960%	     0.000	        1	[efficientnetv2-l/block7e_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1190
	                LOGISTIC	        28031.372	    8.413	    8.341	  0.029%	 95.989%	     0.000	        1	[efficientnetv2-l/block7e_activation/Sigmoid]:1191
	                     MUL	        28039.724	   61.289	   60.897	  0.209%	 96.197%	     0.000	        1	[efficientnetv2-l/block7e_activation/mul_1]:1192
	                    MEAN	        28100.632	  147.668	  147.303	  0.504%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_squeeze/Mean]:1193
	                   SHAPE	        28247.948	    0.008	    0.009	  0.000%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Shape]:1194
	           STRIDED_SLICE	        28247.963	    0.021	    0.022	  0.000%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/strided_slice]:1195
	                    PACK	        28247.992	    0.030	    0.030	  0.000%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape/shape]:1196
	                 RESHAPE	        28248.031	    0.015	    0.015	  0.000%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape]:1197
	                 CONV_2D	        28248.052	    0.085	    0.068	  0.000%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7e_se_reduce/Conv2D]:1198
	                LOGISTIC	        28248.126	    0.011	    0.011	  0.000%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/Sigmoid]:1199
	                     MUL	        28248.143	    0.025	    0.025	  0.000%	 96.702%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/mul_1]:1200
	                 CONV_2D	        28248.175	    0.136	    0.159	  0.001%	 96.703%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_se_expand/Conv2D]:1201
	                LOGISTIC	        28248.340	    0.058	    0.049	  0.000%	 96.703%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/Sigmoid]:1202
	                     MUL	        28248.396	   61.105	   60.733	  0.208%	 96.911%	     0.000	        1	[efficientnetv2-l/block7e_se_excite/mul]:1203
	                 CONV_2D	        28309.140	   12.537	   12.408	  0.042%	 96.953%	     0.000	        1	[efficientnetv2-l/block7e_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_project_conv/Conv2D]:1204
	                     ADD	        28321.558	   13.882	   13.768	  0.047%	 97.001%	     0.000	        1	[efficientnetv2-l/block7e_add/add]:1205
	                 CONV_2D	        28335.336	   19.966	   19.746	  0.068%	 97.068%	     0.000	        1	[efficientnetv2-l/block7f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_expand_conv/Conv2D]:1206
	                LOGISTIC	        28355.093	    8.325	    8.318	  0.028%	 97.097%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/Sigmoid]:1207
	                     MUL	        28363.421	   61.017	   61.072	  0.209%	 97.306%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/mul_1]:1208
	       DEPTHWISE_CONV_2D	        28424.506	    5.339	    5.315	  0.018%	 97.324%	     0.000	        1	[efficientnetv2-l/block7f_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1209
	                LOGISTIC	        28429.834	    8.324	    8.333	  0.029%	 97.353%	     0.000	        1	[efficientnetv2-l/block7f_activation/Sigmoid]:1210
	                     MUL	        28438.178	   60.978	   60.883	  0.209%	 97.561%	     0.000	        1	[efficientnetv2-l/block7f_activation/mul_1]:1211
	                    MEAN	        28499.072	  146.947	  147.706	  0.506%	 98.067%	     0.000	        1	[efficientnetv2-l/block7f_se_squeeze/Mean]:1212
	                   SHAPE	        28646.789	    0.008	    0.010	  0.000%	 98.067%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Shape]:1213
	           STRIDED_SLICE	        28646.805	    0.020	    0.022	  0.000%	 98.067%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/strided_slice]:1214
	                    PACK	        28646.835	    0.029	    0.033	  0.000%	 98.067%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape/shape]:1215
	                 RESHAPE	        28646.874	    0.015	    0.015	  0.000%	 98.067%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape]:1216
	                 CONV_2D	        28646.895	    0.063	    0.064	  0.000%	 98.067%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7f_se_reduce/Conv2D]:1217
	                LOGISTIC	        28646.965	    0.011	    0.011	  0.000%	 98.067%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/Sigmoid]:1218
	                     MUL	        28646.982	    0.024	    0.036	  0.000%	 98.068%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/mul_1]:1219
	                 CONV_2D	        28647.025	    0.157	    0.154	  0.001%	 98.068%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_se_expand/Conv2D]:1220
	                LOGISTIC	        28647.185	    0.045	    0.044	  0.000%	 98.068%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/Sigmoid]:1221
	                     MUL	        28647.235	   60.365	   61.148	  0.209%	 98.278%	     0.000	        1	[efficientnetv2-l/block7f_se_excite/mul]:1222
	                 CONV_2D	        28708.397	   12.030	   12.082	  0.041%	 98.319%	     0.000	        1	[efficientnetv2-l/block7f_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_project_conv/Conv2D]:1223
	                     ADD	        28720.488	   13.728	   13.752	  0.047%	 98.366%	     0.000	        1	[efficientnetv2-l/block7f_add/add]:1224
	                 CONV_2D	        28734.250	   19.650	   19.734	  0.068%	 98.434%	     0.000	        1	[efficientnetv2-l/block7g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_expand_conv/Conv2D]:1225
	                LOGISTIC	        28753.995	    8.336	    8.341	  0.029%	 98.462%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/Sigmoid]:1226
	                     MUL	        28762.346	   60.491	   60.921	  0.209%	 98.671%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/mul_1]:1227
	       DEPTHWISE_CONV_2D	        28823.279	    5.125	    5.173	  0.018%	 98.689%	     0.000	        1	[efficientnetv2-l/block7g_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_dwconv2/depthwise]:1228
	                LOGISTIC	        28828.466	    8.339	    8.342	  0.029%	 98.717%	     0.000	        1	[efficientnetv2-l/block7g_activation/Sigmoid]:1229
	                     MUL	        28836.818	   60.549	   60.803	  0.208%	 98.925%	     0.000	        1	[efficientnetv2-l/block7g_activation/mul_1]:1230
	                    MEAN	        28897.633	  146.471	  147.109	  0.504%	 99.429%	     0.000	        1	[efficientnetv2-l/block7g_se_squeeze/Mean]:1231
	                   SHAPE	        29044.752	    0.009	    0.009	  0.000%	 99.429%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Shape]:1232
	           STRIDED_SLICE	        29044.768	    0.021	    0.022	  0.000%	 99.429%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/strided_slice]:1233
	                    PACK	        29044.796	    0.031	    0.035	  0.000%	 99.429%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape/shape]:1234
	                 RESHAPE	        29044.838	    0.015	    0.015	  0.000%	 99.429%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape]:1235
	                 CONV_2D	        29044.859	    0.081	    0.075	  0.000%	 99.430%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7g_se_reduce/Conv2D]:1236
	                LOGISTIC	        29044.941	    0.011	    0.011	  0.000%	 99.430%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/Sigmoid]:1237
	                     MUL	        29044.958	    0.025	    0.025	  0.000%	 99.430%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/mul_1]:1238
	                 CONV_2D	        29044.989	    0.155	    0.149	  0.001%	 99.430%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_se_expand/Conv2D]:1239
	                LOGISTIC	        29045.146	    0.046	    0.049	  0.000%	 99.431%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/Sigmoid]:1240
	                     MUL	        29045.200	   60.399	   60.744	  0.208%	 99.639%	     0.000	        1	[efficientnetv2-l/block7g_se_excite/mul]:1241
	                 CONV_2D	        29105.956	   12.089	   12.199	  0.042%	 99.680%	     0.000	        1	[efficientnetv2-l/block7g_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_project_conv/Conv2D]:1242
	                     ADD	        29118.165	   13.704	   13.826	  0.047%	 99.728%	     0.000	        1	[efficientnetv2-l/block7g_add/add]:1243
	                 CONV_2D	        29132.001	    6.720	    6.743	  0.023%	 99.751%	     0.000	        1	[efficientnetv2-l/top_bn/FusedBatchNormV3;efficientnetv2-l/top_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/top_conv/Conv2D]:1244
	                LOGISTIC	        29138.753	    2.731	    2.797	  0.010%	 99.760%	     0.000	        1	[efficientnetv2-l/top_activation/Sigmoid]:1245
	                     MUL	        29141.559	   20.120	   20.327	  0.070%	 99.830%	     0.000	        1	[efficientnetv2-l/top_activation/mul_1]:1246
	                    MEAN	        29161.896	   48.692	   49.196	  0.168%	 99.998%	     0.000	        1	[efficientnetv2-l/avg_pool/Mean]:1247
	         FULLY_CONNECTED	        29211.102	    0.359	    0.364	  0.001%	100.000%	     0.000	        1	[efficientnetv2-l/predictions/MatMul;efficientnetv2-l/predictions/BiasAdd]:1248
	                 SOFTMAX	        29211.473	    0.082	    0.089	  0.000%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:1249

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	         2610.128	  257.910	  261.056	  0.894%	  0.894%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                     MUL	         3139.375	  260.838	  259.711	  0.889%	  1.783%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                     MUL	         4722.336	  257.704	  259.295	  0.888%	  2.671%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                     MUL	         3668.205	  258.665	  259.143	  0.887%	  3.559%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                     MUL	         4195.474	  257.727	  258.705	  0.886%	  4.445%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                     MUL	         5251.308	  258.666	  258.548	  0.885%	  5.330%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                    MEAN	        13029.522	  207.456	  206.357	  0.707%	  6.037%	     0.000	        1	[efficientnetv2-l/block5f_se_squeeze/Mean]:378
	                    MEAN	        14127.688	  204.627	  205.732	  0.705%	  6.742%	     0.000	        1	[efficientnetv2-l/block5h_se_squeeze/Mean]:416
	                    MEAN	        19609.082	  204.476	  205.617	  0.704%	  7.446%	     0.000	        1	[efficientnetv2-l/block5r_se_squeeze/Mean]:606
	                    MEAN	        17965.174	  206.972	  205.605	  0.704%	  8.150%	     0.000	        1	[efficientnetv2-l/block5o_se_squeeze/Mean]:549

Number of nodes executed: 1250
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                     MUL	      265	 13267.509	    45.437%	    45.437%	     0.000	      265
	                    MEAN	       62	  8179.185	    28.011%	    73.448%	     0.000	       62
	                 CONV_2D	      278	  3648.488	    12.495%	    85.943%	     0.000	      278
	                     ADD	       74	  2241.058	     7.675%	    93.618%	     0.000	       74
	                LOGISTIC	      264	  1367.370	     4.683%	    98.301%	     0.000	      264
	       DEPTHWISE_CONV_2D	       61	   490.854	     1.681%	    99.982%	     0.000	       61
	                    PACK	       61	     1.983	     0.007%	    99.989%	     0.000	       61
	           STRIDED_SLICE	       61	     1.362	     0.005%	    99.994%	     0.000	       61
	                 RESHAPE	       61	     0.871	     0.003%	    99.997%	     0.000	       61
	                   SHAPE	       61	     0.514	     0.002%	    99.998%	     0.000	       61
	         FULLY_CONNECTED	        1	     0.363	     0.001%	   100.000%	     0.000	        1
	                 SOFTMAX	        1	     0.088	     0.000%	   100.000%	     0.000	        1

Timings (microseconds): count=6 first=29179869 curr=29182370 min=29179869 max=29228873 avg=2.92002e+07 std=16246
Memory (bytes): count=0
1250 nodes observed



[ perf record: Woken up 984 times to write data ]
Warning:
Processed 1403769 events and lost 2 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 246.034 MB /tmp/data.record (1401546 samples) ]

353.085

