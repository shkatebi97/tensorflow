STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/EfficientNetV2L.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/EfficientNetV2L.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (230400, 3, ), and Output shape (57600, 32, ), and the ID is 0
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 16)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 1
	Allocating LowPrecision Weight Tensors with Shape of (32, 144)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 144)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 144)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 144)
(57600, 32, ), and the ID is 2
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 3
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 144)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 144)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 4
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 144)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 144)
Applying Conv Low-Precision for Kernel shape (128, 288, ), Input shape (57600, 32, ), and Output shape (14400, 128, ), and the ID is 5
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (128, 144)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (14400, 128, ), and Output shape (14400, 64, ), and the ID is 6
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 7
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 288)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 128)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 8
	Allocating LowPrecision Activations Tensors with Shape of (14400, 128)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 288)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 128)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 128)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 288)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 9
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 10
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 11
	Allocating LowPrecision Activations Tensors with Shape of (14400, 288)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 128)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 128)
(14400, 256, ), and Output shape (14400, 64, ), and the ID is 12
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 288)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 13
	Allocating LowPrecision Activations Tensors with Shape of (14400, 288)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 14
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 128)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 128)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 15
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 288)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 288)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 16
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 128)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 128)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 17
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 288)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 288)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 18
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 128)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 128)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (3600, 256, ), and the ID is 19
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 288)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 288)
Applying Conv Low-Precision for Kernel shape (96, 256, ), Input shape (3600, 256, ), and Output shape (3600, 96, ), and the ID is 20
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 128)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 128)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 432)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 21
	Allocating LowPrecision Activations Tensors with Shape of (3600, 432)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 22	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 192)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 192)

Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 23
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 432)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 432)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 192)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 192)
, and the ID is 24
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 432)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 25
	Allocating LowPrecision Activations Tensors with Shape of (3600, 432)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 192)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 192)
(3600, 96, ), and the ID is 26
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 432)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 27
	Allocating LowPrecision Activations Tensors with Shape of (3600, 432)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 192)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 192)
28
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 432)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 29
	Allocating LowPrecision Activations Tensors with Shape of (3600, 432)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 192)
(3600, 384, ), and Output shape (3600, 96, ), and the ID is 30
	Allocating LowPrecision Activations Tensors with Shape of (3600, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 432)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 31
	Allocating LowPrecision Activations Tensors with Shape of (3600, 432)
Applying Conv Low-Precision for Kernel shape (96, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 192)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 192)
, Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 32
Applying Conv Low-Precision for Kernel shape (384, 96, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 33
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
The input model file size (MB): 127.361
Initialized session in 232.113ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
Applying Conv Low-Precision for Kernel shape (24, 384, ), Input shape (1, 384, ), and Output shape (1, 24, ), and the ID is 34	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (24, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)

	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 24, ), Input shape (1, 24, ), and Output shape (1, 384, ), and the ID is 35
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (192, 384, ), Input shape (900, 384, ), and Output shape (900, 192, ), and the ID is 36
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 37
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 38	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)

	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 39
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
, and Output shape (900, 192, ), and the ID is 40
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 41
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 42
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 43
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 44
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 45
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 46
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 47
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 48
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
49
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 50
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 51
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
(900, 192, ), and the ID is 52
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 53	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)

	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 54
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 55
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 56	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)

Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 57
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 58
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 59
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 60
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 768, ), and the ID is 61
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 62
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 63
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
(192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 64
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 65
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 66
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 67
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
(900, 192, ), and the ID is 68
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 69
	Allocating LowPrecision Weight Tensors with Shape of (768, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 70
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 384)
	Allocating LowPrecision Activations Tensors with Shape of (1, 384)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 71
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
72
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 384)
	Allocating LowPrecision Activations Tensors with Shape of (900, 384)
Applying Conv Low-Precision for Kernel shape (1152, 192, ), Input shape (900, 192, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 1152, ), and the ID is 73
	Allocating LowPrecision Weight Tensors with Shape of (1152, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (48, 1152, ), Input shape (1, 1152, ), and Output shape (1, 48, ), and the ID is 74
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (1152, 48, ), Input shape (1, 48, ), and Output shape (1, 1152, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 75
	Allocating LowPrecision Weight Tensors with Shape of (1152, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1152, ), Input shape (900, 1152, ), and Output shape (900, 224, ), and the ID is 76	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 576)

	Allocating LowPrecision Activations Tensors with Shape of (900, 576)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 77	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
, and the ID is 78
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 79
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
80
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 224, ), and Output shape (900, 1344, ), and the ID is 81
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 82
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 83
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 84	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)

	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 224, ), and Output shape (900, 1344, ), and the ID is 85
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 86
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 87
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
(224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 88
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 89
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 90
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 91
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
, and Output shape (900, 224, ), and the ID is 92
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 93	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 94
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 95
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
(900, 224, ), and the ID is 96
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
97
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 98
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 99	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)

	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 100
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 101
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 102
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 103
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
104
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 105
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 106
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
, and the ID is 107
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 108
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
109
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 110
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 111
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 112
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 1344, ), and the ID is 113
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 114
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 115
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 116
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and Output shape (900, 1344, ), and the ID is 117
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 118
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
119
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 224, ), and the ID is 120
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 121
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 122
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
123
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 1344, ), and Output shape (900, 224, ), and the ID is 124
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 125
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 126
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 127
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
, and Output shape (900, 224, ), and the ID is 128
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(900, 1344, ), and the ID is 129
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 130
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 131
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
(900, 224, ), and the ID is 132
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 133
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 134
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 135
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 136
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 137
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
, and the ID is 138
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 139
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
(900, 224, ), and the ID is 140
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 141
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 142
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 143
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 144
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 145
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 146
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)
	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 147	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)

	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 672)
148
	Allocating LowPrecision Activations Tensors with Shape of (900, 672)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 149
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 112)
	Allocating LowPrecision Activations Tensors with Shape of (900, 112)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 150	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 672)

	Allocating LowPrecision Activations Tensors with Shape of (1, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 151
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 1344, ), Input shape (225, 1344, ), and Output shape (225, 384, ), and the ID is 152
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 672)
	Allocating LowPrecision Activations Tensors with Shape of (228, 672)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 153
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 154
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and Output shape (1, 2304, ), and the ID is 155
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 156
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 157
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 158
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 159	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 2304, ), and Output shape (225, 384, ), and the ID is 160
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 161
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 162
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
163
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 2304, ), and Output shape (225, 384, ), and the ID is 164
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 165
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 166
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 167
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 168
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 169
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 170
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 171
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 384, ), and the ID is 172
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 173
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 174
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 175
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
, and the ID is 176
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 177
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 178
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 179
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 384, ), and the ID is 180
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 181
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 182
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and Output shape (1, 2304, ), and the ID is 183
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(225, 384, ), and the ID is 184
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 185
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 186
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
187
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
, Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 188
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 189
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 190
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 191
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 384, ), and the ID is 192
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 193
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 194
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 195
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 196
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 197
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 198
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 199
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 200
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 201
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 202
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 203
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 204
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 205
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 206
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 207
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(225, 384, ), and the ID is 208
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 209
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
, and the ID is 210
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 211
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 2304, ), and Output shape (225, 384, ), and the ID is 212
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 213
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 214
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 215
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
, and the ID is 216
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 217
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 218
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 219
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 2304, ), and Output shape (225, 384, ), and the ID is 220
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 221
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 222
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 223
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 384, ), and the ID is 224
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 225
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 226
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and Output shape (1, 2304, ), and the ID is 227
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
, and the ID is 228
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 229
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 230
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 231
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(225, 2304, ), and Output shape (225, 384, ), and the ID is 232
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 233
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
, and the ID is 234
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 235
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 236
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 237
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 238
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 2304, ), and the ID is 239
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 240
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 241
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 242
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 243
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 244	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 245
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
, and the ID is 246
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 247
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 1152)
(225, 2304, ), and Output shape (225, 384, ), and the ID is 248
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 249
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 192)
	Allocating LowPrecision Activations Tensors with Shape of (228, 192)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 250
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1152)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 251
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 2304, ), Input shape (225, 2304, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(225, 640, ), and the ID is 252
	Allocating LowPrecision Weight Tensors with Shape of (640, 1152)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1152)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 253
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 320)
	Allocating LowPrecision Activations Tensors with Shape of (228, 320)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 254
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(1, 160, ), and Output shape (1, 3840, ), and the ID is 255
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (1, 80)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
(225, 640, ), and the ID is 256
	Allocating LowPrecision Weight Tensors with Shape of (640, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 257
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 320)
	Allocating LowPrecision Activations Tensors with Shape of (228, 320)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 1920)
, and the ID is 258
	Allocating LowPrecision Activations Tensors with Shape of (1, 1920)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 259
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (1, 80)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
, and the ID is 260
	Allocating LowPrecision Weight Tensors with Shape of (640, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 261	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors

	Allocating LowPrecision Weight Tensors with Shape of (3840, 320)
	Allocating LowPrecision Activations Tensors with Shape of (228, 320)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 262
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1920)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 263
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (1, 80)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 1920)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 264
	Allocating LowPrecision Activations Tensors with Shape of (228, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 265
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 320)
	Allocating LowPrecision Activations Tensors with Shape of (228, 320)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 266
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 267
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (1, 80)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 268
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (228, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 269
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 320)
	Allocating LowPrecision Activations Tensors with Shape of (228, 320)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 270
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
271
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (1, 80)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 1920)
272
	Allocating LowPrecision Activations Tensors with Shape of (228, 1920)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 273
	Allocating LowPrecision Weight Tensors with Shape of (3840, 320)
	Allocating LowPrecision Activations Tensors with Shape of (228, 320)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 274
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 1920)
	Allocating LowPrecision Activations Tensors with Shape of (1, 1920)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 275
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (1, 80)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 1920)
(225, 3840, ), and Output shape (225, 640, ), and the ID is 276
	Allocating LowPrecision Activations Tensors with Shape of (228, 1920)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1280, 320)
Applying Conv Low-Precision for Kernel shape (1280, 640, ), Input shape (225, 640, ), and Output shape (225, 1280, ), and the ID is 277
	Allocating LowPrecision Activations Tensors with Shape of (228, 320)
Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 7 Number of Temporaries Tensors
	Transformed Filter Shape: (1000, 640)
	Transformed Activation Shape From: (1, 1280) To: (1, 640)
count=6 first=30366919 curr=29801045 min=29801045 max=30366919 avg=2.9916e+07 std=204387

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=6 first=29822543 curr=29880430 min=29820852 max=29880430 avg=2.98415e+07 std=20901

Inference timings in us: Init: 232113, First inference: 30366919, Warmup (avg): 2.9916e+07, Inference (avg): 2.98415e+07
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=39.5234 overall=217.973
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   24.457	   24.457	100.000%	100.000%	  3828.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   24.457	   24.457	100.000%	100.000%	  3828.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    24.457	   100.000%	   100.000%	  3828.000	        1

Timings (microseconds): count=1 curr=24457
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	            0.028	   38.637	   38.612	  0.129%	  0.129%	     0.000	        1	[efficientnetv2-l/rescaling/mul]:0
	                     ADD	           38.651	   31.723	   31.786	  0.107%	  0.236%	     0.000	        1	[efficientnetv2-l/rescaling/add]:1
	                 CONV_2D	           70.448	   42.885	   42.853	  0.144%	  0.380%	     0.000	        1	[efficientnetv2-l/stem_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/stem_conv/Conv2D]:2
	                LOGISTIC	          113.315	   18.159	   18.176	  0.061%	  0.441%	     0.000	        1	[efficientnetv2-l/stem_activation/Sigmoid]:3
	                     MUL	          131.502	  129.064	  128.996	  0.432%	  0.873%	     0.000	        1	[efficientnetv2-l/stem_activation/mul_1]:4
	                 CONV_2D	          260.510	   85.027	   84.803	  0.284%	  1.157%	     0.000	        1	[efficientnetv2-l/block1a_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1a_project_conv/Conv2D]:5
	                LOGISTIC	          345.326	   17.999	   18.087	  0.061%	  1.218%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/Sigmoid]:6
	                     MUL	          363.426	  129.173	  129.095	  0.433%	  1.651%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/mul_1]:7
	                     ADD	          492.534	  175.474	  175.769	  0.589%	  2.240%	     0.000	        1	[efficientnetv2-l/block1a_add/add]:8
	                 CONV_2D	          668.315	   83.150	   84.391	  0.283%	  2.523%	     0.000	        1	[efficientnetv2-l/block1b_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1b_project_conv/Conv2D]:9
	                LOGISTIC	          752.718	   18.144	   18.191	  0.061%	  2.584%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/Sigmoid]:10
	                     MUL	          770.922	  129.233	  130.231	  0.437%	  3.020%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/mul_1]:11
	                     ADD	          901.166	  176.163	  177.222	  0.594%	  3.615%	     0.000	        1	[efficientnetv2-l/block1b_add/add]:12
	                 CONV_2D	         1078.403	   86.326	   86.579	  0.290%	  3.905%	     0.000	        1	[efficientnetv2-l/block1c_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1c_project_conv/Conv2D]:13
	                LOGISTIC	         1164.993	   18.203	   18.326	  0.061%	  3.966%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/Sigmoid]:14
	                     MUL	         1183.331	  132.050	  130.842	  0.439%	  4.405%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/mul_1]:15
	                     ADD	         1314.184	  177.358	  177.524	  0.595%	  5.000%	     0.000	        1	[efficientnetv2-l/block1c_add/add]:16
	                 CONV_2D	         1491.720	   85.819	   85.842	  0.288%	  5.288%	     0.000	        1	[efficientnetv2-l/block1d_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1d_project_conv/Conv2D]:17
	                LOGISTIC	         1577.574	   18.180	   18.129	  0.061%	  5.349%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/Sigmoid]:18
	                     MUL	         1595.714	  130.291	  129.725	  0.435%	  5.783%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/mul_1]:19
	                     ADD	         1725.450	  176.554	  176.345	  0.591%	  6.375%	     0.000	        1	[efficientnetv2-l/block1d_add/add]:20
	                 CONV_2D	         1901.807	   52.991	   52.198	  0.175%	  6.550%	     0.000	        1	[efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_expand_conv/Conv2D]:21
	                LOGISTIC	         1954.018	   18.284	   18.203	  0.061%	  6.611%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/Sigmoid]:22
	                     MUL	         1972.232	  130.092	  129.180	  0.433%	  7.044%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/mul_1]:23
	                 CONV_2D	         2101.424	   10.549	   10.538	  0.035%	  7.079%	     0.000	        1	[efficientnetv2-l/block2a_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_project_conv/Conv2D]:24
	                 CONV_2D	         2111.973	  153.071	  152.430	  0.511%	  7.590%	     0.000	        1	[efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_expand_conv/Conv2D]:25
	                LOGISTIC	         2264.415	   35.727	   35.827	  0.120%	  7.710%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/Sigmoid]:26
	                     MUL	         2300.256	  258.068	  258.205	  0.866%	  8.576%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                 CONV_2D	         2558.473	   18.385	   18.399	  0.062%	  8.637%	     0.000	        1	[efficientnetv2-l/block2b_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_project_conv/Conv2D]:28
	                     ADD	         2576.884	   87.716	   87.683	  0.294%	  8.931%	     0.000	        1	[efficientnetv2-l/block2b_add/add]:29
	                 CONV_2D	         2664.580	  153.575	  153.163	  0.513%	  9.445%	     0.000	        1	[efficientnetv2-l/block2c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_expand_conv/Conv2D]:30
	                LOGISTIC	         2817.755	   36.116	   36.012	  0.121%	  9.565%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/Sigmoid]:31
	                     MUL	         2853.780	  258.109	  258.168	  0.865%	 10.431%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                 CONV_2D	         3111.959	   18.441	   18.491	  0.062%	 10.493%	     0.000	        1	[efficientnetv2-l/block2c_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_project_conv/Conv2D]:33
	                     ADD	         3130.462	   87.746	   87.994	  0.295%	 10.788%	     0.000	        1	[efficientnetv2-l/block2c_add/add]:34
	                 CONV_2D	         3218.468	  153.873	  154.486	  0.518%	 11.306%	     0.000	        1	[efficientnetv2-l/block2d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_expand_conv/Conv2D]:35
	                LOGISTIC	         3372.967	   35.885	   36.134	  0.121%	 11.427%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/Sigmoid]:36
	                     MUL	         3409.118	  259.164	  261.786	  0.878%	 12.305%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                 CONV_2D	         3670.916	   18.686	   18.772	  0.063%	 12.367%	     0.000	        1	[efficientnetv2-l/block2d_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_project_conv/Conv2D]:38
	                     ADD	         3689.700	   88.857	   88.975	  0.298%	 12.666%	     0.000	        1	[efficientnetv2-l/block2d_add/add]:39
	                 CONV_2D	         3778.686	  155.641	  155.244	  0.520%	 13.186%	     0.000	        1	[efficientnetv2-l/block2e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_expand_conv/Conv2D]:40
	                LOGISTIC	         3933.942	   36.233	   36.264	  0.122%	 13.308%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/Sigmoid]:41
	                     MUL	         3970.218	  260.125	  259.521	  0.870%	 14.178%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                 CONV_2D	         4229.751	   18.518	   18.472	  0.062%	 14.240%	     0.000	        1	[efficientnetv2-l/block2e_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_project_conv/Conv2D]:43
	                     ADD	         4248.234	   88.304	   88.170	  0.296%	 14.535%	     0.000	        1	[efficientnetv2-l/block2e_add/add]:44
	                 CONV_2D	         4336.416	  154.583	  154.423	  0.518%	 15.053%	     0.000	        1	[efficientnetv2-l/block2f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_expand_conv/Conv2D]:45
	                LOGISTIC	         4490.852	   35.980	   35.913	  0.120%	 15.173%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/Sigmoid]:46
	                     MUL	         4526.776	  258.219	  258.008	  0.865%	 16.038%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                 CONV_2D	         4784.798	   18.344	   18.363	  0.062%	 16.100%	     0.000	        1	[efficientnetv2-l/block2f_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_project_conv/Conv2D]:48
	                     ADD	         4803.176	   87.734	   87.696	  0.294%	 16.394%	     0.000	        1	[efficientnetv2-l/block2f_add/add]:49
	                 CONV_2D	         4890.884	  154.008	  153.683	  0.515%	 16.909%	     0.000	        1	[efficientnetv2-l/block2g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_expand_conv/Conv2D]:50
	                LOGISTIC	         5044.579	   36.038	   35.981	  0.121%	 17.030%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/Sigmoid]:51
	                     MUL	         5080.572	  258.022	  257.969	  0.865%	 17.894%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                 CONV_2D	         5338.553	   18.397	   18.482	  0.062%	 17.956%	     0.000	        1	[efficientnetv2-l/block2g_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_project_conv/Conv2D]:53
	                     ADD	         5357.047	   87.620	   87.695	  0.294%	 18.250%	     0.000	        1	[efficientnetv2-l/block2g_add/add]:54
	                 CONV_2D	         5444.755	   38.372	   38.549	  0.129%	 18.380%	     0.000	        1	[efficientnetv2-l/block3a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_expand_conv/Conv2D]:55
	                LOGISTIC	         5483.316	    8.949	    8.982	  0.030%	 18.410%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/Sigmoid]:56
	                     MUL	         5492.308	   64.618	   64.638	  0.217%	 18.626%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/mul_1]:57
	                 CONV_2D	         5556.957	    6.875	    6.825	  0.023%	 18.649%	     0.000	        1	[efficientnetv2-l/block3a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_project_conv/Conv2D]:58
	                 CONV_2D	         5563.792	   86.498	   86.735	  0.291%	 18.940%	     0.000	        1	[efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_expand_conv/Conv2D]:59
	                LOGISTIC	         5650.539	   13.319	   13.370	  0.045%	 18.985%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/Sigmoid]:60
	                     MUL	         5663.919	   96.895	   97.213	  0.326%	 19.311%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/mul_1]:61
	                 CONV_2D	         5761.145	    9.698	    9.743	  0.033%	 19.343%	     0.000	        1	[efficientnetv2-l/block3b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_project_conv/Conv2D]:62
	                     ADD	         5770.900	   32.946	   33.117	  0.111%	 19.454%	     0.000	        1	[efficientnetv2-l/block3b_add/add]:63
	                 CONV_2D	         5804.029	   86.454	   87.908	  0.295%	 19.749%	     0.000	        1	[efficientnetv2-l/block3c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_expand_conv/Conv2D]:64
	                LOGISTIC	         5891.948	   13.293	   13.449	  0.045%	 19.794%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/Sigmoid]:65
	                     MUL	         5905.409	   97.159	   97.719	  0.328%	 20.122%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/mul_1]:66
	                 CONV_2D	         6003.142	    9.666	    9.781	  0.033%	 20.155%	     0.000	        1	[efficientnetv2-l/block3c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_project_conv/Conv2D]:67
	                     ADD	         6012.944	   33.043	   33.200	  0.111%	 20.266%	     0.000	        1	[efficientnetv2-l/block3c_add/add]:68
	                 CONV_2D	         6046.155	   87.957	   88.982	  0.298%	 20.564%	     0.000	        1	[efficientnetv2-l/block3d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_expand_conv/Conv2D]:69
	                LOGISTIC	         6135.149	   13.429	   13.530	  0.045%	 20.610%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/Sigmoid]:70
	                     MUL	         6148.691	   99.314	   98.230	  0.329%	 20.939%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/mul_1]:71
	                 CONV_2D	         6246.932	    9.794	    9.761	  0.033%	 20.972%	     0.000	        1	[efficientnetv2-l/block3d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_project_conv/Conv2D]:72
	                     ADD	         6256.705	   33.823	   33.369	  0.112%	 21.083%	     0.000	        1	[efficientnetv2-l/block3d_add/add]:73
	                 CONV_2D	         6290.088	   88.469	   88.226	  0.296%	 21.379%	     0.000	        1	[efficientnetv2-l/block3e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_expand_conv/Conv2D]:74
	                LOGISTIC	         6378.327	   13.647	   13.455	  0.045%	 21.424%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/Sigmoid]:75
	                     MUL	         6391.793	   97.857	   97.584	  0.327%	 21.751%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/mul_1]:76
	                 CONV_2D	         6489.388	    9.711	    9.723	  0.033%	 21.784%	     0.000	        1	[efficientnetv2-l/block3e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_project_conv/Conv2D]:77
	                     ADD	         6499.125	   33.314	   33.163	  0.111%	 21.895%	     0.000	        1	[efficientnetv2-l/block3e_add/add]:78
	                 CONV_2D	         6532.300	   87.756	   87.124	  0.292%	 22.187%	     0.000	        1	[efficientnetv2-l/block3f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_expand_conv/Conv2D]:79
	                LOGISTIC	         6619.435	   13.378	   13.360	  0.045%	 22.232%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/Sigmoid]:80
	                     MUL	         6632.807	   97.721	   97.255	  0.326%	 22.558%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/mul_1]:81
	                 CONV_2D	         6730.074	    9.760	    9.719	  0.033%	 22.591%	     0.000	        1	[efficientnetv2-l/block3f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_project_conv/Conv2D]:82
	                     ADD	         6739.806	   33.145	   33.040	  0.111%	 22.702%	     0.000	        1	[efficientnetv2-l/block3f_add/add]:83
	                 CONV_2D	         6772.857	   87.558	   87.020	  0.292%	 22.993%	     0.000	        1	[efficientnetv2-l/block3g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_expand_conv/Conv2D]:84
	                LOGISTIC	         6859.889	   13.350	   13.371	  0.045%	 23.038%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/Sigmoid]:85
	                     MUL	         6873.272	   97.662	   96.956	  0.325%	 23.363%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/mul_1]:86
	                 CONV_2D	         6970.242	    9.996	    9.971	  0.033%	 23.397%	     0.000	        1	[efficientnetv2-l/block3g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_project_conv/Conv2D]:87
	                     ADD	         6980.224	   33.167	   32.988	  0.111%	 23.507%	     0.000	        1	[efficientnetv2-l/block3g_add/add]:88
	                 CONV_2D	         7013.224	   16.454	   16.311	  0.055%	 23.562%	     0.000	        1	[efficientnetv2-l/block4a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_expand_conv/Conv2D]:89
	                LOGISTIC	         7029.547	   13.498	   13.495	  0.045%	 23.607%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/Sigmoid]:90
	                     MUL	         7043.053	   97.546	   96.976	  0.325%	 23.932%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/mul_1]:91
	       DEPTHWISE_CONV_2D	         7140.042	  122.934	  123.047	  0.412%	 24.345%	     0.000	        1	[efficientnetv2-l/block4a_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_dwconv2/depthwise;efficientnetv2-l/block6y_project_bn/FusedBatchNormV3]:92
	                LOGISTIC	         7263.101	    3.375	    3.404	  0.011%	 24.356%	     0.000	        1	[efficientnetv2-l/block4a_activation/Sigmoid]:93
	                     MUL	         7266.513	   24.185	   24.186	  0.081%	 24.437%	     0.000	        1	[efficientnetv2-l/block4a_activation/mul_1]:94
	                    MEAN	         7290.710	   58.341	   58.322	  0.196%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_squeeze/Mean]:95
	                   SHAPE	         7349.042	    0.008	    0.008	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Shape]:96
	           STRIDED_SLICE	         7349.056	    0.020	    0.020	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/strided_slice]:97
	                    PACK	         7349.083	    0.029	    0.027	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape/shape]:98
	                 RESHAPE	         7349.116	    0.014	    0.014	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape]:99
	                 CONV_2D	         7349.136	    0.041	    0.052	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/BiasAdd;efficientnetv2-l/block4a_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4a_se_reduce/Conv2D]:100
	                LOGISTIC	         7349.195	    0.009	    0.009	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/Sigmoid]:101
	                     MUL	         7349.210	    0.018	    0.018	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/mul_1]:102
	                 CONV_2D	         7349.234	    0.022	    0.022	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/BiasAdd;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_se_expand/Conv2D]:103
	                LOGISTIC	         7349.263	    0.011	    0.011	  0.000%	 24.633%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/Sigmoid]:104
	                     MUL	         7349.280	   24.237	   24.332	  0.082%	 24.715%	     0.000	        1	[efficientnetv2-l/block4a_se_excite/mul]:105
	                 CONV_2D	         7373.623	    4.804	    4.815	  0.016%	 24.731%	     0.000	        1	[efficientnetv2-l/block4a_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_project_conv/Conv2D]:106
	                 CONV_2D	         7378.445	   10.183	   10.199	  0.034%	 24.765%	     0.000	        1	[efficientnetv2-l/block4b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_expand_conv/Conv2D]:107
	                LOGISTIC	         7388.653	    6.699	    6.712	  0.023%	 24.788%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/Sigmoid]:108
	                     MUL	         7395.376	   48.435	   48.401	  0.162%	 24.950%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/mul_1]:109
	       DEPTHWISE_CONV_2D	         7443.788	    3.561	    3.495	  0.012%	 24.962%	     0.000	        1	[efficientnetv2-l/block4b_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:110
	                LOGISTIC	         7447.295	    6.726	    6.722	  0.023%	 24.984%	     0.000	        1	[efficientnetv2-l/block4b_activation/Sigmoid]:111
	                     MUL	         7454.029	   48.398	   48.425	  0.162%	 25.146%	     0.000	        1	[efficientnetv2-l/block4b_activation/mul_1]:112
	                    MEAN	         7502.467	  116.664	  116.626	  0.391%	 25.537%	     0.000	        1	[efficientnetv2-l/block4b_se_squeeze/Mean]:113
	                   SHAPE	         7619.107	    0.009	    0.009	  0.000%	 25.537%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Shape]:114
	           STRIDED_SLICE	         7619.122	    0.021	    0.021	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/strided_slice]:115
	                    PACK	         7619.149	    0.027	    0.029	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape/shape]:116
	                 RESHAPE	         7619.185	    0.014	    0.014	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape]:117
	                 CONV_2D	         7619.205	    0.044	    0.050	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4b_se_reduce/Conv2D]:118
	                LOGISTIC	         7619.261	    0.009	    0.010	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/Sigmoid]:119
	                     MUL	         7619.276	    0.017	    0.018	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/mul_1]:120
	                 CONV_2D	         7619.300	    0.022	    0.023	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_se_expand/Conv2D]:121
	                LOGISTIC	         7619.329	    0.014	    0.015	  0.000%	 25.538%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/Sigmoid]:122
	                     MUL	         7619.350	   48.443	   48.414	  0.162%	 25.700%	     0.000	        1	[efficientnetv2-l/block4b_se_excite/mul]:123
	                 CONV_2D	         7667.775	    9.021	    9.041	  0.030%	 25.731%	     0.000	        1	[efficientnetv2-l/block4b_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_project_conv/Conv2D]:124
	                     ADD	         7676.825	   16.463	   16.461	  0.055%	 25.786%	     0.000	        1	[efficientnetv2-l/block4b_add/add]:125
	                 CONV_2D	         7693.295	   10.254	   10.261	  0.034%	 25.820%	     0.000	        1	[efficientnetv2-l/block4c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_expand_conv/Conv2D]:126
	                LOGISTIC	         7703.564	    6.724	    6.726	  0.023%	 25.843%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/Sigmoid]:127
	                     MUL	         7710.301	   48.373	   48.495	  0.163%	 26.005%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/mul_1]:128
	       DEPTHWISE_CONV_2D	         7758.807	    3.524	    3.549	  0.012%	 26.017%	     0.000	        1	[efficientnetv2-l/block4c_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:129
	                LOGISTIC	         7762.370	    6.737	    6.700	  0.022%	 26.040%	     0.000	        1	[efficientnetv2-l/block4c_activation/Sigmoid]:130
	                     MUL	         7769.081	   48.446	   48.420	  0.162%	 26.202%	     0.000	        1	[efficientnetv2-l/block4c_activation/mul_1]:131
	                    MEAN	         7817.513	  116.770	  116.684	  0.391%	 26.593%	     0.000	        1	[efficientnetv2-l/block4c_se_squeeze/Mean]:132
	                   SHAPE	         7934.209	    0.008	    0.008	  0.000%	 26.593%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Shape]:133
	           STRIDED_SLICE	         7934.224	    0.021	    0.022	  0.000%	 26.593%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/strided_slice]:134
	                    PACK	         7934.252	    0.027	    0.033	  0.000%	 26.593%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape/shape]:135
	                 RESHAPE	         7934.292	    0.014	    0.013	  0.000%	 26.593%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape]:136
	                 CONV_2D	         7934.312	    0.043	    0.047	  0.000%	 26.594%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4c_se_reduce/Conv2D]:137
	                LOGISTIC	         7934.365	    0.009	    0.009	  0.000%	 26.594%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/Sigmoid]:138
	                     MUL	         7934.380	    0.018	    0.018	  0.000%	 26.594%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/mul_1]:139
	                 CONV_2D	         7934.404	    0.025	    0.022	  0.000%	 26.594%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_se_expand/Conv2D]:140
	                LOGISTIC	         7934.432	    0.015	    0.015	  0.000%	 26.594%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/Sigmoid]:141
	                     MUL	         7934.453	   48.475	   48.484	  0.163%	 26.756%	     0.000	        1	[efficientnetv2-l/block4c_se_excite/mul]:142
	                 CONV_2D	         7982.948	    9.047	    9.070	  0.030%	 26.787%	     0.000	        1	[efficientnetv2-l/block4c_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_project_conv/Conv2D]:143
	                     ADD	         7992.030	   16.475	   16.504	  0.055%	 26.842%	     0.000	        1	[efficientnetv2-l/block4c_add/add]:144
	                 CONV_2D	         8008.543	   10.243	   10.260	  0.034%	 26.877%	     0.000	        1	[efficientnetv2-l/block4d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_expand_conv/Conv2D]:145
	                LOGISTIC	         8018.812	    6.676	    6.697	  0.022%	 26.899%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/Sigmoid]:146
	                     MUL	         8025.521	   48.459	   48.444	  0.162%	 27.061%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/mul_1]:147
	       DEPTHWISE_CONV_2D	         8073.976	    3.559	    3.592	  0.012%	 27.073%	     0.000	        1	[efficientnetv2-l/block4d_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:148
	                LOGISTIC	         8077.579	    6.707	    6.725	  0.023%	 27.096%	     0.000	        1	[efficientnetv2-l/block4d_activation/Sigmoid]:149
	                     MUL	         8084.315	   48.446	   48.599	  0.163%	 27.259%	     0.000	        1	[efficientnetv2-l/block4d_activation/mul_1]:150
	                    MEAN	         8132.926	  116.765	  117.159	  0.393%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_squeeze/Mean]:151
	                   SHAPE	         8250.098	    0.009	    0.009	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Shape]:152
	           STRIDED_SLICE	         8250.113	    0.032	    0.028	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/strided_slice]:153
	                    PACK	         8250.147	    0.027	    0.028	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape/shape]:154
	                 RESHAPE	         8250.183	    0.013	    0.016	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape]:155
	                 CONV_2D	         8250.206	    0.044	    0.046	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4d_se_reduce/Conv2D]:156
	                LOGISTIC	         8250.257	    0.009	    0.009	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/Sigmoid]:157
	                     MUL	         8250.273	    0.018	    0.018	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/mul_1]:158
	                 CONV_2D	         8250.297	    0.024	    0.024	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_se_expand/Conv2D]:159
	                LOGISTIC	         8250.327	    0.014	    0.014	  0.000%	 27.652%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/Sigmoid]:160
	                     MUL	         8250.347	   48.366	   48.642	  0.163%	 27.815%	     0.000	        1	[efficientnetv2-l/block4d_se_excite/mul]:161
	                 CONV_2D	         8299.004	    9.014	    9.072	  0.030%	 27.846%	     0.000	        1	[efficientnetv2-l/block4d_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_project_conv/Conv2D]:162
	                     ADD	         8308.086	   16.468	   16.609	  0.056%	 27.901%	     0.000	        1	[efficientnetv2-l/block4d_add/add]:163
	                 CONV_2D	         8324.705	   10.263	   10.425	  0.035%	 27.936%	     0.000	        1	[efficientnetv2-l/block4e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_expand_conv/Conv2D]:164
	                LOGISTIC	         8335.141	    6.716	    6.761	  0.023%	 27.959%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/Sigmoid]:165
	                     MUL	         8341.912	   48.468	   48.877	  0.164%	 28.123%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/mul_1]:166
	       DEPTHWISE_CONV_2D	         8390.800	    3.458	    3.633	  0.012%	 28.135%	     0.000	        1	[efficientnetv2-l/block4e_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:167
	                LOGISTIC	         8394.444	    6.729	    6.768	  0.023%	 28.158%	     0.000	        1	[efficientnetv2-l/block4e_activation/Sigmoid]:168
	                     MUL	         8401.226	   48.594	   48.904	  0.164%	 28.322%	     0.000	        1	[efficientnetv2-l/block4e_activation/mul_1]:169
	                    MEAN	         8450.149	  117.043	  117.987	  0.396%	 28.717%	     0.000	        1	[efficientnetv2-l/block4e_se_squeeze/Mean]:170
	                   SHAPE	         8568.148	    0.010	    0.009	  0.000%	 28.717%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Shape]:171
	           STRIDED_SLICE	         8568.164	    0.022	    0.025	  0.000%	 28.717%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/strided_slice]:172
	                    PACK	         8568.196	    0.027	    0.029	  0.000%	 28.717%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape/shape]:173
	                 RESHAPE	         8568.233	    0.014	    0.015	  0.000%	 28.718%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape]:174
	                 CONV_2D	         8568.253	    0.044	    0.063	  0.000%	 28.718%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4e_se_reduce/Conv2D]:175
	                LOGISTIC	         8568.323	    0.010	    0.010	  0.000%	 28.718%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/Sigmoid]:176
	                     MUL	         8568.339	    0.018	    0.019	  0.000%	 28.718%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/mul_1]:177
	                 CONV_2D	         8568.365	    0.039	    0.027	  0.000%	 28.718%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_se_expand/Conv2D]:178
	                LOGISTIC	         8568.398	    0.016	    0.015	  0.000%	 28.718%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/Sigmoid]:179
	                     MUL	         8568.419	   48.772	   49.192	  0.165%	 28.883%	     0.000	        1	[efficientnetv2-l/block4e_se_excite/mul]:180
	                 CONV_2D	         8617.622	    9.237	    9.295	  0.031%	 28.914%	     0.000	        1	[efficientnetv2-l/block4e_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_project_conv/Conv2D]:181
	                     ADD	         8626.928	   16.652	   16.736	  0.056%	 28.970%	     0.000	        1	[efficientnetv2-l/block4e_add/add]:182
	                 CONV_2D	         8643.675	   10.460	   10.572	  0.035%	 29.006%	     0.000	        1	[efficientnetv2-l/block4f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_expand_conv/Conv2D]:183
	                LOGISTIC	         8654.261	    6.781	    6.815	  0.023%	 29.028%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/Sigmoid]:184
	                     MUL	         8661.088	   48.986	   49.019	  0.164%	 29.193%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/mul_1]:185
	       DEPTHWISE_CONV_2D	         8710.119	    3.770	    3.612	  0.012%	 29.205%	     0.000	        1	[efficientnetv2-l/block4f_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:186
	                LOGISTIC	         8713.744	    6.755	    6.740	  0.023%	 29.227%	     0.000	        1	[efficientnetv2-l/block4f_activation/Sigmoid]:187
	                     MUL	         8720.495	   49.281	   49.512	  0.166%	 29.393%	     0.000	        1	[efficientnetv2-l/block4f_activation/mul_1]:188
	                    MEAN	         8770.019	  118.260	  118.401	  0.397%	 29.790%	     0.000	        1	[efficientnetv2-l/block4f_se_squeeze/Mean]:189
	                   SHAPE	         8888.431	    0.008	    0.009	  0.000%	 29.790%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Shape]:190
	           STRIDED_SLICE	         8888.446	    0.023	    0.022	  0.000%	 29.790%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/strided_slice]:191
	                    PACK	         8888.475	    0.031	    0.032	  0.000%	 29.791%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape/shape]:192
	                 RESHAPE	         8888.513	    0.014	    0.023	  0.000%	 29.791%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape]:193
	                 CONV_2D	         8888.542	    0.046	    0.050	  0.000%	 29.791%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4f_se_reduce/Conv2D]:194
	                LOGISTIC	         8888.599	    0.010	    0.010	  0.000%	 29.791%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/Sigmoid]:195
	                     MUL	         8888.614	    0.052	    0.024	  0.000%	 29.791%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/mul_1]:196
	                 CONV_2D	         8888.644	    0.026	    0.028	  0.000%	 29.791%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_se_expand/Conv2D]:197
	                LOGISTIC	         8888.678	    0.015	    0.015	  0.000%	 29.791%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/Sigmoid]:198
	                     MUL	         8888.699	   49.096	   48.901	  0.164%	 29.955%	     0.000	        1	[efficientnetv2-l/block4f_se_excite/mul]:199
	                 CONV_2D	         8937.612	    9.125	    9.122	  0.031%	 29.986%	     0.000	        1	[efficientnetv2-l/block4f_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_project_conv/Conv2D]:200
	                     ADD	         8946.745	   16.628	   16.627	  0.056%	 30.041%	     0.000	        1	[efficientnetv2-l/block4f_add/add]:201
	                 CONV_2D	         8963.382	   10.340	   10.373	  0.035%	 30.076%	     0.000	        1	[efficientnetv2-l/block4g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_expand_conv/Conv2D]:202
	                LOGISTIC	         8973.767	    6.719	    6.755	  0.023%	 30.099%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/Sigmoid]:203
	                     MUL	         8980.534	   48.804	   48.778	  0.164%	 30.262%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/mul_1]:204
	       DEPTHWISE_CONV_2D	         9029.322	    3.601	    3.586	  0.012%	 30.274%	     0.000	        1	[efficientnetv2-l/block4g_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:205
	                LOGISTIC	         9032.919	    6.727	    6.732	  0.023%	 30.297%	     0.000	        1	[efficientnetv2-l/block4g_activation/Sigmoid]:206
	                     MUL	         9039.661	   48.799	   48.737	  0.163%	 30.460%	     0.000	        1	[efficientnetv2-l/block4g_activation/mul_1]:207
	                    MEAN	         9088.417	  117.447	  117.151	  0.393%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_squeeze/Mean]:208
	                   SHAPE	         9205.579	    0.009	    0.009	  0.000%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Shape]:209
	           STRIDED_SLICE	         9205.594	    0.023	    0.024	  0.000%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/strided_slice]:210
	                    PACK	         9205.624	    0.028	    0.031	  0.000%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape/shape]:211
	                 RESHAPE	         9205.662	    0.013	    0.014	  0.000%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape]:212
	                 CONV_2D	         9205.682	    0.044	    0.048	  0.000%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4g_se_reduce/Conv2D]:213
	                LOGISTIC	         9205.737	    0.009	    0.009	  0.000%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/Sigmoid]:214
	                     MUL	         9205.752	    0.018	    0.017	  0.000%	 30.853%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/mul_1]:215
	                 CONV_2D	         9205.776	    0.024	    0.024	  0.000%	 30.854%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_se_expand/Conv2D]:216
	                LOGISTIC	         9205.806	    0.015	    0.015	  0.000%	 30.854%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/Sigmoid]:217
	                     MUL	         9205.827	   48.775	   48.538	  0.163%	 31.016%	     0.000	        1	[efficientnetv2-l/block4g_se_excite/mul]:218
	                 CONV_2D	         9254.376	    9.067	    9.024	  0.030%	 31.047%	     0.000	        1	[efficientnetv2-l/block4g_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_project_conv/Conv2D]:219
	                     ADD	         9263.410	   16.625	   16.527	  0.055%	 31.102%	     0.000	        1	[efficientnetv2-l/block4g_add/add]:220
	                 CONV_2D	         9279.948	   10.367	   10.283	  0.034%	 31.136%	     0.000	        1	[efficientnetv2-l/block4h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_expand_conv/Conv2D]:221
	                LOGISTIC	         9290.240	    6.777	    6.732	  0.023%	 31.159%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/Sigmoid]:222
	                     MUL	         9296.983	   48.752	   48.565	  0.163%	 31.322%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/mul_1]:223
	       DEPTHWISE_CONV_2D	         9345.560	    3.725	    3.610	  0.012%	 31.334%	     0.000	        1	[efficientnetv2-l/block4h_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:224
	                LOGISTIC	         9349.182	    6.753	    6.746	  0.023%	 31.357%	     0.000	        1	[efficientnetv2-l/block4h_activation/Sigmoid]:225
	                     MUL	         9355.947	   48.799	   48.604	  0.163%	 31.519%	     0.000	        1	[efficientnetv2-l/block4h_activation/mul_1]:226
	                    MEAN	         9404.562	  117.574	  116.802	  0.392%	 31.911%	     0.000	        1	[efficientnetv2-l/block4h_se_squeeze/Mean]:227
	                   SHAPE	         9521.374	    0.010	    0.009	  0.000%	 31.911%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Shape]:228
	           STRIDED_SLICE	         9521.389	    0.053	    0.026	  0.000%	 31.911%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/strided_slice]:229
	                    PACK	         9521.422	    0.030	    0.031	  0.000%	 31.911%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape/shape]:230
	                 RESHAPE	         9521.460	    0.015	    0.014	  0.000%	 31.911%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape]:231
	                 CONV_2D	         9521.480	    0.050	    0.048	  0.000%	 31.911%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4h_se_reduce/Conv2D]:232
	                LOGISTIC	         9521.534	    0.010	    0.010	  0.000%	 31.912%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/Sigmoid]:233
	                     MUL	         9521.553	    0.020	    0.029	  0.000%	 31.912%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/mul_1]:234
	                 CONV_2D	         9521.590	    0.024	    0.024	  0.000%	 31.912%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_se_expand/Conv2D]:235
	                LOGISTIC	         9521.620	    0.014	    0.015	  0.000%	 31.912%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/Sigmoid]:236
	                     MUL	         9521.641	   48.734	   48.446	  0.162%	 32.074%	     0.000	        1	[efficientnetv2-l/block4h_se_excite/mul]:237
	                 CONV_2D	         9570.098	    9.140	    9.056	  0.030%	 32.104%	     0.000	        1	[efficientnetv2-l/block4h_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_project_conv/Conv2D]:238
	                     ADD	         9579.162	   16.616	   16.496	  0.055%	 32.160%	     0.000	        1	[efficientnetv2-l/block4h_add/add]:239
	                 CONV_2D	         9595.667	   10.353	   10.258	  0.034%	 32.194%	     0.000	        1	[efficientnetv2-l/block4i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_expand_conv/Conv2D]:240
	                LOGISTIC	         9605.935	    6.724	    6.677	  0.022%	 32.217%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/Sigmoid]:241
	                     MUL	         9612.624	   48.558	   48.411	  0.162%	 32.379%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/mul_1]:242
	       DEPTHWISE_CONV_2D	         9661.048	    3.485	    3.455	  0.012%	 32.390%	     0.000	        1	[efficientnetv2-l/block4i_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:243
	                LOGISTIC	         9664.514	    6.694	    6.712	  0.023%	 32.413%	     0.000	        1	[efficientnetv2-l/block4i_activation/Sigmoid]:244
	                     MUL	         9671.238	   48.393	   48.397	  0.162%	 32.575%	     0.000	        1	[efficientnetv2-l/block4i_activation/mul_1]:245
	                    MEAN	         9719.646	  116.593	  116.590	  0.391%	 32.966%	     0.000	        1	[efficientnetv2-l/block4i_se_squeeze/Mean]:246
	                   SHAPE	         9836.247	    0.008	    0.008	  0.000%	 32.966%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Shape]:247
	           STRIDED_SLICE	         9836.261	    0.021	    0.021	  0.000%	 32.966%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/strided_slice]:248
	                    PACK	         9836.289	    0.027	    0.030	  0.000%	 32.966%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape/shape]:249
	                 RESHAPE	         9836.326	    0.014	    0.013	  0.000%	 32.966%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape]:250
	                 CONV_2D	         9836.345	    0.043	    0.050	  0.000%	 32.966%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4i_se_reduce/Conv2D]:251
	                LOGISTIC	         9836.401	    0.009	    0.017	  0.000%	 32.967%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/Sigmoid]:252
	                     MUL	         9836.424	    0.018	    0.018	  0.000%	 32.967%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/mul_1]:253
	                 CONV_2D	         9836.448	    0.022	    0.025	  0.000%	 32.967%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_se_expand/Conv2D]:254
	                LOGISTIC	         9836.480	    0.015	    0.015	  0.000%	 32.967%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/Sigmoid]:255
	                     MUL	         9836.501	   48.423	   48.398	  0.162%	 33.129%	     0.000	        1	[efficientnetv2-l/block4i_se_excite/mul]:256
	                 CONV_2D	         9884.909	    9.047	    9.078	  0.030%	 33.159%	     0.000	        1	[efficientnetv2-l/block4i_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_project_conv/Conv2D]:257
	                     ADD	         9893.996	   16.560	   16.470	  0.055%	 33.215%	     0.000	        1	[efficientnetv2-l/block4i_add/add]:258
	                 CONV_2D	         9910.475	   10.175	   10.188	  0.034%	 33.249%	     0.000	        1	[efficientnetv2-l/block4j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_expand_conv/Conv2D]:259
	                LOGISTIC	         9920.673	    6.725	    6.716	  0.023%	 33.271%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/Sigmoid]:260
	                     MUL	         9927.400	   48.538	   48.413	  0.162%	 33.434%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/mul_1]:261
	       DEPTHWISE_CONV_2D	         9975.825	    3.473	    3.515	  0.012%	 33.445%	     0.000	        1	[efficientnetv2-l/block4j_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_dwconv2/depthwise]:262
	                LOGISTIC	         9979.352	    6.753	    6.731	  0.023%	 33.468%	     0.000	        1	[efficientnetv2-l/block4j_activation/Sigmoid]:263
	                     MUL	         9986.093	   48.439	   48.396	  0.162%	 33.630%	     0.000	        1	[efficientnetv2-l/block4j_activation/mul_1]:264
	                    MEAN	        10034.500	  116.582	  116.686	  0.391%	 34.021%	     0.000	        1	[efficientnetv2-l/block4j_se_squeeze/Mean]:265
	                   SHAPE	        10151.197	    0.008	    0.008	  0.000%	 34.021%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Shape]:266
	           STRIDED_SLICE	        10151.212	    0.031	    0.023	  0.000%	 34.021%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/strided_slice]:267
	                    PACK	        10151.241	    0.027	    0.028	  0.000%	 34.022%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape/shape]:268
	                 RESHAPE	        10151.276	    0.014	    0.016	  0.000%	 34.022%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape]:269
	                 CONV_2D	        10151.298	    0.042	    0.043	  0.000%	 34.022%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4j_se_reduce/Conv2D]:270
	                LOGISTIC	        10151.347	    0.009	    0.009	  0.000%	 34.022%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/Sigmoid]:271
	                     MUL	        10151.363	    0.017	    0.020	  0.000%	 34.022%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/mul_1]:272
	                 CONV_2D	        10151.389	    0.025	    0.024	  0.000%	 34.022%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_se_expand/Conv2D]:273
	                LOGISTIC	        10151.419	    0.014	    0.015	  0.000%	 34.022%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/Sigmoid]:274
	                     MUL	        10151.440	   48.359	   48.386	  0.162%	 34.184%	     0.000	        1	[efficientnetv2-l/block4j_se_excite/mul]:275
	                 CONV_2D	        10199.838	    9.028	    9.030	  0.030%	 34.214%	     0.000	        1	[efficientnetv2-l/block4j_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_project_conv/Conv2D]:276
	                     ADD	        10208.877	   16.443	   16.494	  0.055%	 34.270%	     0.000	        1	[efficientnetv2-l/block4j_add/add]:277
	                 CONV_2D	        10225.380	   15.236	   15.254	  0.051%	 34.321%	     0.000	        1	[efficientnetv2-l/block5a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_expand_conv/Conv2D]:278
	                LOGISTIC	        10240.646	   10.140	   10.142	  0.034%	 34.355%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/Sigmoid]:279
	                     MUL	        10250.800	   72.575	   72.605	  0.243%	 34.598%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/mul_1]:280
	       DEPTHWISE_CONV_2D	        10323.417	    5.310	    5.307	  0.018%	 34.616%	     0.000	        1	[efficientnetv2-l/block5a_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_dwconv2/depthwise]:281
	                LOGISTIC	        10328.736	   10.142	   10.136	  0.034%	 34.650%	     0.000	        1	[efficientnetv2-l/block5a_activation/Sigmoid]:282
	                     MUL	        10338.882	   72.667	   72.663	  0.244%	 34.894%	     0.000	        1	[efficientnetv2-l/block5a_activation/mul_1]:283
	                    MEAN	        10411.557	  175.016	  175.353	  0.588%	 35.481%	     0.000	        1	[efficientnetv2-l/block5a_se_squeeze/Mean]:284
	                   SHAPE	        10586.921	    0.008	    0.011	  0.000%	 35.481%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Shape]:285
	           STRIDED_SLICE	        10586.938	    0.021	    0.022	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/strided_slice]:286
	                    PACK	        10586.966	    0.041	    0.030	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape/shape]:287
	                 RESHAPE	        10587.003	    0.015	    0.014	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape]:288
	                 CONV_2D	        10587.023	    0.047	    0.047	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5a_se_reduce/Conv2D]:289
	                LOGISTIC	        10587.077	    0.009	    0.009	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/Sigmoid]:290
	                     MUL	        10587.105	    0.019	    0.018	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/mul_1]:291
	                 CONV_2D	        10587.130	    0.026	    0.026	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/BiasAdd;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_se_expand/Conv2D]:292
	                LOGISTIC	        10587.163	    0.019	    0.024	  0.000%	 35.482%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/Sigmoid]:293
	                     MUL	        10587.192	   72.634	   72.784	  0.244%	 35.726%	     0.000	        1	[efficientnetv2-l/block5a_se_excite/mul]:294
	                 CONV_2D	        10659.988	   15.361	   15.475	  0.052%	 35.778%	     0.000	        1	[efficientnetv2-l/block5a_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_project_conv/Conv2D]:295
	                 CONV_2D	        10675.474	   22.854	   22.976	  0.077%	 35.855%	     0.000	        1	[efficientnetv2-l/block5b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_expand_conv/Conv2D]:296
	                LOGISTIC	        10698.461	   11.666	   11.841	  0.040%	 35.895%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/Sigmoid]:297
	                     MUL	        10710.315	   84.737	   86.058	  0.288%	 36.183%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/mul_1]:298
	       DEPTHWISE_CONV_2D	        10796.386	    6.178	    6.536	  0.022%	 36.205%	     0.000	        1	[efficientnetv2-l/block5b_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:299
	                LOGISTIC	        10802.934	   11.851	   11.877	  0.040%	 36.245%	     0.000	        1	[efficientnetv2-l/block5b_activation/Sigmoid]:300
	                     MUL	        10814.822	   84.672	   85.519	  0.287%	 36.532%	     0.000	        1	[efficientnetv2-l/block5b_activation/mul_1]:301
	                    MEAN	        10900.363	  205.364	  207.180	  0.695%	 37.226%	     0.000	        1	[efficientnetv2-l/block5b_se_squeeze/Mean]:302
	                   SHAPE	        11107.554	    0.009	    0.009	  0.000%	 37.226%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Shape]:303
	           STRIDED_SLICE	        11107.570	    0.023	    0.023	  0.000%	 37.226%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/strided_slice]:304
	                    PACK	        11107.600	    0.050	    0.040	  0.000%	 37.226%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape/shape]:305
	                 RESHAPE	        11107.646	    0.015	    0.015	  0.000%	 37.226%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape]:306
	                 CONV_2D	        11107.667	    0.053	    0.057	  0.000%	 37.227%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5b_se_reduce/Conv2D]:307
	                LOGISTIC	        11107.731	    0.011	    0.010	  0.000%	 37.227%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/Sigmoid]:308
	                     MUL	        11107.747	    0.022	    0.022	  0.000%	 37.227%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/mul_1]:309
	                 CONV_2D	        11107.775	    0.030	    0.036	  0.000%	 37.227%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_se_expand/Conv2D]:310
	                LOGISTIC	        11107.818	    0.020	    0.020	  0.000%	 37.227%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/Sigmoid]:311
	                     MUL	        11107.844	   85.670	   86.192	  0.289%	 37.516%	     0.000	        1	[efficientnetv2-l/block5b_se_excite/mul]:312
	                 CONV_2D	        11194.048	   18.172	   18.320	  0.061%	 37.577%	     0.000	        1	[efficientnetv2-l/block5b_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_project_conv/Conv2D]:313
	                     ADD	        11212.380	   19.426	   19.474	  0.065%	 37.643%	     0.000	        1	[efficientnetv2-l/block5b_add/add]:314
	                 CONV_2D	        11231.864	   23.505	   23.247	  0.078%	 37.721%	     0.000	        1	[efficientnetv2-l/block5c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_expand_conv/Conv2D]:315
	                LOGISTIC	        11255.122	   11.980	   11.937	  0.040%	 37.761%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/Sigmoid]:316
	                     MUL	        11267.072	   85.431	   85.862	  0.288%	 38.048%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/mul_1]:317
	       DEPTHWISE_CONV_2D	        11352.949	    7.132	    6.626	  0.022%	 38.071%	     0.000	        1	[efficientnetv2-l/block5c_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:318
	                LOGISTIC	        11359.587	   12.012	   11.979	  0.040%	 38.111%	     0.000	        1	[efficientnetv2-l/block5c_activation/Sigmoid]:319
	                     MUL	        11371.577	   85.658	   85.366	  0.286%	 38.397%	     0.000	        1	[efficientnetv2-l/block5c_activation/mul_1]:320
	                    MEAN	        11456.955	  205.730	  205.647	  0.689%	 39.086%	     0.000	        1	[efficientnetv2-l/block5c_se_squeeze/Mean]:321
	                   SHAPE	        11662.613	    0.009	    0.009	  0.000%	 39.086%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Shape]:322
	           STRIDED_SLICE	        11662.629	    0.023	    0.022	  0.000%	 39.086%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/strided_slice]:323
	                    PACK	        11662.657	    0.030	    0.033	  0.000%	 39.087%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape/shape]:324
	                 RESHAPE	        11662.696	    0.014	    0.014	  0.000%	 39.087%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape]:325
	                 CONV_2D	        11662.717	    0.080	    0.057	  0.000%	 39.087%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5c_se_reduce/Conv2D]:326
	                LOGISTIC	        11662.781	    0.010	    0.013	  0.000%	 39.087%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/Sigmoid]:327
	                     MUL	        11662.800	    0.023	    0.034	  0.000%	 39.087%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/mul_1]:328
	                 CONV_2D	        11662.840	    0.030	    0.029	  0.000%	 39.087%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_se_expand/Conv2D]:329
	                LOGISTIC	        11662.875	    0.020	    0.020	  0.000%	 39.087%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/Sigmoid]:330
	                     MUL	        11662.900	   85.397	   84.983	  0.285%	 39.372%	     0.000	        1	[efficientnetv2-l/block5c_se_excite/mul]:331
	                 CONV_2D	        11747.898	   17.941	   17.865	  0.060%	 39.432%	     0.000	        1	[efficientnetv2-l/block5c_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_project_conv/Conv2D]:332
	                     ADD	        11765.774	   19.390	   19.325	  0.065%	 39.497%	     0.000	        1	[efficientnetv2-l/block5c_add/add]:333
	                 CONV_2D	        11785.110	   23.180	   22.933	  0.077%	 39.574%	     0.000	        1	[efficientnetv2-l/block5d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_expand_conv/Conv2D]:334
	                LOGISTIC	        11808.055	   11.861	   11.820	  0.040%	 39.613%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/Sigmoid]:335
	                     MUL	        11819.885	   85.276	   84.825	  0.284%	 39.898%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/mul_1]:336
	       DEPTHWISE_CONV_2D	        11904.722	    6.263	    6.290	  0.021%	 39.919%	     0.000	        1	[efficientnetv2-l/block5d_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:337
	                LOGISTIC	        11911.023	   11.825	   11.787	  0.040%	 39.958%	     0.000	        1	[efficientnetv2-l/block5d_activation/Sigmoid]:338
	                     MUL	        11922.822	   84.800	   84.765	  0.284%	 40.242%	     0.000	        1	[efficientnetv2-l/block5d_activation/mul_1]:339
	                    MEAN	        12007.598	  204.479	  204.329	  0.685%	 40.927%	     0.000	        1	[efficientnetv2-l/block5d_se_squeeze/Mean]:340
	                   SHAPE	        12211.939	    0.008	    0.009	  0.000%	 40.927%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Shape]:341
	           STRIDED_SLICE	        12211.954	    0.021	    0.022	  0.000%	 40.927%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/strided_slice]:342
	                    PACK	        12211.982	    0.029	    0.030	  0.000%	 40.928%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape/shape]:343
	                 RESHAPE	        12212.018	    0.014	    0.026	  0.000%	 40.928%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape]:344
	                 CONV_2D	        12212.050	    0.048	    0.055	  0.000%	 40.928%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5d_se_reduce/Conv2D]:345
	                LOGISTIC	        12212.112	    0.009	    0.009	  0.000%	 40.928%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/Sigmoid]:346
	                     MUL	        12212.128	    0.021	    0.024	  0.000%	 40.928%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/mul_1]:347
	                 CONV_2D	        12212.157	    0.029	    0.029	  0.000%	 40.928%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_se_expand/Conv2D]:348
	                LOGISTIC	        12212.193	    0.021	    0.021	  0.000%	 40.928%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/Sigmoid]:349
	                     MUL	        12212.219	   84.448	   84.570	  0.284%	 41.212%	     0.000	        1	[efficientnetv2-l/block5d_se_excite/mul]:350
	                 CONV_2D	        12296.801	   17.751	   17.829	  0.060%	 41.271%	     0.000	        1	[efficientnetv2-l/block5d_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_project_conv/Conv2D]:351
	                     ADD	        12314.640	   19.197	   19.203	  0.064%	 41.336%	     0.000	        1	[efficientnetv2-l/block5d_add/add]:352
	                 CONV_2D	        12333.853	   22.759	   22.845	  0.077%	 41.412%	     0.000	        1	[efficientnetv2-l/block5e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_expand_conv/Conv2D]:353
	                LOGISTIC	        12356.709	   11.736	   11.748	  0.039%	 41.452%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/Sigmoid]:354
	                     MUL	        12368.468	   84.737	   84.688	  0.284%	 41.736%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/mul_1]:355
	       DEPTHWISE_CONV_2D	        12453.170	    6.336	    6.280	  0.021%	 41.757%	     0.000	        1	[efficientnetv2-l/block5e_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:356
	                LOGISTIC	        12459.465	   11.740	   11.760	  0.039%	 41.796%	     0.000	        1	[efficientnetv2-l/block5e_activation/Sigmoid]:357
	                     MUL	        12471.237	   84.711	   84.712	  0.284%	 42.080%	     0.000	        1	[efficientnetv2-l/block5e_activation/mul_1]:358
	                    MEAN	        12555.960	  204.470	  204.584	  0.686%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_squeeze/Mean]:359
	                   SHAPE	        12760.556	    0.008	    0.009	  0.000%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Shape]:360
	           STRIDED_SLICE	        12760.570	    0.022	    0.022	  0.000%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/strided_slice]:361
	                    PACK	        12760.598	    0.029	    0.029	  0.000%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape/shape]:362
	                 RESHAPE	        12760.634	    0.013	    0.014	  0.000%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape]:363
	                 CONV_2D	        12760.655	    0.050	    0.053	  0.000%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5e_se_reduce/Conv2D]:364
	                LOGISTIC	        12760.713	    0.010	    0.009	  0.000%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/Sigmoid]:365
	                     MUL	        12760.729	    0.020	    0.021	  0.000%	 42.766%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/mul_1]:366
	                 CONV_2D	        12760.756	    0.028	    0.030	  0.000%	 42.767%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_se_expand/Conv2D]:367
	                LOGISTIC	        12760.793	    0.019	    0.020	  0.000%	 42.767%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/Sigmoid]:368
	                     MUL	        12760.819	   84.649	   84.647	  0.284%	 43.050%	     0.000	        1	[efficientnetv2-l/block5e_se_excite/mul]:369
	                 CONV_2D	        12845.478	   17.732	   17.758	  0.060%	 43.110%	     0.000	        1	[efficientnetv2-l/block5e_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_project_conv/Conv2D]:370
	                     ADD	        12863.247	   19.221	   19.235	  0.064%	 43.174%	     0.000	        1	[efficientnetv2-l/block5e_add/add]:371
	                 CONV_2D	        12882.493	   22.774	   22.814	  0.076%	 43.251%	     0.000	        1	[efficientnetv2-l/block5f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_expand_conv/Conv2D]:372
	                LOGISTIC	        12905.317	   11.832	   11.844	  0.040%	 43.291%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/Sigmoid]:373
	                     MUL	        12917.173	   84.715	   84.834	  0.284%	 43.575%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/mul_1]:374
	       DEPTHWISE_CONV_2D	        13002.018	    6.148	    6.147	  0.021%	 43.596%	     0.000	        1	[efficientnetv2-l/block5f_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:375
	                LOGISTIC	        13008.178	   11.865	   11.902	  0.040%	 43.635%	     0.000	        1	[efficientnetv2-l/block5f_activation/Sigmoid]:376
	                     MUL	        13020.091	   84.621	   84.888	  0.285%	 43.920%	     0.000	        1	[efficientnetv2-l/block5f_activation/mul_1]:377
	                    MEAN	        13104.992	  204.592	  206.087	  0.691%	 44.611%	     0.000	        1	[efficientnetv2-l/block5f_se_squeeze/Mean]:378
	                   SHAPE	        13311.090	    0.008	    0.009	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Shape]:379
	           STRIDED_SLICE	        13311.105	    0.022	    0.030	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/strided_slice]:380
	                    PACK	        13311.142	    0.046	    0.034	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape/shape]:381
	                 RESHAPE	        13311.182	    0.014	    0.018	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape]:382
	                 CONV_2D	        13311.207	    0.050	    0.057	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5f_se_reduce/Conv2D]:383
	                LOGISTIC	        13311.270	    0.009	    0.017	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/Sigmoid]:384
	                     MUL	        13311.293	    0.021	    0.022	  0.000%	 44.612%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/mul_1]:385
	                 CONV_2D	        13311.322	    0.028	    0.030	  0.000%	 44.612%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_se_expand/Conv2D]:386
	                LOGISTIC	        13311.359	    0.021	    0.029	  0.000%	 44.612%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/Sigmoid]:387
	                     MUL	        13311.394	   84.489	   85.427	  0.286%	 44.898%	     0.000	        1	[efficientnetv2-l/block5f_se_excite/mul]:388
	                 CONV_2D	        13396.832	   17.930	   18.299	  0.061%	 44.959%	     0.000	        1	[efficientnetv2-l/block5f_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_project_conv/Conv2D]:389
	                     ADD	        13415.143	   19.301	   19.425	  0.065%	 45.025%	     0.000	        1	[efficientnetv2-l/block5f_add/add]:390
	                 CONV_2D	        13434.580	   22.874	   23.353	  0.078%	 45.103%	     0.000	        1	[efficientnetv2-l/block5g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_expand_conv/Conv2D]:391
	                LOGISTIC	        13457.944	   11.910	   11.945	  0.040%	 45.143%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/Sigmoid]:392
	                     MUL	        13469.900	   84.866	   85.598	  0.287%	 45.430%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/mul_1]:393
	       DEPTHWISE_CONV_2D	        13555.510	    6.462	    6.598	  0.022%	 45.452%	     0.000	        1	[efficientnetv2-l/block5g_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:394
	                LOGISTIC	        13562.119	   11.820	   12.018	  0.040%	 45.492%	     0.000	        1	[efficientnetv2-l/block5g_activation/Sigmoid]:395
	                     MUL	        13574.149	   85.710	   85.893	  0.288%	 45.780%	     0.000	        1	[efficientnetv2-l/block5g_activation/mul_1]:396
	                    MEAN	        13660.054	  207.148	  206.630	  0.693%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_squeeze/Mean]:397
	                   SHAPE	        13866.696	    0.008	    0.009	  0.000%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Shape]:398
	           STRIDED_SLICE	        13866.711	    0.022	    0.026	  0.000%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/strided_slice]:399
	                    PACK	        13866.744	    0.053	    0.034	  0.000%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape/shape]:400
	                 RESHAPE	        13866.784	    0.014	    0.017	  0.000%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape]:401
	                 CONV_2D	        13866.808	    0.050	    0.051	  0.000%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5g_se_reduce/Conv2D]:402
	                LOGISTIC	        13866.865	    0.010	    0.010	  0.000%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/Sigmoid]:403
	                     MUL	        13866.881	    0.021	    0.021	  0.000%	 46.473%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/mul_1]:404
	                 CONV_2D	        13866.909	    0.029	    0.033	  0.000%	 46.474%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_se_expand/Conv2D]:405
	                LOGISTIC	        13866.948	    0.019	    0.019	  0.000%	 46.474%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/Sigmoid]:406
	                     MUL	        13866.974	   85.675	   85.427	  0.286%	 46.760%	     0.000	        1	[efficientnetv2-l/block5g_se_excite/mul]:407
	                 CONV_2D	        13952.412	   18.055	   18.056	  0.061%	 46.821%	     0.000	        1	[efficientnetv2-l/block5g_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_project_conv/Conv2D]:408
	                     ADD	        13970.479	   19.389	   19.334	  0.065%	 46.885%	     0.000	        1	[efficientnetv2-l/block5g_add/add]:409
	                 CONV_2D	        13989.824	   23.216	   23.048	  0.077%	 46.963%	     0.000	        1	[efficientnetv2-l/block5h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_expand_conv/Conv2D]:410
	                LOGISTIC	        14012.882	   11.831	   11.796	  0.040%	 47.002%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/Sigmoid]:411
	                     MUL	        14024.691	   85.429	   85.057	  0.285%	 47.287%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/mul_1]:412
	       DEPTHWISE_CONV_2D	        14109.759	    6.337	    6.247	  0.021%	 47.308%	     0.000	        1	[efficientnetv2-l/block5h_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:413
	                LOGISTIC	        14116.018	   11.838	   11.804	  0.040%	 47.348%	     0.000	        1	[efficientnetv2-l/block5h_activation/Sigmoid]:414
	                     MUL	        14127.833	   85.321	   84.967	  0.285%	 47.633%	     0.000	        1	[efficientnetv2-l/block5h_activation/mul_1]:415
	                    MEAN	        14212.812	  205.980	  205.121	  0.688%	 48.320%	     0.000	        1	[efficientnetv2-l/block5h_se_squeeze/Mean]:416
	                   SHAPE	        14417.947	    0.008	    0.009	  0.000%	 48.320%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Shape]:417
	           STRIDED_SLICE	        14417.961	    0.021	    0.023	  0.000%	 48.320%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/strided_slice]:418
	                    PACK	        14417.991	    0.029	    0.029	  0.000%	 48.320%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape/shape]:419
	                 RESHAPE	        14418.027	    0.014	    0.014	  0.000%	 48.321%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape]:420
	                 CONV_2D	        14418.047	    0.049	    0.049	  0.000%	 48.321%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5h_se_reduce/Conv2D]:421
	                LOGISTIC	        14418.103	    0.010	    0.012	  0.000%	 48.321%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/Sigmoid]:422
	                     MUL	        14418.122	    0.021	    0.021	  0.000%	 48.321%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/mul_1]:423
	                 CONV_2D	        14418.149	    0.029	    0.030	  0.000%	 48.321%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_se_expand/Conv2D]:424
	                LOGISTIC	        14418.185	    0.020	    0.020	  0.000%	 48.321%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/Sigmoid]:425
	                     MUL	        14418.211	   84.600	   84.612	  0.284%	 48.605%	     0.000	        1	[efficientnetv2-l/block5h_se_excite/mul]:426
	                 CONV_2D	        14502.835	   17.826	   17.775	  0.060%	 48.664%	     0.000	        1	[efficientnetv2-l/block5h_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_project_conv/Conv2D]:427
	                     ADD	        14520.620	   19.229	   19.231	  0.064%	 48.729%	     0.000	        1	[efficientnetv2-l/block5h_add/add]:428
	                 CONV_2D	        14539.862	   22.808	   22.809	  0.076%	 48.805%	     0.000	        1	[efficientnetv2-l/block5i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_expand_conv/Conv2D]:429
	                LOGISTIC	        14562.681	   11.844	   11.823	  0.040%	 48.845%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/Sigmoid]:430
	                     MUL	        14574.515	   84.690	   84.704	  0.284%	 49.129%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/mul_1]:431
	       DEPTHWISE_CONV_2D	        14659.232	    6.316	    6.285	  0.021%	 49.150%	     0.000	        1	[efficientnetv2-l/block5i_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:432
	                LOGISTIC	        14665.530	   11.835	   11.850	  0.040%	 49.190%	     0.000	        1	[efficientnetv2-l/block5i_activation/Sigmoid]:433
	                     MUL	        14677.391	   84.811	   84.745	  0.284%	 49.474%	     0.000	        1	[efficientnetv2-l/block5i_activation/mul_1]:434
	                    MEAN	        14762.148	  204.555	  204.638	  0.686%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_squeeze/Mean]:435
	                   SHAPE	        14966.797	    0.009	    0.009	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Shape]:436
	           STRIDED_SLICE	        14966.812	    0.022	    0.025	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/strided_slice]:437
	                    PACK	        14966.843	    0.030	    0.030	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape/shape]:438
	                 RESHAPE	        14966.880	    0.013	    0.014	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape]:439
	                 CONV_2D	        14966.900	    0.048	    0.048	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5i_se_reduce/Conv2D]:440
	                LOGISTIC	        14966.954	    0.009	    0.009	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/Sigmoid]:441
	                     MUL	        14966.970	    0.020	    0.021	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/mul_1]:442
	                 CONV_2D	        14966.997	    0.028	    0.038	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_se_expand/Conv2D]:443
	                LOGISTIC	        14967.041	    0.020	    0.024	  0.000%	 50.160%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/Sigmoid]:444
	                     MUL	        14967.072	   84.724	   84.697	  0.284%	 50.444%	     0.000	        1	[efficientnetv2-l/block5i_se_excite/mul]:445
	                 CONV_2D	        15051.780	   17.789	   17.807	  0.060%	 50.504%	     0.000	        1	[efficientnetv2-l/block5i_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_project_conv/Conv2D]:446
	                     ADD	        15069.599	   19.230	   19.251	  0.065%	 50.569%	     0.000	        1	[efficientnetv2-l/block5i_add/add]:447
	                 CONV_2D	        15088.859	   22.906	   22.878	  0.077%	 50.645%	     0.000	        1	[efficientnetv2-l/block5j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_expand_conv/Conv2D]:448
	                LOGISTIC	        15111.748	   11.822	   11.846	  0.040%	 50.685%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/Sigmoid]:449
	                     MUL	        15123.604	   84.757	   84.702	  0.284%	 50.969%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/mul_1]:450
	       DEPTHWISE_CONV_2D	        15208.318	    6.113	    6.139	  0.021%	 50.990%	     0.000	        1	[efficientnetv2-l/block5j_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:451
	                LOGISTIC	        15214.471	   11.878	   11.879	  0.040%	 51.029%	     0.000	        1	[efficientnetv2-l/block5j_activation/Sigmoid]:452
	                     MUL	        15226.362	   84.847	   84.718	  0.284%	 51.313%	     0.000	        1	[efficientnetv2-l/block5j_activation/mul_1]:453
	                    MEAN	        15311.093	  204.719	  204.755	  0.686%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_squeeze/Mean]:454
	                   SHAPE	        15515.862	    0.008	    0.009	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Shape]:455
	           STRIDED_SLICE	        15515.877	    0.022	    0.022	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/strided_slice]:456
	                    PACK	        15515.907	    0.029	    0.030	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape/shape]:457
	                 RESHAPE	        15515.944	    0.013	    0.013	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape]:458
	                 CONV_2D	        15515.963	    0.049	    0.056	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5j_se_reduce/Conv2D]:459
	                LOGISTIC	        15516.025	    0.009	    0.010	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/Sigmoid]:460
	                     MUL	        15516.041	    0.021	    0.021	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/mul_1]:461
	                 CONV_2D	        15516.069	    0.027	    0.030	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_se_expand/Conv2D]:462
	                LOGISTIC	        15516.105	    0.019	    0.024	  0.000%	 52.000%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/Sigmoid]:463
	                     MUL	        15516.136	   84.592	   84.890	  0.285%	 52.285%	     0.000	        1	[efficientnetv2-l/block5j_se_excite/mul]:464
	                 CONV_2D	        15601.038	   17.745	   17.871	  0.060%	 52.345%	     0.000	        1	[efficientnetv2-l/block5j_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_project_conv/Conv2D]:465
	                     ADD	        15618.920	   19.251	   19.281	  0.065%	 52.410%	     0.000	        1	[efficientnetv2-l/block5j_add/add]:466
	                 CONV_2D	        15638.211	   22.869	   23.012	  0.077%	 52.487%	     0.000	        1	[efficientnetv2-l/block5k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_expand_conv/Conv2D]:467
	                LOGISTIC	        15661.235	   11.744	   11.851	  0.040%	 52.526%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/Sigmoid]:468
	                     MUL	        15673.105	   84.730	   85.162	  0.285%	 52.812%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/mul_1]:469
	       DEPTHWISE_CONV_2D	        15758.279	    6.206	    6.577	  0.022%	 52.834%	     0.000	        1	[efficientnetv2-l/block5k_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:470
	                LOGISTIC	        15764.868	   11.725	   11.857	  0.040%	 52.874%	     0.000	        1	[efficientnetv2-l/block5k_activation/Sigmoid]:471
	                     MUL	        15776.738	   84.773	   85.490	  0.287%	 53.160%	     0.000	        1	[efficientnetv2-l/block5k_activation/mul_1]:472
	                    MEAN	        15862.240	  205.806	  206.824	  0.693%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_squeeze/Mean]:473
	                   SHAPE	        16069.076	    0.009	    0.009	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Shape]:474
	           STRIDED_SLICE	        16069.091	    0.025	    0.023	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/strided_slice]:475
	                    PACK	        16069.121	    0.033	    0.034	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape/shape]:476
	                 RESHAPE	        16069.161	    0.015	    0.014	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape]:477
	                 CONV_2D	        16069.182	    0.057	    0.055	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5k_se_reduce/Conv2D]:478
	                LOGISTIC	        16069.244	    0.011	    0.010	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/Sigmoid]:479
	                     MUL	        16069.260	    0.027	    0.027	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/mul_1]:480
	                 CONV_2D	        16069.293	    0.063	    0.040	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_se_expand/Conv2D]:481
	                LOGISTIC	        16069.339	    0.022	    0.024	  0.000%	 53.854%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/Sigmoid]:482
	                     MUL	        16069.369	   85.651	   85.996	  0.288%	 54.143%	     0.000	        1	[efficientnetv2-l/block5k_se_excite/mul]:483
	                 CONV_2D	        16155.379	   18.246	   18.120	  0.061%	 54.204%	     0.000	        1	[efficientnetv2-l/block5k_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_project_conv/Conv2D]:484
	                     ADD	        16173.511	   22.034	   19.813	  0.066%	 54.270%	     0.000	        1	[efficientnetv2-l/block5k_add/add]:485
	                 CONV_2D	        16193.336	   23.654	   23.321	  0.078%	 54.348%	     0.000	        1	[efficientnetv2-l/block5l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_expand_conv/Conv2D]:486
	                LOGISTIC	        16216.669	   12.078	   11.955	  0.040%	 54.388%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/Sigmoid]:487
	                     MUL	        16228.636	   85.572	   85.948	  0.288%	 54.676%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/mul_1]:488
	       DEPTHWISE_CONV_2D	        16314.595	    6.503	    6.598	  0.022%	 54.698%	     0.000	        1	[efficientnetv2-l/block5l_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:489
	                LOGISTIC	        16321.205	   11.917	   11.973	  0.040%	 54.739%	     0.000	        1	[efficientnetv2-l/block5l_activation/Sigmoid]:490
	                     MUL	        16333.192	   85.626	   85.491	  0.287%	 55.025%	     0.000	        1	[efficientnetv2-l/block5l_activation/mul_1]:491
	                    MEAN	        16418.695	  205.484	  205.636	  0.689%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_squeeze/Mean]:492
	                   SHAPE	        16624.342	    0.009	    0.009	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Shape]:493
	           STRIDED_SLICE	        16624.357	    0.023	    0.022	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/strided_slice]:494
	                    PACK	        16624.386	    0.030	    0.030	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape/shape]:495
	                 RESHAPE	        16624.423	    0.014	    0.017	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape]:496
	                 CONV_2D	        16624.446	    0.054	    0.061	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5l_se_reduce/Conv2D]:497
	                LOGISTIC	        16624.518	    0.012	    0.010	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/Sigmoid]:498
	                     MUL	        16624.535	    0.021	    0.021	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/mul_1]:499
	                 CONV_2D	        16624.562	    0.032	    0.034	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_se_expand/Conv2D]:500
	                LOGISTIC	        16624.602	    0.021	    0.025	  0.000%	 55.715%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/Sigmoid]:501
	                     MUL	        16624.634	   85.349	   85.150	  0.285%	 56.001%	     0.000	        1	[efficientnetv2-l/block5l_se_excite/mul]:502
	                 CONV_2D	        16709.795	   17.953	   17.924	  0.060%	 56.061%	     0.000	        1	[efficientnetv2-l/block5l_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_project_conv/Conv2D]:503
	                     ADD	        16727.729	   19.341	   19.310	  0.065%	 56.126%	     0.000	        1	[efficientnetv2-l/block5l_add/add]:504
	                 CONV_2D	        16747.049	   23.150	   23.010	  0.077%	 56.203%	     0.000	        1	[efficientnetv2-l/block5m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_expand_conv/Conv2D]:505
	                LOGISTIC	        16770.071	   11.903	   11.891	  0.040%	 56.243%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/Sigmoid]:506
	                     MUL	        16781.974	   85.244	   84.840	  0.284%	 56.527%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/mul_1]:507
	       DEPTHWISE_CONV_2D	        16866.825	    6.437	    6.238	  0.021%	 56.548%	     0.000	        1	[efficientnetv2-l/block5m_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:508
	                LOGISTIC	        16873.075	   11.902	   11.849	  0.040%	 56.588%	     0.000	        1	[efficientnetv2-l/block5m_activation/Sigmoid]:509
	                     MUL	        16884.935	   85.343	   84.857	  0.284%	 56.872%	     0.000	        1	[efficientnetv2-l/block5m_activation/mul_1]:510
	                    MEAN	        16969.804	  205.459	  204.733	  0.686%	 57.558%	     0.000	        1	[efficientnetv2-l/block5m_se_squeeze/Mean]:511
	                   SHAPE	        17174.549	    0.009	    0.009	  0.000%	 57.558%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Shape]:512
	           STRIDED_SLICE	        17174.564	    0.031	    0.023	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/strided_slice]:513
	                    PACK	        17174.594	    0.030	    0.030	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape/shape]:514
	                 RESHAPE	        17174.630	    0.014	    0.014	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape]:515
	                 CONV_2D	        17174.651	    0.049	    0.055	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5m_se_reduce/Conv2D]:516
	                LOGISTIC	        17174.712	    0.010	    0.010	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/Sigmoid]:517
	                     MUL	        17174.728	    0.022	    0.021	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/mul_1]:518
	                 CONV_2D	        17174.756	    0.030	    0.029	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_se_expand/Conv2D]:519
	                LOGISTIC	        17174.791	    0.021	    0.024	  0.000%	 57.559%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/Sigmoid]:520
	                     MUL	        17174.821	   84.692	   84.649	  0.284%	 57.843%	     0.000	        1	[efficientnetv2-l/block5m_se_excite/mul]:521
	                 CONV_2D	        17259.482	   17.767	   17.801	  0.060%	 57.903%	     0.000	        1	[efficientnetv2-l/block5m_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_project_conv/Conv2D]:522
	                     ADD	        17277.293	   19.216	   19.239	  0.064%	 57.967%	     0.000	        1	[efficientnetv2-l/block5m_add/add]:523
	                 CONV_2D	        17296.542	   22.832	   22.873	  0.077%	 58.044%	     0.000	        1	[efficientnetv2-l/block5n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_expand_conv/Conv2D]:524
	                LOGISTIC	        17319.426	   11.824	   11.805	  0.040%	 58.083%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/Sigmoid]:525
	                     MUL	        17331.249	   84.648	   84.674	  0.284%	 58.367%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/mul_1]:526
	       DEPTHWISE_CONV_2D	        17415.934	    6.147	    6.160	  0.021%	 58.388%	     0.000	        1	[efficientnetv2-l/block5n_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:527
	                LOGISTIC	        17422.107	   11.775	   11.771	  0.039%	 58.427%	     0.000	        1	[efficientnetv2-l/block5n_activation/Sigmoid]:528
	                     MUL	        17433.889	   84.616	   84.699	  0.284%	 58.711%	     0.000	        1	[efficientnetv2-l/block5n_activation/mul_1]:529
	                    MEAN	        17518.600	  204.324	  204.465	  0.685%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_squeeze/Mean]:530
	                   SHAPE	        17723.076	    0.008	    0.008	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Shape]:531
	           STRIDED_SLICE	        17723.091	    0.022	    0.024	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/strided_slice]:532
	                    PACK	        17723.121	    0.042	    0.032	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape/shape]:533
	                 RESHAPE	        17723.159	    0.014	    0.014	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape]:534
	                 CONV_2D	        17723.179	    0.050	    0.056	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5n_se_reduce/Conv2D]:535
	                LOGISTIC	        17723.242	    0.009	    0.009	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/Sigmoid]:536
	                     MUL	        17723.257	    0.021	    0.021	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/mul_1]:537
	                 CONV_2D	        17723.285	    0.026	    0.028	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_se_expand/Conv2D]:538
	                LOGISTIC	        17723.319	    0.021	    0.022	  0.000%	 59.397%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/Sigmoid]:539
	                     MUL	        17723.347	   84.528	   84.555	  0.283%	 59.681%	     0.000	        1	[efficientnetv2-l/block5n_se_excite/mul]:540
	                 CONV_2D	        17807.915	   17.789	   17.812	  0.060%	 59.741%	     0.000	        1	[efficientnetv2-l/block5n_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_project_conv/Conv2D]:541
	                     ADD	        17825.737	   19.166	   19.178	  0.064%	 59.805%	     0.000	        1	[efficientnetv2-l/block5n_add/add]:542
	                 CONV_2D	        17844.924	   22.836	   22.843	  0.077%	 59.881%	     0.000	        1	[efficientnetv2-l/block5o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_expand_conv/Conv2D]:543
	                LOGISTIC	        17867.777	   11.734	   11.841	  0.040%	 59.921%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/Sigmoid]:544
	                     MUL	        17879.631	   84.729	   84.767	  0.284%	 60.205%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/mul_1]:545
	       DEPTHWISE_CONV_2D	        17964.411	    6.268	    6.230	  0.021%	 60.226%	     0.000	        1	[efficientnetv2-l/block5o_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:546
	                LOGISTIC	        17970.652	   11.874	   11.860	  0.040%	 60.266%	     0.000	        1	[efficientnetv2-l/block5o_activation/Sigmoid]:547
	                     MUL	        17982.523	   84.534	   84.820	  0.284%	 60.550%	     0.000	        1	[efficientnetv2-l/block5o_activation/mul_1]:548
	                    MEAN	        18067.354	  204.734	  205.891	  0.690%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_squeeze/Mean]:549
	                   SHAPE	        18273.259	    0.009	    0.009	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Shape]:550
	           STRIDED_SLICE	        18273.274	    0.021	    0.023	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/strided_slice]:551
	                    PACK	        18273.304	    0.030	    0.035	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape/shape]:552
	                 RESHAPE	        18273.346	    0.014	    0.015	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape]:553
	                 CONV_2D	        18273.368	    0.049	    0.064	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5o_se_reduce/Conv2D]:554
	                LOGISTIC	        18273.438	    0.009	    0.010	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/Sigmoid]:555
	                     MUL	        18273.454	    0.021	    0.026	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/mul_1]:556
	                 CONV_2D	        18273.487	    0.029	    0.032	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_se_expand/Conv2D]:557
	                LOGISTIC	        18273.525	    0.021	    0.020	  0.000%	 61.241%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/Sigmoid]:558
	                     MUL	        18273.551	   84.597	   85.544	  0.287%	 61.528%	     0.000	        1	[efficientnetv2-l/block5o_se_excite/mul]:559
	                 CONV_2D	        18359.107	   17.781	   18.109	  0.061%	 61.589%	     0.000	        1	[efficientnetv2-l/block5o_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_project_conv/Conv2D]:560
	                     ADD	        18377.227	   19.291	   19.407	  0.065%	 61.654%	     0.000	        1	[efficientnetv2-l/block5o_add/add]:561
	                 CONV_2D	        18396.645	   23.020	   23.316	  0.078%	 61.732%	     0.000	        1	[efficientnetv2-l/block5p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_expand_conv/Conv2D]:562
	                LOGISTIC	        18419.973	   11.954	   11.937	  0.040%	 61.772%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/Sigmoid]:563
	                     MUL	        18431.922	   84.849	   85.464	  0.287%	 62.059%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/mul_1]:564
	       DEPTHWISE_CONV_2D	        18517.397	    6.453	    6.677	  0.022%	 62.081%	     0.000	        1	[efficientnetv2-l/block5p_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:565
	                LOGISTIC	        18524.086	   11.926	   11.934	  0.040%	 62.121%	     0.000	        1	[efficientnetv2-l/block5p_activation/Sigmoid]:566
	                     MUL	        18536.031	   85.483	   85.677	  0.287%	 62.408%	     0.000	        1	[efficientnetv2-l/block5p_activation/mul_1]:567
	                    MEAN	        18621.720	  206.721	  207.221	  0.695%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_squeeze/Mean]:568
	                   SHAPE	        18828.952	    0.009	    0.009	  0.000%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Shape]:569
	           STRIDED_SLICE	        18828.967	    0.032	    0.029	  0.000%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/strided_slice]:570
	                    PACK	        18829.003	    0.031	    0.031	  0.000%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape/shape]:571
	                 RESHAPE	        18829.041	    0.027	    0.016	  0.000%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape]:572
	                 CONV_2D	        18829.064	    0.048	    0.066	  0.000%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5p_se_reduce/Conv2D]:573
	                LOGISTIC	        18829.137	    0.010	    0.010	  0.000%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/Sigmoid]:574
	                     MUL	        18829.153	    0.021	    0.021	  0.000%	 63.103%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/mul_1]:575
	                 CONV_2D	        18829.181	    0.029	    0.041	  0.000%	 63.104%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_se_expand/Conv2D]:576
	                LOGISTIC	        18829.228	    0.020	    0.025	  0.000%	 63.104%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/Sigmoid]:577
	                     MUL	        18829.258	   85.792	   85.219	  0.286%	 63.389%	     0.000	        1	[efficientnetv2-l/block5p_se_excite/mul]:578
	                 CONV_2D	        18914.489	   17.981	   17.955	  0.060%	 63.450%	     0.000	        1	[efficientnetv2-l/block5p_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_project_conv/Conv2D]:579
	                     ADD	        18932.455	   19.298	   19.363	  0.065%	 63.514%	     0.000	        1	[efficientnetv2-l/block5p_add/add]:580
	                 CONV_2D	        18951.829	   23.161	   23.118	  0.077%	 63.592%	     0.000	        1	[efficientnetv2-l/block5q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_expand_conv/Conv2D]:581
	                LOGISTIC	        18974.958	   11.834	   11.896	  0.040%	 63.632%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/Sigmoid]:582
	                     MUL	        18986.866	   85.287	   85.135	  0.285%	 63.917%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/mul_1]:583
	       DEPTHWISE_CONV_2D	        19072.014	    6.469	    6.375	  0.021%	 63.939%	     0.000	        1	[efficientnetv2-l/block5q_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:584
	                LOGISTIC	        19078.410	   11.983	   11.913	  0.040%	 63.979%	     0.000	        1	[efficientnetv2-l/block5q_activation/Sigmoid]:585
	                     MUL	        19090.334	   85.380	   84.978	  0.285%	 64.263%	     0.000	        1	[efficientnetv2-l/block5q_activation/mul_1]:586
	                    MEAN	        19175.324	  206.025	  204.851	  0.687%	 64.950%	     0.000	        1	[efficientnetv2-l/block5q_se_squeeze/Mean]:587
	                   SHAPE	        19380.189	    0.008	    0.011	  0.000%	 64.950%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Shape]:588
	           STRIDED_SLICE	        19380.206	    0.021	    0.021	  0.000%	 64.950%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/strided_slice]:589
	                    PACK	        19380.234	    0.029	    0.031	  0.000%	 64.950%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape/shape]:590
	                 RESHAPE	        19380.272	    0.014	    0.014	  0.000%	 64.950%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape]:591
	                 CONV_2D	        19380.292	    0.062	    0.059	  0.000%	 64.951%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5q_se_reduce/Conv2D]:592
	                LOGISTIC	        19380.358	    0.010	    0.010	  0.000%	 64.951%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/Sigmoid]:593
	                     MUL	        19380.374	    0.021	    0.021	  0.000%	 64.951%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/mul_1]:594
	                 CONV_2D	        19380.400	    0.028	    0.028	  0.000%	 64.951%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_se_expand/Conv2D]:595
	                LOGISTIC	        19380.435	    0.021	    0.020	  0.000%	 64.951%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/Sigmoid]:596
	                     MUL	        19380.461	   84.648	   84.714	  0.284%	 65.235%	     0.000	        1	[efficientnetv2-l/block5q_se_excite/mul]:597
	                 CONV_2D	        19465.189	   17.720	   17.741	  0.059%	 65.294%	     0.000	        1	[efficientnetv2-l/block5q_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_project_conv/Conv2D]:598
	                     ADD	        19482.941	   19.170	   19.203	  0.064%	 65.359%	     0.000	        1	[efficientnetv2-l/block5q_add/add]:599
	                 CONV_2D	        19502.153	   22.843	   22.835	  0.077%	 65.435%	     0.000	        1	[efficientnetv2-l/block5r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_expand_conv/Conv2D]:600
	                LOGISTIC	        19524.999	   11.690	   11.715	  0.039%	 65.475%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/Sigmoid]:601
	                     MUL	        19536.725	   84.582	   84.704	  0.284%	 65.759%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/mul_1]:602
	       DEPTHWISE_CONV_2D	        19621.440	    6.150	    6.154	  0.021%	 65.779%	     0.000	        1	[efficientnetv2-l/block5r_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:603
	                LOGISTIC	        19627.606	   11.745	   11.795	  0.040%	 65.819%	     0.000	        1	[efficientnetv2-l/block5r_activation/Sigmoid]:604
	                     MUL	        19639.412	   84.645	   84.667	  0.284%	 66.103%	     0.000	        1	[efficientnetv2-l/block5r_activation/mul_1]:605
	                    MEAN	        19724.091	  204.212	  204.386	  0.685%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_squeeze/Mean]:606
	                   SHAPE	        19928.488	    0.007	    0.009	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Shape]:607
	           STRIDED_SLICE	        19928.505	    0.021	    0.026	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/strided_slice]:608
	                    PACK	        19928.537	    0.030	    0.032	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape/shape]:609
	                 RESHAPE	        19928.576	    0.013	    0.013	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape]:610
	                 CONV_2D	        19928.596	    0.048	    0.051	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5r_se_reduce/Conv2D]:611
	                LOGISTIC	        19928.653	    0.009	    0.010	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/Sigmoid]:612
	                     MUL	        19928.669	    0.041	    0.025	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/mul_1]:613
	                 CONV_2D	        19928.699	    0.030	    0.029	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_se_expand/Conv2D]:614
	                LOGISTIC	        19928.735	    0.020	    0.025	  0.000%	 66.788%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/Sigmoid]:615
	                     MUL	        19928.766	   84.808	   84.598	  0.284%	 67.072%	     0.000	        1	[efficientnetv2-l/block5r_se_excite/mul]:616
	                 CONV_2D	        20013.376	   17.786	   17.766	  0.060%	 67.132%	     0.000	        1	[efficientnetv2-l/block5r_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_project_conv/Conv2D]:617
	                     ADD	        20031.152	   19.182	   19.203	  0.064%	 67.196%	     0.000	        1	[efficientnetv2-l/block5r_add/add]:618
	                 CONV_2D	        20050.363	   22.774	   22.799	  0.076%	 67.272%	     0.000	        1	[efficientnetv2-l/block5s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_expand_conv/Conv2D]:619
	                LOGISTIC	        20073.173	   11.882	   11.912	  0.040%	 67.312%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/Sigmoid]:620
	                     MUL	        20085.097	   84.661	   84.718	  0.284%	 67.596%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/mul_1]:621
	       DEPTHWISE_CONV_2D	        20169.826	    6.160	    6.209	  0.021%	 67.617%	     0.000	        1	[efficientnetv2-l/block5s_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:622
	                LOGISTIC	        20176.050	   11.888	   11.902	  0.040%	 67.657%	     0.000	        1	[efficientnetv2-l/block5s_activation/Sigmoid]:623
	                     MUL	        20187.964	   84.709	   84.660	  0.284%	 67.941%	     0.000	        1	[efficientnetv2-l/block5s_activation/mul_1]:624
	                    MEAN	        20272.638	  204.740	  204.969	  0.687%	 68.628%	     0.000	        1	[efficientnetv2-l/block5s_se_squeeze/Mean]:625
	                   SHAPE	        20477.620	    0.009	    0.009	  0.000%	 68.628%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Shape]:626
	           STRIDED_SLICE	        20477.635	    0.022	    0.025	  0.000%	 68.628%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/strided_slice]:627
	                    PACK	        20477.666	    0.043	    0.032	  0.000%	 68.628%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape/shape]:628
	                 RESHAPE	        20477.710	    0.014	    0.014	  0.000%	 68.628%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape]:629
	                 CONV_2D	        20477.731	    0.051	    0.057	  0.000%	 68.628%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5s_se_reduce/Conv2D]:630
	                LOGISTIC	        20477.794	    0.009	    0.018	  0.000%	 68.628%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/Sigmoid]:631
	                     MUL	        20477.818	    0.022	    0.028	  0.000%	 68.629%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/mul_1]:632
	                 CONV_2D	        20477.853	    0.029	    0.028	  0.000%	 68.629%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_se_expand/Conv2D]:633
	                LOGISTIC	        20477.887	    0.022	    0.021	  0.000%	 68.629%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/Sigmoid]:634
	                     MUL	        20477.914	   84.732	   85.002	  0.285%	 68.914%	     0.000	        1	[efficientnetv2-l/block5s_se_excite/mul]:635
	                 CONV_2D	        20562.928	   17.804	   17.939	  0.060%	 68.974%	     0.000	        1	[efficientnetv2-l/block5s_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_project_conv/Conv2D]:636
	                     ADD	        20580.879	   19.200	   19.383	  0.065%	 69.039%	     0.000	        1	[efficientnetv2-l/block5s_add/add]:637
	                 CONV_2D	        20600.273	   22.784	   23.024	  0.077%	 69.116%	     0.000	        1	[efficientnetv2-l/block6a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_expand_conv/Conv2D]:638
	                LOGISTIC	        20623.312	   11.808	   11.876	  0.040%	 69.156%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/Sigmoid]:639
	                     MUL	        20635.199	   84.583	   85.492	  0.287%	 69.442%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/mul_1]:640
	       DEPTHWISE_CONV_2D	        20720.703	  107.968	  111.597	  0.374%	 69.817%	     0.000	        1	[efficientnetv2-l/block6a_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_dwconv2/depthwise]:641
	                LOGISTIC	        20832.311	    2.912	    2.968	  0.010%	 69.826%	     0.000	        1	[efficientnetv2-l/block6a_activation/Sigmoid]:642
	                     MUL	        20835.289	   21.182	   21.381	  0.072%	 69.898%	     0.000	        1	[efficientnetv2-l/block6a_activation/mul_1]:643
	                    MEAN	        20856.681	   51.433	   51.912	  0.174%	 70.072%	     0.000	        1	[efficientnetv2-l/block6a_se_squeeze/Mean]:644
	                   SHAPE	        20908.609	    0.009	    0.009	  0.000%	 70.072%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Shape]:645
	           STRIDED_SLICE	        20908.625	    0.021	    0.022	  0.000%	 70.072%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/strided_slice]:646
	                    PACK	        20908.654	    0.030	    0.032	  0.000%	 70.072%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape/shape]:647
	                 RESHAPE	        20908.692	    0.014	    0.015	  0.000%	 70.072%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape]:648
	                 CONV_2D	        20908.713	    0.048	    0.064	  0.000%	 70.073%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block6a_se_reduce/Conv2D]:649
	                LOGISTIC	        20908.783	    0.010	    0.015	  0.000%	 70.073%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/Sigmoid]:650
	                     MUL	        20908.804	    0.020	    0.025	  0.000%	 70.073%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/mul_1]:651
	                 CONV_2D	        20908.835	    0.044	    0.033	  0.000%	 70.073%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_se_expand/Conv2D]:652
	                LOGISTIC	        20908.874	    0.020	    0.020	  0.000%	 70.073%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/Sigmoid]:653
	                     MUL	        20908.900	   21.227	   21.454	  0.072%	 70.145%	     0.000	        1	[efficientnetv2-l/block6a_se_excite/mul]:654
	                 CONV_2D	        20930.369	    7.657	    8.784	  0.029%	 70.174%	     0.000	        1	[efficientnetv2-l/block6a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_project_conv/Conv2D]:655
	                 CONV_2D	        20939.165	   13.911	   14.531	  0.049%	 70.223%	     0.000	        1	[efficientnetv2-l/block6b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_expand_conv/Conv2D]:656
	                LOGISTIC	        20953.708	    5.035	    5.112	  0.017%	 70.240%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/Sigmoid]:657
	                     MUL	        20958.829	   36.420	   36.647	  0.123%	 70.363%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/mul_1]:658
	       DEPTHWISE_CONV_2D	        20995.488	    3.063	    3.225	  0.011%	 70.374%	     0.000	        1	[efficientnetv2-l/block6b_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:659
	                LOGISTIC	        20998.724	    5.145	    5.127	  0.017%	 70.391%	     0.000	        1	[efficientnetv2-l/block6b_activation/Sigmoid]:660
	                     MUL	        21003.861	   36.449	   36.632	  0.123%	 70.514%	     0.000	        1	[efficientnetv2-l/block6b_activation/mul_1]:661
	                    MEAN	        21040.505	   88.919	   88.879	  0.298%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_squeeze/Mean]:662
	                   SHAPE	        21129.395	    0.009	    0.009	  0.000%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Shape]:663
	           STRIDED_SLICE	        21129.411	    0.023	    0.030	  0.000%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/strided_slice]:664
	                    PACK	        21129.449	    0.029	    0.029	  0.000%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape/shape]:665
	                 RESHAPE	        21129.485	    0.015	    0.015	  0.000%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape]:666
	                 CONV_2D	        21129.506	    0.096	    0.087	  0.000%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_reduce/Conv2D]:667
	                LOGISTIC	        21129.600	    0.010	    0.010	  0.000%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/Sigmoid]:668
	                     MUL	        21129.617	    0.022	    0.022	  0.000%	 70.812%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/mul_1]:669
	                 CONV_2D	        21129.645	    0.057	    0.066	  0.000%	 70.813%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_expand/Conv2D]:670
	                LOGISTIC	        21129.717	    0.028	    0.033	  0.000%	 70.813%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/Sigmoid]:671
	                     MUL	        21129.757	   36.716	   36.635	  0.123%	 70.936%	     0.000	        1	[efficientnetv2-l/block6b_se_excite/mul]:672
	                 CONV_2D	        21166.404	   13.628	   13.436	  0.045%	 70.981%	     0.000	        1	[efficientnetv2-l/block6b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_project_conv/Conv2D]:673
	                     ADD	        21179.851	    8.335	    8.354	  0.028%	 71.009%	     0.000	        1	[efficientnetv2-l/block6b_add/add]:674
	                 CONV_2D	        21188.216	   14.531	   14.707	  0.049%	 71.058%	     0.000	        1	[efficientnetv2-l/block6c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_expand_conv/Conv2D]:675
	                LOGISTIC	        21202.933	    5.080	    5.093	  0.017%	 71.075%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/Sigmoid]:676
	                     MUL	        21208.039	   36.828	   36.676	  0.123%	 71.198%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/mul_1]:677
	       DEPTHWISE_CONV_2D	        21244.727	    3.048	    3.148	  0.011%	 71.209%	     0.000	        1	[efficientnetv2-l/block6c_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:678
	                LOGISTIC	        21247.886	    5.077	    5.087	  0.017%	 71.226%	     0.000	        1	[efficientnetv2-l/block6c_activation/Sigmoid]:679
	                     MUL	        21252.985	   36.678	   36.623	  0.123%	 71.348%	     0.000	        1	[efficientnetv2-l/block6c_activation/mul_1]:680
	                    MEAN	        21289.619	   88.781	   88.591	  0.297%	 71.645%	     0.000	        1	[efficientnetv2-l/block6c_se_squeeze/Mean]:681
	                   SHAPE	        21378.222	    0.009	    0.009	  0.000%	 71.645%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Shape]:682
	           STRIDED_SLICE	        21378.238	    0.022	    0.032	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/strided_slice]:683
	                    PACK	        21378.276	    0.031	    0.033	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape/shape]:684
	                 RESHAPE	        21378.315	    0.014	    0.015	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape]:685
	                 CONV_2D	        21378.336	    0.067	    0.073	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_reduce/Conv2D]:686
	                LOGISTIC	        21378.417	    0.010	    0.010	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/Sigmoid]:687
	                     MUL	        21378.433	    0.021	    0.025	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/mul_1]:688
	                 CONV_2D	        21378.464	    0.082	    0.067	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_expand/Conv2D]:689
	                LOGISTIC	        21378.538	    0.030	    0.036	  0.000%	 71.646%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/Sigmoid]:690
	                     MUL	        21378.581	   36.593	   36.625	  0.123%	 71.769%	     0.000	        1	[efficientnetv2-l/block6c_se_excite/mul]:691
	                 CONV_2D	        21415.218	   13.304	   13.540	  0.045%	 71.815%	     0.000	        1	[efficientnetv2-l/block6c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_project_conv/Conv2D]:692
	                     ADD	        21428.770	    8.316	    8.343	  0.028%	 71.843%	     0.000	        1	[efficientnetv2-l/block6c_add/add]:693
	                 CONV_2D	        21437.123	   14.329	   14.247	  0.048%	 71.890%	     0.000	        1	[efficientnetv2-l/block6d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_expand_conv/Conv2D]:694
	                LOGISTIC	        21451.381	    5.101	    5.164	  0.017%	 71.908%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/Sigmoid]:695
	                     MUL	        21456.556	   36.543	   36.568	  0.123%	 72.030%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/mul_1]:696
	       DEPTHWISE_CONV_2D	        21493.135	    2.995	    3.068	  0.010%	 72.040%	     0.000	        1	[efficientnetv2-l/block6d_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:697
	                LOGISTIC	        21496.213	    5.067	    5.106	  0.017%	 72.058%	     0.000	        1	[efficientnetv2-l/block6d_activation/Sigmoid]:698
	                     MUL	        21501.331	   36.537	   36.560	  0.123%	 72.180%	     0.000	        1	[efficientnetv2-l/block6d_activation/mul_1]:699
	                    MEAN	        21537.901	   88.523	   88.399	  0.296%	 72.476%	     0.000	        1	[efficientnetv2-l/block6d_se_squeeze/Mean]:700
	                   SHAPE	        21626.311	    0.009	    0.009	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Shape]:701
	           STRIDED_SLICE	        21626.326	    0.022	    0.024	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/strided_slice]:702
	                    PACK	        21626.356	    0.030	    0.035	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape/shape]:703
	                 RESHAPE	        21626.398	    0.014	    0.014	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape]:704
	                 CONV_2D	        21626.418	    0.092	    0.072	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_reduce/Conv2D]:705
	                LOGISTIC	        21626.497	    0.011	    0.010	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/Sigmoid]:706
	                     MUL	        21626.513	    0.022	    0.024	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/mul_1]:707
	                 CONV_2D	        21626.543	    0.056	    0.055	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_expand/Conv2D]:708
	                LOGISTIC	        21626.604	    0.029	    0.033	  0.000%	 72.477%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/Sigmoid]:709
	                     MUL	        21626.643	   36.529	   36.394	  0.122%	 72.599%	     0.000	        1	[efficientnetv2-l/block6d_se_excite/mul]:710
	                 CONV_2D	        21663.048	   13.413	   13.101	  0.044%	 72.643%	     0.000	        1	[efficientnetv2-l/block6d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_project_conv/Conv2D]:711
	                     ADD	        21676.159	    8.310	    8.279	  0.028%	 72.671%	     0.000	        1	[efficientnetv2-l/block6d_add/add]:712
	                 CONV_2D	        21684.447	   14.227	   14.160	  0.047%	 72.719%	     0.000	        1	[efficientnetv2-l/block6e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_expand_conv/Conv2D]:713
	                LOGISTIC	        21698.618	    5.182	    5.110	  0.017%	 72.736%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/Sigmoid]:714
	                     MUL	        21703.739	   36.497	   36.394	  0.122%	 72.858%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/mul_1]:715
	       DEPTHWISE_CONV_2D	        21740.144	    3.161	    2.833	  0.009%	 72.867%	     0.000	        1	[efficientnetv2-l/block6e_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:716
	                LOGISTIC	        21742.987	    5.065	    5.089	  0.017%	 72.884%	     0.000	        1	[efficientnetv2-l/block6e_activation/Sigmoid]:717
	                     MUL	        21748.087	   36.557	   36.404	  0.122%	 73.006%	     0.000	        1	[efficientnetv2-l/block6e_activation/mul_1]:718
	                    MEAN	        21784.502	   87.975	   87.863	  0.295%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_squeeze/Mean]:719
	                   SHAPE	        21872.375	    0.009	    0.009	  0.000%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Shape]:720
	           STRIDED_SLICE	        21872.390	    0.022	    0.021	  0.000%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/strided_slice]:721
	                    PACK	        21872.417	    0.029	    0.033	  0.000%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape/shape]:722
	                 RESHAPE	        21872.458	    0.015	    0.014	  0.000%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape]:723
	                 CONV_2D	        21872.478	    0.066	    0.064	  0.000%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_reduce/Conv2D]:724
	                LOGISTIC	        21872.551	    0.011	    0.011	  0.000%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/Sigmoid]:725
	                     MUL	        21872.568	    0.020	    0.023	  0.000%	 73.301%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/mul_1]:726
	                 CONV_2D	        21872.597	    0.074	    0.056	  0.000%	 73.302%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_expand/Conv2D]:727
	                LOGISTIC	        21872.660	    0.028	    0.032	  0.000%	 73.302%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/Sigmoid]:728
	                     MUL	        21872.698	   36.202	   36.227	  0.121%	 73.423%	     0.000	        1	[efficientnetv2-l/block6e_se_excite/mul]:729
	                 CONV_2D	        21908.936	   12.950	   13.015	  0.044%	 73.467%	     0.000	        1	[efficientnetv2-l/block6e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_project_conv/Conv2D]:730
	                     ADD	        21921.960	    8.313	    8.279	  0.028%	 73.495%	     0.000	        1	[efficientnetv2-l/block6e_add/add]:731
	                 CONV_2D	        21930.248	   13.966	   13.972	  0.047%	 73.541%	     0.000	        1	[efficientnetv2-l/block6f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_expand_conv/Conv2D]:732
	                LOGISTIC	        21944.230	    5.050	    5.082	  0.017%	 73.558%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/Sigmoid]:733
	                     MUL	        21949.321	   36.377	   36.341	  0.122%	 73.680%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/mul_1]:734
	       DEPTHWISE_CONV_2D	        21985.674	    2.778	    2.803	  0.009%	 73.690%	     0.000	        1	[efficientnetv2-l/block6f_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:735
	                LOGISTIC	        21988.487	    5.063	    5.104	  0.017%	 73.707%	     0.000	        1	[efficientnetv2-l/block6f_activation/Sigmoid]:736
	                     MUL	        21993.602	   36.290	   36.347	  0.122%	 73.829%	     0.000	        1	[efficientnetv2-l/block6f_activation/mul_1]:737
	                    MEAN	        22029.967	   88.061	   88.034	  0.295%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_squeeze/Mean]:738
	                   SHAPE	        22118.011	    0.021	    0.010	  0.000%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Shape]:739
	           STRIDED_SLICE	        22118.027	    0.021	    0.021	  0.000%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/strided_slice]:740
	                    PACK	        22118.055	    0.029	    0.030	  0.000%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape/shape]:741
	                 RESHAPE	        22118.092	    0.014	    0.014	  0.000%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape]:742
	                 CONV_2D	        22118.114	    0.064	    0.074	  0.000%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_reduce/Conv2D]:743
	                LOGISTIC	        22118.195	    0.010	    0.010	  0.000%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/Sigmoid]:744
	                     MUL	        22118.211	    0.021	    0.021	  0.000%	 74.124%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/mul_1]:745
	                 CONV_2D	        22118.238	    0.052	    0.056	  0.000%	 74.125%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_expand/Conv2D]:746
	                LOGISTIC	        22118.301	    0.029	    0.029	  0.000%	 74.125%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/Sigmoid]:747
	                     MUL	        22118.337	   36.283	   36.347	  0.122%	 74.246%	     0.000	        1	[efficientnetv2-l/block6f_se_excite/mul]:748
	                 CONV_2D	        22154.695	   12.933	   13.065	  0.044%	 74.290%	     0.000	        1	[efficientnetv2-l/block6f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_project_conv/Conv2D]:749
	                     ADD	        22167.769	    8.242	    8.261	  0.028%	 74.318%	     0.000	        1	[efficientnetv2-l/block6f_add/add]:750
	                 CONV_2D	        22176.038	   13.924	   14.018	  0.047%	 74.365%	     0.000	        1	[efficientnetv2-l/block6g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_expand_conv/Conv2D]:751
	                LOGISTIC	        22190.067	    5.096	    5.090	  0.017%	 74.382%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/Sigmoid]:752
	                     MUL	        22195.167	   36.302	   36.324	  0.122%	 74.504%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/mul_1]:753
	       DEPTHWISE_CONV_2D	        22231.502	    2.779	    2.776	  0.009%	 74.513%	     0.000	        1	[efficientnetv2-l/block6g_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:754
	                LOGISTIC	        22234.289	    5.075	    5.069	  0.017%	 74.530%	     0.000	        1	[efficientnetv2-l/block6g_activation/Sigmoid]:755
	                     MUL	        22239.368	   36.393	   36.367	  0.122%	 74.652%	     0.000	        1	[efficientnetv2-l/block6g_activation/mul_1]:756
	                    MEAN	        22275.746	   87.642	   87.775	  0.294%	 74.946%	     0.000	        1	[efficientnetv2-l/block6g_se_squeeze/Mean]:757
	                   SHAPE	        22363.532	    0.009	    0.008	  0.000%	 74.946%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Shape]:758
	           STRIDED_SLICE	        22363.547	    0.031	    0.025	  0.000%	 74.946%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/strided_slice]:759
	                    PACK	        22363.578	    0.029	    0.028	  0.000%	 74.946%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape/shape]:760
	                 RESHAPE	        22363.613	    0.014	    0.014	  0.000%	 74.947%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape]:761
	                 CONV_2D	        22363.633	    0.064	    0.069	  0.000%	 74.947%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_reduce/Conv2D]:762
	                LOGISTIC	        22363.709	    0.010	    0.010	  0.000%	 74.947%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/Sigmoid]:763
	                     MUL	        22363.725	    0.020	    0.020	  0.000%	 74.947%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/mul_1]:764
	                 CONV_2D	        22363.751	    0.053	    0.060	  0.000%	 74.947%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_expand/Conv2D]:765
	                LOGISTIC	        22363.818	    0.028	    0.030	  0.000%	 74.947%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/Sigmoid]:766
	                     MUL	        22363.854	   36.178	   36.262	  0.122%	 75.069%	     0.000	        1	[efficientnetv2-l/block6g_se_excite/mul]:767
	                 CONV_2D	        22400.127	   12.965	   13.059	  0.044%	 75.112%	     0.000	        1	[efficientnetv2-l/block6g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_project_conv/Conv2D]:768
	                     ADD	        22413.196	    8.253	    8.332	  0.028%	 75.140%	     0.000	        1	[efficientnetv2-l/block6g_add/add]:769
	                 CONV_2D	        22421.536	   13.960	   14.000	  0.047%	 75.187%	     0.000	        1	[efficientnetv2-l/block6h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_expand_conv/Conv2D]:770
	                LOGISTIC	        22435.547	    5.010	    5.039	  0.017%	 75.204%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/Sigmoid]:771
	                     MUL	        22440.596	   36.351	   36.316	  0.122%	 75.326%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/mul_1]:772
	       DEPTHWISE_CONV_2D	        22476.924	    2.731	    2.776	  0.009%	 75.335%	     0.000	        1	[efficientnetv2-l/block6h_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:773
	                LOGISTIC	        22479.710	    5.034	    5.043	  0.017%	 75.352%	     0.000	        1	[efficientnetv2-l/block6h_activation/Sigmoid]:774
	                     MUL	        22484.763	   36.366	   36.352	  0.122%	 75.474%	     0.000	        1	[efficientnetv2-l/block6h_activation/mul_1]:775
	                    MEAN	        22521.125	   88.136	   88.162	  0.296%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_squeeze/Mean]:776
	                   SHAPE	        22609.298	    0.008	    0.008	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Shape]:777
	           STRIDED_SLICE	        22609.312	    0.022	    0.021	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/strided_slice]:778
	                    PACK	        22609.339	    0.029	    0.033	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape/shape]:779
	                 RESHAPE	        22609.379	    0.014	    0.015	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape]:780
	                 CONV_2D	        22609.401	    0.065	    0.067	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_reduce/Conv2D]:781
	                LOGISTIC	        22609.474	    0.010	    0.010	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/Sigmoid]:782
	                     MUL	        22609.490	    0.021	    0.021	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/mul_1]:783
	                 CONV_2D	        22609.517	    0.052	    0.057	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_expand/Conv2D]:784
	                LOGISTIC	        22609.580	    0.046	    0.033	  0.000%	 75.770%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/Sigmoid]:785
	                     MUL	        22609.618	   36.216	   36.309	  0.122%	 75.892%	     0.000	        1	[efficientnetv2-l/block6h_se_excite/mul]:786
	                 CONV_2D	        22645.940	   12.971	   13.080	  0.044%	 75.936%	     0.000	        1	[efficientnetv2-l/block6h_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_project_conv/Conv2D]:787
	                     ADD	        22659.030	    8.225	    8.272	  0.028%	 75.964%	     0.000	        1	[efficientnetv2-l/block6h_add/add]:788
	                 CONV_2D	        22667.310	   13.938	   14.030	  0.047%	 76.011%	     0.000	        1	[efficientnetv2-l/block6i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_expand_conv/Conv2D]:789
	                LOGISTIC	        22681.350	    5.054	    5.068	  0.017%	 76.028%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/Sigmoid]:790
	                     MUL	        22686.428	   36.277	   36.312	  0.122%	 76.150%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/mul_1]:791
	       DEPTHWISE_CONV_2D	        22722.751	    2.842	    2.855	  0.010%	 76.159%	     0.000	        1	[efficientnetv2-l/block6i_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:792
	                LOGISTIC	        22725.617	    5.063	    5.119	  0.017%	 76.176%	     0.000	        1	[efficientnetv2-l/block6i_activation/Sigmoid]:793
	                     MUL	        22730.753	   36.233	   36.377	  0.122%	 76.298%	     0.000	        1	[efficientnetv2-l/block6i_activation/mul_1]:794
	                    MEAN	        22767.142	   87.755	   87.894	  0.295%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_squeeze/Mean]:795
	                   SHAPE	        22855.046	    0.008	    0.009	  0.000%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Shape]:796
	           STRIDED_SLICE	        22855.062	    0.022	    0.023	  0.000%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/strided_slice]:797
	                    PACK	        22855.092	    0.029	    0.028	  0.000%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape/shape]:798
	                 RESHAPE	        22855.127	    0.014	    0.017	  0.000%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape]:799
	                 CONV_2D	        22855.150	    0.063	    0.064	  0.000%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_reduce/Conv2D]:800
	                LOGISTIC	        22855.223	    0.010	    0.010	  0.000%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/Sigmoid]:801
	                     MUL	        22855.239	    0.020	    0.024	  0.000%	 76.593%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/mul_1]:802
	                 CONV_2D	        22855.269	    0.052	    0.052	  0.000%	 76.594%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_expand/Conv2D]:803
	                LOGISTIC	        22855.327	    0.031	    0.034	  0.000%	 76.594%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/Sigmoid]:804
	                     MUL	        22855.367	   36.190	   36.233	  0.121%	 76.715%	     0.000	        1	[efficientnetv2-l/block6i_se_excite/mul]:805
	                 CONV_2D	        22891.610	   12.924	   12.978	  0.044%	 76.759%	     0.000	        1	[efficientnetv2-l/block6i_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_project_conv/Conv2D]:806
	                     ADD	        22904.597	    8.225	    8.247	  0.028%	 76.786%	     0.000	        1	[efficientnetv2-l/block6i_add/add]:807
	                 CONV_2D	        22912.852	   14.008	   13.958	  0.047%	 76.833%	     0.000	        1	[efficientnetv2-l/block6j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_expand_conv/Conv2D]:808
	                LOGISTIC	        22926.820	    5.120	    5.137	  0.017%	 76.850%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/Sigmoid]:809
	                     MUL	        22931.968	   36.291	   36.495	  0.122%	 76.973%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/mul_1]:810
	       DEPTHWISE_CONV_2D	        22968.475	    2.711	    2.823	  0.009%	 76.982%	     0.000	        1	[efficientnetv2-l/block6j_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:811
	                LOGISTIC	        22971.309	    5.115	    5.125	  0.017%	 76.999%	     0.000	        1	[efficientnetv2-l/block6j_activation/Sigmoid]:812
	                     MUL	        22976.445	   36.269	   36.423	  0.122%	 77.121%	     0.000	        1	[efficientnetv2-l/block6j_activation/mul_1]:813
	                    MEAN	        23012.879	   88.062	   88.280	  0.296%	 77.417%	     0.000	        1	[efficientnetv2-l/block6j_se_squeeze/Mean]:814
	                   SHAPE	        23101.170	    0.018	    0.012	  0.000%	 77.417%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Shape]:815
	           STRIDED_SLICE	        23101.188	    0.021	    0.022	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/strided_slice]:816
	                    PACK	        23101.217	    0.029	    0.031	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape/shape]:817
	                 RESHAPE	        23101.255	    0.014	    0.017	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape]:818
	                 CONV_2D	        23101.278	    0.065	    0.074	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_reduce/Conv2D]:819
	                LOGISTIC	        23101.359	    0.010	    0.010	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/Sigmoid]:820
	                     MUL	        23101.375	    0.020	    0.021	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/mul_1]:821
	                 CONV_2D	        23101.403	    0.054	    0.056	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_expand/Conv2D]:822
	                LOGISTIC	        23101.464	    0.029	    0.033	  0.000%	 77.418%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/Sigmoid]:823
	                     MUL	        23101.503	   36.226	   36.518	  0.122%	 77.541%	     0.000	        1	[efficientnetv2-l/block6j_se_excite/mul]:824
	                 CONV_2D	        23138.033	   12.981	   13.196	  0.044%	 77.585%	     0.000	        1	[efficientnetv2-l/block6j_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_project_conv/Conv2D]:825
	                     ADD	        23151.239	    8.236	    8.295	  0.028%	 77.613%	     0.000	        1	[efficientnetv2-l/block6j_add/add]:826
	                 CONV_2D	        23159.545	   13.918	   14.234	  0.048%	 77.661%	     0.000	        1	[efficientnetv2-l/block6k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_expand_conv/Conv2D]:827
	                LOGISTIC	        23173.790	    5.018	    5.073	  0.017%	 77.678%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/Sigmoid]:828
	                     MUL	        23178.873	   36.264	   36.520	  0.122%	 77.800%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/mul_1]:829
	       DEPTHWISE_CONV_2D	        23215.405	    2.792	    3.107	  0.010%	 77.810%	     0.000	        1	[efficientnetv2-l/block6k_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:830
	                LOGISTIC	        23218.523	    5.040	    5.086	  0.017%	 77.827%	     0.000	        1	[efficientnetv2-l/block6k_activation/Sigmoid]:831
	                     MUL	        23223.620	   36.251	   36.684	  0.123%	 77.950%	     0.000	        1	[efficientnetv2-l/block6k_activation/mul_1]:832
	                    MEAN	        23260.317	   88.060	   88.770	  0.298%	 78.248%	     0.000	        1	[efficientnetv2-l/block6k_se_squeeze/Mean]:833
	                   SHAPE	        23349.100	    0.009	    0.009	  0.000%	 78.248%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Shape]:834
	           STRIDED_SLICE	        23349.116	    0.022	    0.026	  0.000%	 78.248%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/strided_slice]:835
	                    PACK	        23349.148	    0.031	    0.036	  0.000%	 78.248%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape/shape]:836
	                 RESHAPE	        23349.192	    0.014	    0.015	  0.000%	 78.248%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape]:837
	                 CONV_2D	        23349.213	    0.065	    0.076	  0.000%	 78.249%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_reduce/Conv2D]:838
	                LOGISTIC	        23349.296	    0.009	    0.010	  0.000%	 78.249%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/Sigmoid]:839
	                     MUL	        23349.312	    0.039	    0.026	  0.000%	 78.249%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/mul_1]:840
	                 CONV_2D	        23349.344	    0.055	    0.061	  0.000%	 78.249%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_expand/Conv2D]:841
	                LOGISTIC	        23349.411	    0.030	    0.029	  0.000%	 78.249%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/Sigmoid]:842
	                     MUL	        23349.532	   36.492	   36.726	  0.123%	 78.372%	     0.000	        1	[efficientnetv2-l/block6k_se_excite/mul]:843
	                 CONV_2D	        23386.269	   12.966	   13.378	  0.045%	 78.417%	     0.000	        1	[efficientnetv2-l/block6k_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_project_conv/Conv2D]:844
	                     ADD	        23399.661	    8.293	    8.487	  0.028%	 78.445%	     0.000	        1	[efficientnetv2-l/block6k_add/add]:845
	                 CONV_2D	        23408.159	   13.943	   14.425	  0.048%	 78.494%	     0.000	        1	[efficientnetv2-l/block6l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_expand_conv/Conv2D]:846
	                LOGISTIC	        23422.596	    5.055	    5.116	  0.017%	 78.511%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/Sigmoid]:847
	                     MUL	        23427.723	   36.388	   36.983	  0.124%	 78.635%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/mul_1]:848
	       DEPTHWISE_CONV_2D	        23464.717	    3.029	    3.191	  0.011%	 78.646%	     0.000	        1	[efficientnetv2-l/block6l_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:849
	                LOGISTIC	        23467.919	    5.064	    5.093	  0.017%	 78.663%	     0.000	        1	[efficientnetv2-l/block6l_activation/Sigmoid]:850
	                     MUL	        23473.024	   36.482	   36.672	  0.123%	 78.786%	     0.000	        1	[efficientnetv2-l/block6l_activation/mul_1]:851
	                    MEAN	        23509.709	   91.176	   89.577	  0.300%	 79.086%	     0.000	        1	[efficientnetv2-l/block6l_se_squeeze/Mean]:852
	                   SHAPE	        23599.297	    0.010	    0.009	  0.000%	 79.086%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Shape]:853
	           STRIDED_SLICE	        23599.313	    0.024	    0.023	  0.000%	 79.086%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/strided_slice]:854
	                    PACK	        23599.341	    0.034	    0.041	  0.000%	 79.086%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape/shape]:855
	                 RESHAPE	        23599.393	    0.015	    0.015	  0.000%	 79.086%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape]:856
	                 CONV_2D	        23599.414	    0.069	    0.072	  0.000%	 79.086%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_reduce/Conv2D]:857
	                LOGISTIC	        23599.493	    0.011	    0.011	  0.000%	 79.086%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/Sigmoid]:858
	                     MUL	        23599.510	    0.023	    0.025	  0.000%	 79.087%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/mul_1]:859
	                 CONV_2D	        23599.540	    0.059	    0.066	  0.000%	 79.087%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_expand/Conv2D]:860
	                LOGISTIC	        23599.613	    0.032	    0.030	  0.000%	 79.087%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/Sigmoid]:861
	                     MUL	        23599.649	   39.187	   37.313	  0.125%	 79.212%	     0.000	        1	[efficientnetv2-l/block6l_se_excite/mul]:862
	                 CONV_2D	        23636.974	   13.589	   13.383	  0.045%	 79.257%	     0.000	        1	[efficientnetv2-l/block6l_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_project_conv/Conv2D]:863
	                     ADD	        23650.369	    8.345	    8.321	  0.028%	 79.285%	     0.000	        1	[efficientnetv2-l/block6l_add/add]:864
	                 CONV_2D	        23658.703	   14.531	   14.469	  0.049%	 79.333%	     0.000	        1	[efficientnetv2-l/block6m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_expand_conv/Conv2D]:865
	                LOGISTIC	        23673.183	    5.133	    5.113	  0.017%	 79.350%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/Sigmoid]:866
	                     MUL	        23678.307	   36.636	   36.589	  0.123%	 79.473%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/mul_1]:867
	       DEPTHWISE_CONV_2D	        23714.907	    3.002	    3.135	  0.011%	 79.484%	     0.000	        1	[efficientnetv2-l/block6m_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:868
	                LOGISTIC	        23718.054	    5.351	    5.303	  0.018%	 79.501%	     0.000	        1	[efficientnetv2-l/block6m_activation/Sigmoid]:869
	                     MUL	        23723.368	   37.097	   36.737	  0.123%	 79.624%	     0.000	        1	[efficientnetv2-l/block6m_activation/mul_1]:870
	                    MEAN	        23760.117	   89.006	   88.620	  0.297%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_squeeze/Mean]:871
	                   SHAPE	        23848.748	    0.009	    0.009	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Shape]:872
	           STRIDED_SLICE	        23848.764	    0.022	    0.023	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/strided_slice]:873
	                    PACK	        23848.793	    0.030	    0.032	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape/shape]:874
	                 RESHAPE	        23848.831	    0.014	    0.015	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape]:875
	                 CONV_2D	        23848.852	    0.067	    0.079	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_reduce/Conv2D]:876
	                LOGISTIC	        23848.937	    0.011	    0.011	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/Sigmoid]:877
	                     MUL	        23848.953	    0.022	    0.022	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/mul_1]:878
	                 CONV_2D	        23848.982	    0.055	    0.064	  0.000%	 79.922%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_expand/Conv2D]:879
	                LOGISTIC	        23849.053	    0.052	    0.033	  0.000%	 79.923%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/Sigmoid]:880
	                     MUL	        23849.091	   36.773	   36.643	  0.123%	 80.045%	     0.000	        1	[efficientnetv2-l/block6m_se_excite/mul]:881
	                 CONV_2D	        23885.746	   13.120	   13.186	  0.044%	 80.090%	     0.000	        1	[efficientnetv2-l/block6m_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_project_conv/Conv2D]:882
	                     ADD	        23898.943	    8.295	    8.322	  0.028%	 80.117%	     0.000	        1	[efficientnetv2-l/block6m_add/add]:883
	                 CONV_2D	        23907.277	   14.358	   14.335	  0.048%	 80.166%	     0.000	        1	[efficientnetv2-l/block6n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_expand_conv/Conv2D]:884
	                LOGISTIC	        23921.624	    5.072	    5.059	  0.017%	 80.182%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/Sigmoid]:885
	                     MUL	        23926.693	   36.729	   36.609	  0.123%	 80.305%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/mul_1]:886
	       DEPTHWISE_CONV_2D	        23963.313	    3.087	    2.980	  0.010%	 80.315%	     0.000	        1	[efficientnetv2-l/block6n_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:887
	                LOGISTIC	        23966.319	    5.066	    5.077	  0.017%	 80.332%	     0.000	        1	[efficientnetv2-l/block6n_activation/Sigmoid]:888
	                     MUL	        23971.406	   36.593	   36.550	  0.123%	 80.455%	     0.000	        1	[efficientnetv2-l/block6n_activation/mul_1]:889
	                    MEAN	        24007.967	   88.888	   88.463	  0.297%	 80.751%	     0.000	        1	[efficientnetv2-l/block6n_se_squeeze/Mean]:890
	                   SHAPE	        24096.441	    0.009	    0.009	  0.000%	 80.751%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Shape]:891
	           STRIDED_SLICE	        24096.456	    0.022	    0.022	  0.000%	 80.751%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/strided_slice]:892
	                    PACK	        24096.484	    0.030	    0.028	  0.000%	 80.751%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape/shape]:893
	                 RESHAPE	        24096.519	    0.014	    0.014	  0.000%	 80.752%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape]:894
	                 CONV_2D	        24096.539	    0.088	    0.071	  0.000%	 80.752%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_reduce/Conv2D]:895
	                LOGISTIC	        24096.617	    0.011	    0.010	  0.000%	 80.752%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/Sigmoid]:896
	                     MUL	        24096.633	    0.020	    0.024	  0.000%	 80.752%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/mul_1]:897
	                 CONV_2D	        24096.664	    0.091	    0.065	  0.000%	 80.752%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_expand/Conv2D]:898
	                LOGISTIC	        24096.735	    0.030	    0.034	  0.000%	 80.752%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/Sigmoid]:899
	                     MUL	        24096.775	   36.611	   36.481	  0.122%	 80.875%	     0.000	        1	[efficientnetv2-l/block6n_se_excite/mul]:900
	                 CONV_2D	        24133.268	   13.331	   13.150	  0.044%	 80.919%	     0.000	        1	[efficientnetv2-l/block6n_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_project_conv/Conv2D]:901
	                     ADD	        24146.428	    8.285	    8.286	  0.028%	 80.946%	     0.000	        1	[efficientnetv2-l/block6n_add/add]:902
	                 CONV_2D	        24154.723	   14.352	   14.201	  0.048%	 80.994%	     0.000	        1	[efficientnetv2-l/block6o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_expand_conv/Conv2D]:903
	                LOGISTIC	        24168.934	    5.034	    5.056	  0.017%	 81.011%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/Sigmoid]:904
	                     MUL	        24174.000	   36.473	   36.499	  0.122%	 81.133%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/mul_1]:905
	       DEPTHWISE_CONV_2D	        24210.510	    3.204	    3.115	  0.010%	 81.144%	     0.000	        1	[efficientnetv2-l/block6o_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:906
	                LOGISTIC	        24213.636	    5.071	    5.061	  0.017%	 81.161%	     0.000	        1	[efficientnetv2-l/block6o_activation/Sigmoid]:907
	                     MUL	        24218.707	   36.630	   36.484	  0.122%	 81.283%	     0.000	        1	[efficientnetv2-l/block6o_activation/mul_1]:908
	                    MEAN	        24255.203	   87.889	   87.935	  0.295%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_squeeze/Mean]:909
	                   SHAPE	        24343.149	    0.008	    0.009	  0.000%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Shape]:910
	           STRIDED_SLICE	        24343.164	    0.022	    0.022	  0.000%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/strided_slice]:911
	                    PACK	        24343.192	    0.029	    0.028	  0.000%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape/shape]:912
	                 RESHAPE	        24343.226	    0.014	    0.014	  0.000%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape]:913
	                 CONV_2D	        24343.247	    0.065	    0.067	  0.000%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_reduce/Conv2D]:914
	                LOGISTIC	        24343.320	    0.009	    0.010	  0.000%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/Sigmoid]:915
	                     MUL	        24343.336	    0.021	    0.024	  0.000%	 81.578%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/mul_1]:916
	                 CONV_2D	        24343.367	    0.070	    0.057	  0.000%	 81.579%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_expand/Conv2D]:917
	                LOGISTIC	        24343.430	    0.030	    0.032	  0.000%	 81.579%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/Sigmoid]:918
	                     MUL	        24343.468	   36.352	   36.310	  0.122%	 81.700%	     0.000	        1	[efficientnetv2-l/block6o_se_excite/mul]:919
	                 CONV_2D	        24379.789	   12.980	   13.018	  0.044%	 81.744%	     0.000	        1	[efficientnetv2-l/block6o_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_project_conv/Conv2D]:920
	                     ADD	        24392.816	    8.251	    8.252	  0.028%	 81.772%	     0.000	        1	[efficientnetv2-l/block6o_add/add]:921
	                 CONV_2D	        24401.076	   13.902	   13.934	  0.047%	 81.818%	     0.000	        1	[efficientnetv2-l/block6p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_expand_conv/Conv2D]:922
	                LOGISTIC	        24415.020	    5.027	    5.053	  0.017%	 81.835%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/Sigmoid]:923
	                     MUL	        24420.083	   36.425	   36.364	  0.122%	 81.957%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/mul_1]:924
	       DEPTHWISE_CONV_2D	        24456.459	    2.771	    2.792	  0.009%	 81.967%	     0.000	        1	[efficientnetv2-l/block6p_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:925
	                LOGISTIC	        24459.262	    5.106	    5.080	  0.017%	 81.984%	     0.000	        1	[efficientnetv2-l/block6p_activation/Sigmoid]:926
	                     MUL	        24464.352	   36.249	   36.324	  0.122%	 82.105%	     0.000	        1	[efficientnetv2-l/block6p_activation/mul_1]:927
	                    MEAN	        24500.686	   87.914	   87.941	  0.295%	 82.400%	     0.000	        1	[efficientnetv2-l/block6p_se_squeeze/Mean]:928
	                   SHAPE	        24588.638	    0.008	    0.008	  0.000%	 82.400%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Shape]:929
	           STRIDED_SLICE	        24588.653	    0.021	    0.021	  0.000%	 82.400%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/strided_slice]:930
	                    PACK	        24588.680	    0.029	    0.037	  0.000%	 82.400%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape/shape]:931
	                 RESHAPE	        24588.724	    0.014	    0.014	  0.000%	 82.401%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape]:932
	                 CONV_2D	        24588.744	    0.064	    0.069	  0.000%	 82.401%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_reduce/Conv2D]:933
	                LOGISTIC	        24588.820	    0.011	    0.015	  0.000%	 82.401%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/Sigmoid]:934
	                     MUL	        24588.841	    0.020	    0.020	  0.000%	 82.401%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/mul_1]:935
	                 CONV_2D	        24588.867	    0.073	    0.061	  0.000%	 82.401%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_expand/Conv2D]:936
	                LOGISTIC	        24588.935	    0.030	    0.030	  0.000%	 82.401%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/Sigmoid]:937
	                     MUL	        24588.974	   36.609	   36.322	  0.122%	 82.523%	     0.000	        1	[efficientnetv2-l/block6p_se_excite/mul]:938
	                 CONV_2D	        24625.307	   12.963	   12.966	  0.043%	 82.566%	     0.000	        1	[efficientnetv2-l/block6p_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_project_conv/Conv2D]:939
	                     ADD	        24638.282	    8.270	    8.233	  0.028%	 82.594%	     0.000	        1	[efficientnetv2-l/block6p_add/add]:940
	                 CONV_2D	        24646.523	   13.981	   13.967	  0.047%	 82.641%	     0.000	        1	[efficientnetv2-l/block6q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_expand_conv/Conv2D]:941
	                LOGISTIC	        24660.499	    5.043	    5.046	  0.017%	 82.658%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/Sigmoid]:942
	                     MUL	        24665.555	   36.346	   36.325	  0.122%	 82.780%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/mul_1]:943
	       DEPTHWISE_CONV_2D	        24701.894	    2.833	    2.764	  0.009%	 82.789%	     0.000	        1	[efficientnetv2-l/block6q_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:944
	                LOGISTIC	        24704.669	    5.064	    5.086	  0.017%	 82.806%	     0.000	        1	[efficientnetv2-l/block6q_activation/Sigmoid]:945
	                     MUL	        24709.768	   36.555	   36.370	  0.122%	 82.928%	     0.000	        1	[efficientnetv2-l/block6q_activation/mul_1]:946
	                    MEAN	        24746.148	   87.953	   87.857	  0.295%	 83.222%	     0.000	        1	[efficientnetv2-l/block6q_se_squeeze/Mean]:947
	                   SHAPE	        24834.016	    0.008	    0.008	  0.000%	 83.222%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Shape]:948
	           STRIDED_SLICE	        24834.031	    0.022	    0.021	  0.000%	 83.222%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/strided_slice]:949
	                    PACK	        24834.058	    0.030	    0.028	  0.000%	 83.222%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape/shape]:950
	                 RESHAPE	        24834.093	    0.014	    0.014	  0.000%	 83.223%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape]:951
	                 CONV_2D	        24834.113	    0.063	    0.074	  0.000%	 83.223%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_reduce/Conv2D]:952
	                LOGISTIC	        24834.193	    0.010	    0.010	  0.000%	 83.223%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/Sigmoid]:953
	                     MUL	        24834.210	    0.021	    0.023	  0.000%	 83.223%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/mul_1]:954
	                 CONV_2D	        24834.239	    0.051	    0.055	  0.000%	 83.223%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_expand/Conv2D]:955
	                LOGISTIC	        24834.301	    0.030	    0.033	  0.000%	 83.223%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/Sigmoid]:956
	                     MUL	        24834.339	   36.318	   36.278	  0.122%	 83.345%	     0.000	        1	[efficientnetv2-l/block6q_se_excite/mul]:957
	                 CONV_2D	        24870.629	   12.969	   13.013	  0.044%	 83.388%	     0.000	        1	[efficientnetv2-l/block6q_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_project_conv/Conv2D]:958
	                     ADD	        24883.651	    8.257	    8.258	  0.028%	 83.416%	     0.000	        1	[efficientnetv2-l/block6q_add/add]:959
	                 CONV_2D	        24891.916	   13.964	   13.931	  0.047%	 83.463%	     0.000	        1	[efficientnetv2-l/block6r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_expand_conv/Conv2D]:960
	                LOGISTIC	        24905.857	    4.997	    5.040	  0.017%	 83.480%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/Sigmoid]:961
	                     MUL	        24910.907	   36.270	   36.304	  0.122%	 83.601%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/mul_1]:962
	       DEPTHWISE_CONV_2D	        24947.223	    2.780	    2.776	  0.009%	 83.611%	     0.000	        1	[efficientnetv2-l/block6r_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:963
	                LOGISTIC	        24950.009	    5.032	    5.070	  0.017%	 83.628%	     0.000	        1	[efficientnetv2-l/block6r_activation/Sigmoid]:964
	                     MUL	        24955.096	   36.261	   36.340	  0.122%	 83.750%	     0.000	        1	[efficientnetv2-l/block6r_activation/mul_1]:965
	                    MEAN	        24991.447	   87.926	   88.049	  0.295%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_squeeze/Mean]:966
	                   SHAPE	        25079.506	    0.009	    0.008	  0.000%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Shape]:967
	           STRIDED_SLICE	        25079.520	    0.021	    0.021	  0.000%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/strided_slice]:968
	                    PACK	        25079.548	    0.030	    0.029	  0.000%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape/shape]:969
	                 RESHAPE	        25079.584	    0.015	    0.014	  0.000%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape]:970
	                 CONV_2D	        25079.604	    0.066	    0.067	  0.000%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_reduce/Conv2D]:971
	                LOGISTIC	        25079.678	    0.011	    0.010	  0.000%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/Sigmoid]:972
	                     MUL	        25079.694	    0.037	    0.023	  0.000%	 84.045%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/mul_1]:973
	                 CONV_2D	        25079.723	    0.113	    0.072	  0.000%	 84.046%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_expand/Conv2D]:974
	                LOGISTIC	        25079.802	    0.030	    0.029	  0.000%	 84.046%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/Sigmoid]:975
	                     MUL	        25079.838	   36.203	   36.236	  0.121%	 84.167%	     0.000	        1	[efficientnetv2-l/block6r_se_excite/mul]:976
	                 CONV_2D	        25116.084	   12.992	   12.988	  0.044%	 84.211%	     0.000	        1	[efficientnetv2-l/block6r_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_project_conv/Conv2D]:977
	                     ADD	        25129.081	    8.219	    8.236	  0.028%	 84.238%	     0.000	        1	[efficientnetv2-l/block6r_add/add]:978
	                 CONV_2D	        25137.324	   13.923	   13.965	  0.047%	 84.285%	     0.000	        1	[efficientnetv2-l/block6s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_expand_conv/Conv2D]:979
	                LOGISTIC	        25151.299	    5.094	    5.098	  0.017%	 84.302%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/Sigmoid]:980
	                     MUL	        25156.408	   36.235	   36.295	  0.122%	 84.424%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/mul_1]:981
	       DEPTHWISE_CONV_2D	        25192.714	    2.757	    2.814	  0.009%	 84.433%	     0.000	        1	[efficientnetv2-l/block6s_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:982
	                LOGISTIC	        25195.539	    5.102	    5.070	  0.017%	 84.450%	     0.000	        1	[efficientnetv2-l/block6s_activation/Sigmoid]:983
	                     MUL	        25200.619	   36.279	   36.373	  0.122%	 84.572%	     0.000	        1	[efficientnetv2-l/block6s_activation/mul_1]:984
	                    MEAN	        25237.004	   87.594	   87.878	  0.295%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_squeeze/Mean]:985
	                   SHAPE	        25324.893	    0.008	    0.009	  0.000%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Shape]:986
	           STRIDED_SLICE	        25324.908	    0.022	    0.023	  0.000%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/strided_slice]:987
	                    PACK	        25324.938	    0.035	    0.032	  0.000%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape/shape]:988
	                 RESHAPE	        25324.980	    0.044	    0.019	  0.000%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape]:989
	                 CONV_2D	        25325.005	    0.065	    0.072	  0.000%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_reduce/Conv2D]:990
	                LOGISTIC	        25325.084	    0.010	    0.010	  0.000%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/Sigmoid]:991
	                     MUL	        25325.102	    0.021	    0.021	  0.000%	 84.867%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/mul_1]:992
	                 CONV_2D	        25325.129	    0.054	    0.055	  0.000%	 84.868%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_expand/Conv2D]:993
	                LOGISTIC	        25325.191	    0.028	    0.028	  0.000%	 84.868%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/Sigmoid]:994
	                     MUL	        25325.226	   36.393	   36.319	  0.122%	 84.989%	     0.000	        1	[efficientnetv2-l/block6s_se_excite/mul]:995
	                 CONV_2D	        25361.557	   13.003	   12.984	  0.044%	 85.033%	     0.000	        1	[efficientnetv2-l/block6s_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_project_conv/Conv2D]:996
	                     ADD	        25374.550	    8.227	    8.260	  0.028%	 85.061%	     0.000	        1	[efficientnetv2-l/block6s_add/add]:997
	                 CONV_2D	        25382.818	   13.935	   13.952	  0.047%	 85.107%	     0.000	        1	[efficientnetv2-l/block6t_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_expand_conv/Conv2D]:998
	                LOGISTIC	        25396.780	    5.017	    5.030	  0.017%	 85.124%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/Sigmoid]:999
	                     MUL	        25401.820	   36.228	   36.457	  0.122%	 85.247%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/mul_1]:1000
	       DEPTHWISE_CONV_2D	        25438.288	    2.788	    2.881	  0.010%	 85.256%	     0.000	        1	[efficientnetv2-l/block6t_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1001
	                LOGISTIC	        25441.180	    5.052	    5.069	  0.017%	 85.273%	     0.000	        1	[efficientnetv2-l/block6t_activation/Sigmoid]:1002
	                     MUL	        25446.260	   36.262	   36.429	  0.122%	 85.395%	     0.000	        1	[efficientnetv2-l/block6t_activation/mul_1]:1003
	                    MEAN	        25482.700	   87.922	   88.279	  0.296%	 85.691%	     0.000	        1	[efficientnetv2-l/block6t_se_squeeze/Mean]:1004
	                   SHAPE	        25570.990	    0.008	    0.008	  0.000%	 85.691%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Shape]:1005
	           STRIDED_SLICE	        25571.005	    0.020	    0.022	  0.000%	 85.691%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/strided_slice]:1006
	                    PACK	        25571.033	    0.027	    0.028	  0.000%	 85.691%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape/shape]:1007
	                 RESHAPE	        25571.068	    0.014	    0.014	  0.000%	 85.691%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape]:1008
	                 CONV_2D	        25571.089	    0.064	    0.074	  0.000%	 85.692%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_reduce/Conv2D]:1009
	                LOGISTIC	        25571.172	    0.011	    0.011	  0.000%	 85.692%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/Sigmoid]:1010
	                     MUL	        25571.189	    0.020	    0.021	  0.000%	 85.692%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/mul_1]:1011
	                 CONV_2D	        25571.216	    0.070	    0.059	  0.000%	 85.692%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_expand/Conv2D]:1012
	                LOGISTIC	        25571.282	    0.031	    0.029	  0.000%	 85.692%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/Sigmoid]:1013
	                     MUL	        25571.317	   36.511	   36.517	  0.122%	 85.815%	     0.000	        1	[efficientnetv2-l/block6t_se_excite/mul]:1014
	                 CONV_2D	        25607.846	   12.943	   13.180	  0.044%	 85.859%	     0.000	        1	[efficientnetv2-l/block6t_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_project_conv/Conv2D]:1015
	                     ADD	        25621.036	    8.247	    8.297	  0.028%	 85.887%	     0.000	        1	[efficientnetv2-l/block6t_add/add]:1016
	                 CONV_2D	        25629.342	   14.055	   14.184	  0.048%	 85.934%	     0.000	        1	[efficientnetv2-l/block6u_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_expand_conv/Conv2D]:1017
	                LOGISTIC	        25643.537	    5.007	    5.071	  0.017%	 85.951%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/Sigmoid]:1018
	                     MUL	        25648.619	   36.310	   36.714	  0.123%	 86.074%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/mul_1]:1019
	       DEPTHWISE_CONV_2D	        25685.344	    2.798	    3.032	  0.010%	 86.084%	     0.000	        1	[efficientnetv2-l/block6u_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1020
	                LOGISTIC	        25688.386	    5.019	    5.064	  0.017%	 86.101%	     0.000	        1	[efficientnetv2-l/block6u_activation/Sigmoid]:1021
	                     MUL	        25693.463	   36.520	   36.676	  0.123%	 86.224%	     0.000	        1	[efficientnetv2-l/block6u_activation/mul_1]:1022
	                    MEAN	        25730.151	   88.432	   88.623	  0.297%	 86.521%	     0.000	        1	[efficientnetv2-l/block6u_se_squeeze/Mean]:1023
	                   SHAPE	        25818.785	    0.009	    0.009	  0.000%	 86.521%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Shape]:1024
	           STRIDED_SLICE	        25818.800	    0.022	    0.022	  0.000%	 86.521%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/strided_slice]:1025
	                    PACK	        25818.829	    0.028	    0.045	  0.000%	 86.522%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape/shape]:1026
	                 RESHAPE	        25818.881	    0.015	    0.015	  0.000%	 86.522%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape]:1027
	                 CONV_2D	        25818.903	    0.087	    0.077	  0.000%	 86.522%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_reduce/Conv2D]:1028
	                LOGISTIC	        25818.987	    0.011	    0.011	  0.000%	 86.522%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/Sigmoid]:1029
	                     MUL	        25819.004	    0.022	    0.022	  0.000%	 86.522%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/mul_1]:1030
	                 CONV_2D	        25819.032	    0.057	    0.072	  0.000%	 86.522%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_expand/Conv2D]:1031
	                LOGISTIC	        25819.111	    0.029	    0.029	  0.000%	 86.522%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/Sigmoid]:1032
	                     MUL	        25819.147	   36.718	   36.753	  0.123%	 86.646%	     0.000	        1	[efficientnetv2-l/block6u_se_excite/mul]:1033
	                 CONV_2D	        25855.911	   13.032	   13.357	  0.045%	 86.690%	     0.000	        1	[efficientnetv2-l/block6u_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_project_conv/Conv2D]:1034
	                     ADD	        25869.279	    8.337	    8.341	  0.028%	 86.718%	     0.000	        1	[efficientnetv2-l/block6u_add/add]:1035
	                 CONV_2D	        25877.630	   13.974	   14.445	  0.048%	 86.767%	     0.000	        1	[efficientnetv2-l/block6v_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_expand_conv/Conv2D]:1036
	                LOGISTIC	        25892.086	    5.026	    5.110	  0.017%	 86.784%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/Sigmoid]:1037
	                     MUL	        25897.206	   36.619	   36.691	  0.123%	 86.907%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/mul_1]:1038
	       DEPTHWISE_CONV_2D	        25933.908	    3.018	    3.186	  0.011%	 86.918%	     0.000	        1	[efficientnetv2-l/block6v_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1039
	                LOGISTIC	        25937.108	    5.055	    5.098	  0.017%	 86.935%	     0.000	        1	[efficientnetv2-l/block6v_activation/Sigmoid]:1040
	                     MUL	        25942.216	   36.729	   36.673	  0.123%	 87.058%	     0.000	        1	[efficientnetv2-l/block6v_activation/mul_1]:1041
	                    MEAN	        25978.900	   90.096	   89.838	  0.301%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_squeeze/Mean]:1042
	                   SHAPE	        26068.749	    0.010	    0.009	  0.000%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Shape]:1043
	           STRIDED_SLICE	        26068.765	    0.024	    0.022	  0.000%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/strided_slice]:1044
	                    PACK	        26068.793	    0.031	    0.029	  0.000%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape/shape]:1045
	                 RESHAPE	        26068.828	    0.017	    0.021	  0.000%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape]:1046
	                 CONV_2D	        26068.856	    0.078	    0.082	  0.000%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_reduce/Conv2D]:1047
	                LOGISTIC	        26068.944	    0.011	    0.012	  0.000%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/Sigmoid]:1048
	                     MUL	        26068.964	    0.026	    0.025	  0.000%	 87.359%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/mul_1]:1049
	                 CONV_2D	        26068.996	    0.091	    0.071	  0.000%	 87.360%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_expand/Conv2D]:1050
	                LOGISTIC	        26069.073	    0.031	    0.034	  0.000%	 87.360%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/Sigmoid]:1051
	                     MUL	        26069.113	   36.901	   36.862	  0.124%	 87.483%	     0.000	        1	[efficientnetv2-l/block6v_se_excite/mul]:1052
	                 CONV_2D	        26105.987	   13.444	   13.299	  0.045%	 87.528%	     0.000	        1	[efficientnetv2-l/block6v_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_project_conv/Conv2D]:1053
	                     ADD	        26119.297	    8.372	    8.339	  0.028%	 87.556%	     0.000	        1	[efficientnetv2-l/block6v_add/add]:1054
	                 CONV_2D	        26127.649	   14.581	   14.614	  0.049%	 87.605%	     0.000	        1	[efficientnetv2-l/block6w_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_expand_conv/Conv2D]:1055
	                LOGISTIC	        26142.277	    5.146	    5.091	  0.017%	 87.622%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/Sigmoid]:1056
	                     MUL	        26147.378	   36.769	   36.771	  0.123%	 87.745%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/mul_1]:1057
	       DEPTHWISE_CONV_2D	        26184.160	    3.054	    3.192	  0.011%	 87.756%	     0.000	        1	[efficientnetv2-l/block6w_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1058
	                LOGISTIC	        26187.362	    5.139	    5.090	  0.017%	 87.773%	     0.000	        1	[efficientnetv2-l/block6w_activation/Sigmoid]:1059
	                     MUL	        26192.463	   37.197	   36.707	  0.123%	 87.896%	     0.000	        1	[efficientnetv2-l/block6w_activation/mul_1]:1060
	                    MEAN	        26229.180	   89.113	   88.640	  0.297%	 88.193%	     0.000	        1	[efficientnetv2-l/block6w_se_squeeze/Mean]:1061
	                   SHAPE	        26317.832	    0.009	    0.009	  0.000%	 88.193%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Shape]:1062
	           STRIDED_SLICE	        26317.847	    0.022	    0.026	  0.000%	 88.193%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/strided_slice]:1063
	                    PACK	        26317.880	    0.028	    0.032	  0.000%	 88.193%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape/shape]:1064
	                 RESHAPE	        26317.918	    0.014	    0.015	  0.000%	 88.193%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape]:1065
	                 CONV_2D	        26317.939	    0.088	    0.076	  0.000%	 88.194%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_reduce/Conv2D]:1066
	                LOGISTIC	        26318.022	    0.011	    0.011	  0.000%	 88.194%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/Sigmoid]:1067
	                     MUL	        26318.039	    0.021	    0.021	  0.000%	 88.194%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/mul_1]:1068
	                 CONV_2D	        26318.067	    0.056	    0.061	  0.000%	 88.194%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_expand/Conv2D]:1069
	                LOGISTIC	        26318.133	    0.030	    0.032	  0.000%	 88.194%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/Sigmoid]:1070
	                     MUL	        26318.172	   36.696	   36.580	  0.123%	 88.317%	     0.000	        1	[efficientnetv2-l/block6w_se_excite/mul]:1071
	                 CONV_2D	        26354.762	   13.157	   13.222	  0.044%	 88.361%	     0.000	        1	[efficientnetv2-l/block6w_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_project_conv/Conv2D]:1072
	                     ADD	        26367.995	    8.345	    8.341	  0.028%	 88.389%	     0.000	        1	[efficientnetv2-l/block6w_add/add]:1073
	                 CONV_2D	        26376.347	   14.426	   14.361	  0.048%	 88.437%	     0.000	        1	[efficientnetv2-l/block6x_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_expand_conv/Conv2D]:1074
	                LOGISTIC	        26390.719	    5.103	    5.090	  0.017%	 88.454%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/Sigmoid]:1075
	                     MUL	        26395.820	   36.601	   36.543	  0.123%	 88.577%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/mul_1]:1076
	       DEPTHWISE_CONV_2D	        26432.377	    3.249	    3.091	  0.010%	 88.587%	     0.000	        1	[efficientnetv2-l/block6x_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1077
	                LOGISTIC	        26435.480	    5.068	    5.089	  0.017%	 88.604%	     0.000	        1	[efficientnetv2-l/block6x_activation/Sigmoid]:1078
	                     MUL	        26440.581	   36.633	   36.580	  0.123%	 88.727%	     0.000	        1	[efficientnetv2-l/block6x_activation/mul_1]:1079
	                    MEAN	        26477.172	   88.760	   88.397	  0.296%	 89.023%	     0.000	        1	[efficientnetv2-l/block6x_se_squeeze/Mean]:1080
	                   SHAPE	        26565.580	    0.008	    0.008	  0.000%	 89.023%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Shape]:1081
	           STRIDED_SLICE	        26565.595	    0.022	    0.023	  0.000%	 89.023%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/strided_slice]:1082
	                    PACK	        26565.624	    0.027	    0.032	  0.000%	 89.023%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape/shape]:1083
	                 RESHAPE	        26565.663	    0.080	    0.025	  0.000%	 89.023%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape]:1084
	                 CONV_2D	        26565.695	    0.065	    0.066	  0.000%	 89.024%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_reduce/Conv2D]:1085
	                LOGISTIC	        26565.767	    0.011	    0.011	  0.000%	 89.024%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/Sigmoid]:1086
	                     MUL	        26565.784	    0.020	    0.024	  0.000%	 89.024%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/mul_1]:1087
	                 CONV_2D	        26565.814	    0.054	    0.054	  0.000%	 89.024%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_expand/Conv2D]:1088
	                LOGISTIC	        26565.874	    0.031	    0.030	  0.000%	 89.024%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/Sigmoid]:1089
	                     MUL	        26565.914	   37.028	   36.459	  0.122%	 89.146%	     0.000	        1	[efficientnetv2-l/block6x_se_excite/mul]:1090
	                 CONV_2D	        26602.385	   13.694	   13.183	  0.044%	 89.190%	     0.000	        1	[efficientnetv2-l/block6x_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_project_conv/Conv2D]:1091
	                     ADD	        26615.578	    8.778	    8.362	  0.028%	 89.219%	     0.000	        1	[efficientnetv2-l/block6x_add/add]:1092
	                 CONV_2D	        26623.949	   14.853	   14.258	  0.048%	 89.266%	     0.000	        1	[efficientnetv2-l/block6y_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_expand_conv/Conv2D]:1093
	                LOGISTIC	        26638.218	    5.108	    5.099	  0.017%	 89.283%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/Sigmoid]:1094
	                     MUL	        26643.328	   37.700	   36.623	  0.123%	 89.406%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/mul_1]:1095
	       DEPTHWISE_CONV_2D	        26679.962	    3.121	    2.923	  0.010%	 89.416%	     0.000	        1	[efficientnetv2-l/block6y_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1096
	                LOGISTIC	        26682.898	    5.080	    5.071	  0.017%	 89.433%	     0.000	        1	[efficientnetv2-l/block6y_activation/Sigmoid]:1097
	                     MUL	        26687.980	   36.694	   36.424	  0.122%	 89.555%	     0.000	        1	[efficientnetv2-l/block6y_activation/mul_1]:1098
	                    MEAN	        26724.415	   88.201	   87.980	  0.295%	 89.850%	     0.000	        1	[efficientnetv2-l/block6y_se_squeeze/Mean]:1099
	                   SHAPE	        26812.406	    0.009	    0.009	  0.000%	 89.850%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Shape]:1100
	           STRIDED_SLICE	        26812.421	    0.032	    0.023	  0.000%	 89.850%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/strided_slice]:1101
	                    PACK	        26812.450	    0.028	    0.033	  0.000%	 89.850%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape/shape]:1102
	                 RESHAPE	        26812.490	    0.014	    0.014	  0.000%	 89.850%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape]:1103
	                 CONV_2D	        26812.510	    0.065	    0.077	  0.000%	 89.851%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_reduce/Conv2D]:1104
	                LOGISTIC	        26812.594	    0.010	    0.012	  0.000%	 89.851%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/Sigmoid]:1105
	                     MUL	        26812.612	    0.021	    0.021	  0.000%	 89.851%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/mul_1]:1106
	                 CONV_2D	        26812.639	    0.053	    0.053	  0.000%	 89.851%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_expand/Conv2D]:1107
	                LOGISTIC	        26812.699	    0.030	    0.030	  0.000%	 89.851%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/Sigmoid]:1108
	                     MUL	        26812.735	   36.213	   36.235	  0.121%	 89.972%	     0.000	        1	[efficientnetv2-l/block6y_se_excite/mul]:1109
	                 CONV_2D	        26848.981	   13.114	   12.981	  0.044%	 90.016%	     0.000	        1	[efficientnetv2-l/block6y_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_project_conv/Conv2D]:1110
	                     ADD	        26861.971	    8.257	    8.253	  0.028%	 90.044%	     0.000	        1	[efficientnetv2-l/block6y_add/add]:1111
	                 CONV_2D	        26870.231	   13.922	   13.926	  0.047%	 90.090%	     0.000	        1	[efficientnetv2-l/block7a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_expand_conv/Conv2D]:1112
	                LOGISTIC	        26884.166	    5.153	    5.066	  0.017%	 90.107%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/Sigmoid]:1113
	                     MUL	        26889.245	   36.384	   36.349	  0.122%	 90.229%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/mul_1]:1114
	       DEPTHWISE_CONV_2D	        26925.606	    2.773	    2.776	  0.009%	 90.238%	     0.000	        1	[efficientnetv2-l/block7a_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_dwconv2/depthwise]:1115
	                LOGISTIC	        26928.392	    5.051	    5.085	  0.017%	 90.255%	     0.000	        1	[efficientnetv2-l/block7a_activation/Sigmoid]:1116
	                     MUL	        26933.487	   36.306	   36.321	  0.122%	 90.377%	     0.000	        1	[efficientnetv2-l/block7a_activation/mul_1]:1117
	                    MEAN	        26969.820	   88.040	   88.073	  0.295%	 90.672%	     0.000	        1	[efficientnetv2-l/block7a_se_squeeze/Mean]:1118
	                   SHAPE	        27057.905	    0.008	    0.008	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Shape]:1119
	           STRIDED_SLICE	        27057.920	    0.022	    0.025	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/strided_slice]:1120
	                    PACK	        27057.951	    0.040	    0.030	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape/shape]:1121
	                 RESHAPE	        27057.988	    0.013	    0.014	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape]:1122
	                 CONV_2D	        27058.008	    0.065	    0.071	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_reduce/Conv2D]:1123
	                LOGISTIC	        27058.086	    0.011	    0.010	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/Sigmoid]:1124
	                     MUL	        27058.102	    0.020	    0.020	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/mul_1]:1125
	                 CONV_2D	        27058.129	    0.055	    0.061	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_expand/Conv2D]:1126
	                LOGISTIC	        27058.196	    0.029	    0.032	  0.000%	 90.673%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/Sigmoid]:1127
	                     MUL	        27058.234	   36.205	   36.264	  0.122%	 90.795%	     0.000	        1	[efficientnetv2-l/block7a_se_excite/mul]:1128
	                 CONV_2D	        27094.508	   21.360	   21.389	  0.072%	 90.867%	     0.000	        1	[efficientnetv2-l/block7a_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_project_conv/Conv2D]:1129
	                 CONV_2D	        27115.907	   37.707	   37.598	  0.126%	 90.993%	     0.000	        1	[efficientnetv2-l/block7b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_expand_conv/Conv2D]:1130
	                LOGISTIC	        27153.517	    8.345	    8.355	  0.028%	 91.021%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/Sigmoid]:1131
	                     MUL	        27161.883	   60.444	   60.662	  0.203%	 91.224%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/mul_1]:1132
	       DEPTHWISE_CONV_2D	        27222.556	    5.104	    5.074	  0.017%	 91.241%	     0.000	        1	[efficientnetv2-l/block7b_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1133
	                LOGISTIC	        27227.644	    8.317	    8.381	  0.028%	 91.269%	     0.000	        1	[efficientnetv2-l/block7b_activation/Sigmoid]:1134
	                     MUL	        27236.037	   60.490	   60.690	  0.203%	 91.473%	     0.000	        1	[efficientnetv2-l/block7b_activation/mul_1]:1135
	                    MEAN	        27296.738	  146.647	  146.714	  0.492%	 91.964%	     0.000	        1	[efficientnetv2-l/block7b_se_squeeze/Mean]:1136
	                   SHAPE	        27443.463	    0.008	    0.009	  0.000%	 91.965%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Shape]:1137
	           STRIDED_SLICE	        27443.478	    0.020	    0.021	  0.000%	 91.965%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/strided_slice]:1138
	                    PACK	        27443.505	    0.028	    0.028	  0.000%	 91.965%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape/shape]:1139
	                 RESHAPE	        27443.539	    0.015	    0.015	  0.000%	 91.965%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape]:1140
	                 CONV_2D	        27443.561	    0.121	    0.119	  0.000%	 91.965%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7b_se_reduce/Conv2D]:1141
	                LOGISTIC	        27443.687	    0.010	    0.014	  0.000%	 91.965%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/Sigmoid]:1142
	                     MUL	        27443.707	    0.026	    0.032	  0.000%	 91.965%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/mul_1]:1143
	                 CONV_2D	        27443.745	    0.100	    0.110	  0.000%	 91.966%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_se_expand/Conv2D]:1144
	                LOGISTIC	        27443.862	    0.055	    0.046	  0.000%	 91.966%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/Sigmoid]:1145
	                     MUL	        27443.914	   60.572	   60.435	  0.203%	 92.168%	     0.000	        1	[efficientnetv2-l/block7b_se_excite/mul]:1146
	                 CONV_2D	        27504.360	   35.644	   35.634	  0.119%	 92.288%	     0.000	        1	[efficientnetv2-l/block7b_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_project_conv/Conv2D]:1147
	                     ADD	        27540.006	   13.724	   13.757	  0.046%	 92.334%	     0.000	        1	[efficientnetv2-l/block7b_add/add]:1148
	                 CONV_2D	        27553.771	   37.556	   37.635	  0.126%	 92.460%	     0.000	        1	[efficientnetv2-l/block7c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_expand_conv/Conv2D]:1149
	                LOGISTIC	        27591.418	    8.310	    8.338	  0.028%	 92.488%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/Sigmoid]:1150
	                     MUL	        27599.768	   60.548	   60.558	  0.203%	 92.691%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/mul_1]:1151
	       DEPTHWISE_CONV_2D	        27660.338	    5.088	    5.096	  0.017%	 92.708%	     0.000	        1	[efficientnetv2-l/block7c_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1152
	                LOGISTIC	        27665.446	    8.300	    8.344	  0.028%	 92.736%	     0.000	        1	[efficientnetv2-l/block7c_activation/Sigmoid]:1153
	                     MUL	        27673.801	   60.820	   60.657	  0.203%	 92.940%	     0.000	        1	[efficientnetv2-l/block7c_activation/mul_1]:1154
	                    MEAN	        27734.470	  146.954	  147.036	  0.493%	 93.432%	     0.000	        1	[efficientnetv2-l/block7c_se_squeeze/Mean]:1155
	                   SHAPE	        27881.519	    0.009	    0.009	  0.000%	 93.432%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Shape]:1156
	           STRIDED_SLICE	        27881.534	    0.021	    0.021	  0.000%	 93.433%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/strided_slice]:1157
	                    PACK	        27881.561	    0.029	    0.028	  0.000%	 93.433%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape/shape]:1158
	                 RESHAPE	        27881.595	    0.015	    0.015	  0.000%	 93.433%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape]:1159
	                 CONV_2D	        27881.616	    0.121	    0.128	  0.000%	 93.433%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7c_se_reduce/Conv2D]:1160
	                LOGISTIC	        27881.751	    0.011	    0.011	  0.000%	 93.433%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/Sigmoid]:1161
	                     MUL	        27881.768	    0.026	    0.025	  0.000%	 93.433%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/mul_1]:1162
	                 CONV_2D	        27881.799	    0.102	    0.106	  0.000%	 93.434%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_se_expand/Conv2D]:1163
	                LOGISTIC	        27881.912	    0.058	    0.046	  0.000%	 93.434%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/Sigmoid]:1164
	                     MUL	        27881.964	   60.781	   60.725	  0.204%	 93.637%	     0.000	        1	[efficientnetv2-l/block7c_se_excite/mul]:1165
	                 CONV_2D	        27942.700	   35.683	   35.782	  0.120%	 93.757%	     0.000	        1	[efficientnetv2-l/block7c_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_project_conv/Conv2D]:1166
	                     ADD	        27978.496	   13.733	   13.786	  0.046%	 93.803%	     0.000	        1	[efficientnetv2-l/block7c_add/add]:1167
	                 CONV_2D	        27992.290	   37.610	   37.894	  0.127%	 93.931%	     0.000	        1	[efficientnetv2-l/block7d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_expand_conv/Conv2D]:1168
	                LOGISTIC	        28030.198	    8.384	    8.399	  0.028%	 93.959%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/Sigmoid]:1169
	                     MUL	        28038.608	   60.542	   60.845	  0.204%	 94.163%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/mul_1]:1170
	       DEPTHWISE_CONV_2D	        28099.465	    5.010	    5.317	  0.018%	 94.180%	     0.000	        1	[efficientnetv2-l/block7d_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1171
	                LOGISTIC	        28104.793	    8.342	    8.372	  0.028%	 94.209%	     0.000	        1	[efficientnetv2-l/block7d_activation/Sigmoid]:1172
	                     MUL	        28113.176	   60.686	   62.014	  0.208%	 94.416%	     0.000	        1	[efficientnetv2-l/block7d_activation/mul_1]:1173
	                    MEAN	        28175.202	  147.406	  148.069	  0.496%	 94.913%	     0.000	        1	[efficientnetv2-l/block7d_se_squeeze/Mean]:1174
	                   SHAPE	        28323.286	    0.009	    0.009	  0.000%	 94.913%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Shape]:1175
	           STRIDED_SLICE	        28323.307	    0.022	    0.024	  0.000%	 94.913%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/strided_slice]:1176
	                    PACK	        28323.338	    0.027	    0.030	  0.000%	 94.913%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape/shape]:1177
	                 RESHAPE	        28323.374	    0.015	    0.015	  0.000%	 94.913%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape]:1178
	                 CONV_2D	        28323.396	    0.124	    0.131	  0.000%	 94.914%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7d_se_reduce/Conv2D]:1179
	                LOGISTIC	        28323.534	    0.011	    0.012	  0.000%	 94.914%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/Sigmoid]:1180
	                     MUL	        28323.552	    0.026	    0.027	  0.000%	 94.914%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/mul_1]:1181
	                 CONV_2D	        28323.585	    0.099	    0.113	  0.000%	 94.914%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_se_expand/Conv2D]:1182
	                LOGISTIC	        28323.704	    0.047	    0.052	  0.000%	 94.914%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/Sigmoid]:1183
	                     MUL	        28323.763	   60.600	   61.138	  0.205%	 95.119%	     0.000	        1	[efficientnetv2-l/block7d_se_excite/mul]:1184
	                 CONV_2D	        28384.912	   36.668	   36.619	  0.123%	 95.242%	     0.000	        1	[efficientnetv2-l/block7d_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_project_conv/Conv2D]:1185
	                     ADD	        28421.543	   13.854	   13.892	  0.047%	 95.288%	     0.000	        1	[efficientnetv2-l/block7d_add/add]:1186
	                 CONV_2D	        28435.447	   38.416	   38.388	  0.129%	 95.417%	     0.000	        1	[efficientnetv2-l/block7e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_expand_conv/Conv2D]:1187
	                LOGISTIC	        28473.846	    8.471	    8.464	  0.028%	 95.446%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/Sigmoid]:1188
	                     MUL	        28482.321	   61.311	   61.589	  0.206%	 95.652%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/mul_1]:1189
	       DEPTHWISE_CONV_2D	        28543.922	    5.985	    5.637	  0.019%	 95.671%	     0.000	        1	[efficientnetv2-l/block7e_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1190
	                LOGISTIC	        28549.570	    8.648	    8.494	  0.028%	 95.699%	     0.000	        1	[efficientnetv2-l/block7e_activation/Sigmoid]:1191
	                     MUL	        28558.080	   61.100	   61.596	  0.206%	 95.906%	     0.000	        1	[efficientnetv2-l/block7e_activation/mul_1]:1192
	                    MEAN	        28619.687	  149.331	  148.385	  0.497%	 96.403%	     0.000	        1	[efficientnetv2-l/block7e_se_squeeze/Mean]:1193
	                   SHAPE	        28768.084	    0.010	    0.009	  0.000%	 96.403%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Shape]:1194
	           STRIDED_SLICE	        28768.099	    0.023	    0.025	  0.000%	 96.403%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/strided_slice]:1195
	                    PACK	        28768.130	    0.029	    0.033	  0.000%	 96.404%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape/shape]:1196
	                 RESHAPE	        28768.169	    0.016	    0.015	  0.000%	 96.404%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape]:1197
	                 CONV_2D	        28768.197	    0.140	    0.129	  0.000%	 96.404%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7e_se_reduce/Conv2D]:1198
	                LOGISTIC	        28768.333	    0.013	    0.012	  0.000%	 96.404%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/Sigmoid]:1199
	                     MUL	        28768.351	    0.026	    0.026	  0.000%	 96.404%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/mul_1]:1200
	                 CONV_2D	        28768.384	    0.109	    0.125	  0.000%	 96.405%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_se_expand/Conv2D]:1201
	                LOGISTIC	        28768.516	    0.044	    0.048	  0.000%	 96.405%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/Sigmoid]:1202
	                     MUL	        28768.570	   61.053	   60.964	  0.204%	 96.609%	     0.000	        1	[efficientnetv2-l/block7e_se_excite/mul]:1203
	                 CONV_2D	        28829.545	   36.497	   36.323	  0.122%	 96.731%	     0.000	        1	[efficientnetv2-l/block7e_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_project_conv/Conv2D]:1204
	                     ADD	        28865.881	   13.848	   13.830	  0.046%	 96.777%	     0.000	        1	[efficientnetv2-l/block7e_add/add]:1205
	                 CONV_2D	        28879.722	   38.149	   38.010	  0.127%	 96.905%	     0.000	        1	[efficientnetv2-l/block7f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_expand_conv/Conv2D]:1206
	                LOGISTIC	        28917.743	    8.591	    8.403	  0.028%	 96.933%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/Sigmoid]:1207
	                     MUL	        28926.156	   61.072	   60.933	  0.204%	 97.137%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/mul_1]:1208
	       DEPTHWISE_CONV_2D	        28987.100	    5.531	    5.347	  0.018%	 97.155%	     0.000	        1	[efficientnetv2-l/block7f_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1209
	                LOGISTIC	        28992.459	    8.355	    8.334	  0.028%	 97.183%	     0.000	        1	[efficientnetv2-l/block7f_activation/Sigmoid]:1210
	                     MUL	        29000.803	   61.001	   60.747	  0.204%	 97.387%	     0.000	        1	[efficientnetv2-l/block7f_activation/mul_1]:1211
	                    MEAN	        29061.561	  147.452	  146.931	  0.493%	 97.879%	     0.000	        1	[efficientnetv2-l/block7f_se_squeeze/Mean]:1212
	                   SHAPE	        29208.503	    0.008	    0.009	  0.000%	 97.879%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Shape]:1213
	           STRIDED_SLICE	        29208.518	    0.022	    0.025	  0.000%	 97.879%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/strided_slice]:1214
	                    PACK	        29208.550	    0.029	    0.031	  0.000%	 97.879%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape/shape]:1215
	                 RESHAPE	        29208.588	    0.016	    0.018	  0.000%	 97.879%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape]:1216
	                 CONV_2D	        29208.612	    0.112	    0.112	  0.000%	 97.880%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7f_se_reduce/Conv2D]:1217
	                LOGISTIC	        29208.730	    0.011	    0.011	  0.000%	 97.880%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/Sigmoid]:1218
	                     MUL	        29208.747	    0.025	    0.027	  0.000%	 97.880%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/mul_1]:1219
	                 CONV_2D	        29208.781	    0.136	    0.115	  0.000%	 97.880%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_se_expand/Conv2D]:1220
	                LOGISTIC	        29208.903	    0.047	    0.047	  0.000%	 97.880%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/Sigmoid]:1221
	                     MUL	        29208.956	   60.641	   60.508	  0.203%	 98.083%	     0.000	        1	[efficientnetv2-l/block7f_se_excite/mul]:1222
	                 CONV_2D	        29269.476	   35.833	   35.805	  0.120%	 98.203%	     0.000	        1	[efficientnetv2-l/block7f_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_project_conv/Conv2D]:1223
	                     ADD	        29305.292	   13.714	   13.742	  0.046%	 98.249%	     0.000	        1	[efficientnetv2-l/block7f_add/add]:1224
	                 CONV_2D	        29319.043	   37.320	   37.458	  0.126%	 98.375%	     0.000	        1	[efficientnetv2-l/block7g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_expand_conv/Conv2D]:1225
	                LOGISTIC	        29356.513	    8.367	    8.368	  0.028%	 98.403%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/Sigmoid]:1226
	                     MUL	        29364.892	   60.398	   60.548	  0.203%	 98.606%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/mul_1]:1227
	       DEPTHWISE_CONV_2D	        29425.451	    5.203	    5.182	  0.017%	 98.623%	     0.000	        1	[efficientnetv2-l/block7g_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_dwconv2/depthwise]:1228
	                LOGISTIC	        29430.645	    8.396	    8.363	  0.028%	 98.651%	     0.000	        1	[efficientnetv2-l/block7g_activation/Sigmoid]:1229
	                     MUL	        29439.019	   60.655	   60.546	  0.203%	 98.854%	     0.000	        1	[efficientnetv2-l/block7g_activation/mul_1]:1230
	                    MEAN	        29499.577	  146.809	  146.899	  0.492%	 99.347%	     0.000	        1	[efficientnetv2-l/block7g_se_squeeze/Mean]:1231
	                   SHAPE	        29646.486	    0.008	    0.009	  0.000%	 99.347%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Shape]:1232
	           STRIDED_SLICE	        29646.501	    0.021	    0.021	  0.000%	 99.347%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/strided_slice]:1233
	                    PACK	        29646.529	    0.027	    0.030	  0.000%	 99.347%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape/shape]:1234
	                 RESHAPE	        29646.566	    0.015	    0.017	  0.000%	 99.347%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape]:1235
	                 CONV_2D	        29646.589	    0.106	    0.111	  0.000%	 99.347%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7g_se_reduce/Conv2D]:1236
	                LOGISTIC	        29646.707	    0.011	    0.011	  0.000%	 99.348%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/Sigmoid]:1237
	                     MUL	        29646.724	    0.025	    0.025	  0.000%	 99.348%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/mul_1]:1238
	                 CONV_2D	        29646.755	    0.122	    0.112	  0.000%	 99.348%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_se_expand/Conv2D]:1239
	                LOGISTIC	        29646.873	    0.044	    0.046	  0.000%	 99.348%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/Sigmoid]:1240
	                     MUL	        29646.926	   60.463	   60.534	  0.203%	 99.551%	     0.000	        1	[efficientnetv2-l/block7g_se_excite/mul]:1241
	                 CONV_2D	        29707.472	   35.699	   35.608	  0.119%	 99.670%	     0.000	        1	[efficientnetv2-l/block7g_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_project_conv/Conv2D]:1242
	                     ADD	        29743.091	   13.747	   13.755	  0.046%	 99.717%	     0.000	        1	[efficientnetv2-l/block7g_add/add]:1243
	                 CONV_2D	        29756.854	   12.378	   12.398	  0.042%	 99.758%	     0.000	        1	[efficientnetv2-l/top_bn/FusedBatchNormV3;efficientnetv2-l/top_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/top_conv/Conv2D]:1244
	                LOGISTIC	        29769.261	    2.804	    2.803	  0.009%	 99.768%	     0.000	        1	[efficientnetv2-l/top_activation/Sigmoid]:1245
	                     MUL	        29772.071	   20.072	   20.153	  0.068%	 99.835%	     0.000	        1	[efficientnetv2-l/top_activation/mul_1]:1246
	                    MEAN	        29792.234	   48.727	   48.742	  0.163%	 99.998%	     0.000	        1	[efficientnetv2-l/avg_pool/Mean]:1247
	         FULLY_CONNECTED	        29840.986	    0.413	    0.373	  0.001%	100.000%	     0.000	        1	[efficientnetv2-l/predictions/MatMul;efficientnetv2-l/predictions/BiasAdd]:1248
	                 SOFTMAX	        29841.370	    0.082	    0.085	  0.000%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:1249

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	         3409.118	  259.164	  261.786	  0.878%	  0.878%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                     MUL	         3970.218	  260.125	  259.521	  0.870%	  1.748%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                     MUL	         2300.256	  258.068	  258.205	  0.866%	  2.613%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                     MUL	         2853.780	  258.109	  258.168	  0.865%	  3.479%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                     MUL	         4526.776	  258.219	  258.008	  0.865%	  4.344%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                     MUL	         5080.572	  258.022	  257.969	  0.865%	  5.208%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                    MEAN	        18621.720	  206.721	  207.221	  0.695%	  5.903%	     0.000	        1	[efficientnetv2-l/block5p_se_squeeze/Mean]:568
	                    MEAN	        10900.363	  205.364	  207.180	  0.695%	  6.598%	     0.000	        1	[efficientnetv2-l/block5b_se_squeeze/Mean]:302
	                    MEAN	        15862.240	  205.806	  206.824	  0.693%	  7.291%	     0.000	        1	[efficientnetv2-l/block5k_se_squeeze/Mean]:473
	                    MEAN	        13660.054	  207.148	  206.630	  0.693%	  7.984%	     0.000	        1	[efficientnetv2-l/block5g_se_squeeze/Mean]:397

Number of nodes executed: 1250
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                     MUL	      265	 13272.227	    44.494%	    44.494%	     0.000	      265
	                    MEAN	       62	  8179.164	    27.420%	    71.914%	     0.000	       62
	                 CONV_2D	      278	  4260.956	    14.284%	    86.198%	     0.000	      278
	                     ADD	       74	  2244.504	     7.525%	    93.723%	     0.000	       74
	                LOGISTIC	      264	  1375.155	     4.610%	    98.333%	     0.000	      264
	       DEPTHWISE_CONV_2D	       61	   492.055	     1.650%	    99.983%	     0.000	       61
	                    PACK	       61	     1.889	     0.006%	    99.989%	     0.000	       61
	           STRIDED_SLICE	       61	     1.407	     0.005%	    99.994%	     0.000	       61
	                 RESHAPE	       61	     0.913	     0.003%	    99.997%	     0.000	       61
	                   SHAPE	       61	     0.522	     0.002%	    99.998%	     0.000	       61
	         FULLY_CONNECTED	        1	     0.373	     0.001%	   100.000%	     0.000	        1
	                 SOFTMAX	        1	     0.084	     0.000%	   100.000%	     0.000	        1

Timings (microseconds): count=6 first=29810958 curr=29868638 min=29809267 max=29868638 avg=2.98298e+07 std=20844
Memory (bytes): count=0
1250 nodes observed



[ perf record: Woken up 1008 times to write data ]
[ perf record: Captured and wrote 252.197 MB /tmp/data.record (1434210 samples) ]

361.080

