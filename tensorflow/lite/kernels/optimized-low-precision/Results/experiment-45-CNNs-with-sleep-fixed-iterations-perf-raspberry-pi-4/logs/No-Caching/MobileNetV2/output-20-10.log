STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/MobileNetV2.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/MobileNetV2.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (50176, 3, ), and Output shape (12544, 32, ), and the ID is 0
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (16, 32, ), Input shape (12544, 32, ), and Output shape (12544, 16, ), and the ID is 1
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(96, 16, ), Input shape (12544, 16, ), and Output shape (12544, 96, ), and the ID is 2
NOT Applying Conv Low-Precision for Kernel shape (24, 96, ), Input shape (3136, 96, ), and Output shape (3136, 24, ), and the ID is 3
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (144, 24, ), Input shape (3136, 24, ), and Output shape (3136, 144, ), and the ID is 4
NOT Applying Conv Low-Precision for Kernel shape (24, 144, ), Input shape (3136, 144, ), and Output shape (3136, 24, ), and the ID is 5
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (144, 24, ), Input shape (3136, 24, ), and Output shape (3136, 144, ), and the ID is 6
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (32, 144, ), Input shape (784, 144, ), and Output shape (784, 32, ), and the ID is 7
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape 	Changing Input Shape
(784, 192, ), and the ID is 8
NOT Applying Conv Low-Precision for Kernel shape (32, 192, ), Input shape (784, 192, ), and Output shape 	Changing Input Shape
	Changing Input Shape
(784, 32, ), and the ID is 9
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, ), and the ID is 10
NOT Applying Conv Low-Precision for Kernel shape (32, 192, ), Input shape (784, 192, ), and Output shape (784, 32, ), and the ID is 11
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, ), and the ID is 12
NOT Applying Conv Low-Precision for Kernel shape (64, 192, ), Input shape (196, 192, ), and Output shape (196, 64, ), and the ID is 13
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 14
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape 	Changing Input Shape
(196, 384, ), and Output shape (196, 64, ), and the ID is 15
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape 	Changing Input Shape
(196, 384, ), and the ID is 16
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape (196, 384, ), and Output shape (196, 64, ), and the ID is 17
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 18
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape (196, 384, ), and Output shape (196, 64, ), and the ID is 19
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 20
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (196, 384, ), and Output shape (196, 96, ), and the ID is 21
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, ), and the ID is 22
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (196, 576, ), and Output shape (196, 96, ), and the ID is 23	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape 	Changing Input Shape
(196, 96, ), and Output shape (196, 576, ), and the ID is 24
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (196, 576, ), and Output shape (196, 96, ), and the ID is 25
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, ), and the ID is 26	Changing Input Shape

	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (160, 576, ), Input shape (49, 576, ), and Output shape (49, 160, ), and the ID is 27
NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape (49, 160, ), and Output shape (49, 960, ), and the ID is 28
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (160, 960, ), Input shape (49, 960, ), and Output shape (49, 160, ), and the ID is 29	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape 	Changing Input Shape
(49, 160, ), and Output shape (49, 960, ), and the ID is 30
NOT Applying Conv Low-Precision for Kernel shape (160, 960, ), Input shape (49, 960, ), and Output shape (49, 160, ), and the ID is 	Changing Input Shape
31
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape (49, 160, ), and Output shape (49, 960, ), and the ID is 32
NOT Applying Conv Low-Precision for Kernel shape (320, 960, ), Input shape (49, 960, ), and Output shape (49, 320, ), and the ID is 	Changing Input Shape
33
NOT Applying Conv Low-Precision for Kernel shape (1280, 320, ), Input shape (49, 320, ), and Output shape (49, 1280, ), and the ID is 34
	Changing Input Shape
NOT Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 5 Number of Temp Tensors
The input model file size (MB): 3.94093
Initialized session in 19.141ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=10 first=175407 curr=166610 min=158679 max=175407 avg=163429 std=5438

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=165389 curr=161235 min=160031 max=171633 avg=162717 std=3444

Inference timings in us: Init: 19141, First inference: 175407, Warmup (avg): 163429, Inference (avg): 162717
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=5.05469 overall=12.2227
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	    6.114	    6.114	100.000%	100.000%	     0.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	    6.114	    6.114	100.000%	100.000%	     0.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	     6.114	   100.000%	   100.000%	     0.000	        1

Timings (microseconds): count=1 curr=6114
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.020	    7.890	    7.933	  4.896%	  4.896%	     0.000	        1	[mobilenetv2_1.00_224/Conv1_relu/Relu6;mobilenetv2_1.00_224/bn_Conv1/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv1/Conv2D]:0
	       DEPTHWISE_CONV_2D	            7.965	    1.455	    1.507	  0.930%	  5.826%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_depthwise_relu/Relu6;mobilenetv2_1.00_224/expanded_conv_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_depthwise/depthwise;mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3]:1
	                 CONV_2D	            9.483	    4.572	    4.587	  2.831%	  8.657%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_project/Conv2D]:2
	                 CONV_2D	           14.082	   10.101	    9.961	  6.147%	 14.804%	     0.000	        1	[mobilenetv2_1.00_224/block_1_expand_relu/Relu6;mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_expand/Conv2D]:3
	                     PAD	           24.056	   26.832	   26.840	 16.564%	 31.368%	     0.000	        1	[mobilenetv2_1.00_224/block_1_pad/Pad]:4
	       DEPTHWISE_CONV_2D	           50.908	    2.430	    2.425	  1.496%	 32.864%	     0.000	        1	[mobilenetv2_1.00_224/block_1_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_1_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_depthwise/depthwise;mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3]:5
	                 CONV_2D	           53.343	    2.310	    2.187	  1.350%	 34.214%	     0.000	        1	[mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_project/Conv2D]:6
	                 CONV_2D	           55.542	    4.525	    4.483	  2.766%	 36.981%	     0.000	        1	[mobilenetv2_1.00_224/block_2_expand_relu/Relu6;mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_expand/Conv2D]:7
	       DEPTHWISE_CONV_2D	           60.036	    2.223	    2.244	  1.385%	 38.365%	     0.000	        1	[mobilenetv2_1.00_224/block_2_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_depthwise/depthwise;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3]:8
	                 CONV_2D	           62.289	    2.900	    2.851	  1.760%	 40.125%	     0.000	        1	[mobilenetv2_1.00_224/block_2_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_project/Conv2D]:9
	                     ADD	           65.152	    6.947	    6.902	  4.259%	 44.384%	     0.000	        1	[mobilenetv2_1.00_224/block_2_add/add]:10
	                 CONV_2D	           72.063	    4.599	    4.473	  2.760%	 47.145%	     0.000	        1	[mobilenetv2_1.00_224/block_3_expand_relu/Relu6;mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_expand/Conv2D]:11
	                     PAD	           76.546	   10.188	   10.181	  6.283%	 53.428%	     0.000	        1	[mobilenetv2_1.00_224/block_3_pad/Pad]:12
	       DEPTHWISE_CONV_2D	           86.736	    0.968	    0.902	  0.557%	 53.985%	     0.000	        1	[mobilenetv2_1.00_224/block_3_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_depthwise/depthwise]:13
	                 CONV_2D	           87.649	    0.833	    0.825	  0.509%	 54.494%	     0.000	        1	[mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_project/Conv2D]:14
	                 CONV_2D	           88.482	    1.467	    1.460	  0.901%	 55.395%	     0.000	        1	[mobilenetv2_1.00_224/block_4_expand_relu/Relu6;mobilenetv2_1.00_224/block_4_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_expand/Conv2D]:15
	       DEPTHWISE_CONV_2D	           89.952	    0.774	    0.741	  0.457%	 55.852%	     0.000	        1	[mobilenetv2_1.00_224/block_4_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3]:16
	                 CONV_2D	           90.701	    1.038	    0.954	  0.589%	 56.441%	     0.000	        1	[mobilenetv2_1.00_224/block_4_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_project/Conv2D]:17
	                     ADD	           91.664	    2.298	    2.310	  1.426%	 57.867%	     0.000	        1	[mobilenetv2_1.00_224/block_4_add/add]:18
	                 CONV_2D	           93.981	    1.535	    1.489	  0.919%	 58.786%	     0.000	        1	[mobilenetv2_1.00_224/block_5_expand_relu/Relu6;mobilenetv2_1.00_224/block_5_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_expand/Conv2D]:19
	       DEPTHWISE_CONV_2D	           95.479	    0.802	    0.741	  0.458%	 59.243%	     0.000	        1	[mobilenetv2_1.00_224/block_5_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_5_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3]:20
	                 CONV_2D	           96.228	    1.016	    0.942	  0.581%	 59.824%	     0.000	        1	[mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_project/Conv2D]:21
	                     ADD	           97.179	    2.355	    2.317	  1.430%	 61.254%	     0.000	        1	[mobilenetv2_1.00_224/block_5_add/add]:22
	                 CONV_2D	           99.504	    1.485	    1.460	  0.901%	 62.156%	     0.000	        1	[mobilenetv2_1.00_224/block_6_expand_relu/Relu6;mobilenetv2_1.00_224/block_6_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_expand/Conv2D]:23
	                     PAD	          100.973	    3.536	    3.482	  2.149%	 64.304%	     0.000	        1	[mobilenetv2_1.00_224/block_6_pad/Pad]:24
	       DEPTHWISE_CONV_2D	          104.463	    0.287	    0.265	  0.163%	 64.467%	     0.000	        1	[mobilenetv2_1.00_224/block_6_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_depthwise/depthwise]:25
	                 CONV_2D	          104.735	    0.474	    0.446	  0.275%	 64.742%	     0.000	        1	[mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_project/Conv2D]:26
	                 CONV_2D	          105.189	    1.064	    1.080	  0.666%	 65.409%	     0.000	        1	[mobilenetv2_1.00_224/block_7_expand_relu/Relu6;mobilenetv2_1.00_224/block_7_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_expand/Conv2D]:27
	       DEPTHWISE_CONV_2D	          106.277	    0.392	    0.366	  0.226%	 65.635%	     0.000	        1	[mobilenetv2_1.00_224/block_7_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_7_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:28
	                 CONV_2D	          106.651	    0.879	    0.775	  0.478%	 66.113%	     0.000	        1	[mobilenetv2_1.00_224/block_7_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_project/Conv2D]:29
	                     ADD	          107.434	    1.171	    1.175	  0.725%	 66.838%	     0.000	        1	[mobilenetv2_1.00_224/block_7_add/add]:30
	                 CONV_2D	          108.616	    1.112	    1.087	  0.671%	 67.509%	     0.000	        1	[mobilenetv2_1.00_224/block_8_expand_relu/Relu6;mobilenetv2_1.00_224/block_8_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_expand/Conv2D]:31
	       DEPTHWISE_CONV_2D	          109.712	    0.370	    0.356	  0.220%	 67.729%	     0.000	        1	[mobilenetv2_1.00_224/block_8_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_8_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:32
	                 CONV_2D	          110.075	    0.848	    0.805	  0.497%	 68.226%	     0.000	        1	[mobilenetv2_1.00_224/block_8_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_project/Conv2D]:33
	                     ADD	          110.889	    1.168	    1.160	  0.716%	 68.942%	     0.000	        1	[mobilenetv2_1.00_224/block_8_add/add]:34
	                 CONV_2D	          112.057	    1.136	    1.110	  0.685%	 69.627%	     0.000	        1	[mobilenetv2_1.00_224/block_9_expand_relu/Relu6;mobilenetv2_1.00_224/block_9_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_expand/Conv2D]:35
	       DEPTHWISE_CONV_2D	          113.177	    0.389	    0.361	  0.223%	 69.850%	     0.000	        1	[mobilenetv2_1.00_224/block_9_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_9_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:36
	                 CONV_2D	          113.545	    0.867	    0.800	  0.494%	 70.344%	     0.000	        1	[mobilenetv2_1.00_224/block_9_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_project/Conv2D]:37
	                     ADD	          114.354	    1.168	    1.171	  0.723%	 71.066%	     0.000	        1	[mobilenetv2_1.00_224/block_9_add/add]:38
	                 CONV_2D	          115.532	    1.117	    1.107	  0.683%	 71.749%	     0.000	        1	[mobilenetv2_1.00_224/block_10_expand_relu/Relu6;mobilenetv2_1.00_224/block_10_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_expand/Conv2D]:39
	       DEPTHWISE_CONV_2D	          116.648	    0.363	    0.351	  0.217%	 71.966%	     0.000	        1	[mobilenetv2_1.00_224/block_10_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_depthwise/depthwise]:40
	                 CONV_2D	          117.007	    1.219	    1.129	  0.697%	 72.663%	     0.000	        1	[mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_project/Conv2D]:41
	                 CONV_2D	          118.145	    2.096	    2.067	  1.276%	 73.939%	     0.000	        1	[mobilenetv2_1.00_224/block_11_expand_relu/Relu6;mobilenetv2_1.00_224/block_11_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_expand/Conv2D]:42
	       DEPTHWISE_CONV_2D	          120.220	    0.560	    0.526	  0.325%	 74.263%	     0.000	        1	[mobilenetv2_1.00_224/block_11_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3]:43
	                 CONV_2D	          120.754	    1.682	    1.609	  0.993%	 75.256%	     0.000	        1	[mobilenetv2_1.00_224/block_11_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_project/Conv2D]:44
	                     ADD	          122.373	    1.750	    1.745	  1.077%	 76.333%	     0.000	        1	[mobilenetv2_1.00_224/block_11_add/add]:45
	                 CONV_2D	          124.125	    2.125	    2.046	  1.263%	 77.596%	     0.000	        1	[mobilenetv2_1.00_224/block_12_expand_relu/Relu6;mobilenetv2_1.00_224/block_12_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_expand/Conv2D]:46
	       DEPTHWISE_CONV_2D	          126.181	    0.539	    0.515	  0.318%	 77.913%	     0.000	        1	[mobilenetv2_1.00_224/block_12_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_12_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3]:47
	                 CONV_2D	          126.704	    1.632	    1.610	  0.994%	 78.907%	     0.000	        1	[mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_project/Conv2D]:48
	                     ADD	          128.325	    1.794	    1.735	  1.071%	 79.978%	     0.000	        1	[mobilenetv2_1.00_224/block_12_add/add]:49
	                 CONV_2D	          130.067	    2.191	    2.067	  1.276%	 81.254%	     0.000	        1	[mobilenetv2_1.00_224/block_13_expand_relu/Relu6;mobilenetv2_1.00_224/block_13_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_expand/Conv2D]:50
	                     PAD	          132.148	    2.800	    2.748	  1.696%	 82.950%	     0.000	        1	[mobilenetv2_1.00_224/block_13_pad/Pad]:51
	       DEPTHWISE_CONV_2D	          134.904	    0.265	    0.210	  0.130%	 83.079%	     0.000	        1	[mobilenetv2_1.00_224/block_13_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_depthwise/depthwise]:52
	                 CONV_2D	          135.121	    0.928	    0.820	  0.506%	 83.585%	     0.000	        1	[mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_project/Conv2D]:53
	                 CONV_2D	          135.949	    1.528	    1.482	  0.915%	 84.500%	     0.000	        1	[mobilenetv2_1.00_224/block_14_expand_relu/Relu6;mobilenetv2_1.00_224/block_14_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_expand/Conv2D]:54
	       DEPTHWISE_CONV_2D	          137.441	    0.296	    0.282	  0.174%	 84.674%	     0.000	        1	[mobilenetv2_1.00_224/block_14_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3]:55
	                 CONV_2D	          137.730	    1.269	    1.247	  0.770%	 85.444%	     0.000	        1	[mobilenetv2_1.00_224/block_14_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_project/Conv2D]:56
	                     ADD	          138.986	    0.742	    0.741	  0.457%	 85.901%	     0.000	        1	[mobilenetv2_1.00_224/block_14_add/add]:57
	                 CONV_2D	          139.734	    1.578	    1.479	  0.913%	 86.814%	     0.000	        1	[mobilenetv2_1.00_224/block_15_expand_relu/Relu6;mobilenetv2_1.00_224/block_15_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_expand/Conv2D]:58
	       DEPTHWISE_CONV_2D	          141.222	    0.341	    0.265	  0.163%	 86.977%	     0.000	        1	[mobilenetv2_1.00_224/block_15_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_15_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3]:59
	                 CONV_2D	          141.494	    1.266	    1.221	  0.753%	 87.731%	     0.000	        1	[mobilenetv2_1.00_224/block_15_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_project/Conv2D]:60
	                     ADD	          142.723	    0.738	    0.733	  0.452%	 88.183%	     0.000	        1	[mobilenetv2_1.00_224/block_15_add/add]:61
	                 CONV_2D	          143.463	    1.553	    1.486	  0.917%	 89.100%	     0.000	        1	[mobilenetv2_1.00_224/block_16_expand_relu/Relu6;mobilenetv2_1.00_224/block_16_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_expand/Conv2D]:62
	       DEPTHWISE_CONV_2D	          144.957	    0.328	    0.264	  0.163%	 89.263%	     0.000	        1	[mobilenetv2_1.00_224/block_16_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_depthwise/depthwise]:63
	                 CONV_2D	          145.229	    2.504	    2.401	  1.482%	 90.745%	     0.000	        1	[mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_project/Conv2D]:64
	                 CONV_2D	          147.642	    3.562	    3.448	  2.128%	 92.873%	     0.000	        1	[mobilenetv2_1.00_224/out_relu/Relu6;mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3;mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv_1/Conv2D]:65
	                    MEAN	          151.102	   10.828	   10.836	  6.687%	 99.560%	     0.000	        1	[mobilenetv2_1.00_224/global_average_pooling2d/Mean]:66
	         FULLY_CONNECTED	          161.946	    0.559	    0.625	  0.386%	 99.946%	     0.000	        1	[mobilenetv2_1.00_224/predictions/MatMul;mobilenetv2_1.00_224/predictions/BiasAdd]:67
	                 SOFTMAX	          162.581	    0.084	    0.088	  0.054%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:68

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     PAD	           24.056	   26.832	   26.840	 16.564%	 16.564%	     0.000	        1	[mobilenetv2_1.00_224/block_1_pad/Pad]:4
	                    MEAN	          151.102	   10.828	   10.836	  6.687%	 23.251%	     0.000	        1	[mobilenetv2_1.00_224/global_average_pooling2d/Mean]:66
	                     PAD	           76.546	   10.188	   10.181	  6.283%	 29.534%	     0.000	        1	[mobilenetv2_1.00_224/block_3_pad/Pad]:12
	                 CONV_2D	           14.082	   10.101	    9.961	  6.147%	 35.682%	     0.000	        1	[mobilenetv2_1.00_224/block_1_expand_relu/Relu6;mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_expand/Conv2D]:3
	                 CONV_2D	            0.020	    7.890	    7.933	  4.896%	 40.578%	     0.000	        1	[mobilenetv2_1.00_224/Conv1_relu/Relu6;mobilenetv2_1.00_224/bn_Conv1/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv1/Conv2D]:0
	                     ADD	           65.152	    6.947	    6.902	  4.259%	 44.837%	     0.000	        1	[mobilenetv2_1.00_224/block_2_add/add]:10
	                 CONV_2D	            9.483	    4.572	    4.587	  2.831%	 47.668%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_project/Conv2D]:2
	                 CONV_2D	           55.542	    4.525	    4.483	  2.766%	 50.434%	     0.000	        1	[mobilenetv2_1.00_224/block_2_expand_relu/Relu6;mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_expand/Conv2D]:7
	                 CONV_2D	           72.063	    4.599	    4.473	  2.760%	 53.195%	     0.000	        1	[mobilenetv2_1.00_224/block_3_expand_relu/Relu6;mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_expand/Conv2D]:11
	                     PAD	          100.973	    3.536	    3.482	  2.149%	 55.343%	     0.000	        1	[mobilenetv2_1.00_224/block_6_pad/Pad]:24

Number of nodes executed: 69
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       35	    74.912	    46.242%	    46.242%	     0.000	       35
	                     PAD	        4	    43.248	    26.696%	    72.939%	     0.000	        4
	                     ADD	       10	    19.983	    12.335%	    85.274%	     0.000	       10
	       DEPTHWISE_CONV_2D	       17	    12.310	     7.599%	    92.873%	     0.000	       17
	                    MEAN	        1	    10.835	     6.688%	    99.561%	     0.000	        1
	         FULLY_CONNECTED	        1	     0.624	     0.385%	    99.946%	     0.000	        1
	                 SOFTMAX	        1	     0.087	     0.054%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=164641 curr=160611 min=159433 max=170799 avg=162035 std=3358
Memory (bytes): count=0
69 nodes observed



[ perf record: Woken up 18 times to write data ]
[ perf record: Captured and wrote 4.388 MB /tmp/data.record (19794 samples) ]

6.483

