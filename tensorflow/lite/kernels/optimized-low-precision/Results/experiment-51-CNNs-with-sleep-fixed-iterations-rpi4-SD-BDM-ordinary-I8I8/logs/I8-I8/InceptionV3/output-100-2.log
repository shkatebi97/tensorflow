STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ) (or (22201, 27, )), Output shape (22201, 32, ), ID: 0, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 32, ), Input shape (22201, 32, ) (or (21609, 288, )), Output shape (21609, 32, ), ID: 1, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (21609, 32, ) (or (21609, 288, )), Output shape (21609, 64, ), ID: 2, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (64, 80, ), Input shape (5329, 64, ) (or (5329, 64, )), Output shape (5329, 80, ), ID: 3, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (5329, 64, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (720, 192, ), Input shape (5329, 80, ) (or (5041, 720, )), Output shape (5041, 192, ), ID: 4, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (5041, 720, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 32, ), ID: 5, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 6, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (192, 48, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 48, ), ID: 7, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 8, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 9, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 10, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 11, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 12, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 13, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 48, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 48, ), ID: 14, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 15, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 16, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 17, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 18, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 19, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 20, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 48, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 48, ), ID: 21, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 22, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 23, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 24, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 25, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (2592, 384, ), Input shape (1225, 288, ) (or (289, 2592, )), Output shape (289, 384, ), ID: 26, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 2592, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 27, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 28, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (289, 864, )), Output shape (289, 96, ), ID: 29, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 864, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 30, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 31, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 32, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 33, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 34, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 35, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 36, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 37, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 38, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 39, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 40, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 41, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 42, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 43, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 44, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 45, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 46, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 47, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 48, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 49, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 50, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 51, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 52, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 53, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 54, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 55, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 56, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 57, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 58, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 59, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 60, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 61, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 62, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 63, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 64, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 65, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 66, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 67, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 68, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 69, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 70, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1728, 320, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 320, ), ID: 71, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 72, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 73, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 74, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1728, 192, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 192, ), ID: 75, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1280, 192, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 192, ), ID: 76, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1280, 320, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 320, ), ID: 77, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1280, 384, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 384, ), ID: 78, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 79, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 80, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1280, 448, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 448, ), ID: 81, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 82, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 83, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 84, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (2048, 192, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 192, ), ID: 85, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (2048, 320, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 320, ), ID: 86, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (2048, 384, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 384, ), ID: 87, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 88, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 89, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (2048, 448, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 448, ), ID: 90, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 91, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 92, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 93, Method: NoOptimization
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
NOT Applying FC Low-Precision for Kernel shape (2048, 1000, ), Input shape (1, 2048, ), Output shape (1, 1000, ), ID: 0, Method: NoOptimization
The input model file size (MB): 24.2886
Initialized session in 18.138ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=910619 curr=856225 min=856225 max=910619 avg=883422 std=27197

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=855565 curr=855185 min=852042 max=856459 avg=854737 std=695

Inference timings in us: Init: 18138, First inference: 910619, Warmup (avg): 883422, Inference (avg): 854737
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=9.92188 overall=44.3984
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   13.808	   13.808	100.000%	100.000%	     0.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   13.808	   13.808	100.000%	100.000%	     0.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    13.808	   100.000%	   100.000%	     0.000	        1

Timings (microseconds): count=1 curr=13808
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.014	    8.629	    8.526	  0.998%	  0.998%	     0.000	        1	[inception_v3/activation/Relu;inception_v3/batch_normalization/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d/Conv2D]:0
	                 CONV_2D	            8.541	   42.720	   41.355	  4.839%	  5.837%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	           49.897	   67.920	   67.868	  7.942%	 13.779%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	             MAX_POOL_2D	          117.767	    0.916	    0.935	  0.109%	 13.888%	     0.000	        1	[inception_v3/max_pooling2d/MaxPool]:3
	                 CONV_2D	          118.702	    5.886	    5.810	  0.680%	 14.568%	     0.000	        1	[inception_v3/activation_3/Relu;inception_v3/batch_normalization_3/FusedBatchNormV3;inception_v3/batch_normalization_3/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_3/Conv2D]:4
	                 CONV_2D	          124.514	   96.457	   96.418	 11.283%	 25.851%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	             MAX_POOL_2D	          220.933	    0.507	    0.538	  0.063%	 25.914%	     0.000	        1	[inception_v3/max_pooling2d_1/MaxPool]:6
	         AVERAGE_POOL_2D	          221.473	    2.212	    2.260	  0.264%	 26.178%	     0.000	        1	[inception_v3/average_pooling2d/AvgPool]:7
	                 CONV_2D	          223.734	    1.349	    1.294	  0.151%	 26.330%	     0.000	        1	[inception_v3/activation_11/Relu;inception_v3/batch_normalization_11/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_11/Conv2D]:8
	                 CONV_2D	          225.028	    2.294	    2.330	  0.273%	 26.602%	     0.000	        1	[inception_v3/activation_5/Relu;inception_v3/batch_normalization_5/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_5/Conv2D]:9
	                 CONV_2D	          227.359	    1.780	    1.754	  0.205%	 26.808%	     0.000	        1	[inception_v3/activation_6/Relu;inception_v3/batch_normalization_6/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_6/Conv2D]:10
	                 CONV_2D	          229.114	   14.289	   14.444	  1.690%	 28.498%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          243.559	    2.381	    2.404	  0.281%	 28.779%	     0.000	        1	[inception_v3/activation_8/Relu;inception_v3/batch_normalization_8/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_8/Conv2D]:12
	                 CONV_2D	          245.963	   10.217	   10.242	  1.199%	 29.978%	     0.000	        1	[inception_v3/activation_9/Relu;inception_v3/batch_normalization_9/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_9/Conv2D]:13
	                 CONV_2D	          256.206	   14.693	   14.820	  1.734%	 31.712%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	           CONCATENATION	          271.027	    0.212	    0.224	  0.026%	 31.738%	     0.000	        1	[inception_v3/mixed0/concat]:15
	         AVERAGE_POOL_2D	          271.252	    3.119	    3.103	  0.363%	 32.101%	     0.000	        1	[inception_v3/average_pooling2d_1/AvgPool]:16
	                 CONV_2D	          274.355	    3.128	    3.072	  0.360%	 32.461%	     0.000	        1	[inception_v3/activation_18/Relu;inception_v3/batch_normalization_18/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_18/Conv2D]:17
	                 CONV_2D	          277.429	    3.096	    3.103	  0.363%	 32.824%	     0.000	        1	[inception_v3/activation_12/Relu;inception_v3/batch_normalization_12/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_12/Conv2D]:18
	                 CONV_2D	          280.533	    2.260	    2.318	  0.271%	 33.095%	     0.000	        1	[inception_v3/activation_13/Relu;inception_v3/batch_normalization_13/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_13/Conv2D]:19
	                 CONV_2D	          282.852	   14.354	   14.407	  1.686%	 34.781%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          297.260	    3.152	    3.041	  0.356%	 35.137%	     0.000	        1	[inception_v3/activation_15/Relu;inception_v3/batch_normalization_15/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_15/Conv2D]:21
	                 CONV_2D	          300.302	   10.206	   10.304	  1.206%	 36.343%	     0.000	        1	[inception_v3/activation_16/Relu;inception_v3/batch_normalization_16/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_16/Conv2D]:22
	                 CONV_2D	          310.607	   14.893	   14.789	  1.731%	 38.073%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	           CONCATENATION	          325.397	    0.255	    0.259	  0.030%	 38.103%	     0.000	        1	[inception_v3/mixed1/concat]:24
	         AVERAGE_POOL_2D	          325.657	    3.547	    3.556	  0.416%	 38.520%	     0.000	        1	[inception_v3/average_pooling2d_2/AvgPool]:25
	                 CONV_2D	          329.214	    3.398	    3.399	  0.398%	 38.917%	     0.000	        1	[inception_v3/activation_25/Relu;inception_v3/batch_normalization_25/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_25/Conv2D]:26
	                 CONV_2D	          332.614	    3.343	    3.432	  0.402%	 39.319%	     0.000	        1	[inception_v3/activation_19/Relu;inception_v3/batch_normalization_19/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_19/Conv2D]:27
	                 CONV_2D	          336.047	    2.658	    2.581	  0.302%	 39.621%	     0.000	        1	[inception_v3/activation_20/Relu;inception_v3/batch_normalization_20/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_20/Conv2D]:28
	                 CONV_2D	          338.629	   14.445	   14.400	  1.685%	 41.306%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          353.030	    3.420	    3.443	  0.403%	 41.709%	     0.000	        1	[inception_v3/activation_22/Relu;inception_v3/batch_normalization_22/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_22/Conv2D]:30
	                 CONV_2D	          356.474	   10.225	   10.292	  1.204%	 42.913%	     0.000	        1	[inception_v3/activation_23/Relu;inception_v3/batch_normalization_23/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_23/Conv2D]:31
	                 CONV_2D	          366.768	   14.807	   14.798	  1.732%	 44.645%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	           CONCATENATION	          381.567	    0.206	    0.220	  0.026%	 44.671%	     0.000	        1	[inception_v3/mixed2/concat]:33
	                 CONV_2D	          381.788	   36.576	   36.654	  4.289%	 48.960%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          418.444	    3.409	    3.321	  0.389%	 49.349%	     0.000	        1	[inception_v3/activation_27/Relu;inception_v3/batch_normalization_27/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_27/Conv2D]:35
	                 CONV_2D	          421.765	   10.167	   10.246	  1.199%	 50.548%	     0.000	        1	[inception_v3/activation_28/Relu;inception_v3/batch_normalization_28/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_28/Conv2D]:36
	                 CONV_2D	          432.012	    3.523	    3.459	  0.405%	 50.952%	     0.000	        1	[inception_v3/activation_29/Relu;inception_v3/batch_normalization_29/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_29/Conv2D]:37
	             MAX_POOL_2D	          435.473	    0.279	    0.276	  0.032%	 50.985%	     0.000	        1	[inception_v3/max_pooling2d_2/MaxPool]:38
	           CONCATENATION	          435.750	    0.130	    0.132	  0.015%	 51.000%	     0.000	        1	[inception_v3/mixed3/concat]:39
	         AVERAGE_POOL_2D	          435.883	    2.219	    2.234	  0.261%	 51.262%	     0.000	        1	[inception_v3/average_pooling2d_3/AvgPool]:40
	                 CONV_2D	          438.117	    5.664	    5.715	  0.669%	 51.930%	     0.000	        1	[inception_v3/activation_39/Relu;inception_v3/batch_normalization_39/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_39/Conv2D]:41
	                 CONV_2D	          443.834	    5.670	    5.659	  0.662%	 52.593%	     0.000	        1	[inception_v3/activation_30/Relu;inception_v3/batch_normalization_30/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_30/Conv2D]:42
	                 CONV_2D	          449.494	    3.758	    3.804	  0.445%	 53.038%	     0.000	        1	[inception_v3/activation_31/Relu;inception_v3/batch_normalization_31/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_31/Conv2D]:43
	                 CONV_2D	          453.299	    4.578	    4.544	  0.532%	 53.569%	     0.000	        1	[inception_v3/activation_32/Relu;inception_v3/batch_normalization_32/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_32/Conv2D]:44
	                 CONV_2D	          457.844	    6.535	    6.564	  0.768%	 54.338%	     0.000	        1	[inception_v3/activation_33/Relu;inception_v3/batch_normalization_33/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_33/Conv2D]:45
	                 CONV_2D	          464.410	    3.972	    3.911	  0.458%	 54.795%	     0.000	        1	[inception_v3/activation_34/Relu;inception_v3/batch_normalization_34/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_34/Conv2D]:46
	                 CONV_2D	          468.321	    4.472	    4.525	  0.530%	 55.325%	     0.000	        1	[inception_v3/activation_35/Relu;inception_v3/batch_normalization_35/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_35/Conv2D]:47
	                 CONV_2D	          472.847	    4.385	    4.447	  0.520%	 55.845%	     0.000	        1	[inception_v3/activation_36/Relu;inception_v3/batch_normalization_36/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_36/Conv2D]:48
	                 CONV_2D	          477.295	    4.457	    4.465	  0.523%	 56.368%	     0.000	        1	[inception_v3/activation_37/Relu;inception_v3/batch_normalization_37/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_37/Conv2D]:49
	                 CONV_2D	          481.761	    6.481	    6.553	  0.767%	 57.134%	     0.000	        1	[inception_v3/activation_38/Relu;inception_v3/batch_normalization_38/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_38/Conv2D]:50
	           CONCATENATION	          488.316	    0.144	    0.152	  0.018%	 57.152%	     0.000	        1	[inception_v3/mixed4/concat]:51
	         AVERAGE_POOL_2D	          488.468	    2.180	    2.223	  0.260%	 57.412%	     0.000	        1	[inception_v3/average_pooling2d_4/AvgPool]:52
	                 CONV_2D	          490.692	    5.731	    5.722	  0.670%	 58.082%	     0.000	        1	[inception_v3/activation_49/Relu;inception_v3/batch_normalization_49/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_49/Conv2D]:53
	                 CONV_2D	          496.414	    5.595	    5.644	  0.660%	 58.742%	     0.000	        1	[inception_v3/activation_40/Relu;inception_v3/batch_normalization_40/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_40/Conv2D]:54
	                 CONV_2D	          502.059	    4.738	    4.699	  0.550%	 59.292%	     0.000	        1	[inception_v3/activation_41/Relu;inception_v3/batch_normalization_41/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_41/Conv2D]:55
	                 CONV_2D	          506.759	    7.043	    6.981	  0.817%	 60.109%	     0.000	        1	[inception_v3/activation_42/Relu;inception_v3/batch_normalization_42/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_42/Conv2D]:56
	                 CONV_2D	          513.741	    8.250	    8.279	  0.969%	 61.078%	     0.000	        1	[inception_v3/activation_43/Relu;inception_v3/batch_normalization_43/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_43/Conv2D]:57
	                 CONV_2D	          522.022	    4.761	    4.796	  0.561%	 61.639%	     0.000	        1	[inception_v3/activation_44/Relu;inception_v3/batch_normalization_44/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_44/Conv2D]:58
	                 CONV_2D	          526.819	    7.018	    6.986	  0.818%	 62.456%	     0.000	        1	[inception_v3/activation_45/Relu;inception_v3/batch_normalization_45/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_45/Conv2D]:59
	                 CONV_2D	          533.806	    6.993	    6.937	  0.812%	 63.268%	     0.000	        1	[inception_v3/activation_46/Relu;inception_v3/batch_normalization_46/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_46/Conv2D]:60
	                 CONV_2D	          540.745	    6.928	    6.934	  0.811%	 64.080%	     0.000	        1	[inception_v3/activation_47/Relu;inception_v3/batch_normalization_47/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_47/Conv2D]:61
	                 CONV_2D	          547.680	    8.242	    8.246	  0.965%	 65.045%	     0.000	        1	[inception_v3/activation_48/Relu;inception_v3/batch_normalization_48/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_48/Conv2D]:62
	           CONCATENATION	          555.927	    0.141	    0.151	  0.018%	 65.062%	     0.000	        1	[inception_v3/mixed5/concat]:63
	         AVERAGE_POOL_2D	          556.079	    2.207	    2.219	  0.260%	 65.322%	     0.000	        1	[inception_v3/average_pooling2d_5/AvgPool]:64
	                 CONV_2D	          558.299	    5.786	    5.747	  0.673%	 65.995%	     0.000	        1	[inception_v3/activation_59/Relu;inception_v3/batch_normalization_59/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_59/Conv2D]:65
	                 CONV_2D	          564.048	    5.602	    5.644	  0.660%	 66.655%	     0.000	        1	[inception_v3/activation_50/Relu;inception_v3/batch_normalization_50/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_50/Conv2D]:66
	                 CONV_2D	          569.693	    4.771	    4.712	  0.551%	 67.206%	     0.000	        1	[inception_v3/activation_51/Relu;inception_v3/batch_normalization_51/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_51/Conv2D]:67
	                 CONV_2D	          574.405	    6.947	    6.982	  0.817%	 68.023%	     0.000	        1	[inception_v3/activation_52/Relu;inception_v3/batch_normalization_52/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_52/Conv2D]:68
	                 CONV_2D	          581.389	    8.321	    8.292	  0.970%	 68.994%	     0.000	        1	[inception_v3/activation_53/Relu;inception_v3/batch_normalization_53/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_53/Conv2D]:69
	                 CONV_2D	          589.682	    4.841	    4.802	  0.562%	 69.556%	     0.000	        1	[inception_v3/activation_54/Relu;inception_v3/batch_normalization_54/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_54/Conv2D]:70
	                 CONV_2D	          594.485	    7.007	    6.961	  0.815%	 70.370%	     0.000	        1	[inception_v3/activation_55/Relu;inception_v3/batch_normalization_55/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_55/Conv2D]:71
	                 CONV_2D	          601.447	    6.996	    6.956	  0.814%	 71.184%	     0.000	        1	[inception_v3/activation_56/Relu;inception_v3/batch_normalization_56/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_56/Conv2D]:72
	                 CONV_2D	          608.403	    6.876	    6.948	  0.813%	 71.997%	     0.000	        1	[inception_v3/activation_57/Relu;inception_v3/batch_normalization_57/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_57/Conv2D]:73
	                 CONV_2D	          615.353	    8.233	    8.259	  0.966%	 72.964%	     0.000	        1	[inception_v3/activation_58/Relu;inception_v3/batch_normalization_58/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_58/Conv2D]:74
	           CONCATENATION	          623.613	    0.142	    0.144	  0.017%	 72.981%	     0.000	        1	[inception_v3/mixed6/concat]:75
	         AVERAGE_POOL_2D	          623.758	    2.281	    2.227	  0.261%	 73.241%	     0.000	        1	[inception_v3/average_pooling2d_6/AvgPool]:76
	                 CONV_2D	          625.986	    5.863	    5.754	  0.673%	 73.914%	     0.000	        1	[inception_v3/activation_69/Relu;inception_v3/batch_normalization_69/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_69/Conv2D]:77
	                 CONV_2D	          631.740	    5.718	    5.641	  0.660%	 74.575%	     0.000	        1	[inception_v3/activation_60/Relu;inception_v3/batch_normalization_60/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_60/Conv2D]:78
	                 CONV_2D	          637.383	    5.555	    5.614	  0.657%	 75.231%	     0.000	        1	[inception_v3/activation_61/Relu;inception_v3/batch_normalization_61/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_61/Conv2D]:79
	                 CONV_2D	          642.997	    9.911	    9.932	  1.162%	 76.394%	     0.000	        1	[inception_v3/activation_62/Relu;inception_v3/batch_normalization_62/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_62/Conv2D]:80
	                 CONV_2D	          652.931	    9.863	    9.865	  1.154%	 77.548%	     0.000	        1	[inception_v3/activation_63/Relu;inception_v3/batch_normalization_63/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_63/Conv2D]:81
	                 CONV_2D	          662.797	    5.616	    5.659	  0.662%	 78.210%	     0.000	        1	[inception_v3/activation_64/Relu;inception_v3/batch_normalization_64/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_64/Conv2D]:82
	                 CONV_2D	          668.457	    9.816	    9.907	  1.159%	 79.370%	     0.000	        1	[inception_v3/activation_65/Relu;inception_v3/batch_normalization_65/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_65/Conv2D]:83
	                 CONV_2D	          678.365	    9.891	    9.881	  1.156%	 80.526%	     0.000	        1	[inception_v3/activation_66/Relu;inception_v3/batch_normalization_66/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_66/Conv2D]:84
	                 CONV_2D	          688.248	    9.794	    9.860	  1.154%	 81.680%	     0.000	        1	[inception_v3/activation_67/Relu;inception_v3/batch_normalization_67/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_67/Conv2D]:85
	                 CONV_2D	          698.109	    9.824	    9.856	  1.153%	 82.833%	     0.000	        1	[inception_v3/activation_68/Relu;inception_v3/batch_normalization_68/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_68/Conv2D]:86
	           CONCATENATION	          707.966	    0.143	    0.137	  0.016%	 82.849%	     0.000	        1	[inception_v3/mixed7/concat]:87
	                 CONV_2D	          708.104	    5.643	    5.692	  0.666%	 83.515%	     0.000	        1	[inception_v3/activation_70/Relu;inception_v3/batch_normalization_70/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_70/Conv2D]:88
	                 CONV_2D	          713.797	    4.979	    4.903	  0.574%	 84.089%	     0.000	        1	[inception_v3/activation_71/Relu;inception_v3/batch_normalization_71/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_71/Conv2D]:89
	                 CONV_2D	          718.702	    5.670	    5.700	  0.667%	 84.756%	     0.000	        1	[inception_v3/activation_72/Relu;inception_v3/batch_normalization_72/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_72/Conv2D]:90
	                 CONV_2D	          724.403	    9.780	    9.903	  1.159%	 85.915%	     0.000	        1	[inception_v3/activation_73/Relu;inception_v3/batch_normalization_73/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_73/Conv2D]:91
	                 CONV_2D	          734.307	    9.844	    9.852	  1.153%	 87.068%	     0.000	        1	[inception_v3/activation_74/Relu;inception_v3/batch_normalization_74/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_74/Conv2D]:92
	                 CONV_2D	          744.161	    2.907	    2.921	  0.342%	 87.410%	     0.000	        1	[inception_v3/activation_75/Relu;inception_v3/batch_normalization_75/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_75/Conv2D]:93
	             MAX_POOL_2D	          747.083	    0.174	    0.188	  0.022%	 87.432%	     0.000	        1	[inception_v3/max_pooling2d_3/MaxPool]:94
	           CONCATENATION	          747.272	    0.048	    0.038	  0.004%	 87.436%	     0.000	        1	[inception_v3/mixed8/concat]:95
	         AVERAGE_POOL_2D	          747.310	    0.769	    0.779	  0.091%	 87.527%	     0.000	        1	[inception_v3/average_pooling2d_7/AvgPool]:96
	                 CONV_2D	          748.090	    2.182	    2.190	  0.256%	 87.783%	     0.000	        1	[inception_v3/activation_84/Relu;inception_v3/batch_normalization_84/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_84/Conv2D]:97
	                 CONV_2D	          750.281	    3.671	    3.636	  0.425%	 88.209%	     0.000	        1	[inception_v3/activation_76/Relu;inception_v3/batch_normalization_76/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_76/Conv2D]:98
	                 CONV_2D	          753.918	    4.248	    4.293	  0.502%	 88.711%	     0.000	        1	[inception_v3/activation_77/Relu;inception_v3/batch_normalization_77/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_77/Conv2D]:99
	                 CONV_2D	          758.213	    3.886	    3.920	  0.459%	 89.170%	     0.000	        1	[inception_v3/activation_78/Relu;inception_v3/batch_normalization_78/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_78/Conv2D]:100
	                 CONV_2D	          762.135	    3.961	    3.920	  0.459%	 89.629%	     0.000	        1	[inception_v3/activation_79/Relu;inception_v3/batch_normalization_79/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_79/Conv2D]:101
	           CONCATENATION	          766.056	    0.034	    0.035	  0.004%	 89.633%	     0.000	        1	[inception_v3/mixed9_0/concat]:102
	                 CONV_2D	          766.092	    4.977	    5.035	  0.589%	 90.222%	     0.000	        1	[inception_v3/activation_80/Relu;inception_v3/batch_normalization_80/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_80/Conv2D]:103
	                 CONV_2D	          771.130	   13.604	   13.515	  1.582%	 91.804%	     0.000	        1	[inception_v3/activation_81/Relu;inception_v3/batch_normalization_81/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_81/Conv2D]:104
	                 CONV_2D	          784.646	    3.948	    3.932	  0.460%	 92.264%	     0.000	        1	[inception_v3/activation_82/Relu;inception_v3/batch_normalization_82/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_82/Conv2D]:105
	                 CONV_2D	          788.579	    3.898	    3.913	  0.458%	 92.722%	     0.000	        1	[inception_v3/activation_83/Relu;inception_v3/batch_normalization_83/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_83/Conv2D]:106
	           CONCATENATION	          792.493	    0.031	    0.034	  0.004%	 92.726%	     0.000	        1	[inception_v3/concatenate/concat]:107
	           CONCATENATION	          792.528	    0.075	    0.074	  0.009%	 92.734%	     0.000	        1	[inception_v3/mixed9/concat]:108
	         AVERAGE_POOL_2D	          792.603	    1.346	    1.339	  0.157%	 92.891%	     0.000	        1	[inception_v3/average_pooling2d_8/AvgPool]:109
	                 CONV_2D	          793.943	    3.351	    3.403	  0.398%	 93.289%	     0.000	        1	[inception_v3/activation_93/Relu;inception_v3/batch_normalization_93/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_93/Conv2D]:110
	                 CONV_2D	          797.346	    5.679	    5.623	  0.658%	 93.947%	     0.000	        1	[inception_v3/activation_85/Relu;inception_v3/batch_normalization_85/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_85/Conv2D]:111
	                 CONV_2D	          802.970	    6.633	    6.678	  0.781%	 94.729%	     0.000	        1	[inception_v3/activation_86/Relu;inception_v3/batch_normalization_86/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_86/Conv2D]:112
	                 CONV_2D	          809.649	    3.973	    3.929	  0.460%	 95.188%	     0.000	        1	[inception_v3/activation_87/Relu;inception_v3/batch_normalization_87/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_87/Conv2D]:113
	                 CONV_2D	          813.580	    3.843	    3.887	  0.455%	 95.643%	     0.000	        1	[inception_v3/activation_88/Relu;inception_v3/batch_normalization_88/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_88/Conv2D]:114
	           CONCATENATION	          817.468	    0.031	    0.033	  0.004%	 95.647%	     0.000	        1	[inception_v3/mixed9_1/concat]:115
	                 CONV_2D	          817.502	    7.827	    7.815	  0.915%	 96.562%	     0.000	        1	[inception_v3/activation_89/Relu;inception_v3/batch_normalization_89/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_89/Conv2D]:116
	                 CONV_2D	          825.318	   13.438	   13.484	  1.578%	 98.140%	     0.000	        1	[inception_v3/activation_90/Relu;inception_v3/batch_normalization_90/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_90/Conv2D]:117
	                 CONV_2D	          838.803	    3.948	    3.964	  0.464%	 98.603%	     0.000	        1	[inception_v3/activation_91/Relu;inception_v3/batch_normalization_91/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_91/Conv2D]:118
	                 CONV_2D	          842.769	    3.834	    3.878	  0.454%	 99.057%	     0.000	        1	[inception_v3/activation_92/Relu;inception_v3/batch_normalization_92/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_92/Conv2D]:119
	           CONCATENATION	          846.648	    0.041	    0.033	  0.004%	 99.061%	     0.000	        1	[inception_v3/concatenate_1/concat]:120
	           CONCATENATION	          846.681	    0.115	    0.073	  0.009%	 99.070%	     0.000	        1	[inception_v3/mixed10/concat]:121
	                    MEAN	          846.755	    7.245	    7.213	  0.844%	 99.914%	     0.000	        1	[inception_v3/avg_pool/Mean]:122
	         FULLY_CONNECTED	          853.969	    0.703	    0.721	  0.084%	 99.998%	     0.000	        1	[inception_v3/predictions/MatMul;inception_v3/predictions/BiasAdd]:123
	                 SOFTMAX	          854.691	    0.015	    0.017	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:124

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          124.514	   96.457	   96.418	 11.283%	 11.283%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	                 CONV_2D	           49.897	   67.920	   67.868	  7.942%	 19.225%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	                 CONV_2D	            8.541	   42.720	   41.355	  4.839%	 24.064%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	          381.788	   36.576	   36.654	  4.289%	 28.353%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          256.206	   14.693	   14.820	  1.734%	 30.087%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	                 CONV_2D	          366.768	   14.807	   14.798	  1.732%	 31.819%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	                 CONV_2D	          310.607	   14.893	   14.789	  1.731%	 33.550%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	                 CONV_2D	          229.114	   14.289	   14.444	  1.690%	 35.240%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          282.852	   14.354	   14.407	  1.686%	 36.926%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          338.629	   14.445	   14.400	  1.685%	 38.611%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29

Number of nodes executed: 125
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       94	   822.945	    96.307%	    96.307%	     0.000	       94
	         AVERAGE_POOL_2D	        9	    19.936	     2.333%	    98.640%	     0.000	        9
	                    MEAN	        1	     7.213	     0.844%	    99.484%	     0.000	        1
	             MAX_POOL_2D	        4	     1.935	     0.226%	    99.711%	     0.000	        4
	           CONCATENATION	       15	     1.734	     0.203%	    99.914%	     0.000	       15
	         FULLY_CONNECTED	        1	     0.720	     0.084%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.016	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=855368 curr=855007 min=851873 max=856284 avg=854558 std=696
Memory (bytes): count=0
125 nodes observed



[ perf record: Woken up 278 times to write data ]
Warning:
Processed 333834 events and lost 1 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 69.323 MB /tmp/data.record (333187 samples) ]

93.865

