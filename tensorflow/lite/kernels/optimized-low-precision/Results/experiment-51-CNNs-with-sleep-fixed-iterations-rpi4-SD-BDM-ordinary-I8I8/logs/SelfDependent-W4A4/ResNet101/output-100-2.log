STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/ResNet101.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/ResNet101.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (147, 64, ), Input shape (52900, 3, ) (or (12544, 147, )), Output shape (12544, 64, ), ID: 0, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (12544, 147, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (160, 64, ) DONE
	Preparing Filter With Shape: (147, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 256, ), ID: 1, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 256, ) DONE
	Preparing Filter With Shape: (64, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 64, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 64, ), ID: 2, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 64, ) DONE
	Preparing Filter With Shape: (64, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 64, ), Input shape (3136, 64, ) (or (3136, 576, )), Output shape (3136, 64, ), ID: 3, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 576, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (576, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 256, ), ID: 4, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 256, ) DONE
	Preparing Filter With Shape: (64, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (3136, 256, ) (or (3136, 256, )), Output shape (3136, 64, ), ID: 5, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 64, ), Input shape (3136, 64, ) (or (3136, 576, )), Output shape (3136, 64, ), ID: 6, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 576, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (576, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 256, ), ID: 7, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 256, ) DONE
	Preparing Filter With Shape: (64, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (3136, 256, ) (or (3136, 256, )), Output shape (3136, 64, ), ID: 8, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 64, ), Input shape (3136, 64, ) (or (3136, 576, )), Output shape (3136, 64, ), ID: 9, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 576, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (576, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 256, ), ID: 10, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 256, ) DONE
	Preparing Filter With Shape: (64, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 512, ), Input shape (3136, 256, ) (or (784, 256, )), Output shape (784, 512, ), ID: 11, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 512, ) DONE
	Preparing Filter With Shape: (256, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (3136, 256, ) (or (784, 256, )), Output shape (784, 128, ), ID: 12, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 128, ), ID: 13, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 512, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 512, ), ID: 14, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 512, ) DONE
	Preparing Filter With Shape: (128, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 128, ), Input shape (784, 512, ) (or (784, 512, )), Output shape (784, 128, ), ID: 15, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (512, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 128, ), ID: 16, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 512, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 512, ), ID: 17, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 512, ) DONE
	Preparing Filter With Shape: (128, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 128, ), Input shape (784, 512, ) (or (784, 512, )), Output shape (784, 128, ), ID: 18, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (512, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 128, ), ID: 19, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 512, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 512, ), ID: 20, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 512, ) DONE
	Preparing Filter With Shape: (128, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 128, ), Input shape (784, 512, ) (or (784, 512, )), Output shape (784, 128, ), ID: 21, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (512, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 128, ), ID: 22, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 512, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 512, ), ID: 23, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 512, ) DONE
	Preparing Filter With Shape: (128, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 1024, ), Input shape (784, 512, ) (or (196, 512, )), Output shape (196, 1024, ), ID: 24, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 1024, ) DONE
	Preparing Filter With Shape: (512, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 256, ), Input shape (784, 512, ) (or (196, 512, )), Output shape (196, 256, ), ID: 25, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 256, ) DONE
	Preparing Filter With Shape: (512, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 26, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 27, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 28, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 29, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 30, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 31, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 32, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 33, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 34, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 35, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 36, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 37, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 38, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 39, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 40, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 41, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 42, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 43, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 44, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 45, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 46, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 47, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 48, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 49, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 50, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 51, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 52, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 53, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 54, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 55, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 56, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 57, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 58, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 59, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 60, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 61, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 62, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 63, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 64, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 65, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 66, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 67, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 68, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 69, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 70, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 71, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 72, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 73, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 74, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 75, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 76, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 77, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 78, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 79, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 80, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 81, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 82, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 83, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 84, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 85, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 86, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 87, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 88, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 89, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 90, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 256, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 256, ), ID: 91, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (1024, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (2304, 256, ), Input shape (196, 256, ) (or (196, 2304, )), Output shape (196, 256, ), ID: 92, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 2304, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 256, ) DONE
	Preparing Filter With Shape: (2304, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 1024, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 1024, ), ID: 93, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 1024, ) DONE
	Preparing Filter With Shape: (256, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 2048, ), Input shape (196, 1024, ) (or (49, 1024, )), Output shape (49, 2048, ), ID: 94, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 2048, ) DONE
	Preparing Filter With Shape: (1024, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 2048, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 512, ), Input shape (196, 1024, ) (or (49, 1024, )), Output shape (49, 512, ), ID: 95, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 512, ) DONE
	Preparing Filter With Shape: (1024, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (4608, 512, ), Input shape (49, 512, ) (or (49, 4608, )), Output shape (49, 512, ), ID: 96, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 4608, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (2304, 512, ) DONE
	Preparing Filter With Shape: (4608, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 2304, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 4608, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 2048, ), Input shape (49, 512, ) (or (49, 512, )), Output shape (49, 2048, ), ID: 97, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 512, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 2048, ) DONE
	Preparing Filter With Shape: (512, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 2048, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 512, ), Input shape (49, 2048, ) (or (49, 2048, )), Output shape (49, 512, ), ID: 98, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 2048, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 512, ) DONE
	Preparing Filter With Shape: (2048, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (4608, 512, ), Input shape (49, 512, ) (or (49, 4608, )), Output shape (49, 512, ), ID: 99, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 4608, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (2304, 512, ) DONE
	Preparing Filter With Shape: (4608, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 2304, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 4608, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 2048, ), Input shape (49, 512, ) (or (49, 512, )), Output shape (49, 2048, ), ID: 100, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 512, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 2048, ) DONE
	Preparing Filter With Shape: (512, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 2048, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 512, ), Input shape (49, 2048, ) (or (49, 2048, )), Output shape (49, 512, ), ID: 101, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 2048, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 512, ) DONE
	Preparing Filter With Shape: (2048, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (4608, 512, ), Input shape (49, 512, ) (or (49, 4608, )), Output shape (49, 512, ), ID: 102, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 4608, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (2304, 512, ) DONE
	Preparing Filter With Shape: (4608, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 2304, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 4608, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 2048, ), Input shape (49, 512, ) (or (49, 512, )), Output shape (49, 2048, ), ID: 103, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 512, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 2048, ) DONE
	Preparing Filter With Shape: (512, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 2048, ) DONE
Applying FC Low-Precision for Kernel shape (2048, 1000, ), Input shape (1, 2048, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW4A4
	Allocating Filter Shape: (1024, 1000, ) DONE
	Preparing Filter With Shape: (2048, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 45.8077
Initialized session in 613.363ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=932581 curr=924983 min=924983 max=932581 avg=928782 std=3799

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=915968 curr=917688 min=899552 max=982983 avg=919478 std=8596

Inference timings in us: Init: 613363, First inference: 932581, Warmup (avg): 928782, Inference (avg): 919478
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=71.9414 overall=77.9258
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  605.224	  605.224	100.000%	100.000%	 61172.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  605.224	  605.224	100.000%	100.000%	 61172.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   605.224	   100.000%	   100.000%	 61172.000	        1

Timings (microseconds): count=1 curr=605224
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     PAD	            0.026	    1.188	    1.134	  0.123%	  0.123%	     0.000	        1	[resnet101/conv1_pad/Pad]:0
	                 CONV_2D	            1.161	   19.215	   19.363	  2.106%	  2.230%	     0.000	        1	[resnet101/conv1_relu/Relu;resnet101/conv1_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv1_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv1_conv/Conv2D]:1
	                     PAD	           20.525	    3.677	    3.670	  0.399%	  2.629%	     0.000	        1	[resnet101/pool1_pad/Pad]:2
	             MAX_POOL_2D	           24.196	    0.555	    0.580	  0.063%	  2.692%	     0.000	        1	[resnet101/pool1_pool/MaxPool]:3
	                 CONV_2D	           24.778	    7.347	    7.322	  0.797%	  3.489%	     0.000	        1	[resnet101/conv2_block1_0_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block1_0_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_conv/Conv2D]:4
	                 CONV_2D	           32.101	    1.953	    1.951	  0.212%	  3.701%	     0.000	        1	[resnet101/conv2_block1_1_relu/Relu;resnet101/conv2_block1_1_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block1_1_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block1_1_conv/Conv2D]:5
	                 CONV_2D	           34.054	   14.855	   15.035	  1.636%	  5.336%	     0.000	        1	[resnet101/conv2_block1_2_relu/Relu;resnet101/conv2_block1_2_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block1_2_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block1_2_conv/Conv2D]:6
	                 CONV_2D	           49.091	    7.273	    7.373	  0.802%	  6.139%	     0.000	        1	[resnet101/conv2_block1_3_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block1_3_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv2_block1_3_conv/Conv2D]:7
	                     ADD	           56.465	    3.386	    3.424	  0.373%	  6.511%	     0.000	        1	[resnet101/conv2_block1_out/Relu;resnet101/conv2_block1_add/add]:8
	                 CONV_2D	           59.891	    6.012	    6.057	  0.659%	  7.170%	     0.000	        1	[resnet101/conv2_block2_1_relu/Relu;resnet101/conv2_block2_1_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block2_1_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block2_1_conv/Conv2D]:9
	                 CONV_2D	           65.949	   14.869	   14.967	  1.628%	  8.798%	     0.000	        1	[resnet101/conv2_block2_2_relu/Relu;resnet101/conv2_block2_2_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block2_2_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block2_2_conv/Conv2D]:10
	                 CONV_2D	           80.917	    7.321	    7.347	  0.799%	  9.597%	     0.000	        1	[resnet101/conv2_block2_3_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block2_3_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv2_block2_3_conv/Conv2D]:11
	                     ADD	           88.265	    3.453	    3.393	  0.369%	  9.966%	     0.000	        1	[resnet101/conv2_block2_out/Relu;resnet101/conv2_block2_add/add]:12
	                 CONV_2D	           91.659	    6.130	    6.076	  0.661%	 10.627%	     0.000	        1	[resnet101/conv2_block3_1_relu/Relu;resnet101/conv2_block3_1_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block3_1_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block3_1_conv/Conv2D]:13
	                 CONV_2D	           97.737	   14.869	   15.015	  1.633%	 12.261%	     0.000	        1	[resnet101/conv2_block3_2_relu/Relu;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block3_2_conv/BiasAdd;resnet101/conv2_block3_2_conv/Conv2D]:14
	                 CONV_2D	          112.753	    7.336	    7.379	  0.803%	 13.063%	     0.000	        1	[resnet101/conv2_block3_3_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block3_3_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv2_block3_3_conv/Conv2D]:15
	                     ADD	          120.133	    3.473	    3.387	  0.368%	 13.432%	     0.000	        1	[resnet101/conv2_block3_out/Relu;resnet101/conv2_block3_add/add]:16
	                 CONV_2D	          123.521	   11.884	   11.965	  1.302%	 14.734%	     0.000	        1	[resnet101/conv3_block1_0_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block1_0_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block1_0_conv/Conv2D]:17
	                 CONV_2D	          135.488	    3.288	    3.328	  0.362%	 15.096%	     0.000	        1	[resnet101/conv3_block1_1_relu/Relu;resnet101/conv3_block1_1_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block1_1_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_conv/Conv2D]:18
	                 CONV_2D	          138.817	   13.164	   13.127	  1.428%	 16.524%	     0.000	        1	[resnet101/conv3_block1_2_relu/Relu;resnet101/conv3_block1_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block1_2_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block1_2_conv/Conv2D]:19
	                 CONV_2D	          151.946	    6.435	    6.431	  0.700%	 17.223%	     0.000	        1	[resnet101/conv3_block1_3_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block1_3_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block1_3_conv/Conv2D]:20
	                     ADD	          158.378	    1.706	    1.719	  0.187%	 17.410%	     0.000	        1	[resnet101/conv3_block1_out/Relu;resnet101/conv3_block1_add/add]:21
	                 CONV_2D	          160.099	    5.748	    5.785	  0.629%	 18.040%	     0.000	        1	[resnet101/conv3_block2_1_relu/Relu;resnet101/conv3_block2_1_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block2_1_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block2_1_conv/Conv2D]:22
	                 CONV_2D	          165.885	   12.895	   13.061	  1.421%	 19.460%	     0.000	        1	[resnet101/conv3_block2_2_relu/Relu;resnet101/conv3_block2_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block2_2_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block2_2_conv/Conv2D]:23
	                 CONV_2D	          178.947	    6.372	    6.406	  0.697%	 20.157%	     0.000	        1	[resnet101/conv3_block2_3_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block2_3_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block2_3_conv/Conv2D]:24
	                     ADD	          185.354	    1.704	    1.699	  0.185%	 20.342%	     0.000	        1	[resnet101/conv3_block2_out/Relu;resnet101/conv3_block2_add/add]:25
	                 CONV_2D	          187.055	    5.720	    5.774	  0.628%	 20.970%	     0.000	        1	[resnet101/conv3_block3_1_relu/Relu;resnet101/conv3_block3_1_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block3_1_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block3_1_conv/Conv2D]:26
	                 CONV_2D	          192.830	   13.057	   13.086	  1.424%	 22.394%	     0.000	        1	[resnet101/conv3_block3_2_relu/Relu;resnet101/conv3_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block3_2_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block3_2_conv/Conv2D]:27
	                 CONV_2D	          205.918	    6.402	    6.467	  0.703%	 23.097%	     0.000	        1	[resnet101/conv3_block3_3_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block3_3_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block3_3_conv/Conv2D]:28
	                     ADD	          212.386	    1.745	    1.700	  0.185%	 23.282%	     0.000	        1	[resnet101/conv3_block3_out/Relu;resnet101/conv3_block3_add/add]:29
	                 CONV_2D	          214.087	    5.692	    5.766	  0.627%	 23.910%	     0.000	        1	[resnet101/conv3_block4_1_relu/Relu;resnet101/conv3_block4_1_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block4_1_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block4_1_conv/Conv2D]:30
	                 CONV_2D	          219.854	   12.945	   13.089	  1.424%	 25.334%	     0.000	        1	[resnet101/conv3_block4_2_relu/Relu;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block4_2_conv/BiasAdd;resnet101/conv3_block4_2_conv/Conv2D]:31
	                 CONV_2D	          232.944	    6.488	    6.387	  0.695%	 26.028%	     0.000	        1	[resnet101/conv3_block4_3_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block4_3_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block4_3_conv/Conv2D]:32
	                     ADD	          239.333	    1.659	    1.712	  0.186%	 26.215%	     0.000	        1	[resnet101/conv3_block4_out/Relu;resnet101/conv3_block4_add/add]:33
	                 CONV_2D	          241.046	   11.376	   11.419	  1.242%	 27.457%	     0.000	        1	[resnet101/conv4_block1_0_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block1_0_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block1_0_conv/Conv2D]:34
	                 CONV_2D	          252.466	    2.940	    2.937	  0.320%	 27.776%	     0.000	        1	[resnet101/conv4_block1_1_relu/Relu;resnet101/conv4_block1_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block1_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block1_1_conv/Conv2D]:35
	                 CONV_2D	          255.404	   12.560	   12.625	  1.373%	 29.150%	     0.000	        1	[resnet101/conv4_block1_2_relu/Relu;resnet101/conv4_block1_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block1_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block1_2_conv/Conv2D]:36
	                 CONV_2D	          268.031	    5.851	    5.892	  0.641%	 29.791%	     0.000	        1	[resnet101/conv4_block1_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block1_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block1_3_conv/Conv2D]:37
	                     ADD	          273.925	    0.885	    0.860	  0.094%	 29.884%	     0.000	        1	[resnet101/conv4_block1_out/Relu;resnet101/conv4_block1_add/add]:38
	                 CONV_2D	          274.786	    5.469	    5.539	  0.603%	 30.487%	     0.000	        1	[resnet101/conv4_block2_1_relu/Relu;resnet101/conv4_block2_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block2_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block2_1_conv/Conv2D]:39
	                 CONV_2D	          280.326	   12.611	   12.677	  1.379%	 31.866%	     0.000	        1	[resnet101/conv4_block2_2_relu/Relu;resnet101/conv4_block2_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block2_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block2_2_conv/Conv2D]:40
	                 CONV_2D	          293.004	    5.856	    5.905	  0.642%	 32.508%	     0.000	        1	[resnet101/conv4_block2_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block2_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block2_3_conv/Conv2D]:41
	                     ADD	          298.910	    0.851	    0.867	  0.094%	 32.603%	     0.000	        1	[resnet101/conv4_block2_out/Relu;resnet101/conv4_block2_add/add]:42
	                 CONV_2D	          299.778	    5.521	    5.550	  0.604%	 33.206%	     0.000	        1	[resnet101/conv4_block3_1_relu/Relu;resnet101/conv4_block3_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block3_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block3_1_conv/Conv2D]:43
	                 CONV_2D	          305.329	   12.520	   12.605	  1.371%	 34.578%	     0.000	        1	[resnet101/conv4_block3_2_relu/Relu;resnet101/conv4_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block3_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block3_2_conv/Conv2D]:44
	                 CONV_2D	          317.936	    5.883	    5.926	  0.645%	 35.222%	     0.000	        1	[resnet101/conv4_block3_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block3_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block3_3_conv/Conv2D]:45
	                     ADD	          323.863	    0.835	    0.869	  0.094%	 35.317%	     0.000	        1	[resnet101/conv4_block3_out/Relu;resnet101/conv4_block3_add/add]:46
	                 CONV_2D	          324.732	    5.497	    5.529	  0.601%	 35.918%	     0.000	        1	[resnet101/conv4_block4_1_relu/Relu;resnet101/conv4_block4_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block4_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block4_1_conv/Conv2D]:47
	                 CONV_2D	          330.263	   12.631	   12.645	  1.376%	 37.294%	     0.000	        1	[resnet101/conv4_block4_2_relu/Relu;resnet101/conv4_block4_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block4_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block4_2_conv/Conv2D]:48
	                 CONV_2D	          342.909	    5.864	    5.911	  0.643%	 37.937%	     0.000	        1	[resnet101/conv4_block4_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block4_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block4_3_conv/Conv2D]:49
	                     ADD	          348.821	    0.845	    0.861	  0.094%	 38.030%	     0.000	        1	[resnet101/conv4_block4_out/Relu;resnet101/conv4_block4_add/add]:50
	                 CONV_2D	          349.683	    5.492	    5.527	  0.601%	 38.632%	     0.000	        1	[resnet101/conv4_block5_1_relu/Relu;resnet101/conv4_block5_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block5_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block5_1_conv/Conv2D]:51
	                 CONV_2D	          355.211	   12.535	   12.663	  1.378%	 40.009%	     0.000	        1	[resnet101/conv4_block5_2_relu/Relu;resnet101/conv4_block5_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block5_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block5_2_conv/Conv2D]:52
	                 CONV_2D	          367.875	    5.921	    5.923	  0.644%	 40.654%	     0.000	        1	[resnet101/conv4_block5_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block5_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block5_3_conv/Conv2D]:53
	                     ADD	          373.799	    0.873	    0.860	  0.094%	 40.747%	     0.000	        1	[resnet101/conv4_block5_out/Relu;resnet101/conv4_block5_add/add]:54
	                 CONV_2D	          374.660	    5.495	    5.528	  0.601%	 41.348%	     0.000	        1	[resnet101/conv4_block6_1_relu/Relu;resnet101/conv4_block6_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block6_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block6_1_conv/Conv2D]:55
	                 CONV_2D	          380.189	   12.450	   12.642	  1.375%	 42.724%	     0.000	        1	[resnet101/conv4_block6_2_relu/Relu;resnet101/conv4_block6_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block6_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block6_2_conv/Conv2D]:56
	                 CONV_2D	          392.832	    5.773	    5.927	  0.645%	 43.368%	     0.000	        1	[resnet101/conv4_block6_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block6_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block6_3_conv/Conv2D]:57
	                     ADD	          398.760	    0.946	    0.864	  0.094%	 43.462%	     0.000	        1	[resnet101/conv4_block6_out/Relu;resnet101/conv4_block6_add/add]:58
	                 CONV_2D	          399.626	    5.425	    5.555	  0.604%	 44.067%	     0.000	        1	[resnet101/conv4_block7_1_relu/Relu;resnet101/conv4_block7_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block7_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block7_1_conv/Conv2D]:59
	                 CONV_2D	          405.182	   12.266	   12.752	  1.387%	 45.454%	     0.000	        1	[resnet101/conv4_block7_2_relu/Relu;resnet101/conv4_block7_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block7_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block7_2_conv/Conv2D]:60
	                 CONV_2D	          417.935	    5.870	    5.909	  0.643%	 46.097%	     0.000	        1	[resnet101/conv4_block7_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block7_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block7_3_conv/Conv2D]:61
	                     ADD	          423.846	    0.833	    0.868	  0.094%	 46.191%	     0.000	        1	[resnet101/conv4_block7_out/Relu;resnet101/conv4_block7_add/add]:62
	                 CONV_2D	          424.715	    5.405	    5.542	  0.603%	 46.794%	     0.000	        1	[resnet101/conv4_block8_1_relu/Relu;resnet101/conv4_block8_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block8_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block8_1_conv/Conv2D]:63
	                 CONV_2D	          430.258	   12.210	   12.668	  1.378%	 48.172%	     0.000	        1	[resnet101/conv4_block8_2_relu/Relu;resnet101/conv4_block8_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block8_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block8_2_conv/Conv2D]:64
	                 CONV_2D	          442.928	    5.849	    5.904	  0.642%	 48.815%	     0.000	        1	[resnet101/conv4_block8_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block8_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block8_3_conv/Conv2D]:65
	                     ADD	          448.833	    0.861	    0.864	  0.094%	 48.909%	     0.000	        1	[resnet101/conv4_block8_out/Relu;resnet101/conv4_block8_add/add]:66
	                 CONV_2D	          449.699	    5.416	    5.529	  0.602%	 49.510%	     0.000	        1	[resnet101/conv4_block9_1_relu/Relu;resnet101/conv4_block9_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block9_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block9_1_conv/Conv2D]:67
	                 CONV_2D	          455.229	   12.227	   12.661	  1.377%	 50.887%	     0.000	        1	[resnet101/conv4_block9_2_relu/Relu;resnet101/conv4_block9_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block9_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block9_2_conv/Conv2D]:68
	                 CONV_2D	          467.892	    5.925	    5.939	  0.646%	 51.533%	     0.000	        1	[resnet101/conv4_block9_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block9_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block9_3_conv/Conv2D]:69
	                     ADD	          473.832	    0.840	    0.858	  0.093%	 51.627%	     0.000	        1	[resnet101/conv4_block9_out/Relu;resnet101/conv4_block9_add/add]:70
	                 CONV_2D	          474.691	    5.509	    5.539	  0.603%	 52.229%	     0.000	        1	[resnet101/conv4_block10_1_relu/Relu;resnet101/conv4_block10_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block10_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block10_1_conv/Conv2D]:71
	                 CONV_2D	          480.231	   12.486	   12.635	  1.374%	 53.604%	     0.000	        1	[resnet101/conv4_block10_2_relu/Relu;resnet101/conv4_block10_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block10_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block10_2_conv/Conv2D]:72
	                 CONV_2D	          492.866	    5.923	    5.941	  0.646%	 54.250%	     0.000	        1	[resnet101/conv4_block10_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block10_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_conv/Conv2D]:73
	                     ADD	          498.809	    0.837	    0.863	  0.094%	 54.344%	     0.000	        1	[resnet101/conv4_block10_out/Relu;resnet101/conv4_block10_add/add]:74
	                 CONV_2D	          499.672	    5.555	    5.549	  0.604%	 54.948%	     0.000	        1	[resnet101/conv4_block11_1_relu/Relu;resnet101/conv4_block11_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block11_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block11_1_conv/Conv2D]:75
	                 CONV_2D	          505.223	   12.324	   12.694	  1.381%	 56.328%	     0.000	        1	[resnet101/conv4_block11_2_relu/Relu;resnet101/conv4_block11_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block11_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block11_2_conv/Conv2D]:76
	                 CONV_2D	          517.918	    5.802	    5.939	  0.646%	 56.974%	     0.000	        1	[resnet101/conv4_block11_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block11_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block11_3_conv/Conv2D]:77
	                     ADD	          523.858	    0.833	    0.863	  0.094%	 57.068%	     0.000	        1	[resnet101/conv4_block11_out/Relu;resnet101/conv4_block11_add/add]:78
	                 CONV_2D	          524.722	    5.463	    5.530	  0.602%	 57.670%	     0.000	        1	[resnet101/conv4_block12_1_relu/Relu;resnet101/conv4_block12_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block12_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block12_1_conv/Conv2D]:79
	                 CONV_2D	          530.254	   12.259	   12.644	  1.376%	 59.045%	     0.000	        1	[resnet101/conv4_block12_2_relu/Relu;resnet101/conv4_block12_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block12_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block12_2_conv/Conv2D]:80
	                 CONV_2D	          542.899	    5.869	    5.916	  0.644%	 59.689%	     0.000	        1	[resnet101/conv4_block12_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block12_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block12_3_conv/Conv2D]:81
	                     ADD	          548.817	    0.834	    0.864	  0.094%	 59.783%	     0.000	        1	[resnet101/conv4_block12_out/Relu;resnet101/conv4_block12_add/add]:82
	                 CONV_2D	          549.682	    5.418	    5.518	  0.600%	 60.383%	     0.000	        1	[resnet101/conv4_block13_1_relu/Relu;resnet101/conv4_block13_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block13_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block13_1_conv/Conv2D]:83
	                 CONV_2D	          555.202	   12.232	   12.672	  1.379%	 61.762%	     0.000	        1	[resnet101/conv4_block13_2_relu/Relu;resnet101/conv4_block13_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block13_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block13_2_conv/Conv2D]:84
	                 CONV_2D	          567.875	    5.835	    5.922	  0.644%	 62.406%	     0.000	        1	[resnet101/conv4_block13_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block13_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block13_3_conv/Conv2D]:85
	                     ADD	          573.798	    0.840	    0.860	  0.094%	 62.500%	     0.000	        1	[resnet101/conv4_block13_out/Relu;resnet101/conv4_block13_add/add]:86
	                 CONV_2D	          574.659	    5.619	    5.560	  0.605%	 63.104%	     0.000	        1	[resnet101/conv4_block14_1_relu/Relu;resnet101/conv4_block14_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block14_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block14_1_conv/Conv2D]:87
	                 CONV_2D	          580.220	   12.665	   12.669	  1.378%	 64.483%	     0.000	        1	[resnet101/conv4_block14_2_relu/Relu;resnet101/conv4_block14_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block14_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block14_2_conv/Conv2D]:88
	                 CONV_2D	          592.890	    5.809	    5.935	  0.646%	 65.128%	     0.000	        1	[resnet101/conv4_block14_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block14_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block14_3_conv/Conv2D]:89
	                     ADD	          598.827	    0.865	    0.891	  0.097%	 65.225%	     0.000	        1	[resnet101/conv4_block14_out/Relu;resnet101/conv4_block14_add/add]:90
	                 CONV_2D	          599.718	    5.395	    5.535	  0.602%	 65.827%	     0.000	        1	[resnet101/conv4_block15_1_relu/Relu;resnet101/conv4_block15_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block15_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block15_1_conv/Conv2D]:91
	                 CONV_2D	          605.255	   12.357	   12.657	  1.377%	 67.204%	     0.000	        1	[resnet101/conv4_block15_2_relu/Relu;resnet101/conv4_block15_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block15_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block15_2_conv/Conv2D]:92
	                 CONV_2D	          617.913	    5.923	    5.923	  0.644%	 67.848%	     0.000	        1	[resnet101/conv4_block15_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block15_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block15_3_conv/Conv2D]:93
	                     ADD	          623.837	    0.835	    0.865	  0.094%	 67.943%	     0.000	        1	[resnet101/conv4_block15_out/Relu;resnet101/conv4_block15_add/add]:94
	                 CONV_2D	          624.703	    5.563	    5.546	  0.603%	 68.546%	     0.000	        1	[resnet101/conv4_block16_1_relu/Relu;resnet101/conv4_block16_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block16_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block16_1_conv/Conv2D]:95
	                 CONV_2D	          630.250	   12.677	   12.711	  1.383%	 69.929%	     0.000	        1	[resnet101/conv4_block16_2_relu/Relu;resnet101/conv4_block16_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block16_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block16_2_conv/Conv2D]:96
	                 CONV_2D	          642.963	    5.964	    5.904	  0.642%	 70.571%	     0.000	        1	[resnet101/conv4_block16_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block16_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block16_3_conv/Conv2D]:97
	                     ADD	          648.868	    0.859	    0.861	  0.094%	 70.665%	     0.000	        1	[resnet101/conv4_block16_out/Relu;resnet101/conv4_block16_add/add]:98
	                 CONV_2D	          649.731	    5.641	    5.529	  0.601%	 71.266%	     0.000	        1	[resnet101/conv4_block17_1_relu/Relu;resnet101/conv4_block17_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block17_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block17_1_conv/Conv2D]:99
	                 CONV_2D	          655.261	   12.833	   12.629	  1.374%	 72.640%	     0.000	        1	[resnet101/conv4_block17_2_relu/Relu;resnet101/conv4_block17_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block17_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block17_2_conv/Conv2D]:100
	                 CONV_2D	          667.891	    5.959	    5.915	  0.643%	 73.283%	     0.000	        1	[resnet101/conv4_block17_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block17_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block17_3_conv/Conv2D]:101
	                     ADD	          673.807	    0.893	    0.864	  0.094%	 73.377%	     0.000	        1	[resnet101/conv4_block17_out/Relu;resnet101/conv4_block17_add/add]:102
	                 CONV_2D	          674.673	    5.629	    5.545	  0.603%	 73.981%	     0.000	        1	[resnet101/conv4_block18_1_relu/Relu;resnet101/conv4_block18_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block18_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block18_1_conv/Conv2D]:103
	                 CONV_2D	          680.219	   12.835	   12.677	  1.379%	 75.360%	     0.000	        1	[resnet101/conv4_block18_2_relu/Relu;resnet101/conv4_block18_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block18_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block18_2_conv/Conv2D]:104
	                 CONV_2D	          692.897	    6.091	    5.965	  0.649%	 76.009%	     0.000	        1	[resnet101/conv4_block18_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block18_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block18_3_conv/Conv2D]:105
	                     ADD	          698.864	    0.845	    0.858	  0.093%	 76.102%	     0.000	        1	[resnet101/conv4_block18_out/Relu;resnet101/conv4_block18_add/add]:106
	                 CONV_2D	          699.723	    5.666	    5.572	  0.606%	 76.708%	     0.000	        1	[resnet101/conv4_block19_1_relu/Relu;resnet101/conv4_block19_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block19_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block19_1_conv/Conv2D]:107
	                 CONV_2D	          705.296	   12.974	   12.685	  1.380%	 78.088%	     0.000	        1	[resnet101/conv4_block19_2_relu/Relu;resnet101/conv4_block19_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block19_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block19_2_conv/Conv2D]:108
	                 CONV_2D	          717.982	    6.051	    5.921	  0.644%	 78.732%	     0.000	        1	[resnet101/conv4_block19_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block19_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block19_3_conv/Conv2D]:109
	                     ADD	          723.904	    0.843	    0.860	  0.094%	 78.826%	     0.000	        1	[resnet101/conv4_block19_out/Relu;resnet101/conv4_block19_add/add]:110
	                 CONV_2D	          724.765	    5.656	    5.542	  0.603%	 79.429%	     0.000	        1	[resnet101/conv4_block20_1_relu/Relu;resnet101/conv4_block20_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block20_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block20_1_conv/Conv2D]:111
	                 CONV_2D	          730.309	   13.072	   12.658	  1.377%	 80.806%	     0.000	        1	[resnet101/conv4_block20_2_relu/Relu;resnet101/conv4_block20_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block20_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block20_2_conv/Conv2D]:112
	                 CONV_2D	          742.968	    5.925	    5.919	  0.644%	 81.450%	     0.000	        1	[resnet101/conv4_block20_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block20_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block20_3_conv/Conv2D]:113
	                     ADD	          748.888	    0.899	    0.865	  0.094%	 81.544%	     0.000	        1	[resnet101/conv4_block20_out/Relu;resnet101/conv4_block20_add/add]:114
	                 CONV_2D	          749.754	    5.590	    5.552	  0.604%	 82.148%	     0.000	        1	[resnet101/conv4_block21_1_relu/Relu;resnet101/conv4_block21_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block21_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block21_1_conv/Conv2D]:115
	                 CONV_2D	          755.307	   12.923	   12.691	  1.381%	 83.528%	     0.000	        1	[resnet101/conv4_block21_2_relu/Relu;resnet101/conv4_block21_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block21_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block21_2_conv/Conv2D]:116
	                 CONV_2D	          767.999	    5.965	    5.922	  0.644%	 84.172%	     0.000	        1	[resnet101/conv4_block21_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block21_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block21_3_conv/Conv2D]:117
	                     ADD	          773.922	    0.840	    0.863	  0.094%	 84.266%	     0.000	        1	[resnet101/conv4_block21_out/Relu;resnet101/conv4_block21_add/add]:118
	                 CONV_2D	          774.786	    5.568	    5.531	  0.602%	 84.868%	     0.000	        1	[resnet101/conv4_block22_1_relu/Relu;resnet101/conv4_block22_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block22_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block22_1_conv/Conv2D]:119
	                 CONV_2D	          780.318	   12.892	   12.690	  1.380%	 86.248%	     0.000	        1	[resnet101/conv4_block22_2_relu/Relu;resnet101/conv4_block22_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block22_2_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block22_2_conv/Conv2D]:120
	                 CONV_2D	          793.010	    5.929	    5.969	  0.649%	 86.898%	     0.000	        1	[resnet101/conv4_block22_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block22_3_conv/BiasAdd;resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block22_3_conv/Conv2D]:121
	                     ADD	          798.980	    0.884	    0.866	  0.094%	 86.992%	     0.000	        1	[resnet101/conv4_block22_out/Relu;resnet101/conv4_block22_add/add]:122
	                 CONV_2D	          799.847	    5.676	    5.563	  0.605%	 87.597%	     0.000	        1	[resnet101/conv4_block23_1_relu/Relu;resnet101/conv4_block23_1_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block23_1_conv/BiasAdd;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv4_block23_1_conv/Conv2D]:123
	                 CONV_2D	          805.411	   12.888	   12.677	  1.379%	 88.976%	     0.000	        1	[resnet101/conv4_block23_2_relu/Relu;resnet101/conv4_block23_2_bn/FusedBatchNormV3;resnet101/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block23_2_conv/BiasAdd;resnet101/conv4_block23_2_conv/Conv2D]:124
	                 CONV_2D	          818.090	    6.111	    5.918	  0.644%	 89.620%	     0.000	        1	[resnet101/conv4_block23_3_bn/FusedBatchNormV3;resnet101/conv4_block10_3_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv4_block23_3_conv/BiasAdd;resnet101/conv4_block23_3_conv/Conv2D]:125
	                     ADD	          824.009	    0.949	    0.860	  0.094%	 89.714%	     0.000	        1	[resnet101/conv4_block23_out/Relu;resnet101/conv4_block23_add/add]:126
	                 CONV_2D	          824.870	   12.276	   12.070	  1.313%	 91.027%	     0.000	        1	[resnet101/conv5_block1_0_bn/FusedBatchNormV3;resnet101/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block1_0_conv/BiasAdd;resnet101/conv5_block3_3_bn/FusedBatchNormV3;resnet101/conv5_block1_0_conv/Conv2D]:127
	                 CONV_2D	          836.942	    3.087	    3.082	  0.335%	 91.362%	     0.000	        1	[resnet101/conv5_block1_1_relu/Relu;resnet101/conv5_block1_1_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block1_1_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv5_block1_1_conv/Conv2D]:128
	                 CONV_2D	          840.025	   13.901	   13.685	  1.489%	 92.851%	     0.000	        1	[resnet101/conv5_block1_2_relu/Relu;resnet101/conv5_block1_2_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block1_2_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv5_block1_2_conv/Conv2D]:129
	                 CONV_2D	          853.711	    6.183	    6.194	  0.674%	 93.524%	     0.000	        1	[resnet101/conv5_block1_3_bn/FusedBatchNormV3;resnet101/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block1_3_conv/BiasAdd;resnet101/conv5_block3_3_bn/FusedBatchNormV3;resnet101/conv5_block1_3_conv/Conv2D]:130
	                     ADD	          859.906	    0.471	    0.440	  0.048%	 93.572%	     0.000	        1	[resnet101/conv5_block1_out/Relu;resnet101/conv5_block1_add/add]:131
	                 CONV_2D	          860.347	    5.943	    5.976	  0.650%	 94.222%	     0.000	        1	[resnet101/conv5_block2_1_relu/Relu;resnet101/conv5_block2_1_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block2_1_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv5_block2_1_conv/Conv2D]:132
	                 CONV_2D	          866.325	   13.703	   13.694	  1.490%	 95.712%	     0.000	        1	[resnet101/conv5_block2_2_relu/Relu;resnet101/conv5_block2_2_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block2_2_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv5_block2_2_conv/Conv2D]:133
	                 CONV_2D	          880.020	    6.103	    6.168	  0.671%	 96.383%	     0.000	        1	[resnet101/conv5_block2_3_bn/FusedBatchNormV3;resnet101/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block2_3_conv/BiasAdd;resnet101/conv5_block3_3_bn/FusedBatchNormV3;resnet101/conv5_block2_3_conv/Conv2D]:134
	                     ADD	          886.189	    0.472	    0.447	  0.049%	 96.432%	     0.000	        1	[resnet101/conv5_block2_out/Relu;resnet101/conv5_block2_add/add]:135
	                 CONV_2D	          886.637	    5.946	    5.989	  0.652%	 97.083%	     0.000	        1	[resnet101/conv5_block3_1_relu/Relu;resnet101/conv5_block3_1_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block3_1_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv5_block3_1_conv/Conv2D]:136
	                 CONV_2D	          892.628	   13.497	   13.669	  1.487%	 98.570%	     0.000	        1	[resnet101/conv5_block3_2_relu/Relu;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block3_2_conv/BiasAdd;resnet101/conv5_block3_2_conv/Conv2D]:137
	                 CONV_2D	          906.298	    6.149	    6.150	  0.669%	 99.239%	     0.000	        1	[resnet101/conv5_block3_3_bn/FusedBatchNormV3;resnet101/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block3_3_conv/BiasAdd;resnet101/conv5_block3_3_conv/Conv2D]:138
	                     ADD	          912.449	    0.437	    0.443	  0.048%	 99.287%	     0.000	        1	[resnet101/conv5_block3_out/Relu;resnet101/conv5_block3_add/add]:139
	                    MEAN	          912.893	    5.583	    5.565	  0.605%	 99.893%	     0.000	        1	[resnet101/avg_pool/Mean]:140
	         FULLY_CONNECTED	          918.459	    0.988	    0.969	  0.105%	 99.998%	     0.000	        1	[resnet101/predictions/MatMul;resnet101/predictions/BiasAdd]:141
	                 SOFTMAX	          919.429	    0.016	    0.016	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:142

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            1.161	   19.215	   19.363	  2.106%	  2.106%	     0.000	        1	[resnet101/conv1_relu/Relu;resnet101/conv1_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv1_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv1_conv/Conv2D]:1
	                 CONV_2D	           34.054	   14.855	   15.035	  1.636%	  3.742%	     0.000	        1	[resnet101/conv2_block1_2_relu/Relu;resnet101/conv2_block1_2_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block1_2_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block1_2_conv/Conv2D]:6
	                 CONV_2D	           97.737	   14.869	   15.015	  1.633%	  5.375%	     0.000	        1	[resnet101/conv2_block3_2_relu/Relu;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block3_2_conv/BiasAdd;resnet101/conv2_block3_2_conv/Conv2D]:14
	                 CONV_2D	           65.949	   14.869	   14.967	  1.628%	  7.003%	     0.000	        1	[resnet101/conv2_block2_2_relu/Relu;resnet101/conv2_block2_2_bn/FusedBatchNormV3;resnet101/conv1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv2_block2_2_conv/BiasAdd;resnet101/conv2_block3_2_bn/FusedBatchNormV3;resnet101/conv2_block2_2_conv/Conv2D]:10
	                 CONV_2D	          866.325	   13.703	   13.694	  1.490%	  8.493%	     0.000	        1	[resnet101/conv5_block2_2_relu/Relu;resnet101/conv5_block2_2_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block2_2_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv5_block2_2_conv/Conv2D]:133
	                 CONV_2D	          840.025	   13.901	   13.685	  1.489%	  9.982%	     0.000	        1	[resnet101/conv5_block1_2_relu/Relu;resnet101/conv5_block1_2_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block1_2_conv/BiasAdd;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv5_block1_2_conv/Conv2D]:129
	                 CONV_2D	          892.628	   13.497	   13.669	  1.487%	 11.469%	     0.000	        1	[resnet101/conv5_block3_2_relu/Relu;resnet101/conv5_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv5_block3_2_conv/BiasAdd;resnet101/conv5_block3_2_conv/Conv2D]:137
	                 CONV_2D	          138.817	   13.164	   13.127	  1.428%	 12.897%	     0.000	        1	[resnet101/conv3_block1_2_relu/Relu;resnet101/conv3_block1_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block1_2_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block1_2_conv/Conv2D]:19
	                 CONV_2D	          219.854	   12.945	   13.089	  1.424%	 14.321%	     0.000	        1	[resnet101/conv3_block4_2_relu/Relu;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block4_2_conv/BiasAdd;resnet101/conv3_block4_2_conv/Conv2D]:31
	                 CONV_2D	          192.830	   13.057	   13.086	  1.424%	 15.745%	     0.000	        1	[resnet101/conv3_block3_2_relu/Relu;resnet101/conv3_block3_2_bn/FusedBatchNormV3;resnet101/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp;resnet101/conv3_block3_2_conv/BiasAdd;resnet101/conv3_block4_2_bn/FusedBatchNormV3;resnet101/conv3_block3_2_conv/Conv2D]:27

Number of nodes executed: 143
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	      104	   869.021	    94.544%	    94.544%	     0.000	      104
	                     ADD	       33	    38.222	     4.158%	    98.702%	     0.000	       33
	                    MEAN	        1	     5.564	     0.605%	    99.307%	     0.000	        1
	                     PAD	        2	     4.803	     0.523%	    99.830%	     0.000	        2
	         FULLY_CONNECTED	        1	     0.969	     0.105%	    99.935%	     0.000	        1
	             MAX_POOL_2D	        1	     0.580	     0.063%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.016	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=915755 curr=917444 min=899330 max=982755 avg=919241 std=8593
Memory (bytes): count=0
143 nodes observed



munmap_chunk(): invalid pointer
[ perf record: Woken up 266 times to write data ]
Warning:
Processed 373340 events and lost 5 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 67.167 MB /tmp/data.record (372715 samples) ]

98.208

