STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (147, 64, ), Input shape (52900, 3, ) (or (12544, 147, )), Output shape (12544, 64, ), ID: 0, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (12544, 147, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (160, 64, ) DONE
	Preparing Filter With Shape: (147, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 128, ), ID: 1, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 2, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (96, 128, ), Input shape (3136, 96, ) (or (3136, 96, )), Output shape (3136, 128, ), ID: 3, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 96, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (48, 128, ) DONE
	Preparing Filter With Shape: (96, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 4, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (3136, 128, ) (or (3136, 128, )), Output shape (3136, 128, ), ID: 5, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 6, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (3136, 160, ) (or (3136, 160, )), Output shape (3136, 128, ), ID: 7, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 8, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (3136, 192, ) (or (3136, 192, )), Output shape (3136, 128, ), ID: 9, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 10, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (3136, 224, ) (or (3136, 224, )), Output shape (3136, 128, ), ID: 11, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (112, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 112, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 12, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (3136, 256, ) (or (3136, 256, )), Output shape (3136, 128, ), ID: 13, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 128, ), ID: 14, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 15, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (784, 160, ) (or (784, 160, )), Output shape (784, 128, ), ID: 16, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 17, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (784, 192, ) (or (784, 192, )), Output shape (784, 128, ), ID: 18, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 19, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (784, 224, ) (or (784, 224, )), Output shape (784, 128, ), ID: 20, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (112, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 112, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 21, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (784, 256, ) (or (784, 256, )), Output shape (784, 128, ), ID: 22, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 23, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (784, 288, ) (or (784, 288, )), Output shape (784, 128, ), ID: 24, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 144, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 25, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (784, 320, ) (or (784, 320, )), Output shape (784, 128, ), ID: 26, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 27, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (784, 352, ) (or (784, 352, )), Output shape (784, 128, ), ID: 28, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (176, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 176, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 29, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (784, 384, ) (or (784, 384, )), Output shape (784, 128, ), ID: 30, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 31, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (784, 416, ) (or (784, 416, )), Output shape (784, 128, ), ID: 32, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (208, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 208, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 33, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (784, 448, ) (or (784, 448, )), Output shape (784, 128, ), ID: 34, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 35, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (784, 480, ) (or (784, 480, )), Output shape (784, 128, ), ID: 36, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (240, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 240, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 37, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 256, ), Input shape (784, 512, ) (or (784, 512, )), Output shape (784, 256, ), ID: 38, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 256, ) DONE
	Preparing Filter With Shape: (512, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 128, ), ID: 39, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 40, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (196, 288, ) (or (196, 288, )), Output shape (196, 128, ), ID: 41, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 144, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 42, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (196, 320, ) (or (196, 320, )), Output shape (196, 128, ), ID: 43, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 44, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (196, 352, ) (or (196, 352, )), Output shape (196, 128, ), ID: 45, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (176, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 176, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 46, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (196, 384, ) (or (196, 384, )), Output shape (196, 128, ), ID: 47, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 48, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (196, 416, ) (or (196, 416, )), Output shape (196, 128, ), ID: 49, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (208, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 208, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 50, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (196, 448, ) (or (196, 448, )), Output shape (196, 128, ), ID: 51, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 52, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (196, 480, ) (or (196, 480, )), Output shape (196, 128, ), ID: 53, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (240, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 240, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 54, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 128, ), Input shape (196, 512, ) (or (196, 512, )), Output shape (196, 128, ), ID: 55, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (512, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 56, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (544, 128, ), Input shape (196, 544, ) (or (196, 544, )), Output shape (196, 128, ), ID: 57, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 544, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (272, 128, ) DONE
	Preparing Filter With Shape: (544, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 272, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 58, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 128, ), Input shape (196, 576, ) (or (196, 576, )), Output shape (196, 128, ), ID: 59, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 576, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 128, ) DONE
	Preparing Filter With Shape: (576, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 60, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (608, 128, ), Input shape (196, 608, ) (or (196, 608, )), Output shape (196, 128, ), ID: 61, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 608, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (304, 128, ) DONE
	Preparing Filter With Shape: (608, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 304, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 62, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (640, 128, ), Input shape (196, 640, ) (or (196, 640, )), Output shape (196, 128, ), ID: 63, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 640, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (320, 128, ) DONE
	Preparing Filter With Shape: (640, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 320, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 64, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (672, 128, ), Input shape (196, 672, ) (or (196, 672, )), Output shape (196, 128, ), ID: 65, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 672, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (336, 128, ) DONE
	Preparing Filter With Shape: (672, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 336, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 66, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (704, 128, ), Input shape (196, 704, ) (or (196, 704, )), Output shape (196, 128, ), ID: 67, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 704, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (352, 128, ) DONE
	Preparing Filter With Shape: (704, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 352, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 68, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (736, 128, ), Input shape (196, 736, ) (or (196, 736, )), Output shape (196, 128, ), ID: 69, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 736, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (368, 128, ) DONE
	Preparing Filter With Shape: (736, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 368, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 70, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (196, 768, ) (or (196, 768, )), Output shape (196, 128, ), ID: 71, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 768, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 72, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (800, 128, ), Input shape (196, 800, ) (or (196, 800, )), Output shape (196, 128, ), ID: 73, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 800, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (400, 128, ) DONE
	Preparing Filter With Shape: (800, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 400, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 74, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (832, 128, ), Input shape (196, 832, ) (or (196, 832, )), Output shape (196, 128, ), ID: 75, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 832, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (416, 128, ) DONE
	Preparing Filter With Shape: (832, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 416, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 76, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 128, ), Input shape (196, 864, ) (or (196, 864, )), Output shape (196, 128, ), ID: 77, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 864, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 128, ) DONE
	Preparing Filter With Shape: (864, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 432, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 78, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (196, 896, ) (or (196, 896, )), Output shape (196, 128, ), ID: 79, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 896, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 448, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 80, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (196, 928, ) (or (196, 928, )), Output shape (196, 128, ), ID: 81, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 928, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (464, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 464, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 82, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (196, 960, ) (or (196, 960, )), Output shape (196, 128, ), ID: 83, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 960, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 480, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 84, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (196, 992, ) (or (196, 992, )), Output shape (196, 128, ), ID: 85, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 992, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (496, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 496, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 86, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 128, ), ID: 87, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 88, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (196, 1056, ) (or (196, 1056, )), Output shape (196, 128, ), ID: 89, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1056, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (528, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 528, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 90, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (196, 1088, ) (or (196, 1088, )), Output shape (196, 128, ), ID: 91, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1088, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (544, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 544, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 92, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (196, 1120, ) (or (196, 1120, )), Output shape (196, 128, ), ID: 93, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1120, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 560, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 94, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (196, 1152, ) (or (196, 1152, )), Output shape (196, 128, ), ID: 95, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 96, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (196, 1184, ) (or (196, 1184, )), Output shape (196, 128, ), ID: 97, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1184, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (592, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 592, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 98, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (196, 1216, ) (or (196, 1216, )), Output shape (196, 128, ), ID: 99, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1216, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 608, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 100, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (196, 1248, ) (or (196, 1248, )), Output shape (196, 128, ), ID: 101, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1248, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (624, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 624, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 102, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (196, 1280, ) (or (196, 1280, )), Output shape (196, 128, ), ID: 103, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 104, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (196, 1312, ) (or (196, 1312, )), Output shape (196, 128, ), ID: 105, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1312, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (656, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 656, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 106, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (196, 1344, ) (or (196, 1344, )), Output shape (196, 128, ), ID: 107, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1344, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 672, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 108, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (196, 1376, ) (or (196, 1376, )), Output shape (196, 128, ), ID: 109, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1376, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (688, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 688, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 110, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (196, 1408, ) (or (196, 1408, )), Output shape (196, 128, ), ID: 111, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1408, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (704, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 704, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 112, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (196, 1440, ) (or (196, 1440, )), Output shape (196, 128, ), ID: 113, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1440, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (720, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 720, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 114, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (196, 1472, ) (or (196, 1472, )), Output shape (196, 128, ), ID: 115, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1472, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 736, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 116, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (196, 1504, ) (or (196, 1504, )), Output shape (196, 128, ), ID: 117, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1504, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (752, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 752, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 118, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (196, 1536, ) (or (196, 1536, )), Output shape (196, 128, ), ID: 119, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1536, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 768, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 120, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (196, 1568, ) (or (196, 1568, )), Output shape (196, 128, ), ID: 121, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1568, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (784, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 784, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 122, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (196, 1600, ) (or (196, 1600, )), Output shape (196, 128, ), ID: 123, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1600, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (800, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 800, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 124, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (196, 1632, ) (or (196, 1632, )), Output shape (196, 128, ), ID: 125, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1632, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (816, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 816, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 126, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (196, 1664, ) (or (196, 1664, )), Output shape (196, 128, ), ID: 127, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1664, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (832, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 832, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 128, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (196, 1696, ) (or (196, 1696, )), Output shape (196, 128, ), ID: 129, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1696, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (848, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 848, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 130, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (196, 1728, ) (or (196, 1728, )), Output shape (196, 128, ), ID: 131, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 132, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (196, 1760, ) (or (196, 1760, )), Output shape (196, 128, ), ID: 133, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1760, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (880, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 880, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 134, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 896, ), Input shape (196, 1792, ) (or (196, 1792, )), Output shape (196, 896, ), ID: 135, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1792, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 896, ) DONE
	Preparing Filter With Shape: (1792, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 896, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (49, 896, ) (or (49, 896, )), Output shape (49, 128, ), ID: 136, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 137, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (49, 928, ) (or (49, 928, )), Output shape (49, 128, ), ID: 138, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 928, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (464, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 464, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 139, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (49, 960, ) (or (49, 960, )), Output shape (49, 128, ), ID: 140, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 960, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 480, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 960, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 141, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (49, 992, ) (or (49, 992, )), Output shape (49, 128, ), ID: 142, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 992, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (496, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 496, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 992, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 143, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (49, 1024, ) (or (49, 1024, )), Output shape (49, 128, ), ID: 144, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 145, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (49, 1056, ) (or (49, 1056, )), Output shape (49, 128, ), ID: 146, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1056, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (528, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 528, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1056, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 147, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (49, 1088, ) (or (49, 1088, )), Output shape (49, 128, ), ID: 148, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1088, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (544, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 544, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1088, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 149, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (49, 1120, ) (or (49, 1120, )), Output shape (49, 128, ), ID: 150, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 151, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (49, 1152, ) (or (49, 1152, )), Output shape (49, 128, ), ID: 152, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 153, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (49, 1184, ) (or (49, 1184, )), Output shape (49, 128, ), ID: 154, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1184, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (592, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 592, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1184, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 155, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (49, 1216, ) (or (49, 1216, )), Output shape (49, 128, ), ID: 156, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1216, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 157, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (49, 1248, ) (or (49, 1248, )), Output shape (49, 128, ), ID: 158, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1248, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (624, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 624, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1248, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 159, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (49, 1280, ) (or (49, 1280, )), Output shape (49, 128, ), ID: 160, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1280, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 640, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1280, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 161, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (49, 1312, ) (or (49, 1312, )), Output shape (49, 128, ), ID: 162, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1312, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (656, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 656, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1312, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 163, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (49, 1344, ) (or (49, 1344, )), Output shape (49, 128, ), ID: 164, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 165, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (49, 1376, ) (or (49, 1376, )), Output shape (49, 128, ), ID: 166, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1376, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (688, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 688, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1376, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 167, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (49, 1408, ) (or (49, 1408, )), Output shape (49, 128, ), ID: 168, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1408, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (704, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 704, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1408, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 169, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (49, 1440, ) (or (49, 1440, )), Output shape (49, 128, ), ID: 170, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1440, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (720, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 720, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1440, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 171, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (49, 1472, ) (or (49, 1472, )), Output shape (49, 128, ), ID: 172, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1472, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 736, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1472, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 173, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (49, 1504, ) (or (49, 1504, )), Output shape (49, 128, ), ID: 174, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1504, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (752, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 752, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1504, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 175, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (49, 1536, ) (or (49, 1536, )), Output shape (49, 128, ), ID: 176, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1536, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1536, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 177, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (49, 1568, ) (or (49, 1568, )), Output shape (49, 128, ), ID: 178, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1568, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (784, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 784, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1568, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 179, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (49, 1600, ) (or (49, 1600, )), Output shape (49, 128, ), ID: 180, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1600, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (800, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 800, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1600, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 181, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (49, 1632, ) (or (49, 1632, )), Output shape (49, 128, ), ID: 182, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1632, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (816, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 816, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1632, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 183, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (49, 1664, ) (or (49, 1664, )), Output shape (49, 128, ), ID: 184, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1664, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (832, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 832, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1664, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 185, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (49, 1696, ) (or (49, 1696, )), Output shape (49, 128, ), ID: 186, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1696, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (848, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 848, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1696, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 187, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (49, 1728, ) (or (49, 1728, )), Output shape (49, 128, ), ID: 188, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 864, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 189, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (49, 1760, ) (or (49, 1760, )), Output shape (49, 128, ), ID: 190, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1760, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (880, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 880, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1760, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 191, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 128, ), Input shape (49, 1792, ) (or (49, 1792, )), Output shape (49, 128, ), ID: 192, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1792, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (1792, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1792, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 193, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1824, 128, ), Input shape (49, 1824, ) (or (49, 1824, )), Output shape (49, 128, ), ID: 194, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1824, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (912, 128, ) DONE
	Preparing Filter With Shape: (1824, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 912, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1824, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 195, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1856, 128, ), Input shape (49, 1856, ) (or (49, 1856, )), Output shape (49, 128, ), ID: 196, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1856, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (928, 128, ) DONE
	Preparing Filter With Shape: (1856, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1856, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 197, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1888, 128, ), Input shape (49, 1888, ) (or (49, 1888, )), Output shape (49, 128, ), ID: 198, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1888, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (944, 128, ) DONE
	Preparing Filter With Shape: (1888, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 944, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1888, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 199, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying FC Low-Precision for Kernel shape (1920, 1000, ), Input shape (1, 1920, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW4A4
	Allocating Filter Shape: (960, 1000, ) DONE
	Preparing Filter With Shape: (1920, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 960, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1920, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 20.5199
Initialized session in 168.128ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=681473 curr=667395 min=667395 max=681473 avg=674434 std=7039

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=667605 curr=667857 min=666688 max=672456 avg=667783 std=708

Inference timings in us: Init: 168128, First inference: 681473, Warmup (avg): 674434, Inference (avg): 667783
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=35.3047 overall=43.6328
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  160.614	  160.614	100.000%	100.000%	 21372.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  160.614	  160.614	100.000%	100.000%	 21372.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   160.614	   100.000%	   100.000%	 21372.000	        1

Timings (microseconds): count=1 curr=160614
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     PAD	            0.022	    1.109	    1.127	  0.169%	  0.169%	     0.000	        1	[densenet201/zero_padding2d/Pad]:0
	                 CONV_2D	            1.150	   18.909	   18.864	  2.827%	  2.995%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                     PAD	           20.015	    3.605	    3.649	  0.547%	  3.542%	     0.000	        1	[densenet201/zero_padding2d_1/Pad]:2
	             MAX_POOL_2D	           23.665	    0.621	    0.574	  0.086%	  3.628%	     0.000	        1	[densenet201/pool1/MaxPool]:3
	                     MUL	           24.240	    0.598	    0.609	  0.091%	  3.719%	     0.000	        1	[densenet201/conv2_block1_0_bn/FusedBatchNormV31]:4
	                     ADD	           24.849	    0.838	    0.862	  0.129%	  3.848%	     0.000	        1	[densenet201/conv2_block1_0_relu/Relu;densenet201/conv2_block1_0_bn/FusedBatchNormV3]:5
	                 CONV_2D	           25.711	    3.719	    3.712	  0.556%	  4.405%	     0.000	        1	[densenet201/conv2_block1_1_relu/Relu;densenet201/conv2_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block1_1_conv/Conv2D]:6
	                 CONV_2D	           29.424	   16.240	   16.101	  2.413%	  6.817%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	           CONCATENATION	           45.526	    0.190	    0.189	  0.028%	  6.846%	     0.000	        1	[densenet201/conv2_block1_concat/concat]:8
	                     MUL	           45.716	    0.876	    0.894	  0.134%	  6.980%	     0.000	        1	[densenet201/conv2_block2_0_bn/FusedBatchNormV31]:9
	                     ADD	           46.611	    1.299	    1.262	  0.189%	  7.169%	     0.000	        1	[densenet201/conv2_block2_0_relu/Relu;densenet201/conv2_block2_0_bn/FusedBatchNormV3]:10
	                 CONV_2D	           47.874	    4.979	    5.033	  0.754%	  7.923%	     0.000	        1	[densenet201/conv2_block2_1_relu/Relu;densenet201/conv2_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block2_1_conv/Conv2D]:11
	                 CONV_2D	           52.909	   16.393	   16.429	  2.462%	 10.385%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	           CONCATENATION	           69.339	    0.206	    0.208	  0.031%	 10.416%	     0.000	        1	[densenet201/conv2_block2_concat/concat]:13
	                     MUL	           69.547	    1.139	    1.168	  0.175%	 10.591%	     0.000	        1	[densenet201/conv2_block3_0_bn/FusedBatchNormV3]:14
	                     ADD	           70.716	    1.717	    1.680	  0.252%	 10.842%	     0.000	        1	[densenet201/conv2_block3_0_relu/Relu;densenet201/conv2_block3_0_bn/FusedBatchNormV3]:15
	                 CONV_2D	           72.396	    6.350	    6.431	  0.964%	 11.806%	     0.000	        1	[densenet201/conv2_block3_1_relu/Relu;densenet201/conv2_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block3_1_conv/Conv2D]:16
	                 CONV_2D	           78.828	   16.082	   16.060	  2.407%	 14.213%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	           CONCATENATION	           94.890	    0.355	    0.366	  0.055%	 14.267%	     0.000	        1	[densenet201/conv2_block3_concat/concat]:18
	                     MUL	           95.257	    1.505	    1.455	  0.218%	 14.485%	     0.000	        1	[densenet201/conv2_block4_0_bn/FusedBatchNormV3]:19
	                     ADD	           96.713	    2.032	    2.084	  0.312%	 14.798%	     0.000	        1	[densenet201/conv2_block4_0_relu/Relu;densenet201/conv2_block4_0_bn/FusedBatchNormV3]:20
	                 CONV_2D	           98.798	    7.808	    7.704	  1.154%	 15.952%	     0.000	        1	[densenet201/conv2_block4_1_relu/Relu;densenet201/conv2_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block4_1_conv/Conv2D]:21
	                 CONV_2D	          106.502	   16.011	   16.081	  2.410%	 18.362%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	           CONCATENATION	          122.585	    0.428	    0.442	  0.066%	 18.428%	     0.000	        1	[densenet201/conv2_block4_concat/concat]:23
	                     MUL	          123.027	    1.748	    1.743	  0.261%	 18.689%	     0.000	        1	[densenet201/conv2_block5_0_bn/FusedBatchNormV3]:24
	                     ADD	          124.771	    2.465	    2.488	  0.373%	 19.062%	     0.000	        1	[densenet201/conv2_block5_0_relu/Relu;densenet201/conv2_block5_0_bn/FusedBatchNormV3]:25
	                 CONV_2D	          127.261	    9.072	    9.049	  1.356%	 20.418%	     0.000	        1	[densenet201/conv2_block5_1_relu/Relu;densenet201/conv2_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block5_1_conv/Conv2D]:26
	                 CONV_2D	          136.310	   15.956	   15.985	  2.395%	 22.813%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	           CONCATENATION	          152.296	    0.505	    0.504	  0.076%	 22.889%	     0.000	        1	[densenet201/conv2_block5_concat/concat]:28
	                     MUL	          152.802	    1.974	    2.021	  0.303%	 23.191%	     0.000	        1	[densenet201/conv2_block6_0_bn/FusedBatchNormV3]:29
	                     ADD	          154.824	    2.914	    2.897	  0.434%	 23.625%	     0.000	        1	[densenet201/conv2_block6_0_relu/Relu;densenet201/conv2_block6_0_bn/FusedBatchNormV3]:30
	                 CONV_2D	          157.722	   10.412	   10.401	  1.559%	 25.184%	     0.000	        1	[densenet201/conv2_block6_1_relu/Relu;densenet201/conv2_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block6_1_conv/Conv2D]:31
	                 CONV_2D	          168.125	   16.368	   16.463	  2.467%	 27.651%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	           CONCATENATION	          184.590	    0.670	    0.595	  0.089%	 27.740%	     0.000	        1	[densenet201/conv2_block6_concat/concat]:33
	                     MUL	          185.186	    2.261	    2.315	  0.347%	 28.087%	     0.000	        1	[densenet201/pool2_bn/FusedBatchNormV3]:34
	                     ADD	          187.502	    3.304	    3.315	  0.497%	 28.584%	     0.000	        1	[densenet201/pool2_relu/Relu;densenet201/pool2_bn/FusedBatchNormV3]:35
	                 CONV_2D	          190.818	   11.787	   11.798	  1.768%	 30.351%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	         AVERAGE_POOL_2D	          202.617	    0.896	    0.910	  0.136%	 30.488%	     0.000	        1	[densenet201/pool2_pool/AvgPool]:37
	                     MUL	          203.528	    0.296	    0.302	  0.045%	 30.533%	     0.000	        1	[densenet201/conv3_block1_0_bn/FusedBatchNormV3]:38
	                     ADD	          203.831	    0.486	    0.429	  0.064%	 30.597%	     0.000	        1	[densenet201/conv3_block1_0_relu/Relu;densenet201/conv3_block1_0_bn/FusedBatchNormV3]:39
	                 CONV_2D	          204.260	    1.640	    1.678	  0.251%	 30.849%	     0.000	        1	[densenet201/conv3_block1_1_relu/Relu;densenet201/conv3_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block1_1_conv/Conv2D]:40
	                 CONV_2D	          205.938	    3.670	    3.721	  0.558%	 31.406%	     0.000	        1	[densenet201/conv3_block1_2_conv/Conv2D1]:41
	           CONCATENATION	          209.661	    0.128	    0.129	  0.019%	 31.426%	     0.000	        1	[densenet201/conv3_block1_concat/concat]:42
	                     MUL	          209.791	    0.370	    0.375	  0.056%	 31.482%	     0.000	        1	[densenet201/conv3_block2_0_bn/FusedBatchNormV31]:43
	                     ADD	          210.167	    0.513	    0.522	  0.078%	 31.560%	     0.000	        1	[densenet201/conv3_block2_0_relu/Relu;densenet201/conv3_block2_0_bn/FusedBatchNormV3]:44
	                 CONV_2D	          210.690	    2.054	    1.987	  0.298%	 31.858%	     0.000	        1	[densenet201/conv3_block2_1_relu/Relu;densenet201/conv3_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block2_1_conv/Conv2D]:45
	                 CONV_2D	          212.678	    3.687	    3.686	  0.552%	 32.410%	     0.000	        1	[densenet201/conv3_block2_2_conv/Conv2D1]:46
	           CONCATENATION	          216.365	    0.169	    0.180	  0.027%	 32.437%	     0.000	        1	[densenet201/conv3_block2_concat/concat]:47
	                     MUL	          216.546	    0.436	    0.442	  0.066%	 32.503%	     0.000	        1	[densenet201/conv3_block3_0_bn/FusedBatchNormV31]:48
	                     ADD	          216.988	    0.616	    0.628	  0.094%	 32.597%	     0.000	        1	[densenet201/conv3_block3_0_relu/Relu;densenet201/conv3_block3_0_bn/FusedBatchNormV3]:49
	                 CONV_2D	          217.617	    2.297	    2.318	  0.347%	 32.945%	     0.000	        1	[densenet201/conv3_block3_1_relu/Relu;densenet201/conv3_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block3_1_conv/Conv2D]:50
	                 CONV_2D	          219.936	    3.662	    3.725	  0.558%	 33.503%	     0.000	        1	[densenet201/conv3_block3_2_conv/Conv2D1]:51
	           CONCATENATION	          223.663	    0.186	    0.201	  0.030%	 33.533%	     0.000	        1	[densenet201/conv3_block3_concat/concat]:52
	                     MUL	          223.864	    0.689	    0.520	  0.078%	 33.611%	     0.000	        1	[densenet201/conv3_block4_0_bn/FusedBatchNormV31]:53
	                     ADD	          224.385	    0.720	    0.721	  0.108%	 33.719%	     0.000	        1	[densenet201/conv3_block4_0_relu/Relu;densenet201/conv3_block4_0_bn/FusedBatchNormV3]:54
	                 CONV_2D	          225.106	    2.597	    2.648	  0.397%	 34.116%	     0.000	        1	[densenet201/conv3_block4_1_relu/Relu;densenet201/conv3_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block4_1_conv/Conv2D]:55
	                 CONV_2D	          227.755	    3.712	    3.698	  0.554%	 34.670%	     0.000	        1	[densenet201/conv3_block4_2_conv/Conv2D1]:56
	           CONCATENATION	          231.454	    0.230	    0.244	  0.037%	 34.706%	     0.000	        1	[densenet201/conv3_block4_concat/concat]:57
	                     MUL	          231.699	    0.598	    0.584	  0.088%	 34.794%	     0.000	        1	[densenet201/conv3_block5_0_bn/FusedBatchNormV3]:58
	                     ADD	          232.284	    0.817	    0.829	  0.124%	 34.918%	     0.000	        1	[densenet201/conv3_block5_0_relu/Relu;densenet201/conv3_block5_0_bn/FusedBatchNormV3]:59
	                 CONV_2D	          233.113	    3.045	    2.984	  0.447%	 35.365%	     0.000	        1	[densenet201/conv3_block5_1_relu/Relu;densenet201/conv3_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block5_1_conv/Conv2D]:60
	                 CONV_2D	          236.098	    3.736	    3.753	  0.562%	 35.927%	     0.000	        1	[densenet201/conv3_block5_2_conv/Conv2D1]:61
	           CONCATENATION	          239.852	    0.260	    0.252	  0.038%	 35.965%	     0.000	        1	[densenet201/conv3_block5_concat/concat]:62
	                     MUL	          240.105	    0.645	    0.655	  0.098%	 36.063%	     0.000	        1	[densenet201/conv3_block6_0_bn/FusedBatchNormV3]:63
	                     ADD	          240.760	    0.919	    0.950	  0.142%	 36.206%	     0.000	        1	[densenet201/conv3_block6_0_relu/Relu;densenet201/conv3_block6_0_bn/FusedBatchNormV3]:64
	                 CONV_2D	          241.711	    3.305	    3.315	  0.497%	 36.702%	     0.000	        1	[densenet201/conv3_block6_1_relu/Relu;densenet201/conv3_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block6_1_conv/Conv2D]:65
	                 CONV_2D	          245.026	    3.820	    3.798	  0.569%	 37.271%	     0.000	        1	[densenet201/conv3_block6_2_conv/Conv2D1]:66
	           CONCATENATION	          248.825	    0.317	    0.312	  0.047%	 37.318%	     0.000	        1	[densenet201/conv3_block6_concat/concat]:67
	                     MUL	          249.139	    0.715	    0.731	  0.110%	 37.428%	     0.000	        1	[densenet201/conv3_block7_0_bn/FusedBatchNormV3]:68
	                     ADD	          249.870	    1.027	    1.051	  0.157%	 37.585%	     0.000	        1	[densenet201/conv3_block7_0_relu/Relu;densenet201/conv3_block7_0_bn/FusedBatchNormV3]:69
	                 CONV_2D	          250.922	    3.722	    3.634	  0.545%	 38.130%	     0.000	        1	[densenet201/conv3_block7_1_relu/Relu;densenet201/conv3_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block7_1_conv/Conv2D]:70
	                 CONV_2D	          254.557	    3.773	    3.770	  0.565%	 38.694%	     0.000	        1	[densenet201/conv3_block7_2_conv/Conv2D1]:71
	           CONCATENATION	          258.327	    0.315	    0.332	  0.050%	 38.744%	     0.000	        1	[densenet201/conv3_block7_concat/concat]:72
	                     MUL	          258.660	    0.778	    0.796	  0.119%	 38.863%	     0.000	        1	[densenet201/conv3_block8_0_bn/FusedBatchNormV3]:73
	                     ADD	          259.457	    1.258	    1.154	  0.173%	 39.036%	     0.000	        1	[densenet201/conv3_block8_0_relu/Relu;densenet201/conv3_block8_0_bn/FusedBatchNormV3]:74
	                 CONV_2D	          260.611	    3.965	    3.986	  0.597%	 39.634%	     0.000	        1	[densenet201/conv3_block8_1_relu/Relu;densenet201/conv3_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block8_1_conv/Conv2D]:75
	                 CONV_2D	          264.598	    3.777	    3.770	  0.565%	 40.199%	     0.000	        1	[densenet201/conv3_block8_2_conv/Conv2D1]:76
	           CONCATENATION	          268.370	    0.358	    0.363	  0.054%	 40.253%	     0.000	        1	[densenet201/conv3_block8_concat/concat]:77
	                     MUL	          268.734	    0.852	    0.869	  0.130%	 40.383%	     0.000	        1	[densenet201/conv3_block9_0_bn/FusedBatchNormV3]:78
	                     ADD	          269.603	    1.234	    1.261	  0.189%	 40.572%	     0.000	        1	[densenet201/conv3_block9_0_relu/Relu;densenet201/conv3_block9_0_bn/FusedBatchNormV3]:79
	                 CONV_2D	          270.865	    4.399	    4.340	  0.650%	 41.222%	     0.000	        1	[densenet201/conv3_block9_1_relu/Relu;densenet201/conv3_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block9_1_conv/Conv2D]:80
	                 CONV_2D	          275.206	    3.786	    3.767	  0.564%	 41.787%	     0.000	        1	[densenet201/conv3_block9_2_conv/Conv2D1]:81
	           CONCATENATION	          278.974	    0.363	    0.391	  0.059%	 41.845%	     0.000	        1	[densenet201/conv3_block9_concat/concat]:82
	                     MUL	          279.365	    0.954	    0.939	  0.141%	 41.986%	     0.000	        1	[densenet201/conv3_block10_0_bn/FusedBatchNormV3]:83
	                     ADD	          280.305	    1.333	    1.365	  0.205%	 42.191%	     0.000	        1	[densenet201/conv3_block10_0_relu/Relu;densenet201/conv3_block10_0_bn/FusedBatchNormV3]:84
	                 CONV_2D	          281.671	    4.688	    4.647	  0.696%	 42.887%	     0.000	        1	[densenet201/conv3_block10_1_relu/Relu;densenet201/conv3_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block10_1_conv/Conv2D]:85
	                 CONV_2D	          286.319	    3.710	    3.769	  0.565%	 43.452%	     0.000	        1	[densenet201/conv3_block10_2_conv/Conv2D1]:86
	           CONCATENATION	          290.089	    0.413	    0.432	  0.065%	 43.517%	     0.000	        1	[densenet201/conv3_block10_concat/concat]:87
	                     MUL	          290.522	    0.988	    1.011	  0.152%	 43.668%	     0.000	        1	[densenet201/conv3_block11_0_bn/FusedBatchNormV3]:88
	                     ADD	          291.535	    1.515	    1.477	  0.221%	 43.889%	     0.000	        1	[densenet201/conv3_block11_0_relu/Relu;densenet201/conv3_block11_0_bn/FusedBatchNormV3]:89
	                 CONV_2D	          293.012	    5.029	    4.994	  0.748%	 44.638%	     0.000	        1	[densenet201/conv3_block11_1_relu/Relu;densenet201/conv3_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block11_1_conv/Conv2D]:90
	                 CONV_2D	          298.007	    3.725	    3.757	  0.563%	 45.201%	     0.000	        1	[densenet201/conv3_block11_2_conv/Conv2D1]:91
	           CONCATENATION	          301.766	    0.490	    0.458	  0.069%	 45.269%	     0.000	        1	[densenet201/conv3_block11_concat/concat]:92
	                     MUL	          302.225	    1.055	    1.086	  0.163%	 45.432%	     0.000	        1	[densenet201/conv3_block12_0_bn/FusedBatchNormV3]:93
	                     ADD	          303.312	    1.582	    1.574	  0.236%	 45.668%	     0.000	        1	[densenet201/conv3_block12_0_relu/Relu;densenet201/conv3_block12_0_bn/FusedBatchNormV3]:94
	                 CONV_2D	          304.887	    5.352	    5.318	  0.797%	 46.465%	     0.000	        1	[densenet201/conv3_block12_1_relu/Relu;densenet201/conv3_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block12_1_conv/Conv2D]:95
	                 CONV_2D	          310.206	    3.724	    3.753	  0.562%	 47.027%	     0.000	        1	[densenet201/conv3_block12_2_conv/Conv2D1]:96
	           CONCATENATION	          313.960	    0.458	    0.465	  0.070%	 47.097%	     0.000	        1	[densenet201/conv3_block12_concat/concat]:97
	                     MUL	          314.426	    1.120	    1.148	  0.172%	 47.269%	     0.000	        1	[densenet201/pool3_bn/FusedBatchNormV3]:98
	                     ADD	          315.575	    1.704	    1.682	  0.252%	 47.521%	     0.000	        1	[densenet201/pool3_relu/Relu;densenet201/pool3_bn/FusedBatchNormV3]:99
	                 CONV_2D	          317.258	   11.120	   11.128	  1.667%	 49.189%	     0.000	        1	[densenet201/pool3_conv/Conv2D1]:100
	         AVERAGE_POOL_2D	          328.388	    0.450	    0.456	  0.068%	 49.257%	     0.000	        1	[densenet201/pool3_pool/AvgPool]:101
	                     MUL	          328.844	    0.154	    0.153	  0.023%	 49.280%	     0.000	        1	[densenet201/conv4_block1_0_bn/FusedBatchNormV31]:102
	                     ADD	          328.998	    0.209	    0.212	  0.032%	 49.312%	     0.000	        1	[densenet201/conv4_block1_0_relu/Relu;densenet201/conv4_block1_0_bn/FusedBatchNormV3]:103
	                 CONV_2D	          329.211	    0.789	    0.789	  0.118%	 49.430%	     0.000	        1	[densenet201/conv4_block1_1_relu/Relu;densenet201/conv4_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block1_1_conv/Conv2D]:104
	                 CONV_2D	          330.000	    0.922	    0.903	  0.135%	 49.565%	     0.000	        1	[densenet201/conv4_block1_2_conv/Conv2D1]:105
	           CONCATENATION	          330.904	    0.056	    0.022	  0.003%	 49.568%	     0.000	        1	[densenet201/conv4_block1_concat/concat]:106
	                     MUL	          330.927	    0.168	    0.165	  0.025%	 49.593%	     0.000	        1	[densenet201/conv4_block2_0_bn/FusedBatchNormV31]:107
	                     ADD	          331.092	    0.237	    0.238	  0.036%	 49.629%	     0.000	        1	[densenet201/conv4_block2_0_relu/Relu;densenet201/conv4_block2_0_bn/FusedBatchNormV3]:108
	                 CONV_2D	          331.331	    0.935	    0.824	  0.123%	 49.752%	     0.000	        1	[densenet201/conv4_block2_1_relu/Relu;densenet201/conv4_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block2_1_conv/Conv2D]:109
	                 CONV_2D	          332.155	    0.859	    0.823	  0.123%	 49.875%	     0.000	        1	[densenet201/conv4_block2_2_conv/Conv2D1]:110
	           CONCATENATION	          332.978	    0.029	    0.018	  0.003%	 49.878%	     0.000	        1	[densenet201/conv4_block2_concat/concat]:111
	                     MUL	          332.997	    0.175	    0.181	  0.027%	 49.905%	     0.000	        1	[densenet201/conv4_block3_0_bn/FusedBatchNormV31]:112
	                     ADD	          333.179	    0.260	    0.265	  0.040%	 49.945%	     0.000	        1	[densenet201/conv4_block3_0_relu/Relu;densenet201/conv4_block3_0_bn/FusedBatchNormV3]:113
	                 CONV_2D	          333.444	    0.894	    0.901	  0.135%	 50.080%	     0.000	        1	[densenet201/conv4_block3_1_relu/Relu;densenet201/conv4_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block3_1_conv/Conv2D]:114
	                 CONV_2D	          334.346	    0.797	    0.815	  0.122%	 50.202%	     0.000	        1	[densenet201/conv4_block3_2_conv/Conv2D1]:115
	           CONCATENATION	          335.161	    0.016	    0.019	  0.003%	 50.205%	     0.000	        1	[densenet201/conv4_block3_concat/concat]:116
	                     MUL	          335.181	    0.197	    0.199	  0.030%	 50.235%	     0.000	        1	[densenet201/conv4_block4_0_bn/FusedBatchNormV31]:117
	                     ADD	          335.380	    0.307	    0.287	  0.043%	 50.278%	     0.000	        1	[densenet201/conv4_block4_0_relu/Relu;densenet201/conv4_block4_0_bn/FusedBatchNormV3]:118
	                 CONV_2D	          335.667	    0.977	    0.983	  0.147%	 50.425%	     0.000	        1	[densenet201/conv4_block4_1_relu/Relu;densenet201/conv4_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block4_1_conv/Conv2D]:119
	                 CONV_2D	          336.651	    0.796	    0.818	  0.123%	 50.548%	     0.000	        1	[densenet201/conv4_block4_2_conv/Conv2D1]:120
	           CONCATENATION	          337.470	    0.018	    0.023	  0.003%	 50.551%	     0.000	        1	[densenet201/conv4_block4_concat/concat]:121
	                     MUL	          337.493	    0.214	    0.216	  0.032%	 50.583%	     0.000	        1	[densenet201/conv4_block5_0_bn/FusedBatchNormV31]:122
	                     ADD	          337.709	    0.314	    0.312	  0.047%	 50.630%	     0.000	        1	[densenet201/conv4_block5_0_relu/Relu;densenet201/conv4_block5_0_bn/FusedBatchNormV3]:123
	                 CONV_2D	          338.022	    1.057	    1.077	  0.161%	 50.791%	     0.000	        1	[densenet201/conv4_block5_1_relu/Relu;densenet201/conv4_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block5_1_conv/Conv2D]:124
	                 CONV_2D	          339.099	    0.817	    0.818	  0.123%	 50.914%	     0.000	        1	[densenet201/conv4_block5_2_conv/Conv2D1]:125
	           CONCATENATION	          339.917	    0.021	    0.023	  0.003%	 50.917%	     0.000	        1	[densenet201/conv4_block5_concat/concat]:126
	                     MUL	          339.941	    0.232	    0.233	  0.035%	 50.952%	     0.000	        1	[densenet201/conv4_block6_0_bn/FusedBatchNormV31]:127
	                     ADD	          340.174	    0.333	    0.340	  0.051%	 51.003%	     0.000	        1	[densenet201/conv4_block6_0_relu/Relu;densenet201/conv4_block6_0_bn/FusedBatchNormV3]:128
	                 CONV_2D	          340.514	    1.176	    1.157	  0.173%	 51.176%	     0.000	        1	[densenet201/conv4_block6_1_relu/Relu;densenet201/conv4_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block6_1_conv/Conv2D]:129
	                 CONV_2D	          341.672	    0.804	    0.818	  0.122%	 51.299%	     0.000	        1	[densenet201/conv4_block6_2_conv/Conv2D1]:130
	           CONCATENATION	          342.491	    0.020	    0.023	  0.004%	 51.302%	     0.000	        1	[densenet201/conv4_block6_concat/concat]:131
	                     MUL	          342.515	    0.248	    0.252	  0.038%	 51.340%	     0.000	        1	[densenet201/conv4_block7_0_bn/FusedBatchNormV31]:132
	                     ADD	          342.767	    0.364	    0.364	  0.055%	 51.395%	     0.000	        1	[densenet201/conv4_block7_0_relu/Relu;densenet201/conv4_block7_0_bn/FusedBatchNormV3]:133
	                 CONV_2D	          343.132	    1.314	    1.238	  0.186%	 51.580%	     0.000	        1	[densenet201/conv4_block7_1_relu/Relu;densenet201/conv4_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block7_1_conv/Conv2D]:134
	                 CONV_2D	          344.371	    0.808	    0.817	  0.122%	 51.703%	     0.000	        1	[densenet201/conv4_block7_2_conv/Conv2D1]:135
	           CONCATENATION	          345.188	    0.025	    0.026	  0.004%	 51.707%	     0.000	        1	[densenet201/conv4_block7_concat/concat]:136
	                     MUL	          345.215	    0.266	    0.269	  0.040%	 51.747%	     0.000	        1	[densenet201/conv4_block8_0_bn/FusedBatchNormV31]:137
	                     ADD	          345.485	    0.389	    0.390	  0.058%	 51.805%	     0.000	        1	[densenet201/conv4_block8_0_relu/Relu;densenet201/conv4_block8_0_bn/FusedBatchNormV3]:138
	                 CONV_2D	          345.876	    1.341	    1.325	  0.198%	 52.004%	     0.000	        1	[densenet201/conv4_block8_1_relu/Relu;densenet201/conv4_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block8_1_conv/Conv2D]:139
	                 CONV_2D	          347.201	    0.820	    0.805	  0.121%	 52.124%	     0.000	        1	[densenet201/conv4_block8_2_conv/Conv2D1]:140
	           CONCATENATION	          348.006	    0.026	    0.028	  0.004%	 52.129%	     0.000	        1	[densenet201/conv4_block8_concat/concat]:141
	                     MUL	          348.035	    0.283	    0.288	  0.043%	 52.172%	     0.000	        1	[densenet201/conv4_block9_0_bn/FusedBatchNormV31]:142
	                     ADD	          348.323	    0.408	    0.420	  0.063%	 52.235%	     0.000	        1	[densenet201/conv4_block9_0_relu/Relu;densenet201/conv4_block9_0_bn/FusedBatchNormV3]:143
	                 CONV_2D	          348.744	    1.389	    1.406	  0.211%	 52.445%	     0.000	        1	[densenet201/conv4_block9_1_relu/Relu;densenet201/conv4_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block9_1_conv/Conv2D]:144
	                 CONV_2D	          350.150	    0.792	    0.811	  0.122%	 52.567%	     0.000	        1	[densenet201/conv4_block9_2_conv/Conv2D1]:145
	           CONCATENATION	          350.962	    0.024	    0.030	  0.004%	 52.571%	     0.000	        1	[densenet201/conv4_block9_concat/concat]:146
	                     MUL	          350.992	    0.309	    0.307	  0.046%	 52.617%	     0.000	        1	[densenet201/conv4_block10_0_bn/FusedBatchNormV31]:147
	                     ADD	          351.299	    0.442	    0.435	  0.065%	 52.682%	     0.000	        1	[densenet201/conv4_block10_0_relu/Relu;densenet201/conv4_block10_0_bn/FusedBatchNormV3]:148
	                 CONV_2D	          351.734	    1.475	    1.487	  0.223%	 52.905%	     0.000	        1	[densenet201/conv4_block10_1_relu/Relu;densenet201/conv4_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block10_1_conv/Conv2D]:149
	                 CONV_2D	          353.222	    0.794	    0.809	  0.121%	 53.027%	     0.000	        1	[densenet201/conv4_block10_2_conv/Conv2D1]:150
	           CONCATENATION	          354.032	    0.036	    0.031	  0.005%	 53.031%	     0.000	        1	[densenet201/conv4_block10_concat/concat]:151
	                     MUL	          354.064	    0.315	    0.324	  0.049%	 53.080%	     0.000	        1	[densenet201/conv4_block11_0_bn/FusedBatchNormV31]:152
	                     ADD	          354.388	    0.453	    0.458	  0.069%	 53.148%	     0.000	        1	[densenet201/conv4_block11_0_relu/Relu;densenet201/conv4_block11_0_bn/FusedBatchNormV3]:153
	                 CONV_2D	          354.847	    1.637	    1.572	  0.236%	 53.384%	     0.000	        1	[densenet201/conv4_block11_1_relu/Relu;densenet201/conv4_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block11_1_conv/Conv2D]:154
	                 CONV_2D	          356.420	    0.801	    0.808	  0.121%	 53.505%	     0.000	        1	[densenet201/conv4_block11_2_conv/Conv2D1]:155
	           CONCATENATION	          357.229	    0.044	    0.046	  0.007%	 53.512%	     0.000	        1	[densenet201/conv4_block11_concat/concat]:156
	                     MUL	          357.276	    0.342	    0.344	  0.052%	 53.564%	     0.000	        1	[densenet201/conv4_block12_0_bn/FusedBatchNormV31]:157
	                     ADD	          357.621	    0.480	    0.484	  0.072%	 53.636%	     0.000	        1	[densenet201/conv4_block12_0_relu/Relu;densenet201/conv4_block12_0_bn/FusedBatchNormV3]:158
	                 CONV_2D	          358.105	    1.651	    1.658	  0.249%	 53.885%	     0.000	        1	[densenet201/conv4_block12_1_relu/Relu;densenet201/conv4_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block12_1_conv/Conv2D]:159
	                 CONV_2D	          359.764	    0.813	    0.821	  0.123%	 54.008%	     0.000	        1	[densenet201/conv4_block12_2_conv/Conv2D1]:160
	           CONCATENATION	          360.586	    0.113	    0.042	  0.006%	 54.014%	     0.000	        1	[densenet201/conv4_block12_concat/concat]:161
	                     MUL	          360.628	    0.359	    0.361	  0.054%	 54.068%	     0.000	        1	[densenet201/conv4_block13_0_bn/FusedBatchNormV31]:162
	                     ADD	          360.990	    0.503	    0.514	  0.077%	 54.145%	     0.000	        1	[densenet201/conv4_block13_0_relu/Relu;densenet201/conv4_block13_0_bn/FusedBatchNormV3]:163
	                 CONV_2D	          361.504	    1.727	    1.746	  0.262%	 54.407%	     0.000	        1	[densenet201/conv4_block13_1_relu/Relu;densenet201/conv4_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block13_1_conv/Conv2D]:164
	                 CONV_2D	          363.251	    0.832	    0.822	  0.123%	 54.530%	     0.000	        1	[densenet201/conv4_block13_2_conv/Conv2D1]:165
	           CONCATENATION	          364.074	    0.043	    0.041	  0.006%	 54.536%	     0.000	        1	[densenet201/conv4_block13_concat/concat]:166
	                     MUL	          364.116	    0.369	    0.377	  0.056%	 54.592%	     0.000	        1	[densenet201/conv4_block14_0_bn/FusedBatchNormV31]:167
	                     ADD	          364.493	    0.538	    0.536	  0.080%	 54.673%	     0.000	        1	[densenet201/conv4_block14_0_relu/Relu;densenet201/conv4_block14_0_bn/FusedBatchNormV3]:168
	                 CONV_2D	          365.030	    1.792	    1.814	  0.272%	 54.945%	     0.000	        1	[densenet201/conv4_block14_1_relu/Relu;densenet201/conv4_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block14_1_conv/Conv2D]:169
	                 CONV_2D	          366.844	    0.893	    0.822	  0.123%	 55.068%	     0.000	        1	[densenet201/conv4_block14_2_conv/Conv2D1]:170
	           CONCATENATION	          367.667	    0.050	    0.045	  0.007%	 55.074%	     0.000	        1	[densenet201/conv4_block14_concat/concat]:171
	                     MUL	          367.712	    0.398	    0.397	  0.059%	 55.134%	     0.000	        1	[densenet201/conv4_block15_0_bn/FusedBatchNormV31]:172
	                     ADD	          368.110	    0.553	    0.563	  0.084%	 55.218%	     0.000	        1	[densenet201/conv4_block15_0_relu/Relu;densenet201/conv4_block15_0_bn/FusedBatchNormV3]:173
	                 CONV_2D	          368.673	    1.887	    1.903	  0.285%	 55.503%	     0.000	        1	[densenet201/conv4_block15_1_relu/Relu;densenet201/conv4_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block15_1_conv/Conv2D]:174
	                 CONV_2D	          370.577	    0.802	    0.824	  0.123%	 55.627%	     0.000	        1	[densenet201/conv4_block15_2_conv/Conv2D1]:175
	           CONCATENATION	          371.401	    0.031	    0.040	  0.006%	 55.633%	     0.000	        1	[densenet201/conv4_block15_concat/concat]:176
	                     MUL	          371.442	    0.438	    0.411	  0.062%	 55.694%	     0.000	        1	[densenet201/conv4_block16_0_bn/FusedBatchNormV31]:177
	                     ADD	          371.854	    0.576	    0.587	  0.088%	 55.783%	     0.000	        1	[densenet201/conv4_block16_0_relu/Relu;densenet201/conv4_block16_0_bn/FusedBatchNormV3]:178
	                 CONV_2D	          372.442	    1.960	    1.983	  0.297%	 56.080%	     0.000	        1	[densenet201/conv4_block16_1_relu/Relu;densenet201/conv4_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block16_1_conv/Conv2D]:179
	                 CONV_2D	          374.425	    0.812	    0.832	  0.125%	 56.204%	     0.000	        1	[densenet201/conv4_block16_2_conv/Conv2D1]:180
	           CONCATENATION	          375.259	    0.074	    0.052	  0.008%	 56.212%	     0.000	        1	[densenet201/conv4_block16_concat/concat]:181
	                     MUL	          375.312	    0.441	    0.434	  0.065%	 56.277%	     0.000	        1	[densenet201/conv4_block17_0_bn/FusedBatchNormV31]:182
	                     ADD	          375.746	    0.609	    0.610	  0.091%	 56.369%	     0.000	        1	[densenet201/conv4_block17_0_relu/Relu;densenet201/conv4_block17_0_bn/FusedBatchNormV3]:183
	                 CONV_2D	          376.357	    2.058	    2.072	  0.311%	 56.679%	     0.000	        1	[densenet201/conv4_block17_1_relu/Relu;densenet201/conv4_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block17_1_conv/Conv2D]:184
	                 CONV_2D	          378.430	    0.813	    0.825	  0.124%	 56.803%	     0.000	        1	[densenet201/conv4_block17_2_conv/Conv2D1]:185
	           CONCATENATION	          379.255	    0.060	    0.048	  0.007%	 56.810%	     0.000	        1	[densenet201/conv4_block17_concat/concat]:186
	                     MUL	          379.304	    0.529	    0.446	  0.067%	 56.877%	     0.000	        1	[densenet201/conv4_block18_0_bn/FusedBatchNormV31]:187
	                     ADD	          379.751	    0.659	    0.640	  0.096%	 56.973%	     0.000	        1	[densenet201/conv4_block18_0_relu/Relu;densenet201/conv4_block18_0_bn/FusedBatchNormV3]:188
	                 CONV_2D	          380.392	    2.146	    2.155	  0.323%	 57.296%	     0.000	        1	[densenet201/conv4_block18_1_relu/Relu;densenet201/conv4_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block18_1_conv/Conv2D]:189
	                 CONV_2D	          382.548	    0.812	    0.830	  0.124%	 57.420%	     0.000	        1	[densenet201/conv4_block18_2_conv/Conv2D1]:190
	           CONCATENATION	          383.378	    0.050	    0.059	  0.009%	 57.429%	     0.000	        1	[densenet201/conv4_block18_concat/concat]:191
	                     MUL	          383.439	    0.493	    0.464	  0.069%	 57.498%	     0.000	        1	[densenet201/conv4_block19_0_bn/FusedBatchNormV31]:192
	                     ADD	          383.903	    0.656	    0.663	  0.099%	 57.598%	     0.000	        1	[densenet201/conv4_block19_0_relu/Relu;densenet201/conv4_block19_0_bn/FusedBatchNormV3]:193
	                 CONV_2D	          384.566	    2.220	    2.242	  0.336%	 57.934%	     0.000	        1	[densenet201/conv4_block19_1_relu/Relu;densenet201/conv4_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block19_1_conv/Conv2D]:194
	                 CONV_2D	          386.809	    0.823	    0.817	  0.122%	 58.056%	     0.000	        1	[densenet201/conv4_block19_2_conv/Conv2D1]:195
	           CONCATENATION	          387.626	    0.062	    0.054	  0.008%	 58.064%	     0.000	        1	[densenet201/conv4_block19_concat/concat]:196
	                     MUL	          387.681	    0.476	    0.481	  0.072%	 58.136%	     0.000	        1	[densenet201/conv4_block20_0_bn/FusedBatchNormV31]:197
	                     ADD	          388.162	    0.682	    0.686	  0.103%	 58.239%	     0.000	        1	[densenet201/conv4_block20_0_relu/Relu;densenet201/conv4_block20_0_bn/FusedBatchNormV3]:198
	                 CONV_2D	          388.848	    2.287	    2.321	  0.348%	 58.587%	     0.000	        1	[densenet201/conv4_block20_1_relu/Relu;densenet201/conv4_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block20_1_conv/Conv2D]:199
	                 CONV_2D	          391.170	    0.898	    0.832	  0.125%	 58.711%	     0.000	        1	[densenet201/conv4_block20_2_conv/Conv2D1]:200
	           CONCATENATION	          392.002	    0.082	    0.068	  0.010%	 58.722%	     0.000	        1	[densenet201/conv4_block20_concat/concat]:201
	                     MUL	          392.071	    0.495	    0.508	  0.076%	 58.798%	     0.000	        1	[densenet201/conv4_block21_0_bn/FusedBatchNormV3]:202
	                     ADD	          392.579	    0.706	    0.714	  0.107%	 58.905%	     0.000	        1	[densenet201/conv4_block21_0_relu/Relu;densenet201/conv4_block21_0_bn/FusedBatchNormV3]:203
	                 CONV_2D	          393.294	    2.417	    2.408	  0.361%	 59.265%	     0.000	        1	[densenet201/conv4_block21_1_relu/Relu;densenet201/conv4_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block21_1_conv/Conv2D]:204
	                 CONV_2D	          395.703	    0.813	    0.823	  0.123%	 59.389%	     0.000	        1	[densenet201/conv4_block21_2_conv/Conv2D1]:205
	           CONCATENATION	          396.526	    0.056	    0.066	  0.010%	 59.398%	     0.000	        1	[densenet201/conv4_block21_concat/concat]:206
	                     MUL	          396.592	    0.513	    0.521	  0.078%	 59.477%	     0.000	        1	[densenet201/conv4_block22_0_bn/FusedBatchNormV3]:207
	                     ADD	          397.114	    0.729	    0.741	  0.111%	 59.588%	     0.000	        1	[densenet201/conv4_block22_0_relu/Relu;densenet201/conv4_block22_0_bn/FusedBatchNormV3]:208
	                 CONV_2D	          397.855	    2.492	    2.487	  0.373%	 59.960%	     0.000	        1	[densenet201/conv4_block22_1_relu/Relu;densenet201/conv4_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block22_1_conv/Conv2D]:209
	                 CONV_2D	          400.343	    0.823	    0.837	  0.125%	 60.086%	     0.000	        1	[densenet201/conv4_block22_2_conv/Conv2D1]:210
	           CONCATENATION	          401.180	    0.064	    0.072	  0.011%	 60.096%	     0.000	        1	[densenet201/conv4_block22_concat/concat]:211
	                     MUL	          401.253	    0.535	    0.539	  0.081%	 60.177%	     0.000	        1	[densenet201/conv4_block23_0_bn/FusedBatchNormV3]:212
	                     ADD	          401.792	    0.752	    0.761	  0.114%	 60.291%	     0.000	        1	[densenet201/conv4_block23_0_relu/Relu;densenet201/conv4_block23_0_bn/FusedBatchNormV3]:213
	                 CONV_2D	          402.554	    2.630	    2.567	  0.385%	 60.676%	     0.000	        1	[densenet201/conv4_block23_1_relu/Relu;densenet201/conv4_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block23_1_conv/Conv2D]:214
	                 CONV_2D	          405.122	    0.810	    0.822	  0.123%	 60.799%	     0.000	        1	[densenet201/conv4_block23_2_conv/Conv2D1]:215
	           CONCATENATION	          405.945	    0.056	    0.067	  0.010%	 60.809%	     0.000	        1	[densenet201/conv4_block23_concat/concat]:216
	                     MUL	          406.012	    0.554	    0.557	  0.083%	 60.892%	     0.000	        1	[densenet201/conv4_block24_0_bn/FusedBatchNormV3]:217
	                     ADD	          406.570	    0.777	    0.790	  0.118%	 61.011%	     0.000	        1	[densenet201/conv4_block24_0_relu/Relu;densenet201/conv4_block24_0_bn/FusedBatchNormV3]:218
	                 CONV_2D	          407.361	    2.638	    2.647	  0.397%	 61.407%	     0.000	        1	[densenet201/conv4_block24_1_relu/Relu;densenet201/conv4_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block24_1_conv/Conv2D]:219
	                 CONV_2D	          410.008	    0.853	    0.831	  0.125%	 61.532%	     0.000	        1	[densenet201/conv4_block24_2_conv/Conv2D1]:220
	           CONCATENATION	          410.840	    0.071	    0.085	  0.013%	 61.545%	     0.000	        1	[densenet201/conv4_block24_concat/concat]:221
	                     MUL	          410.926	    0.588	    0.574	  0.086%	 61.631%	     0.000	        1	[densenet201/conv4_block25_0_bn/FusedBatchNormV3]:222
	                     ADD	          411.501	    0.808	    0.815	  0.122%	 61.753%	     0.000	        1	[densenet201/conv4_block25_0_relu/Relu;densenet201/conv4_block25_0_bn/FusedBatchNormV3]:223
	                 CONV_2D	          412.316	    2.682	    2.730	  0.409%	 62.162%	     0.000	        1	[densenet201/conv4_block25_1_relu/Relu;densenet201/conv4_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block25_1_conv/Conv2D]:224
	                 CONV_2D	          415.047	    0.912	    0.833	  0.125%	 62.287%	     0.000	        1	[densenet201/conv4_block25_2_conv/Conv2D1]:225
	           CONCATENATION	          415.881	    0.069	    0.063	  0.009%	 62.296%	     0.000	        1	[densenet201/conv4_block25_concat/concat]:226
	                     MUL	          415.945	    0.583	    0.595	  0.089%	 62.385%	     0.000	        1	[densenet201/conv4_block26_0_bn/FusedBatchNormV3]:227
	                     ADD	          416.541	    0.833	    0.841	  0.126%	 62.512%	     0.000	        1	[densenet201/conv4_block26_0_relu/Relu;densenet201/conv4_block26_0_bn/FusedBatchNormV3]:228
	                 CONV_2D	          417.383	    2.821	    2.831	  0.424%	 62.936%	     0.000	        1	[densenet201/conv4_block26_1_relu/Relu;densenet201/conv4_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block26_1_conv/Conv2D]:229
	                 CONV_2D	          420.215	    0.810	    0.832	  0.125%	 63.061%	     0.000	        1	[densenet201/conv4_block26_2_conv/Conv2D1]:230
	           CONCATENATION	          421.047	    0.086	    0.101	  0.015%	 63.076%	     0.000	        1	[densenet201/conv4_block26_concat/concat]:231
	                     MUL	          421.149	    0.595	    0.611	  0.092%	 63.167%	     0.000	        1	[densenet201/conv4_block27_0_bn/FusedBatchNormV3]:232
	                     ADD	          421.760	    0.857	    0.865	  0.130%	 63.297%	     0.000	        1	[densenet201/conv4_block27_0_relu/Relu;densenet201/conv4_block27_0_bn/FusedBatchNormV3]:233
	                 CONV_2D	          422.626	    2.890	    2.920	  0.438%	 63.734%	     0.000	        1	[densenet201/conv4_block27_1_relu/Relu;densenet201/conv4_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block27_1_conv/Conv2D]:234
	                 CONV_2D	          425.547	    0.809	    0.828	  0.124%	 63.858%	     0.000	        1	[densenet201/conv4_block27_2_conv/Conv2D1]:235
	           CONCATENATION	          426.375	    0.090	    0.106	  0.016%	 63.874%	     0.000	        1	[densenet201/conv4_block27_concat/concat]:236
	                     MUL	          426.482	    0.613	    0.633	  0.095%	 63.969%	     0.000	        1	[densenet201/conv4_block28_0_bn/FusedBatchNormV3]:237
	                     ADD	          427.115	    0.983	    0.888	  0.133%	 64.102%	     0.000	        1	[densenet201/conv4_block28_0_relu/Relu;densenet201/conv4_block28_0_bn/FusedBatchNormV3]:238
	                 CONV_2D	          428.004	    2.960	    3.006	  0.450%	 64.553%	     0.000	        1	[densenet201/conv4_block28_1_relu/Relu;densenet201/conv4_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block28_1_conv/Conv2D]:239
	                 CONV_2D	          431.011	    0.823	    0.826	  0.124%	 64.676%	     0.000	        1	[densenet201/conv4_block28_2_conv/Conv2D1]:240
	           CONCATENATION	          431.837	    0.115	    0.101	  0.015%	 64.691%	     0.000	        1	[densenet201/conv4_block28_concat/concat]:241
	                     MUL	          431.940	    0.634	    0.646	  0.097%	 64.788%	     0.000	        1	[densenet201/conv4_block29_0_bn/FusedBatchNormV3]:242
	                     ADD	          432.586	    0.905	    0.916	  0.137%	 64.925%	     0.000	        1	[densenet201/conv4_block29_0_relu/Relu;densenet201/conv4_block29_0_bn/FusedBatchNormV3]:243
	                 CONV_2D	          433.502	    3.096	    3.088	  0.463%	 65.388%	     0.000	        1	[densenet201/conv4_block29_1_relu/Relu;densenet201/conv4_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block29_1_conv/Conv2D]:244
	                 CONV_2D	          436.591	    0.810	    0.826	  0.124%	 65.512%	     0.000	        1	[densenet201/conv4_block29_2_conv/Conv2D1]:245
	           CONCATENATION	          437.418	    0.083	    0.095	  0.014%	 65.526%	     0.000	        1	[densenet201/conv4_block29_concat/concat]:246
	                     MUL	          437.514	    0.646	    0.660	  0.099%	 65.625%	     0.000	        1	[densenet201/conv4_block30_0_bn/FusedBatchNormV3]:247
	                     ADD	          438.174	    0.950	    0.942	  0.141%	 65.766%	     0.000	        1	[densenet201/conv4_block30_0_relu/Relu;densenet201/conv4_block30_0_bn/FusedBatchNormV3]:248
	                 CONV_2D	          439.116	    3.236	    3.179	  0.476%	 66.243%	     0.000	        1	[densenet201/conv4_block30_1_relu/Relu;densenet201/conv4_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block30_1_conv/Conv2D]:249
	                 CONV_2D	          442.296	    0.815	    0.826	  0.124%	 66.366%	     0.000	        1	[densenet201/conv4_block30_2_conv/Conv2D1]:250
	           CONCATENATION	          443.123	    0.097	    0.096	  0.014%	 66.381%	     0.000	        1	[densenet201/conv4_block30_concat/concat]:251
	                     MUL	          443.219	    0.705	    0.678	  0.102%	 66.482%	     0.000	        1	[densenet201/conv4_block31_0_bn/FusedBatchNormV3]:252
	                     ADD	          443.898	    0.953	    0.968	  0.145%	 66.627%	     0.000	        1	[densenet201/conv4_block31_0_relu/Relu;densenet201/conv4_block31_0_bn/FusedBatchNormV3]:253
	                 CONV_2D	          444.867	    3.237	    3.264	  0.489%	 67.116%	     0.000	        1	[densenet201/conv4_block31_1_relu/Relu;densenet201/conv4_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block31_1_conv/Conv2D]:254
	                 CONV_2D	          448.132	    0.809	    0.835	  0.125%	 67.242%	     0.000	        1	[densenet201/conv4_block31_2_conv/Conv2D1]:255
	           CONCATENATION	          448.968	    0.092	    0.104	  0.016%	 67.257%	     0.000	        1	[densenet201/conv4_block31_concat/concat]:256
	                     MUL	          449.074	    0.686	    0.702	  0.105%	 67.362%	     0.000	        1	[densenet201/conv4_block32_0_bn/FusedBatchNormV3]:257
	                     ADD	          449.776	    0.975	    0.988	  0.148%	 67.511%	     0.000	        1	[densenet201/conv4_block32_0_relu/Relu;densenet201/conv4_block32_0_bn/FusedBatchNormV3]:258
	                 CONV_2D	          450.765	    3.396	    3.346	  0.501%	 68.012%	     0.000	        1	[densenet201/conv4_block32_1_relu/Relu;densenet201/conv4_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block32_1_conv/Conv2D]:259
	                 CONV_2D	          454.112	    0.820	    0.834	  0.125%	 68.137%	     0.000	        1	[densenet201/conv4_block32_2_conv/Conv2D1]:260
	           CONCATENATION	          454.947	    0.081	    0.078	  0.012%	 68.149%	     0.000	        1	[densenet201/conv4_block32_concat/concat]:261
	                     MUL	          455.026	    0.728	    0.712	  0.107%	 68.255%	     0.000	        1	[densenet201/conv4_block33_0_bn/FusedBatchNormV3]:262
	                     ADD	          455.739	    1.005	    1.017	  0.152%	 68.408%	     0.000	        1	[densenet201/conv4_block33_0_relu/Relu;densenet201/conv4_block33_0_bn/FusedBatchNormV3]:263
	                 CONV_2D	          456.756	    3.402	    3.429	  0.514%	 68.921%	     0.000	        1	[densenet201/conv4_block33_1_relu/Relu;densenet201/conv4_block33_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block33_1_conv/Conv2D]:264
	                 CONV_2D	          460.185	    0.804	    0.830	  0.124%	 69.046%	     0.000	        1	[densenet201/conv4_block33_2_conv/Conv2D1]:265
	           CONCATENATION	          461.016	    0.110	    0.121	  0.018%	 69.064%	     0.000	        1	[densenet201/conv4_block33_concat/concat]:266
	                     MUL	          461.137	    0.719	    0.732	  0.110%	 69.173%	     0.000	        1	[densenet201/conv4_block34_0_bn/FusedBatchNormV3]:267
	                     ADD	          461.870	    1.023	    1.040	  0.156%	 69.329%	     0.000	        1	[densenet201/conv4_block34_0_relu/Relu;densenet201/conv4_block34_0_bn/FusedBatchNormV3]:268
	                 CONV_2D	          462.911	    3.572	    3.517	  0.527%	 69.856%	     0.000	        1	[densenet201/conv4_block34_1_relu/Relu;densenet201/conv4_block34_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block34_1_conv/Conv2D]:269
	                 CONV_2D	          466.429	    0.824	    0.830	  0.124%	 69.981%	     0.000	        1	[densenet201/conv4_block34_2_conv/Conv2D1]:270
	           CONCATENATION	          467.260	    0.096	    0.090	  0.014%	 69.994%	     0.000	        1	[densenet201/conv4_block34_concat/concat]:271
	                     MUL	          467.351	    0.763	    0.747	  0.112%	 70.106%	     0.000	        1	[densenet201/conv4_block35_0_bn/FusedBatchNormV3]:272
	                     ADD	          468.098	    1.078	    1.073	  0.161%	 70.267%	     0.000	        1	[densenet201/conv4_block35_0_relu/Relu;densenet201/conv4_block35_0_bn/FusedBatchNormV3]:273
	                 CONV_2D	          469.172	    3.552	    3.594	  0.539%	 70.806%	     0.000	        1	[densenet201/conv4_block35_1_relu/Relu;densenet201/conv4_block35_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block35_1_conv/Conv2D]:274
	                 CONV_2D	          472.767	    0.815	    0.844	  0.127%	 70.932%	     0.000	        1	[densenet201/conv4_block35_2_conv/Conv2D1]:275
	           CONCATENATION	          473.612	    0.120	    0.133	  0.020%	 70.952%	     0.000	        1	[densenet201/conv4_block35_concat/concat]:276
	                     MUL	          473.746	    0.757	    0.769	  0.115%	 71.067%	     0.000	        1	[densenet201/conv4_block36_0_bn/FusedBatchNormV3]:277
	                     ADD	          474.515	    1.074	    1.094	  0.164%	 71.231%	     0.000	        1	[densenet201/conv4_block36_0_relu/Relu;densenet201/conv4_block36_0_bn/FusedBatchNormV3]:278
	                 CONV_2D	          475.610	    3.752	    3.681	  0.552%	 71.783%	     0.000	        1	[densenet201/conv4_block36_1_relu/Relu;densenet201/conv4_block36_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block36_1_conv/Conv2D]:279
	                 CONV_2D	          479.292	    0.880	    0.829	  0.124%	 71.907%	     0.000	        1	[densenet201/conv4_block36_2_conv/Conv2D1]:280
	           CONCATENATION	          480.121	    0.117	    0.097	  0.015%	 71.921%	     0.000	        1	[densenet201/conv4_block36_concat/concat]:281
	                     MUL	          480.219	    0.774	    0.788	  0.118%	 72.040%	     0.000	        1	[densenet201/conv4_block37_0_bn/FusedBatchNormV3]:282
	                     ADD	          481.008	    1.104	    1.119	  0.168%	 72.207%	     0.000	        1	[densenet201/conv4_block37_0_relu/Relu;densenet201/conv4_block37_0_bn/FusedBatchNormV3]:283
	                 CONV_2D	          482.127	    3.747	    3.767	  0.564%	 72.772%	     0.000	        1	[densenet201/conv4_block37_1_relu/Relu;densenet201/conv4_block37_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block37_1_conv/Conv2D]:284
	                 CONV_2D	          485.895	    0.815	    0.835	  0.125%	 72.897%	     0.000	        1	[densenet201/conv4_block37_2_conv/Conv2D1]:285
	           CONCATENATION	          486.732	    0.123	    0.143	  0.021%	 72.918%	     0.000	        1	[densenet201/conv4_block37_concat/concat]:286
	                     MUL	          486.875	    0.798	    0.804	  0.120%	 73.039%	     0.000	        1	[densenet201/conv4_block38_0_bn/FusedBatchNormV3]:287
	                     ADD	          487.680	    1.241	    1.153	  0.173%	 73.212%	     0.000	        1	[densenet201/conv4_block38_0_relu/Relu;densenet201/conv4_block38_0_bn/FusedBatchNormV3]:288
	                 CONV_2D	          488.834	    3.832	    3.843	  0.576%	 73.787%	     0.000	        1	[densenet201/conv4_block38_1_relu/Relu;densenet201/conv4_block38_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block38_1_conv/Conv2D]:289
	                 CONV_2D	          492.678	    0.815	    0.841	  0.126%	 73.913%	     0.000	        1	[densenet201/conv4_block38_2_conv/Conv2D1]:290
	           CONCATENATION	          493.521	    0.112	    0.118	  0.018%	 73.931%	     0.000	        1	[densenet201/conv4_block38_concat/concat]:291
	                     MUL	          493.639	    0.804	    0.820	  0.123%	 74.054%	     0.000	        1	[densenet201/conv4_block39_0_bn/FusedBatchNormV3]:292
	                     ADD	          494.460	    1.145	    1.174	  0.176%	 74.230%	     0.000	        1	[densenet201/conv4_block39_0_relu/Relu;densenet201/conv4_block39_0_bn/FusedBatchNormV3]:293
	                 CONV_2D	          495.634	    3.900	    3.927	  0.588%	 74.818%	     0.000	        1	[densenet201/conv4_block39_1_relu/Relu;densenet201/conv4_block39_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block39_1_conv/Conv2D]:294
	                 CONV_2D	          499.562	    0.844	    0.838	  0.126%	 74.944%	     0.000	        1	[densenet201/conv4_block39_2_conv/Conv2D1]:295
	           CONCATENATION	          500.401	    0.157	    0.154	  0.023%	 74.967%	     0.000	        1	[densenet201/conv4_block39_concat/concat]:296
	                     MUL	          500.555	    0.822	    0.849	  0.127%	 75.094%	     0.000	        1	[densenet201/conv4_block40_0_bn/FusedBatchNormV3]:297
	                     ADD	          501.405	    1.176	    1.192	  0.179%	 75.273%	     0.000	        1	[densenet201/conv4_block40_0_relu/Relu;densenet201/conv4_block40_0_bn/FusedBatchNormV3]:298
	                 CONV_2D	          502.598	    4.029	    4.017	  0.602%	 75.875%	     0.000	        1	[densenet201/conv4_block40_1_relu/Relu;densenet201/conv4_block40_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block40_1_conv/Conv2D]:299
	                 CONV_2D	          506.616	    0.804	    0.834	  0.125%	 76.000%	     0.000	        1	[densenet201/conv4_block40_2_conv/Conv2D1]:300
	           CONCATENATION	          507.451	    0.104	    0.123	  0.018%	 76.018%	     0.000	        1	[densenet201/conv4_block40_concat/concat]:301
	                     MUL	          507.575	    0.880	    0.862	  0.129%	 76.147%	     0.000	        1	[densenet201/conv4_block41_0_bn/FusedBatchNormV3]:302
	                     ADD	          508.438	    1.202	    1.225	  0.184%	 76.331%	     0.000	        1	[densenet201/conv4_block41_0_relu/Relu;densenet201/conv4_block41_0_bn/FusedBatchNormV3]:303
	                 CONV_2D	          509.664	    4.147	    4.099	  0.614%	 76.945%	     0.000	        1	[densenet201/conv4_block41_1_relu/Relu;densenet201/conv4_block41_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block41_1_conv/Conv2D]:304
	                 CONV_2D	          513.763	    0.840	    0.840	  0.126%	 77.071%	     0.000	        1	[densenet201/conv4_block41_2_conv/Conv2D1]:305
	           CONCATENATION	          514.604	    0.160	    0.171	  0.026%	 77.097%	     0.000	        1	[densenet201/conv4_block41_concat/concat]:306
	                     MUL	          514.776	    0.866	    0.877	  0.131%	 77.228%	     0.000	        1	[densenet201/conv4_block42_0_bn/FusedBatchNormV3]:307
	                     ADD	          515.654	    1.258	    1.251	  0.187%	 77.416%	     0.000	        1	[densenet201/conv4_block42_0_relu/Relu;densenet201/conv4_block42_0_bn/FusedBatchNormV3]:308
	                 CONV_2D	          516.906	    4.152	    4.196	  0.629%	 78.044%	     0.000	        1	[densenet201/conv4_block42_1_relu/Relu;densenet201/conv4_block42_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block42_1_conv/Conv2D]:309
	                 CONV_2D	          521.103	    0.802	    0.830	  0.124%	 78.169%	     0.000	        1	[densenet201/conv4_block42_2_conv/Conv2D1]:310
	           CONCATENATION	          521.933	    0.157	    0.142	  0.021%	 78.190%	     0.000	        1	[densenet201/conv4_block42_concat/concat]:311
	                     MUL	          522.076	    0.900	    0.896	  0.134%	 78.324%	     0.000	        1	[densenet201/conv4_block43_0_bn/FusedBatchNormV3]:312
	                     ADD	          522.973	    1.381	    1.270	  0.190%	 78.515%	     0.000	        1	[densenet201/conv4_block43_0_relu/Relu;densenet201/conv4_block43_0_bn/FusedBatchNormV3]:313
	                 CONV_2D	          524.244	    4.235	    4.264	  0.639%	 79.153%	     0.000	        1	[densenet201/conv4_block43_1_relu/Relu;densenet201/conv4_block43_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block43_1_conv/Conv2D]:314
	                 CONV_2D	          528.509	    0.838	    0.856	  0.128%	 79.282%	     0.000	        1	[densenet201/conv4_block43_2_conv/Conv2D1]:315
	           CONCATENATION	          529.366	    0.168	    0.177	  0.027%	 79.308%	     0.000	        1	[densenet201/conv4_block43_concat/concat]:316
	                     MUL	          529.544	    0.900	    0.907	  0.136%	 79.444%	     0.000	        1	[densenet201/conv4_block44_0_bn/FusedBatchNormV3]:317
	                     ADD	          530.452	    1.274	    1.300	  0.195%	 79.639%	     0.000	        1	[densenet201/conv4_block44_0_relu/Relu;densenet201/conv4_block44_0_bn/FusedBatchNormV3]:318
	                 CONV_2D	          531.752	    4.406	    4.352	  0.652%	 80.291%	     0.000	        1	[densenet201/conv4_block44_1_relu/Relu;densenet201/conv4_block44_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block44_1_conv/Conv2D]:319
	                 CONV_2D	          536.105	    0.857	    0.836	  0.125%	 80.416%	     0.000	        1	[densenet201/conv4_block44_2_conv/Conv2D1]:320
	           CONCATENATION	          536.942	    0.180	    0.163	  0.024%	 80.441%	     0.000	        1	[densenet201/conv4_block44_concat/concat]:321
	                     MUL	          537.105	    0.906	    0.931	  0.140%	 80.580%	     0.000	        1	[densenet201/conv4_block45_0_bn/FusedBatchNormV3]:322
	                     ADD	          538.037	    1.306	    1.321	  0.198%	 80.778%	     0.000	        1	[densenet201/conv4_block45_0_relu/Relu;densenet201/conv4_block45_0_bn/FusedBatchNormV3]:323
	                 CONV_2D	          539.359	    4.416	    4.437	  0.665%	 81.443%	     0.000	        1	[densenet201/conv4_block45_1_relu/Relu;densenet201/conv4_block45_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block45_1_conv/Conv2D]:324
	                 CONV_2D	          543.797	    0.832	    0.852	  0.128%	 81.571%	     0.000	        1	[densenet201/conv4_block45_2_conv/Conv2D1]:325
	           CONCATENATION	          544.650	    0.161	    0.187	  0.028%	 81.599%	     0.000	        1	[densenet201/conv4_block45_concat/concat]:326
	                     MUL	          544.838	    0.934	    0.951	  0.142%	 81.741%	     0.000	        1	[densenet201/conv4_block46_0_bn/FusedBatchNormV3]:327
	                     ADD	          545.790	    1.356	    1.355	  0.203%	 81.944%	     0.000	        1	[densenet201/conv4_block46_0_relu/Relu;densenet201/conv4_block46_0_bn/FusedBatchNormV3]:328
	                 CONV_2D	          547.145	    4.589	    4.531	  0.679%	 82.623%	     0.000	        1	[densenet201/conv4_block46_1_relu/Relu;densenet201/conv4_block46_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block46_1_conv/Conv2D]:329
	                 CONV_2D	          551.677	    0.874	    0.867	  0.130%	 82.753%	     0.000	        1	[densenet201/conv4_block46_2_conv/Conv2D1]:330
	           CONCATENATION	          552.545	    0.197	    0.193	  0.029%	 82.782%	     0.000	        1	[densenet201/conv4_block46_concat/concat]:331
	                     MUL	          552.738	    0.946	    0.965	  0.145%	 82.927%	     0.000	        1	[densenet201/conv4_block47_0_bn/FusedBatchNormV3]:332
	                     ADD	          553.704	    1.344	    1.379	  0.207%	 83.133%	     0.000	        1	[densenet201/conv4_block47_0_relu/Relu;densenet201/conv4_block47_0_bn/FusedBatchNormV3]:333
	                 CONV_2D	          555.084	    4.569	    4.610	  0.691%	 83.824%	     0.000	        1	[densenet201/conv4_block47_1_relu/Relu;densenet201/conv4_block47_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block47_1_conv/Conv2D]:334
	                 CONV_2D	          559.695	    0.935	    0.858	  0.129%	 83.953%	     0.000	        1	[densenet201/conv4_block47_2_conv/Conv2D1]:335
	           CONCATENATION	          560.554	    0.213	    0.200	  0.030%	 83.983%	     0.000	        1	[densenet201/conv4_block47_concat/concat]:336
	                     MUL	          560.755	    0.993	    0.990	  0.148%	 84.131%	     0.000	        1	[densenet201/conv4_block48_0_bn/FusedBatchNormV3]:337
	                     ADD	          561.746	    1.369	    1.404	  0.210%	 84.342%	     0.000	        1	[densenet201/conv4_block48_0_relu/Relu;densenet201/conv4_block48_0_bn/FusedBatchNormV3]:338
	                 CONV_2D	          563.151	    4.681	    4.700	  0.704%	 85.046%	     0.000	        1	[densenet201/conv4_block48_1_relu/Relu;densenet201/conv4_block48_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block48_1_conv/Conv2D]:339
	                 CONV_2D	          567.852	    0.854	    0.856	  0.128%	 85.174%	     0.000	        1	[densenet201/conv4_block48_2_conv/Conv2D1]:340
	           CONCATENATION	          568.709	    0.194	    0.203	  0.030%	 85.204%	     0.000	        1	[densenet201/conv4_block48_concat/concat]:341
	                     MUL	          568.912	    0.983	    1.002	  0.150%	 85.355%	     0.000	        1	[densenet201/pool4_bn/FusedBatchNormV3]:342
	                     ADD	          569.915	    1.425	    1.428	  0.214%	 85.568%	     0.000	        1	[densenet201/pool4_relu/Relu;densenet201/pool4_bn/FusedBatchNormV3]:343
	                 CONV_2D	          571.344	   33.374	   33.362	  4.999%	 90.568%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	         AVERAGE_POOL_2D	          604.707	    0.461	    0.466	  0.070%	 90.637%	     0.000	        1	[densenet201/pool4_pool/AvgPool]:345
	                     MUL	          605.174	    0.135	    0.135	  0.020%	 90.658%	     0.000	        1	[densenet201/conv5_block1_0_bn/FusedBatchNormV31]:346
	                     ADD	          605.309	    0.176	    0.190	  0.029%	 90.686%	     0.000	        1	[densenet201/conv5_block1_0_relu/Relu;densenet201/conv5_block1_0_bn/FusedBatchNormV3]:347
	                 CONV_2D	          605.502	    0.735	    0.705	  0.106%	 90.792%	     0.000	        1	[densenet201/conv5_block1_1_relu/Relu;densenet201/conv5_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block1_1_conv/Conv2D]:348
	                 CONV_2D	          606.207	    0.250	    0.256	  0.038%	 90.830%	     0.000	        1	[densenet201/conv5_block1_2_conv/Conv2D1]:349
	           CONCATENATION	          606.464	    0.015	    0.016	  0.002%	 90.833%	     0.000	        1	[densenet201/conv5_block1_concat/concat]:350
	                     MUL	          606.481	    0.136	    0.134	  0.020%	 90.853%	     0.000	        1	[densenet201/conv5_block2_0_bn/FusedBatchNormV31]:351
	                     ADD	          606.616	    0.186	    0.190	  0.028%	 90.881%	     0.000	        1	[densenet201/conv5_block2_0_relu/Relu;densenet201/conv5_block2_0_bn/FusedBatchNormV3]:352
	                 CONV_2D	          606.806	    0.663	    0.683	  0.102%	 90.983%	     0.000	        1	[densenet201/conv5_block2_1_relu/Relu;densenet201/conv5_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block2_1_conv/Conv2D]:353
	                 CONV_2D	          607.490	    0.234	    0.244	  0.037%	 91.020%	     0.000	        1	[densenet201/conv5_block2_2_conv/Conv2D1]:354
	           CONCATENATION	          607.734	    0.011	    0.012	  0.002%	 91.022%	     0.000	        1	[densenet201/conv5_block2_concat/concat]:355
	                     MUL	          607.747	    0.249	    0.138	  0.021%	 91.042%	     0.000	        1	[densenet201/conv5_block3_0_bn/FusedBatchNormV31]:356
	                     ADD	          607.885	    0.200	    0.193	  0.029%	 91.071%	     0.000	        1	[densenet201/conv5_block3_0_relu/Relu;densenet201/conv5_block3_0_bn/FusedBatchNormV3]:357
	                 CONV_2D	          608.078	    0.689	    0.710	  0.106%	 91.178%	     0.000	        1	[densenet201/conv5_block3_1_relu/Relu;densenet201/conv5_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block3_1_conv/Conv2D]:358
	                 CONV_2D	          608.788	    0.235	    0.238	  0.036%	 91.213%	     0.000	        1	[densenet201/conv5_block3_2_conv/Conv2D1]:359
	           CONCATENATION	          609.027	    0.012	    0.013	  0.002%	 91.215%	     0.000	        1	[densenet201/conv5_block3_concat/concat]:360
	                     MUL	          609.041	    0.145	    0.142	  0.021%	 91.237%	     0.000	        1	[densenet201/conv5_block4_0_bn/FusedBatchNormV31]:361
	                     ADD	          609.184	    0.199	    0.200	  0.030%	 91.267%	     0.000	        1	[densenet201/conv5_block4_0_relu/Relu;densenet201/conv5_block4_0_bn/FusedBatchNormV3]:362
	                 CONV_2D	          609.384	    0.712	    0.722	  0.108%	 91.375%	     0.000	        1	[densenet201/conv5_block4_1_relu/Relu;densenet201/conv5_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block4_1_conv/Conv2D]:363
	                 CONV_2D	          610.106	    0.232	    0.239	  0.036%	 91.411%	     0.000	        1	[densenet201/conv5_block4_2_conv/Conv2D1]:364
	           CONCATENATION	          610.346	    0.010	    0.012	  0.002%	 91.412%	     0.000	        1	[densenet201/conv5_block4_concat/concat]:365
	                     MUL	          610.359	    0.186	    0.147	  0.022%	 91.434%	     0.000	        1	[densenet201/conv5_block5_0_bn/FusedBatchNormV31]:366
	                     ADD	          610.507	    0.198	    0.205	  0.031%	 91.465%	     0.000	        1	[densenet201/conv5_block5_0_relu/Relu;densenet201/conv5_block5_0_bn/FusedBatchNormV3]:367
	                 CONV_2D	          610.713	    0.745	    0.744	  0.112%	 91.577%	     0.000	        1	[densenet201/conv5_block5_1_relu/Relu;densenet201/conv5_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block5_1_conv/Conv2D]:368
	                 CONV_2D	          611.458	    0.248	    0.239	  0.036%	 91.613%	     0.000	        1	[densenet201/conv5_block5_2_conv/Conv2D1]:369
	           CONCATENATION	          611.698	    0.015	    0.013	  0.002%	 91.615%	     0.000	        1	[densenet201/conv5_block5_concat/concat]:370
	                     MUL	          611.712	    0.181	    0.150	  0.022%	 91.637%	     0.000	        1	[densenet201/conv5_block6_0_bn/FusedBatchNormV31]:371
	                     ADD	          611.862	    0.217	    0.211	  0.032%	 91.669%	     0.000	        1	[densenet201/conv5_block6_0_relu/Relu;densenet201/conv5_block6_0_bn/FusedBatchNormV3]:372
	                 CONV_2D	          612.074	    0.774	    0.771	  0.116%	 91.784%	     0.000	        1	[densenet201/conv5_block6_1_relu/Relu;densenet201/conv5_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block6_1_conv/Conv2D]:373
	                 CONV_2D	          612.845	    0.240	    0.240	  0.036%	 91.820%	     0.000	        1	[densenet201/conv5_block6_2_conv/Conv2D1]:374
	           CONCATENATION	          613.086	    0.014	    0.013	  0.002%	 91.822%	     0.000	        1	[densenet201/conv5_block6_concat/concat]:375
	                     MUL	          613.099	    0.156	    0.154	  0.023%	 91.845%	     0.000	        1	[densenet201/conv5_block7_0_bn/FusedBatchNormV31]:376
	                     ADD	          613.254	    0.218	    0.218	  0.033%	 91.878%	     0.000	        1	[densenet201/conv5_block7_0_relu/Relu;densenet201/conv5_block7_0_bn/FusedBatchNormV3]:377
	                 CONV_2D	          613.472	    0.808	    0.791	  0.119%	 91.996%	     0.000	        1	[densenet201/conv5_block7_1_relu/Relu;densenet201/conv5_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block7_1_conv/Conv2D]:378
	                 CONV_2D	          614.264	    0.240	    0.242	  0.036%	 92.033%	     0.000	        1	[densenet201/conv5_block7_2_conv/Conv2D1]:379
	           CONCATENATION	          614.507	    0.012	    0.013	  0.002%	 92.035%	     0.000	        1	[densenet201/conv5_block7_concat/concat]:380
	                     MUL	          614.521	    0.153	    0.159	  0.024%	 92.059%	     0.000	        1	[densenet201/conv5_block8_0_bn/FusedBatchNormV31]:381
	                     ADD	          614.680	    0.224	    0.227	  0.034%	 92.093%	     0.000	        1	[densenet201/conv5_block8_0_relu/Relu;densenet201/conv5_block8_0_bn/FusedBatchNormV3]:382
	                 CONV_2D	          614.909	    0.839	    0.813	  0.122%	 92.214%	     0.000	        1	[densenet201/conv5_block8_1_relu/Relu;densenet201/conv5_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block8_1_conv/Conv2D]:383
	                 CONV_2D	          615.722	    0.239	    0.240	  0.036%	 92.250%	     0.000	        1	[densenet201/conv5_block8_2_conv/Conv2D1]:384
	           CONCATENATION	          615.963	    0.012	    0.013	  0.002%	 92.252%	     0.000	        1	[densenet201/conv5_block8_concat/concat]:385
	                     MUL	          615.977	    0.157	    0.164	  0.025%	 92.277%	     0.000	        1	[densenet201/conv5_block9_0_bn/FusedBatchNormV31]:386
	                     ADD	          616.141	    0.229	    0.230	  0.034%	 92.311%	     0.000	        1	[densenet201/conv5_block9_0_relu/Relu;densenet201/conv5_block9_0_bn/FusedBatchNormV3]:387
	                 CONV_2D	          616.371	    0.831	    0.841	  0.126%	 92.437%	     0.000	        1	[densenet201/conv5_block9_1_relu/Relu;densenet201/conv5_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block9_1_conv/Conv2D]:388
	                 CONV_2D	          617.213	    0.238	    0.246	  0.037%	 92.474%	     0.000	        1	[densenet201/conv5_block9_2_conv/Conv2D1]:389
	           CONCATENATION	          617.460	    0.011	    0.014	  0.002%	 92.476%	     0.000	        1	[densenet201/conv5_block9_concat/concat]:390
	                     MUL	          617.475	    0.161	    0.170	  0.025%	 92.502%	     0.000	        1	[densenet201/conv5_block10_0_bn/FusedBatchNormV31]:391
	                     ADD	          617.645	    0.236	    0.239	  0.036%	 92.538%	     0.000	        1	[densenet201/conv5_block10_0_relu/Relu;densenet201/conv5_block10_0_bn/FusedBatchNormV3]:392
	                 CONV_2D	          617.884	    0.851	    0.859	  0.129%	 92.666%	     0.000	        1	[densenet201/conv5_block10_1_relu/Relu;densenet201/conv5_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block10_1_conv/Conv2D]:393
	                 CONV_2D	          618.744	    0.237	    0.249	  0.037%	 92.704%	     0.000	        1	[densenet201/conv5_block10_2_conv/Conv2D1]:394
	           CONCATENATION	          618.993	    0.012	    0.014	  0.002%	 92.706%	     0.000	        1	[densenet201/conv5_block10_concat/concat]:395
	                     MUL	          619.008	    0.165	    0.173	  0.026%	 92.732%	     0.000	        1	[densenet201/conv5_block11_0_bn/FusedBatchNormV31]:396
	                     ADD	          619.181	    0.241	    0.243	  0.036%	 92.768%	     0.000	        1	[densenet201/conv5_block11_0_relu/Relu;densenet201/conv5_block11_0_bn/FusedBatchNormV3]:397
	                 CONV_2D	          619.424	    0.962	    0.883	  0.132%	 92.900%	     0.000	        1	[densenet201/conv5_block11_1_relu/Relu;densenet201/conv5_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block11_1_conv/Conv2D]:398
	                 CONV_2D	          620.308	    0.248	    0.248	  0.037%	 92.937%	     0.000	        1	[densenet201/conv5_block11_2_conv/Conv2D1]:399
	           CONCATENATION	          620.556	    0.015	    0.016	  0.002%	 92.940%	     0.000	        1	[densenet201/conv5_block11_concat/concat]:400
	                     MUL	          620.572	    0.178	    0.179	  0.027%	 92.966%	     0.000	        1	[densenet201/conv5_block12_0_bn/FusedBatchNormV31]:401
	                     ADD	          620.752	    0.248	    0.250	  0.037%	 93.004%	     0.000	        1	[densenet201/conv5_block12_0_relu/Relu;densenet201/conv5_block12_0_bn/FusedBatchNormV3]:402
	                 CONV_2D	          621.002	    0.883	    0.904	  0.135%	 93.139%	     0.000	        1	[densenet201/conv5_block12_1_relu/Relu;densenet201/conv5_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block12_1_conv/Conv2D]:403
	                 CONV_2D	          621.906	    0.235	    0.240	  0.036%	 93.175%	     0.000	        1	[densenet201/conv5_block12_2_conv/Conv2D1]:404
	           CONCATENATION	          622.147	    0.012	    0.015	  0.002%	 93.177%	     0.000	        1	[densenet201/conv5_block12_concat/concat]:405
	                     MUL	          622.162	    0.182	    0.182	  0.027%	 93.205%	     0.000	        1	[densenet201/conv5_block13_0_bn/FusedBatchNormV31]:406
	                     ADD	          622.345	    0.254	    0.256	  0.038%	 93.243%	     0.000	        1	[densenet201/conv5_block13_0_relu/Relu;densenet201/conv5_block13_0_bn/FusedBatchNormV3]:407
	                 CONV_2D	          622.601	    0.911	    0.923	  0.138%	 93.381%	     0.000	        1	[densenet201/conv5_block13_1_relu/Relu;densenet201/conv5_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block13_1_conv/Conv2D]:408
	                 CONV_2D	          623.525	    0.267	    0.245	  0.037%	 93.418%	     0.000	        1	[densenet201/conv5_block13_2_conv/Conv2D1]:409
	           CONCATENATION	          623.771	    0.015	    0.015	  0.002%	 93.420%	     0.000	        1	[densenet201/conv5_block13_concat/concat]:410
	                     MUL	          623.786	    0.178	    0.185	  0.028%	 93.448%	     0.000	        1	[densenet201/conv5_block14_0_bn/FusedBatchNormV31]:411
	                     ADD	          623.971	    0.265	    0.262	  0.039%	 93.487%	     0.000	        1	[densenet201/conv5_block14_0_relu/Relu;densenet201/conv5_block14_0_bn/FusedBatchNormV3]:412
	                 CONV_2D	          624.234	    0.936	    0.945	  0.142%	 93.629%	     0.000	        1	[densenet201/conv5_block14_1_relu/Relu;densenet201/conv5_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block14_1_conv/Conv2D]:413
	                 CONV_2D	          625.179	    0.238	    0.242	  0.036%	 93.665%	     0.000	        1	[densenet201/conv5_block14_2_conv/Conv2D1]:414
	           CONCATENATION	          625.422	    0.014	    0.017	  0.003%	 93.668%	     0.000	        1	[densenet201/conv5_block14_concat/concat]:415
	                     MUL	          625.439	    0.190	    0.191	  0.029%	 93.696%	     0.000	        1	[densenet201/conv5_block15_0_bn/FusedBatchNormV31]:416
	                     ADD	          625.631	    0.264	    0.269	  0.040%	 93.737%	     0.000	        1	[densenet201/conv5_block15_0_relu/Relu;densenet201/conv5_block15_0_bn/FusedBatchNormV3]:417
	                 CONV_2D	          625.900	    0.955	    0.969	  0.145%	 93.882%	     0.000	        1	[densenet201/conv5_block15_1_relu/Relu;densenet201/conv5_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block15_1_conv/Conv2D]:418
	                 CONV_2D	          626.869	    0.235	    0.246	  0.037%	 93.918%	     0.000	        1	[densenet201/conv5_block15_2_conv/Conv2D1]:419
	           CONCATENATION	          627.116	    0.013	    0.016	  0.002%	 93.921%	     0.000	        1	[densenet201/conv5_block15_concat/concat]:420
	                     MUL	          627.132	    0.194	    0.194	  0.029%	 93.950%	     0.000	        1	[densenet201/conv5_block16_0_bn/FusedBatchNormV31]:421
	                     ADD	          627.327	    0.272	    0.276	  0.041%	 93.991%	     0.000	        1	[densenet201/conv5_block16_0_relu/Relu;densenet201/conv5_block16_0_bn/FusedBatchNormV3]:422
	                 CONV_2D	          627.603	    0.997	    0.994	  0.149%	 94.140%	     0.000	        1	[densenet201/conv5_block16_1_relu/Relu;densenet201/conv5_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block16_1_conv/Conv2D]:423
	                 CONV_2D	          628.598	    0.239	    0.242	  0.036%	 94.177%	     0.000	        1	[densenet201/conv5_block16_2_conv/Conv2D1]:424
	           CONCATENATION	          628.841	    0.041	    0.017	  0.002%	 94.179%	     0.000	        1	[densenet201/conv5_block16_concat/concat]:425
	                     MUL	          628.858	    0.201	    0.201	  0.030%	 94.209%	     0.000	        1	[densenet201/conv5_block17_0_bn/FusedBatchNormV31]:426
	                     ADD	          629.060	    0.278	    0.281	  0.042%	 94.251%	     0.000	        1	[densenet201/conv5_block17_0_relu/Relu;densenet201/conv5_block17_0_bn/FusedBatchNormV3]:427
	                 CONV_2D	          629.341	    0.999	    1.015	  0.152%	 94.403%	     0.000	        1	[densenet201/conv5_block17_1_relu/Relu;densenet201/conv5_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block17_1_conv/Conv2D]:428
	                 CONV_2D	          630.357	    0.240	    0.246	  0.037%	 94.440%	     0.000	        1	[densenet201/conv5_block17_2_conv/Conv2D1]:429
	           CONCATENATION	          630.603	    0.014	    0.017	  0.002%	 94.443%	     0.000	        1	[densenet201/conv5_block17_concat/concat]:430
	                     MUL	          630.620	    0.203	    0.205	  0.031%	 94.473%	     0.000	        1	[densenet201/conv5_block18_0_bn/FusedBatchNormV31]:431
	                     ADD	          630.826	    0.282	    0.290	  0.044%	 94.517%	     0.000	        1	[densenet201/conv5_block18_0_relu/Relu;densenet201/conv5_block18_0_bn/FusedBatchNormV3]:432
	                 CONV_2D	          631.117	    1.047	    1.032	  0.155%	 94.672%	     0.000	        1	[densenet201/conv5_block18_1_relu/Relu;densenet201/conv5_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block18_1_conv/Conv2D]:433
	                 CONV_2D	          632.149	    0.244	    0.244	  0.036%	 94.708%	     0.000	        1	[densenet201/conv5_block18_2_conv/Conv2D1]:434
	           CONCATENATION	          632.393	    0.015	    0.016	  0.002%	 94.710%	     0.000	        1	[densenet201/conv5_block18_concat/concat]:435
	                     MUL	          632.410	    0.206	    0.211	  0.032%	 94.742%	     0.000	        1	[densenet201/conv5_block19_0_bn/FusedBatchNormV31]:436
	                     ADD	          632.622	    0.289	    0.296	  0.044%	 94.786%	     0.000	        1	[densenet201/conv5_block19_0_relu/Relu;densenet201/conv5_block19_0_bn/FusedBatchNormV3]:437
	                 CONV_2D	          632.918	    1.041	    1.060	  0.159%	 94.945%	     0.000	        1	[densenet201/conv5_block19_1_relu/Relu;densenet201/conv5_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block19_1_conv/Conv2D]:438
	                 CONV_2D	          633.979	    0.237	    0.242	  0.036%	 94.981%	     0.000	        1	[densenet201/conv5_block19_2_conv/Conv2D1]:439
	           CONCATENATION	          634.221	    0.014	    0.017	  0.003%	 94.984%	     0.000	        1	[densenet201/conv5_block19_concat/concat]:440
	                     MUL	          634.239	    0.210	    0.213	  0.032%	 95.016%	     0.000	        1	[densenet201/conv5_block20_0_bn/FusedBatchNormV31]:441
	                     ADD	          634.452	    0.293	    0.298	  0.045%	 95.061%	     0.000	        1	[densenet201/conv5_block20_0_relu/Relu;densenet201/conv5_block20_0_bn/FusedBatchNormV3]:442
	                 CONV_2D	          634.751	    1.136	    1.088	  0.163%	 95.224%	     0.000	        1	[densenet201/conv5_block20_1_relu/Relu;densenet201/conv5_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block20_1_conv/Conv2D]:443
	                 CONV_2D	          635.840	    0.244	    0.248	  0.037%	 95.261%	     0.000	        1	[densenet201/conv5_block20_2_conv/Conv2D1]:444
	           CONCATENATION	          636.088	    0.016	    0.017	  0.003%	 95.263%	     0.000	        1	[densenet201/conv5_block20_concat/concat]:445
	                     MUL	          636.106	    0.216	    0.217	  0.033%	 95.296%	     0.000	        1	[densenet201/conv5_block21_0_bn/FusedBatchNormV31]:446
	                     ADD	          636.323	    0.301	    0.309	  0.046%	 95.342%	     0.000	        1	[densenet201/conv5_block21_0_relu/Relu;densenet201/conv5_block21_0_bn/FusedBatchNormV3]:447
	                 CONV_2D	          636.633	    1.085	    1.106	  0.166%	 95.508%	     0.000	        1	[densenet201/conv5_block21_1_relu/Relu;densenet201/conv5_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block21_1_conv/Conv2D]:448
	                 CONV_2D	          637.740	    0.237	    0.244	  0.037%	 95.545%	     0.000	        1	[densenet201/conv5_block21_2_conv/Conv2D1]:449
	           CONCATENATION	          637.985	    0.015	    0.019	  0.003%	 95.547%	     0.000	        1	[densenet201/conv5_block21_concat/concat]:450
	                     MUL	          638.004	    0.219	    0.221	  0.033%	 95.580%	     0.000	        1	[densenet201/conv5_block22_0_bn/FusedBatchNormV31]:451
	                     ADD	          638.225	    0.306	    0.313	  0.047%	 95.627%	     0.000	        1	[densenet201/conv5_block22_0_relu/Relu;densenet201/conv5_block22_0_bn/FusedBatchNormV3]:452
	                 CONV_2D	          638.539	    1.112	    1.129	  0.169%	 95.796%	     0.000	        1	[densenet201/conv5_block22_1_relu/Relu;densenet201/conv5_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block22_1_conv/Conv2D]:453
	                 CONV_2D	          639.669	    0.258	    0.249	  0.037%	 95.834%	     0.000	        1	[densenet201/conv5_block22_2_conv/Conv2D1]:454
	           CONCATENATION	          639.918	    0.016	    0.019	  0.003%	 95.837%	     0.000	        1	[densenet201/conv5_block22_concat/concat]:455
	                     MUL	          639.937	    0.225	    0.225	  0.034%	 95.870%	     0.000	        1	[densenet201/conv5_block23_0_bn/FusedBatchNormV31]:456
	                     ADD	          640.162	    0.313	    0.320	  0.048%	 95.918%	     0.000	        1	[densenet201/conv5_block23_0_relu/Relu;densenet201/conv5_block23_0_bn/FusedBatchNormV3]:457
	                 CONV_2D	          640.482	    1.139	    1.157	  0.173%	 96.091%	     0.000	        1	[densenet201/conv5_block23_1_relu/Relu;densenet201/conv5_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block23_1_conv/Conv2D]:458
	                 CONV_2D	          641.640	    0.241	    0.247	  0.037%	 96.128%	     0.000	        1	[densenet201/conv5_block23_2_conv/Conv2D1]:459
	           CONCATENATION	          641.888	    0.015	    0.018	  0.003%	 96.131%	     0.000	        1	[densenet201/conv5_block23_concat/concat]:460
	                     MUL	          641.906	    0.226	    0.229	  0.034%	 96.165%	     0.000	        1	[densenet201/conv5_block24_0_bn/FusedBatchNormV31]:461
	                     ADD	          642.136	    0.318	    0.325	  0.049%	 96.214%	     0.000	        1	[densenet201/conv5_block24_0_relu/Relu;densenet201/conv5_block24_0_bn/FusedBatchNormV3]:462
	                 CONV_2D	          642.462	    1.153	    1.164	  0.174%	 96.389%	     0.000	        1	[densenet201/conv5_block24_1_relu/Relu;densenet201/conv5_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block24_1_conv/Conv2D]:463
	                 CONV_2D	          643.626	    0.228	    0.248	  0.037%	 96.426%	     0.000	        1	[densenet201/conv5_block24_2_conv/Conv2D1]:464
	           CONCATENATION	          643.875	    0.107	    0.019	  0.003%	 96.429%	     0.000	        1	[densenet201/conv5_block24_concat/concat]:465
	                     MUL	          643.895	    0.241	    0.235	  0.035%	 96.464%	     0.000	        1	[densenet201/conv5_block25_0_bn/FusedBatchNormV31]:466
	                     ADD	          644.131	    0.327	    0.331	  0.050%	 96.514%	     0.000	        1	[densenet201/conv5_block25_0_relu/Relu;densenet201/conv5_block25_0_bn/FusedBatchNormV3]:467
	                 CONV_2D	          644.462	    1.199	    1.197	  0.179%	 96.693%	     0.000	        1	[densenet201/conv5_block25_1_relu/Relu;densenet201/conv5_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block25_1_conv/Conv2D]:468
	                 CONV_2D	          645.660	    0.241	    0.250	  0.037%	 96.730%	     0.000	        1	[densenet201/conv5_block25_2_conv/Conv2D1]:469
	           CONCATENATION	          645.911	    0.017	    0.019	  0.003%	 96.733%	     0.000	        1	[densenet201/conv5_block25_concat/concat]:470
	                     MUL	          645.930	    0.237	    0.240	  0.036%	 96.769%	     0.000	        1	[densenet201/conv5_block26_0_bn/FusedBatchNormV31]:471
	                     ADD	          646.170	    0.331	    0.338	  0.051%	 96.820%	     0.000	        1	[densenet201/conv5_block26_0_relu/Relu;densenet201/conv5_block26_0_bn/FusedBatchNormV3]:472
	                 CONV_2D	          646.509	    1.196	    1.210	  0.181%	 97.001%	     0.000	        1	[densenet201/conv5_block26_1_relu/Relu;densenet201/conv5_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block26_1_conv/Conv2D]:473
	                 CONV_2D	          647.720	    0.305	    0.251	  0.038%	 97.039%	     0.000	        1	[densenet201/conv5_block26_2_conv/Conv2D1]:474
	           CONCATENATION	          647.971	    0.018	    0.019	  0.003%	 97.042%	     0.000	        1	[densenet201/conv5_block26_concat/concat]:475
	                     MUL	          647.991	    0.241	    0.241	  0.036%	 97.078%	     0.000	        1	[densenet201/conv5_block27_0_bn/FusedBatchNormV31]:476
	                     ADD	          648.233	    0.337	    0.344	  0.052%	 97.129%	     0.000	        1	[densenet201/conv5_block27_0_relu/Relu;densenet201/conv5_block27_0_bn/FusedBatchNormV3]:477
	                 CONV_2D	          648.577	    1.237	    1.236	  0.185%	 97.315%	     0.000	        1	[densenet201/conv5_block27_1_relu/Relu;densenet201/conv5_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block27_1_conv/Conv2D]:478
	                 CONV_2D	          649.814	    0.235	    0.248	  0.037%	 97.352%	     0.000	        1	[densenet201/conv5_block27_2_conv/Conv2D1]:479
	           CONCATENATION	          650.063	    0.025	    0.022	  0.003%	 97.355%	     0.000	        1	[densenet201/conv5_block27_concat/concat]:480
	                     MUL	          650.085	    0.246	    0.250	  0.037%	 97.392%	     0.000	        1	[densenet201/conv5_block28_0_bn/FusedBatchNormV31]:481
	                     ADD	          650.335	    0.342	    0.350	  0.052%	 97.445%	     0.000	        1	[densenet201/conv5_block28_0_relu/Relu;densenet201/conv5_block28_0_bn/FusedBatchNormV3]:482
	                 CONV_2D	          650.686	    1.261	    1.263	  0.189%	 97.634%	     0.000	        1	[densenet201/conv5_block28_1_relu/Relu;densenet201/conv5_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block28_1_conv/Conv2D]:483
	                 CONV_2D	          651.949	    0.240	    0.247	  0.037%	 97.671%	     0.000	        1	[densenet201/conv5_block28_2_conv/Conv2D1]:484
	           CONCATENATION	          652.196	    0.019	    0.022	  0.003%	 97.674%	     0.000	        1	[densenet201/conv5_block28_concat/concat]:485
	                     MUL	          652.219	    0.248	    0.251	  0.038%	 97.712%	     0.000	        1	[densenet201/conv5_block29_0_bn/FusedBatchNormV31]:486
	                     ADD	          652.471	    0.350	    0.359	  0.054%	 97.766%	     0.000	        1	[densenet201/conv5_block29_0_relu/Relu;densenet201/conv5_block29_0_bn/FusedBatchNormV3]:487
	                 CONV_2D	          652.830	    1.258	    1.284	  0.192%	 97.958%	     0.000	        1	[densenet201/conv5_block29_1_relu/Relu;densenet201/conv5_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block29_1_conv/Conv2D]:488
	                 CONV_2D	          654.114	    0.236	    0.244	  0.037%	 97.995%	     0.000	        1	[densenet201/conv5_block29_2_conv/Conv2D1]:489
	           CONCATENATION	          654.359	    0.018	    0.023	  0.003%	 97.998%	     0.000	        1	[densenet201/conv5_block29_concat/concat]:490
	                     MUL	          654.382	    0.278	    0.257	  0.038%	 98.036%	     0.000	        1	[densenet201/conv5_block30_0_bn/FusedBatchNormV31]:491
	                     ADD	          654.639	    0.355	    0.367	  0.055%	 98.091%	     0.000	        1	[densenet201/conv5_block30_0_relu/Relu;densenet201/conv5_block30_0_bn/FusedBatchNormV3]:492
	                 CONV_2D	          655.007	    1.375	    1.302	  0.195%	 98.286%	     0.000	        1	[densenet201/conv5_block30_1_relu/Relu;densenet201/conv5_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block30_1_conv/Conv2D]:493
	                 CONV_2D	          656.309	    0.250	    0.251	  0.038%	 98.324%	     0.000	        1	[densenet201/conv5_block30_2_conv/Conv2D1]:494
	           CONCATENATION	          656.560	    0.021	    0.022	  0.003%	 98.327%	     0.000	        1	[densenet201/conv5_block30_concat/concat]:495
	                     MUL	          656.583	    0.258	    0.262	  0.039%	 98.367%	     0.000	        1	[densenet201/conv5_block31_0_bn/FusedBatchNormV31]:496
	                     ADD	          656.845	    0.368	    0.369	  0.055%	 98.422%	     0.000	        1	[densenet201/conv5_block31_0_relu/Relu;densenet201/conv5_block31_0_bn/FusedBatchNormV3]:497
	                 CONV_2D	          657.215	    1.301	    1.324	  0.198%	 98.620%	     0.000	        1	[densenet201/conv5_block31_1_relu/Relu;densenet201/conv5_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block31_1_conv/Conv2D]:498
	                 CONV_2D	          658.540	    0.240	    0.248	  0.037%	 98.657%	     0.000	        1	[densenet201/conv5_block31_2_conv/Conv2D1]:499
	           CONCATENATION	          658.788	    0.017	    0.021	  0.003%	 98.661%	     0.000	        1	[densenet201/conv5_block31_concat/concat]:500
	                     MUL	          658.810	    0.262	    0.268	  0.040%	 98.701%	     0.000	        1	[densenet201/conv5_block32_0_bn/FusedBatchNormV31]:501
	                     ADD	          659.079	    0.374	    0.374	  0.056%	 98.757%	     0.000	        1	[densenet201/conv5_block32_0_relu/Relu;densenet201/conv5_block32_0_bn/FusedBatchNormV3]:502
	                 CONV_2D	          659.454	    1.347	    1.347	  0.202%	 98.959%	     0.000	        1	[densenet201/conv5_block32_1_relu/Relu;densenet201/conv5_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block32_1_conv/Conv2D]:503
	                 CONV_2D	          660.801	    0.240	    0.244	  0.037%	 98.995%	     0.000	        1	[densenet201/conv5_block32_2_conv/Conv2D210]:504
	           CONCATENATION	          661.046	    0.020	    0.022	  0.003%	 98.999%	     0.000	        1	[densenet201/conv5_block32_concat/concat]:505
	                     MUL	          661.068	    0.265	    0.269	  0.040%	 99.039%	     0.000	        1	[densenet201/bn/FusedBatchNormV31]:506
	                     ADD	          661.338	    0.378	    0.381	  0.057%	 99.096%	     0.000	        1	[densenet201/relu/Relu;densenet201/bn/FusedBatchNormV3]:507
	                    MEAN	          661.719	    5.112	    5.150	  0.772%	 99.868%	     0.000	        1	[densenet201/avg_pool/Mean]:508
	         FULLY_CONNECTED	          666.870	    0.855	    0.867	  0.130%	 99.997%	     0.000	        1	[densenet201/predictions/MatMul;densenet201/predictions/BiasAdd]:509
	                 SOFTMAX	          667.738	    0.015	    0.017	  0.003%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:510

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          571.344	   33.374	   33.362	  4.999%	  4.999%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	                 CONV_2D	            1.150	   18.909	   18.864	  2.827%	  7.826%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                 CONV_2D	          168.125	   16.368	   16.463	  2.467%	 10.292%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	                 CONV_2D	           52.909	   16.393	   16.429	  2.462%	 12.754%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	                 CONV_2D	           29.424	   16.240	   16.101	  2.413%	 15.167%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	                 CONV_2D	          106.502	   16.011	   16.081	  2.410%	 17.576%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	                 CONV_2D	           78.828	   16.082	   16.060	  2.407%	 19.983%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	                 CONV_2D	          136.310	   15.956	   15.985	  2.395%	 22.378%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	                 CONV_2D	          190.818	   11.787	   11.798	  1.768%	 24.146%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	                 CONV_2D	          317.258	   11.120	   11.128	  1.667%	 25.813%	     0.000	        1	[densenet201/pool3_conv/Conv2D1]:100

Number of nodes executed: 511
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	      200	   511.319	    76.645%	    76.645%	     0.000	      200
	                     ADD	      102	    77.516	    11.619%	    88.265%	     0.000	      102
	                     MUL	      102	    54.332	     8.144%	    96.409%	     0.000	      102
	           CONCATENATION	       98	    10.746	     1.611%	    98.020%	     0.000	       98
	                    MEAN	        1	     5.150	     0.772%	    98.792%	     0.000	        1
	                     PAD	        2	     4.774	     0.716%	    99.507%	     0.000	        2
	         AVERAGE_POOL_2D	        3	     1.831	     0.274%	    99.782%	     0.000	        3
	         FULLY_CONNECTED	        1	     0.866	     0.130%	    99.912%	     0.000	        1
	             MAX_POOL_2D	        1	     0.573	     0.086%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.016	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=667188 curr=667429 min=666298 max=672025 avg=667372 std=710
Memory (bytes): count=0
511 nodes observed



free(): invalid pointer
[ perf record: Woken up 189 times to write data ]
[ perf record: Captured and wrote 47.013 MB /tmp/data.record (273799 samples) ]

71.183

