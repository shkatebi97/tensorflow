STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (147, 64, ), Input shape (52900, 3, ) (or (12544, 147, )), Output shape (12544, 64, ), ID: 0, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (12544, 147, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (160, 64, ) DONE
	Preparing Filter With Shape: (147, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 128, ), ID: 1, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 2, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (96, 128, ), Input shape (3136, 96, ) (or (3136, 96, )), Output shape (3136, 128, ), ID: 3, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 96, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (48, 128, ) DONE
	Preparing Filter With Shape: (96, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 4, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (3136, 128, ) (or (3136, 128, )), Output shape (3136, 128, ), ID: 5, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 6, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (3136, 160, ) (or (3136, 160, )), Output shape (3136, 128, ), ID: 7, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 8, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (3136, 192, ) (or (3136, 192, )), Output shape (3136, 128, ), ID: 9, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 10, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (3136, 224, ) (or (3136, 224, )), Output shape (3136, 128, ), ID: 11, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (112, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 112, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 12, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (3136, 256, ) (or (3136, 256, )), Output shape (3136, 128, ), ID: 13, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (3136, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 128, ), ID: 14, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 15, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (784, 160, ) (or (784, 160, )), Output shape (784, 128, ), ID: 16, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 17, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (784, 192, ) (or (784, 192, )), Output shape (784, 128, ), ID: 18, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 19, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (784, 224, ) (or (784, 224, )), Output shape (784, 128, ), ID: 20, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (112, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 112, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 21, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (784, 256, ) (or (784, 256, )), Output shape (784, 128, ), ID: 22, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 23, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (784, 288, ) (or (784, 288, )), Output shape (784, 128, ), ID: 24, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 144, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 25, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (784, 320, ) (or (784, 320, )), Output shape (784, 128, ), ID: 26, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 27, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (784, 352, ) (or (784, 352, )), Output shape (784, 128, ), ID: 28, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (176, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 176, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 29, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (784, 384, ) (or (784, 384, )), Output shape (784, 128, ), ID: 30, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 31, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (784, 416, ) (or (784, 416, )), Output shape (784, 128, ), ID: 32, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (208, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 208, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 33, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (784, 448, ) (or (784, 448, )), Output shape (784, 128, ), ID: 34, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 35, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (784, 480, ) (or (784, 480, )), Output shape (784, 128, ), ID: 36, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (240, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 240, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 37, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 256, ), Input shape (784, 512, ) (or (784, 512, )), Output shape (784, 256, ), ID: 38, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (784, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 256, ) DONE
	Preparing Filter With Shape: (512, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 128, ), ID: 39, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 40, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (196, 288, ) (or (196, 288, )), Output shape (196, 128, ), ID: 41, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 144, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 42, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (196, 320, ) (or (196, 320, )), Output shape (196, 128, ), ID: 43, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 44, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (196, 352, ) (or (196, 352, )), Output shape (196, 128, ), ID: 45, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (176, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 176, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 46, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (196, 384, ) (or (196, 384, )), Output shape (196, 128, ), ID: 47, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 48, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (196, 416, ) (or (196, 416, )), Output shape (196, 128, ), ID: 49, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (208, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 208, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 50, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (196, 448, ) (or (196, 448, )), Output shape (196, 128, ), ID: 51, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 52, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (196, 480, ) (or (196, 480, )), Output shape (196, 128, ), ID: 53, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (240, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 240, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 54, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 128, ), Input shape (196, 512, ) (or (196, 512, )), Output shape (196, 128, ), ID: 55, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (512, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 56, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (544, 128, ), Input shape (196, 544, ) (or (196, 544, )), Output shape (196, 128, ), ID: 57, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 544, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (272, 128, ) DONE
	Preparing Filter With Shape: (544, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 272, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 58, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 128, ), Input shape (196, 576, ) (or (196, 576, )), Output shape (196, 128, ), ID: 59, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 576, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 128, ) DONE
	Preparing Filter With Shape: (576, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 60, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (608, 128, ), Input shape (196, 608, ) (or (196, 608, )), Output shape (196, 128, ), ID: 61, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 608, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (304, 128, ) DONE
	Preparing Filter With Shape: (608, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 304, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 62, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (640, 128, ), Input shape (196, 640, ) (or (196, 640, )), Output shape (196, 128, ), ID: 63, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 640, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (320, 128, ) DONE
	Preparing Filter With Shape: (640, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 320, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 64, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (672, 128, ), Input shape (196, 672, ) (or (196, 672, )), Output shape (196, 128, ), ID: 65, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 672, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (336, 128, ) DONE
	Preparing Filter With Shape: (672, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 336, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 66, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (704, 128, ), Input shape (196, 704, ) (or (196, 704, )), Output shape (196, 128, ), ID: 67, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 704, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (352, 128, ) DONE
	Preparing Filter With Shape: (704, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 352, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 68, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (736, 128, ), Input shape (196, 736, ) (or (196, 736, )), Output shape (196, 128, ), ID: 69, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 736, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (368, 128, ) DONE
	Preparing Filter With Shape: (736, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 368, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 70, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (196, 768, ) (or (196, 768, )), Output shape (196, 128, ), ID: 71, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 768, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 72, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (800, 128, ), Input shape (196, 800, ) (or (196, 800, )), Output shape (196, 128, ), ID: 73, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 800, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (400, 128, ) DONE
	Preparing Filter With Shape: (800, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 400, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 74, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (832, 128, ), Input shape (196, 832, ) (or (196, 832, )), Output shape (196, 128, ), ID: 75, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 832, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (416, 128, ) DONE
	Preparing Filter With Shape: (832, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 416, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 76, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 128, ), Input shape (196, 864, ) (or (196, 864, )), Output shape (196, 128, ), ID: 77, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 864, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 128, ) DONE
	Preparing Filter With Shape: (864, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 432, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 78, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (196, 896, ) (or (196, 896, )), Output shape (196, 128, ), ID: 79, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 896, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 448, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 80, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (196, 928, ) (or (196, 928, )), Output shape (196, 128, ), ID: 81, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 928, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (464, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 464, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 82, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (196, 960, ) (or (196, 960, )), Output shape (196, 128, ), ID: 83, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 960, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 480, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 84, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (196, 992, ) (or (196, 992, )), Output shape (196, 128, ), ID: 85, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 992, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (496, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 496, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 86, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 128, ), ID: 87, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 88, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (196, 1056, ) (or (196, 1056, )), Output shape (196, 128, ), ID: 89, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1056, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (528, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 528, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 90, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (196, 1088, ) (or (196, 1088, )), Output shape (196, 128, ), ID: 91, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1088, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (544, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 544, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 92, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (196, 1120, ) (or (196, 1120, )), Output shape (196, 128, ), ID: 93, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1120, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 560, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 94, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (196, 1152, ) (or (196, 1152, )), Output shape (196, 128, ), ID: 95, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 96, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (196, 1184, ) (or (196, 1184, )), Output shape (196, 128, ), ID: 97, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1184, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (592, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 592, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 98, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (196, 1216, ) (or (196, 1216, )), Output shape (196, 128, ), ID: 99, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1216, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 608, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 100, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (196, 1248, ) (or (196, 1248, )), Output shape (196, 128, ), ID: 101, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1248, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (624, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 624, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 102, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (196, 1280, ) (or (196, 1280, )), Output shape (196, 128, ), ID: 103, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 104, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (196, 1312, ) (or (196, 1312, )), Output shape (196, 128, ), ID: 105, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1312, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (656, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 656, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 106, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (196, 1344, ) (or (196, 1344, )), Output shape (196, 128, ), ID: 107, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1344, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 672, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 108, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (196, 1376, ) (or (196, 1376, )), Output shape (196, 128, ), ID: 109, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1376, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (688, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 688, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 110, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (196, 1408, ) (or (196, 1408, )), Output shape (196, 128, ), ID: 111, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1408, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (704, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 704, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 112, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (196, 1440, ) (or (196, 1440, )), Output shape (196, 128, ), ID: 113, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1440, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (720, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 720, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 114, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (196, 1472, ) (or (196, 1472, )), Output shape (196, 128, ), ID: 115, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1472, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 736, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 116, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (196, 1504, ) (or (196, 1504, )), Output shape (196, 128, ), ID: 117, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1504, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (752, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 752, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 118, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (196, 1536, ) (or (196, 1536, )), Output shape (196, 128, ), ID: 119, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1536, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 768, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 120, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (196, 1568, ) (or (196, 1568, )), Output shape (196, 128, ), ID: 121, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1568, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (784, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 784, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 122, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (196, 1600, ) (or (196, 1600, )), Output shape (196, 128, ), ID: 123, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1600, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (800, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 800, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 124, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (196, 1632, ) (or (196, 1632, )), Output shape (196, 128, ), ID: 125, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1632, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (816, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 816, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 126, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (196, 1664, ) (or (196, 1664, )), Output shape (196, 128, ), ID: 127, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1664, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (832, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 832, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 128, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (196, 1696, ) (or (196, 1696, )), Output shape (196, 128, ), ID: 129, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1696, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (848, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 848, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 130, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (196, 1728, ) (or (196, 1728, )), Output shape (196, 128, ), ID: 131, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 132, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (196, 1760, ) (or (196, 1760, )), Output shape (196, 128, ), ID: 133, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1760, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (880, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 880, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 134, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 896, ), Input shape (196, 1792, ) (or (196, 1792, )), Output shape (196, 896, ), ID: 135, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (196, 1792, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 896, ) DONE
	Preparing Filter With Shape: (1792, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 896, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (49, 896, ) (or (49, 896, )), Output shape (49, 128, ), ID: 136, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 137, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (49, 928, ) (or (49, 928, )), Output shape (49, 128, ), ID: 138, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 928, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (464, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 464, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 139, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (49, 960, ) (or (49, 960, )), Output shape (49, 128, ), ID: 140, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 960, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 480, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 960, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 141, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (49, 992, ) (or (49, 992, )), Output shape (49, 128, ), ID: 142, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 992, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (496, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 496, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 992, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 143, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (49, 1024, ) (or (49, 1024, )), Output shape (49, 128, ), ID: 144, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 145, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (49, 1056, ) (or (49, 1056, )), Output shape (49, 128, ), ID: 146, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1056, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (528, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 528, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1056, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 147, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (49, 1088, ) (or (49, 1088, )), Output shape (49, 128, ), ID: 148, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1088, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (544, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 544, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1088, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 149, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (49, 1120, ) (or (49, 1120, )), Output shape (49, 128, ), ID: 150, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 151, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (49, 1152, ) (or (49, 1152, )), Output shape (49, 128, ), ID: 152, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 153, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (49, 1184, ) (or (49, 1184, )), Output shape (49, 128, ), ID: 154, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1184, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (592, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 592, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1184, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 155, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (49, 1216, ) (or (49, 1216, )), Output shape (49, 128, ), ID: 156, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1216, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 157, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (49, 1248, ) (or (49, 1248, )), Output shape (49, 128, ), ID: 158, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1248, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (624, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 624, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1248, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 159, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (49, 1280, ) (or (49, 1280, )), Output shape (49, 128, ), ID: 160, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1280, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 640, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1280, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 161, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (49, 1312, ) (or (49, 1312, )), Output shape (49, 128, ), ID: 162, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1312, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (656, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 656, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1312, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 163, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (49, 1344, ) (or (49, 1344, )), Output shape (49, 128, ), ID: 164, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 165, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (49, 1376, ) (or (49, 1376, )), Output shape (49, 128, ), ID: 166, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1376, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (688, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 688, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1376, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 167, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (49, 1408, ) (or (49, 1408, )), Output shape (49, 128, ), ID: 168, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1408, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (704, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 704, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1408, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 169, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (49, 1440, ) (or (49, 1440, )), Output shape (49, 128, ), ID: 170, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1440, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (720, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 720, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1440, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 171, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (49, 1472, ) (or (49, 1472, )), Output shape (49, 128, ), ID: 172, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1472, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 736, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1472, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 173, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (49, 1504, ) (or (49, 1504, )), Output shape (49, 128, ), ID: 174, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1504, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (752, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 752, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1504, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 175, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (49, 1536, ) (or (49, 1536, )), Output shape (49, 128, ), ID: 176, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1536, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1536, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 177, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (49, 1568, ) (or (49, 1568, )), Output shape (49, 128, ), ID: 178, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1568, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (784, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 784, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1568, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 179, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (49, 1600, ) (or (49, 1600, )), Output shape (49, 128, ), ID: 180, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1600, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (800, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 800, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1600, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 181, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (49, 1632, ) (or (49, 1632, )), Output shape (49, 128, ), ID: 182, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1632, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (816, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 816, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1632, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 183, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (49, 1664, ) (or (49, 1664, )), Output shape (49, 128, ), ID: 184, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1664, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (832, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 832, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1664, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 185, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (49, 1696, ) (or (49, 1696, )), Output shape (49, 128, ), ID: 186, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1696, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (848, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 848, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1696, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 187, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (49, 1728, ) (or (49, 1728, )), Output shape (49, 128, ), ID: 188, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 864, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 189, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (49, 1760, ) (or (49, 1760, )), Output shape (49, 128, ), ID: 190, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1760, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (880, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 880, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1760, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 191, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 128, ), Input shape (49, 1792, ) (or (49, 1792, )), Output shape (49, 128, ), ID: 192, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1792, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (1792, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1792, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 193, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1824, 128, ), Input shape (49, 1824, ) (or (49, 1824, )), Output shape (49, 128, ), ID: 194, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1824, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (912, 128, ) DONE
	Preparing Filter With Shape: (1824, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 912, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1824, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 195, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1856, 128, ), Input shape (49, 1856, ) (or (49, 1856, )), Output shape (49, 128, ), ID: 196, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1856, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (928, 128, ) DONE
	Preparing Filter With Shape: (1856, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1856, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 197, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1888, 128, ), Input shape (49, 1888, ) (or (49, 1888, )), Output shape (49, 128, ), ID: 198, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1888, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (944, 128, ) DONE
	Preparing Filter With Shape: (1888, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 944, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1888, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 199, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying FC Low-Precision for Kernel shape (1920, 1000, ), Input shape (1, 1920, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW4A4
	Allocating Filter Shape: (960, 1000, ) DONE
	Preparing Filter With Shape: (1920, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 960, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1920, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 20.5199
Initialized session in 286.976ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=738799 curr=724991 min=724991 max=738799 avg=731895 std=6904

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=680243 curr=670349 min=668885 max=682029 avg=670353 std=1951

Inference timings in us: Init: 286976, First inference: 738799, Warmup (avg): 731895, Inference (avg): 670353
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=35.3047 overall=43.6328
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  278.063	  278.063	100.000%	100.000%	 21376.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  278.063	  278.063	100.000%	100.000%	 21376.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   278.063	   100.000%	   100.000%	 21376.000	        1

Timings (microseconds): count=1 curr=278063
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     PAD	            0.021	    1.112	    1.129	  0.169%	  0.169%	     0.000	        1	[densenet201/zero_padding2d/Pad]:0
	                 CONV_2D	            1.151	   20.471	   18.873	  2.817%	  2.986%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                     PAD	           20.025	    3.782	    3.653	  0.545%	  3.531%	     0.000	        1	[densenet201/zero_padding2d_1/Pad]:2
	             MAX_POOL_2D	           23.679	    0.904	    0.593	  0.088%	  3.619%	     0.000	        1	[densenet201/pool1/MaxPool]:3
	                     MUL	           24.273	    0.650	    0.618	  0.092%	  3.712%	     0.000	        1	[densenet201/conv2_block1_0_bn/FusedBatchNormV31]:4
	                     ADD	           24.891	    0.880	    0.856	  0.128%	  3.839%	     0.000	        1	[densenet201/conv2_block1_0_relu/Relu;densenet201/conv2_block1_0_bn/FusedBatchNormV3]:5
	                 CONV_2D	           25.749	    4.036	    3.711	  0.554%	  4.393%	     0.000	        1	[densenet201/conv2_block1_1_relu/Relu;densenet201/conv2_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block1_1_conv/Conv2D]:6
	                 CONV_2D	           29.460	   18.490	   16.246	  2.425%	  6.818%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	           CONCATENATION	           45.708	    0.308	    0.187	  0.028%	  6.846%	     0.000	        1	[densenet201/conv2_block1_concat/concat]:8
	                     MUL	           45.896	    0.915	    0.897	  0.134%	  6.980%	     0.000	        1	[densenet201/conv2_block2_0_bn/FusedBatchNormV31]:9
	                     ADD	           46.793	    1.281	    1.267	  0.189%	  7.169%	     0.000	        1	[densenet201/conv2_block2_0_relu/Relu;densenet201/conv2_block2_0_bn/FusedBatchNormV3]:10
	                 CONV_2D	           48.061	    5.377	    5.037	  0.752%	  7.921%	     0.000	        1	[densenet201/conv2_block2_1_relu/Relu;densenet201/conv2_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block2_1_conv/Conv2D]:11
	                 CONV_2D	           53.098	   16.863	   16.698	  2.492%	 10.413%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	           CONCATENATION	           69.797	    0.302	    0.213	  0.032%	 10.445%	     0.000	        1	[densenet201/conv2_block2_concat/concat]:13
	                     MUL	           70.011	    1.158	    1.166	  0.174%	 10.619%	     0.000	        1	[densenet201/conv2_block3_0_bn/FusedBatchNormV3]:14
	                     ADD	           71.177	    1.740	    1.683	  0.251%	 10.870%	     0.000	        1	[densenet201/conv2_block3_0_relu/Relu;densenet201/conv2_block3_0_bn/FusedBatchNormV3]:15
	                 CONV_2D	           72.861	    6.504	    6.431	  0.960%	 11.830%	     0.000	        1	[densenet201/conv2_block3_1_relu/Relu;densenet201/conv2_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block3_1_conv/Conv2D]:16
	                 CONV_2D	           79.293	   17.340	   16.280	  2.430%	 14.260%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	           CONCATENATION	           95.575	    0.448	    0.361	  0.054%	 14.314%	     0.000	        1	[densenet201/conv2_block3_concat/concat]:18
	                     MUL	           95.936	    1.434	    1.461	  0.218%	 14.532%	     0.000	        1	[densenet201/conv2_block4_0_bn/FusedBatchNormV3]:19
	                     ADD	           97.399	    2.083	    2.085	  0.311%	 14.843%	     0.000	        1	[densenet201/conv2_block4_0_relu/Relu;densenet201/conv2_block4_0_bn/FusedBatchNormV3]:20
	                 CONV_2D	           99.485	    7.826	    7.710	  1.151%	 15.994%	     0.000	        1	[densenet201/conv2_block4_1_relu/Relu;densenet201/conv2_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block4_1_conv/Conv2D]:21
	                 CONV_2D	          107.196	   17.194	   16.121	  2.406%	 18.401%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	           CONCATENATION	          123.319	    0.492	    0.439	  0.066%	 18.466%	     0.000	        1	[densenet201/conv2_block4_concat/concat]:23
	                     MUL	          123.759	    1.731	    1.747	  0.261%	 18.727%	     0.000	        1	[densenet201/conv2_block5_0_bn/FusedBatchNormV3]:24
	                     ADD	          125.507	    2.574	    2.488	  0.371%	 19.098%	     0.000	        1	[densenet201/conv2_block5_0_relu/Relu;densenet201/conv2_block5_0_bn/FusedBatchNormV3]:25
	                 CONV_2D	          127.996	    9.111	    9.030	  1.348%	 20.446%	     0.000	        1	[densenet201/conv2_block5_1_relu/Relu;densenet201/conv2_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block5_1_conv/Conv2D]:26
	                 CONV_2D	          137.027	   16.331	   16.068	  2.398%	 22.844%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	           CONCATENATION	          153.096	    0.512	    0.516	  0.077%	 22.921%	     0.000	        1	[densenet201/conv2_block5_concat/concat]:28
	                     MUL	          153.613	    1.982	    2.020	  0.302%	 23.223%	     0.000	        1	[densenet201/conv2_block6_0_bn/FusedBatchNormV3]:29
	                     ADD	          155.634	    2.917	    2.905	  0.434%	 23.657%	     0.000	        1	[densenet201/conv2_block6_0_relu/Relu;densenet201/conv2_block6_0_bn/FusedBatchNormV3]:30
	                 CONV_2D	          158.540	   10.392	   10.349	  1.545%	 25.201%	     0.000	        1	[densenet201/conv2_block6_1_relu/Relu;densenet201/conv2_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block6_1_conv/Conv2D]:31
	                 CONV_2D	          168.890	   16.475	   16.628	  2.482%	 27.683%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	           CONCATENATION	          185.520	    0.531	    0.571	  0.085%	 27.768%	     0.000	        1	[densenet201/conv2_block6_concat/concat]:33
	                     MUL	          186.092	    2.293	    2.318	  0.346%	 28.114%	     0.000	        1	[densenet201/pool2_bn/FusedBatchNormV3]:34
	                     ADD	          188.411	    3.286	    3.313	  0.495%	 28.609%	     0.000	        1	[densenet201/pool2_relu/Relu;densenet201/pool2_bn/FusedBatchNormV3]:35
	                 CONV_2D	          191.725	   11.875	   11.770	  1.757%	 30.366%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	         AVERAGE_POOL_2D	          203.496	    0.893	    0.916	  0.137%	 30.502%	     0.000	        1	[densenet201/pool2_pool/AvgPool]:37
	                     MUL	          204.413	    0.297	    0.302	  0.045%	 30.548%	     0.000	        1	[densenet201/conv3_block1_0_bn/FusedBatchNormV3]:38
	                     ADD	          204.715	    0.418	    0.428	  0.064%	 30.611%	     0.000	        1	[densenet201/conv3_block1_0_relu/Relu;densenet201/conv3_block1_0_bn/FusedBatchNormV3]:39
	                 CONV_2D	          205.144	    1.773	    1.672	  0.250%	 30.861%	     0.000	        1	[densenet201/conv3_block1_1_relu/Relu;densenet201/conv3_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block1_1_conv/Conv2D]:40
	                 CONV_2D	          206.817	    3.889	    3.719	  0.555%	 31.416%	     0.000	        1	[densenet201/conv3_block1_2_conv/Conv2D1]:41
	           CONCATENATION	          210.538	    0.132	    0.138	  0.021%	 31.437%	     0.000	        1	[densenet201/conv3_block1_concat/concat]:42
	                     MUL	          210.677	    0.361	    0.373	  0.056%	 31.493%	     0.000	        1	[densenet201/conv3_block2_0_bn/FusedBatchNormV31]:43
	                     ADD	          211.051	    0.547	    0.522	  0.078%	 31.571%	     0.000	        1	[densenet201/conv3_block2_0_relu/Relu;densenet201/conv3_block2_0_bn/FusedBatchNormV3]:44
	                 CONV_2D	          211.574	    1.994	    1.982	  0.296%	 31.866%	     0.000	        1	[densenet201/conv3_block2_1_relu/Relu;densenet201/conv3_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block2_1_conv/Conv2D]:45
	                 CONV_2D	          213.556	    3.987	    3.738	  0.558%	 32.424%	     0.000	        1	[densenet201/conv3_block2_2_conv/Conv2D1]:46
	           CONCATENATION	          217.295	    0.119	    0.166	  0.025%	 32.449%	     0.000	        1	[densenet201/conv3_block2_concat/concat]:47
	                     MUL	          217.462	    0.438	    0.445	  0.066%	 32.515%	     0.000	        1	[densenet201/conv3_block3_0_bn/FusedBatchNormV31]:48
	                     ADD	          217.908	    0.608	    0.624	  0.093%	 32.608%	     0.000	        1	[densenet201/conv3_block3_0_relu/Relu;densenet201/conv3_block3_0_bn/FusedBatchNormV3]:49
	                 CONV_2D	          218.533	    2.282	    2.324	  0.347%	 32.955%	     0.000	        1	[densenet201/conv3_block3_1_relu/Relu;densenet201/conv3_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block3_1_conv/Conv2D]:50
	                 CONV_2D	          220.857	    3.859	    3.750	  0.560%	 33.515%	     0.000	        1	[densenet201/conv3_block3_2_conv/Conv2D1]:51
	           CONCATENATION	          224.609	    0.149	    0.192	  0.029%	 33.544%	     0.000	        1	[densenet201/conv3_block3_concat/concat]:52
	                     MUL	          224.802	    0.540	    0.518	  0.077%	 33.621%	     0.000	        1	[densenet201/conv3_block4_0_bn/FusedBatchNormV31]:53
	                     ADD	          225.320	    0.746	    0.725	  0.108%	 33.729%	     0.000	        1	[densenet201/conv3_block4_0_relu/Relu;densenet201/conv3_block4_0_bn/FusedBatchNormV3]:54
	                 CONV_2D	          226.046	    2.613	    2.640	  0.394%	 34.123%	     0.000	        1	[densenet201/conv3_block4_1_relu/Relu;densenet201/conv3_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block4_1_conv/Conv2D]:55
	                 CONV_2D	          228.687	    3.925	    3.753	  0.560%	 34.684%	     0.000	        1	[densenet201/conv3_block4_2_conv/Conv2D1]:56
	           CONCATENATION	          232.442	    0.152	    0.240	  0.036%	 34.720%	     0.000	        1	[densenet201/conv3_block4_concat/concat]:57
	                     MUL	          232.683	    0.615	    0.587	  0.088%	 34.807%	     0.000	        1	[densenet201/conv3_block5_0_bn/FusedBatchNormV3]:58
	                     ADD	          233.270	    0.816	    0.825	  0.123%	 34.930%	     0.000	        1	[densenet201/conv3_block5_0_relu/Relu;densenet201/conv3_block5_0_bn/FusedBatchNormV3]:59
	                 CONV_2D	          234.096	    3.002	    2.972	  0.444%	 35.374%	     0.000	        1	[densenet201/conv3_block5_1_relu/Relu;densenet201/conv3_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block5_1_conv/Conv2D]:60
	                 CONV_2D	          237.069	    3.891	    3.789	  0.566%	 35.940%	     0.000	        1	[densenet201/conv3_block5_2_conv/Conv2D1]:61
	           CONCATENATION	          240.860	    0.180	    0.262	  0.039%	 35.979%	     0.000	        1	[densenet201/conv3_block5_concat/concat]:62
	                     MUL	          241.122	    0.644	    0.659	  0.098%	 36.077%	     0.000	        1	[densenet201/conv3_block6_0_bn/FusedBatchNormV3]:63
	                     ADD	          241.781	    0.928	    0.945	  0.141%	 36.218%	     0.000	        1	[densenet201/conv3_block6_0_relu/Relu;densenet201/conv3_block6_0_bn/FusedBatchNormV3]:64
	                 CONV_2D	          242.727	    3.355	    3.319	  0.495%	 36.713%	     0.000	        1	[densenet201/conv3_block6_1_relu/Relu;densenet201/conv3_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block6_1_conv/Conv2D]:65
	                 CONV_2D	          246.047	    4.070	    3.880	  0.579%	 37.292%	     0.000	        1	[densenet201/conv3_block6_2_conv/Conv2D1]:66
	           CONCATENATION	          249.929	    0.206	    0.307	  0.046%	 37.338%	     0.000	        1	[densenet201/conv3_block6_concat/concat]:67
	                     MUL	          250.237	    0.715	    0.729	  0.109%	 37.447%	     0.000	        1	[densenet201/conv3_block7_0_bn/FusedBatchNormV3]:68
	                     ADD	          250.967	    1.033	    1.051	  0.157%	 37.604%	     0.000	        1	[densenet201/conv3_block7_0_relu/Relu;densenet201/conv3_block7_0_bn/FusedBatchNormV3]:69
	                 CONV_2D	          252.018	    3.752	    3.701	  0.552%	 38.156%	     0.000	        1	[densenet201/conv3_block7_1_relu/Relu;densenet201/conv3_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block7_1_conv/Conv2D]:70
	                 CONV_2D	          255.721	    3.847	    3.845	  0.574%	 38.730%	     0.000	        1	[densenet201/conv3_block7_2_conv/Conv2D1]:71
	           CONCATENATION	          259.567	    0.297	    0.327	  0.049%	 38.779%	     0.000	        1	[densenet201/conv3_block7_concat/concat]:72
	                     MUL	          259.895	    0.817	    0.802	  0.120%	 38.899%	     0.000	        1	[densenet201/conv3_block8_0_bn/FusedBatchNormV3]:73
	                     ADD	          260.697	    1.128	    1.159	  0.173%	 39.072%	     0.000	        1	[densenet201/conv3_block8_0_relu/Relu;densenet201/conv3_block8_0_bn/FusedBatchNormV3]:74
	                 CONV_2D	          261.857	    3.970	    3.994	  0.596%	 39.668%	     0.000	        1	[densenet201/conv3_block8_1_relu/Relu;densenet201/conv3_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block8_1_conv/Conv2D]:75
	                 CONV_2D	          265.852	    3.821	    3.817	  0.570%	 40.238%	     0.000	        1	[densenet201/conv3_block8_2_conv/Conv2D1]:76
	           CONCATENATION	          269.670	    0.359	    0.355	  0.053%	 40.291%	     0.000	        1	[densenet201/conv3_block8_concat/concat]:77
	                     MUL	          270.026	    0.863	    0.872	  0.130%	 40.421%	     0.000	        1	[densenet201/conv3_block9_0_bn/FusedBatchNormV3]:78
	                     ADD	          270.898	    1.240	    1.254	  0.187%	 40.608%	     0.000	        1	[densenet201/conv3_block9_0_relu/Relu;densenet201/conv3_block9_0_bn/FusedBatchNormV3]:79
	                 CONV_2D	          272.153	    4.395	    4.364	  0.651%	 41.259%	     0.000	        1	[densenet201/conv3_block9_1_relu/Relu;densenet201/conv3_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block9_1_conv/Conv2D]:80
	                 CONV_2D	          276.517	    3.886	    3.821	  0.570%	 41.830%	     0.000	        1	[densenet201/conv3_block9_2_conv/Conv2D1]:81
	           CONCATENATION	          280.340	    0.397	    0.392	  0.059%	 41.888%	     0.000	        1	[densenet201/conv3_block9_concat/concat]:82
	                     MUL	          280.733	    0.934	    0.936	  0.140%	 42.028%	     0.000	        1	[densenet201/conv3_block10_0_bn/FusedBatchNormV3]:83
	                     ADD	          281.670	    1.356	    1.366	  0.204%	 42.232%	     0.000	        1	[densenet201/conv3_block10_0_relu/Relu;densenet201/conv3_block10_0_bn/FusedBatchNormV3]:84
	                 CONV_2D	          283.037	    4.699	    4.696	  0.701%	 42.933%	     0.000	        1	[densenet201/conv3_block10_1_relu/Relu;densenet201/conv3_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block10_1_conv/Conv2D]:85
	                 CONV_2D	          287.734	    3.907	    3.809	  0.569%	 43.501%	     0.000	        1	[densenet201/conv3_block10_2_conv/Conv2D1]:86
	           CONCATENATION	          291.544	    0.434	    0.426	  0.064%	 43.565%	     0.000	        1	[densenet201/conv3_block10_concat/concat]:87
	                     MUL	          291.971	    1.044	    1.018	  0.152%	 43.717%	     0.000	        1	[densenet201/conv3_block11_0_bn/FusedBatchNormV3]:88
	                     ADD	          292.989	    1.493	    1.474	  0.220%	 43.937%	     0.000	        1	[densenet201/conv3_block11_0_relu/Relu;densenet201/conv3_block11_0_bn/FusedBatchNormV3]:89
	                 CONV_2D	          294.464	    5.019	    5.004	  0.747%	 44.684%	     0.000	        1	[densenet201/conv3_block11_1_relu/Relu;densenet201/conv3_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block11_1_conv/Conv2D]:90
	                 CONV_2D	          299.469	    3.945	    3.799	  0.567%	 45.251%	     0.000	        1	[densenet201/conv3_block11_2_conv/Conv2D1]:91
	           CONCATENATION	          303.270	    0.396	    0.446	  0.067%	 45.317%	     0.000	        1	[densenet201/conv3_block11_concat/concat]:92
	                     MUL	          303.716	    1.121	    1.078	  0.161%	 45.478%	     0.000	        1	[densenet201/conv3_block12_0_bn/FusedBatchNormV3]:93
	                     ADD	          304.795	    1.557	    1.573	  0.235%	 45.713%	     0.000	        1	[densenet201/conv3_block12_0_relu/Relu;densenet201/conv3_block12_0_bn/FusedBatchNormV3]:94
	                 CONV_2D	          306.369	    5.294	    5.332	  0.796%	 46.509%	     0.000	        1	[densenet201/conv3_block12_1_relu/Relu;densenet201/conv3_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block12_1_conv/Conv2D]:95
	                 CONV_2D	          311.702	    3.947	    3.827	  0.571%	 47.080%	     0.000	        1	[densenet201/conv3_block12_2_conv/Conv2D1]:96
	           CONCATENATION	          315.531	    0.365	    0.447	  0.067%	 47.147%	     0.000	        1	[densenet201/conv3_block12_concat/concat]:97
	                     MUL	          315.980	    1.152	    1.154	  0.172%	 47.319%	     0.000	        1	[densenet201/pool3_bn/FusedBatchNormV3]:98
	                     ADD	          317.134	    1.673	    1.681	  0.251%	 47.570%	     0.000	        1	[densenet201/pool3_relu/Relu;densenet201/pool3_bn/FusedBatchNormV3]:99
	                 CONV_2D	          318.816	   11.142	   11.130	  1.661%	 49.231%	     0.000	        1	[densenet201/pool3_conv/Conv2D1]:100
	         AVERAGE_POOL_2D	          329.948	    0.444	    0.451	  0.067%	 49.299%	     0.000	        1	[densenet201/pool3_pool/AvgPool]:101
	                     MUL	          330.399	    0.154	    0.154	  0.023%	 49.322%	     0.000	        1	[densenet201/conv4_block1_0_bn/FusedBatchNormV31]:102
	                     ADD	          330.554	    0.208	    0.212	  0.032%	 49.353%	     0.000	        1	[densenet201/conv4_block1_0_relu/Relu;densenet201/conv4_block1_0_bn/FusedBatchNormV3]:103
	                 CONV_2D	          330.766	    0.777	    0.791	  0.118%	 49.471%	     0.000	        1	[densenet201/conv4_block1_1_relu/Relu;densenet201/conv4_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block1_1_conv/Conv2D]:104
	                 CONV_2D	          331.557	    0.925	    0.920	  0.137%	 49.609%	     0.000	        1	[densenet201/conv4_block1_2_conv/Conv2D1]:105
	           CONCATENATION	          332.478	    0.033	    0.023	  0.003%	 49.612%	     0.000	        1	[densenet201/conv4_block1_concat/concat]:106
	                     MUL	          332.501	    0.171	    0.167	  0.025%	 49.637%	     0.000	        1	[densenet201/conv4_block2_0_bn/FusedBatchNormV31]:107
	                     ADD	          332.669	    0.234	    0.237	  0.035%	 49.673%	     0.000	        1	[densenet201/conv4_block2_0_relu/Relu;densenet201/conv4_block2_0_bn/FusedBatchNormV3]:108
	                 CONV_2D	          332.907	    0.833	    0.843	  0.126%	 49.798%	     0.000	        1	[densenet201/conv4_block2_1_relu/Relu;densenet201/conv4_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block2_1_conv/Conv2D]:109
	                 CONV_2D	          333.750	    0.805	    0.824	  0.123%	 49.921%	     0.000	        1	[densenet201/conv4_block2_2_conv/Conv2D1]:110
	           CONCATENATION	          334.575	    0.015	    0.017	  0.003%	 49.924%	     0.000	        1	[densenet201/conv4_block2_concat/concat]:111
	                     MUL	          334.593	    0.180	    0.181	  0.027%	 49.951%	     0.000	        1	[densenet201/conv4_block3_0_bn/FusedBatchNormV31]:112
	                     ADD	          334.774	    0.258	    0.261	  0.039%	 49.990%	     0.000	        1	[densenet201/conv4_block3_0_relu/Relu;densenet201/conv4_block3_0_bn/FusedBatchNormV3]:113
	                 CONV_2D	          335.036	    0.887	    0.906	  0.135%	 50.125%	     0.000	        1	[densenet201/conv4_block3_1_relu/Relu;densenet201/conv4_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block3_1_conv/Conv2D]:114
	                 CONV_2D	          335.943	    0.918	    0.821	  0.123%	 50.248%	     0.000	        1	[densenet201/conv4_block3_2_conv/Conv2D1]:115
	           CONCATENATION	          336.764	    0.024	    0.020	  0.003%	 50.251%	     0.000	        1	[densenet201/conv4_block3_concat/concat]:116
	                     MUL	          336.785	    0.192	    0.203	  0.030%	 50.281%	     0.000	        1	[densenet201/conv4_block4_0_bn/FusedBatchNormV31]:117
	                     ADD	          336.988	    0.292	    0.286	  0.043%	 50.324%	     0.000	        1	[densenet201/conv4_block4_0_relu/Relu;densenet201/conv4_block4_0_bn/FusedBatchNormV3]:118
	                 CONV_2D	          337.275	    1.001	    0.998	  0.149%	 50.472%	     0.000	        1	[densenet201/conv4_block4_1_relu/Relu;densenet201/conv4_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block4_1_conv/Conv2D]:119
	                 CONV_2D	          338.273	    0.811	    0.824	  0.123%	 50.596%	     0.000	        1	[densenet201/conv4_block4_2_conv/Conv2D1]:120
	           CONCATENATION	          339.098	    0.017	    0.020	  0.003%	 50.598%	     0.000	        1	[densenet201/conv4_block4_concat/concat]:121
	                     MUL	          339.118	    0.214	    0.216	  0.032%	 50.631%	     0.000	        1	[densenet201/conv4_block5_0_bn/FusedBatchNormV31]:122
	                     ADD	          339.335	    0.308	    0.313	  0.047%	 50.677%	     0.000	        1	[densenet201/conv4_block5_0_relu/Relu;densenet201/conv4_block5_0_bn/FusedBatchNormV3]:123
	                 CONV_2D	          339.649	    1.069	    1.067	  0.159%	 50.837%	     0.000	        1	[densenet201/conv4_block5_1_relu/Relu;densenet201/conv4_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block5_1_conv/Conv2D]:124
	                 CONV_2D	          340.717	    0.817	    0.824	  0.123%	 50.960%	     0.000	        1	[densenet201/conv4_block5_2_conv/Conv2D1]:125
	           CONCATENATION	          341.542	    0.020	    0.024	  0.004%	 50.963%	     0.000	        1	[densenet201/conv4_block5_concat/concat]:126
	                     MUL	          341.566	    0.231	    0.235	  0.035%	 50.998%	     0.000	        1	[densenet201/conv4_block6_0_bn/FusedBatchNormV31]:127
	                     ADD	          341.801	    0.333	    0.339	  0.051%	 51.049%	     0.000	        1	[densenet201/conv4_block6_0_relu/Relu;densenet201/conv4_block6_0_bn/FusedBatchNormV3]:128
	                 CONV_2D	          342.140	    1.191	    1.160	  0.173%	 51.222%	     0.000	        1	[densenet201/conv4_block6_1_relu/Relu;densenet201/conv4_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block6_1_conv/Conv2D]:129
	                 CONV_2D	          343.301	    0.803	    0.813	  0.121%	 51.343%	     0.000	        1	[densenet201/conv4_block6_2_conv/Conv2D1]:130
	           CONCATENATION	          344.115	    0.023	    0.023	  0.003%	 51.347%	     0.000	        1	[densenet201/conv4_block6_concat/concat]:131
	                     MUL	          344.138	    0.267	    0.255	  0.038%	 51.385%	     0.000	        1	[densenet201/conv4_block7_0_bn/FusedBatchNormV31]:132
	                     ADD	          344.394	    0.369	    0.366	  0.055%	 51.440%	     0.000	        1	[densenet201/conv4_block7_0_relu/Relu;densenet201/conv4_block7_0_bn/FusedBatchNormV3]:133
	                 CONV_2D	          344.761	    1.229	    1.241	  0.185%	 51.625%	     0.000	        1	[densenet201/conv4_block7_1_relu/Relu;densenet201/conv4_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block7_1_conv/Conv2D]:134
	                 CONV_2D	          346.002	    0.796	    0.809	  0.121%	 51.746%	     0.000	        1	[densenet201/conv4_block7_2_conv/Conv2D1]:135
	           CONCATENATION	          346.812	    0.023	    0.027	  0.004%	 51.750%	     0.000	        1	[densenet201/conv4_block7_concat/concat]:136
	                     MUL	          346.840	    0.265	    0.268	  0.040%	 51.790%	     0.000	        1	[densenet201/conv4_block8_0_bn/FusedBatchNormV31]:137
	                     ADD	          347.109	    0.389	    0.391	  0.058%	 51.848%	     0.000	        1	[densenet201/conv4_block8_0_relu/Relu;densenet201/conv4_block8_0_bn/FusedBatchNormV3]:138
	                 CONV_2D	          347.501	    1.367	    1.317	  0.197%	 52.045%	     0.000	        1	[densenet201/conv4_block8_1_relu/Relu;densenet201/conv4_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block8_1_conv/Conv2D]:139
	                 CONV_2D	          348.819	    0.807	    0.820	  0.122%	 52.167%	     0.000	        1	[densenet201/conv4_block8_2_conv/Conv2D1]:140
	           CONCATENATION	          349.639	    0.026	    0.026	  0.004%	 52.171%	     0.000	        1	[densenet201/conv4_block8_concat/concat]:141
	                     MUL	          349.666	    0.283	    0.285	  0.043%	 52.214%	     0.000	        1	[densenet201/conv4_block9_0_bn/FusedBatchNormV31]:142
	                     ADD	          349.952	    0.415	    0.418	  0.062%	 52.276%	     0.000	        1	[densenet201/conv4_block9_0_relu/Relu;densenet201/conv4_block9_0_bn/FusedBatchNormV3]:143
	                 CONV_2D	          350.371	    1.389	    1.407	  0.210%	 52.486%	     0.000	        1	[densenet201/conv4_block9_1_relu/Relu;densenet201/conv4_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block9_1_conv/Conv2D]:144
	                 CONV_2D	          351.778	    0.828	    0.821	  0.123%	 52.609%	     0.000	        1	[densenet201/conv4_block9_2_conv/Conv2D1]:145
	           CONCATENATION	          352.600	    0.026	    0.029	  0.004%	 52.613%	     0.000	        1	[densenet201/conv4_block9_concat/concat]:146
	                     MUL	          352.629	    0.300	    0.305	  0.046%	 52.658%	     0.000	        1	[densenet201/conv4_block10_0_bn/FusedBatchNormV31]:147
	                     ADD	          352.935	    0.431	    0.436	  0.065%	 52.724%	     0.000	        1	[densenet201/conv4_block10_0_relu/Relu;densenet201/conv4_block10_0_bn/FusedBatchNormV3]:148
	                 CONV_2D	          353.372	    1.470	    1.486	  0.222%	 52.945%	     0.000	        1	[densenet201/conv4_block10_1_relu/Relu;densenet201/conv4_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block10_1_conv/Conv2D]:149
	                 CONV_2D	          354.858	    0.812	    0.827	  0.123%	 53.069%	     0.000	        1	[densenet201/conv4_block10_2_conv/Conv2D1]:150
	           CONCATENATION	          355.685	    0.025	    0.030	  0.005%	 53.073%	     0.000	        1	[densenet201/conv4_block10_concat/concat]:151
	                     MUL	          355.716	    0.323	    0.322	  0.048%	 53.121%	     0.000	        1	[densenet201/conv4_block11_0_bn/FusedBatchNormV31]:152
	                     ADD	          356.039	    0.464	    0.463	  0.069%	 53.190%	     0.000	        1	[densenet201/conv4_block11_0_relu/Relu;densenet201/conv4_block11_0_bn/FusedBatchNormV3]:153
	                 CONV_2D	          356.502	    1.565	    1.572	  0.235%	 53.425%	     0.000	        1	[densenet201/conv4_block11_1_relu/Relu;densenet201/conv4_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block11_1_conv/Conv2D]:154
	                 CONV_2D	          358.075	    0.803	    0.818	  0.122%	 53.547%	     0.000	        1	[densenet201/conv4_block11_2_conv/Conv2D1]:155
	           CONCATENATION	          358.893	    0.037	    0.045	  0.007%	 53.554%	     0.000	        1	[densenet201/conv4_block11_concat/concat]:156
	                     MUL	          358.939	    0.335	    0.342	  0.051%	 53.605%	     0.000	        1	[densenet201/conv4_block12_0_bn/FusedBatchNormV31]:157
	                     ADD	          359.281	    0.481	    0.486	  0.073%	 53.677%	     0.000	        1	[densenet201/conv4_block12_0_relu/Relu;densenet201/conv4_block12_0_bn/FusedBatchNormV3]:158
	                 CONV_2D	          359.767	    1.673	    1.657	  0.247%	 53.925%	     0.000	        1	[densenet201/conv4_block12_1_relu/Relu;densenet201/conv4_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block12_1_conv/Conv2D]:159
	                 CONV_2D	          361.425	    0.826	    0.828	  0.124%	 54.048%	     0.000	        1	[densenet201/conv4_block12_2_conv/Conv2D1]:160
	           CONCATENATION	          362.253	    0.050	    0.042	  0.006%	 54.054%	     0.000	        1	[densenet201/conv4_block12_concat/concat]:161
	                     MUL	          362.295	    0.351	    0.358	  0.053%	 54.108%	     0.000	        1	[densenet201/conv4_block13_0_bn/FusedBatchNormV31]:162
	                     ADD	          362.654	    0.504	    0.511	  0.076%	 54.184%	     0.000	        1	[densenet201/conv4_block13_0_relu/Relu;densenet201/conv4_block13_0_bn/FusedBatchNormV3]:163
	                 CONV_2D	          363.165	    1.746	    1.742	  0.260%	 54.444%	     0.000	        1	[densenet201/conv4_block13_1_relu/Relu;densenet201/conv4_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block13_1_conv/Conv2D]:164
	                 CONV_2D	          364.907	    0.798	    0.810	  0.121%	 54.565%	     0.000	        1	[densenet201/conv4_block13_2_conv/Conv2D1]:165
	           CONCATENATION	          365.718	    0.033	    0.040	  0.006%	 54.571%	     0.000	        1	[densenet201/conv4_block13_concat/concat]:166
	                     MUL	          365.758	    0.375	    0.377	  0.056%	 54.627%	     0.000	        1	[densenet201/conv4_block14_0_bn/FusedBatchNormV31]:167
	                     ADD	          366.136	    0.530	    0.536	  0.080%	 54.707%	     0.000	        1	[densenet201/conv4_block14_0_relu/Relu;densenet201/conv4_block14_0_bn/FusedBatchNormV3]:168
	                 CONV_2D	          366.673	    1.809	    1.810	  0.270%	 54.977%	     0.000	        1	[densenet201/conv4_block14_1_relu/Relu;densenet201/conv4_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block14_1_conv/Conv2D]:169
	                 CONV_2D	          368.483	    0.832	    0.836	  0.125%	 55.102%	     0.000	        1	[densenet201/conv4_block14_2_conv/Conv2D1]:170
	           CONCATENATION	          369.320	    0.053	    0.047	  0.007%	 55.109%	     0.000	        1	[densenet201/conv4_block14_concat/concat]:171
	                     MUL	          369.368	    0.384	    0.395	  0.059%	 55.168%	     0.000	        1	[densenet201/conv4_block15_0_bn/FusedBatchNormV31]:172
	                     ADD	          369.764	    0.551	    0.562	  0.084%	 55.252%	     0.000	        1	[densenet201/conv4_block15_0_relu/Relu;densenet201/conv4_block15_0_bn/FusedBatchNormV3]:173
	                 CONV_2D	          370.326	    1.874	    1.896	  0.283%	 55.535%	     0.000	        1	[densenet201/conv4_block15_1_relu/Relu;densenet201/conv4_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block15_1_conv/Conv2D]:174
	                 CONV_2D	          372.223	    0.903	    0.829	  0.124%	 55.659%	     0.000	        1	[densenet201/conv4_block15_2_conv/Conv2D1]:175
	           CONCATENATION	          373.052	    0.042	    0.037	  0.005%	 55.664%	     0.000	        1	[densenet201/conv4_block15_concat/concat]:176
	                     MUL	          373.090	    0.408	    0.416	  0.062%	 55.726%	     0.000	        1	[densenet201/conv4_block16_0_bn/FusedBatchNormV31]:177
	                     ADD	          373.506	    0.576	    0.589	  0.088%	 55.814%	     0.000	        1	[densenet201/conv4_block16_0_relu/Relu;densenet201/conv4_block16_0_bn/FusedBatchNormV3]:178
	                 CONV_2D	          374.095	    1.955	    1.980	  0.296%	 56.110%	     0.000	        1	[densenet201/conv4_block16_1_relu/Relu;densenet201/conv4_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block16_1_conv/Conv2D]:179
	                 CONV_2D	          376.076	    0.847	    0.837	  0.125%	 56.235%	     0.000	        1	[densenet201/conv4_block16_2_conv/Conv2D1]:180
	           CONCATENATION	          376.914	    0.049	    0.057	  0.008%	 56.243%	     0.000	        1	[densenet201/conv4_block16_concat/concat]:181
	                     MUL	          376.971	    0.425	    0.431	  0.064%	 56.308%	     0.000	        1	[densenet201/conv4_block17_0_bn/FusedBatchNormV31]:182
	                     ADD	          377.402	    0.603	    0.611	  0.091%	 56.399%	     0.000	        1	[densenet201/conv4_block17_0_relu/Relu;densenet201/conv4_block17_0_bn/FusedBatchNormV3]:183
	                 CONV_2D	          378.014	    2.051	    2.069	  0.309%	 56.708%	     0.000	        1	[densenet201/conv4_block17_1_relu/Relu;densenet201/conv4_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block17_1_conv/Conv2D]:184
	                 CONV_2D	          380.083	    0.932	    0.838	  0.125%	 56.833%	     0.000	        1	[densenet201/conv4_block17_2_conv/Conv2D1]:185
	           CONCATENATION	          380.922	    0.087	    0.057	  0.008%	 56.841%	     0.000	        1	[densenet201/conv4_block17_concat/concat]:186
	                     MUL	          380.979	    0.445	    0.449	  0.067%	 56.908%	     0.000	        1	[densenet201/conv4_block18_0_bn/FusedBatchNormV31]:187
	                     ADD	          381.429	    0.647	    0.640	  0.096%	 57.004%	     0.000	        1	[densenet201/conv4_block18_0_relu/Relu;densenet201/conv4_block18_0_bn/FusedBatchNormV3]:188
	                 CONV_2D	          382.070	    2.126	    2.150	  0.321%	 57.325%	     0.000	        1	[densenet201/conv4_block18_1_relu/Relu;densenet201/conv4_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block18_1_conv/Conv2D]:189
	                 CONV_2D	          384.220	    0.845	    0.835	  0.125%	 57.449%	     0.000	        1	[densenet201/conv4_block18_2_conv/Conv2D1]:190
	           CONCATENATION	          385.056	    0.071	    0.062	  0.009%	 57.459%	     0.000	        1	[densenet201/conv4_block18_concat/concat]:191
	                     MUL	          385.119	    0.459	    0.467	  0.070%	 57.528%	     0.000	        1	[densenet201/conv4_block19_0_bn/FusedBatchNormV31]:192
	                     ADD	          385.586	    0.649	    0.665	  0.099%	 57.627%	     0.000	        1	[densenet201/conv4_block19_0_relu/Relu;densenet201/conv4_block19_0_bn/FusedBatchNormV3]:193
	                 CONV_2D	          386.252	    2.241	    2.249	  0.336%	 57.963%	     0.000	        1	[densenet201/conv4_block19_1_relu/Relu;densenet201/conv4_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block19_1_conv/Conv2D]:194
	                 CONV_2D	          388.502	    0.805	    0.821	  0.123%	 58.086%	     0.000	        1	[densenet201/conv4_block19_2_conv/Conv2D1]:195
	           CONCATENATION	          389.323	    0.054	    0.052	  0.008%	 58.094%	     0.000	        1	[densenet201/conv4_block19_concat/concat]:196
	                     MUL	          389.376	    0.474	    0.482	  0.072%	 58.166%	     0.000	        1	[densenet201/conv4_block20_0_bn/FusedBatchNormV31]:197
	                     ADD	          389.859	    0.673	    0.685	  0.102%	 58.268%	     0.000	        1	[densenet201/conv4_block20_0_relu/Relu;densenet201/conv4_block20_0_bn/FusedBatchNormV3]:198
	                 CONV_2D	          390.545	    2.316	    2.318	  0.346%	 58.614%	     0.000	        1	[densenet201/conv4_block20_1_relu/Relu;densenet201/conv4_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block20_1_conv/Conv2D]:199
	                 CONV_2D	          392.864	    0.842	    0.844	  0.126%	 58.740%	     0.000	        1	[densenet201/conv4_block20_2_conv/Conv2D1]:200
	           CONCATENATION	          393.708	    0.071	    0.078	  0.012%	 58.752%	     0.000	        1	[densenet201/conv4_block20_concat/concat]:201
	                     MUL	          393.787	    0.493	    0.500	  0.075%	 58.826%	     0.000	        1	[densenet201/conv4_block21_0_bn/FusedBatchNormV3]:202
	                     ADD	          394.287	    0.704	    0.711	  0.106%	 58.932%	     0.000	        1	[densenet201/conv4_block21_0_relu/Relu;densenet201/conv4_block21_0_bn/FusedBatchNormV3]:203
	                 CONV_2D	          394.999	    2.468	    2.404	  0.359%	 59.291%	     0.000	        1	[densenet201/conv4_block21_1_relu/Relu;densenet201/conv4_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block21_1_conv/Conv2D]:204
	                 CONV_2D	          397.404	    0.815	    0.825	  0.123%	 59.414%	     0.000	        1	[densenet201/conv4_block21_2_conv/Conv2D1]:205
	           CONCATENATION	          398.230	    0.052	    0.061	  0.009%	 59.423%	     0.000	        1	[densenet201/conv4_block21_concat/concat]:206
	                     MUL	          398.291	    0.516	    0.522	  0.078%	 59.501%	     0.000	        1	[densenet201/conv4_block22_0_bn/FusedBatchNormV3]:207
	                     ADD	          398.814	    0.729	    0.744	  0.111%	 59.612%	     0.000	        1	[densenet201/conv4_block22_0_relu/Relu;densenet201/conv4_block22_0_bn/FusedBatchNormV3]:208
	                 CONV_2D	          399.559	    2.476	    2.480	  0.370%	 59.982%	     0.000	        1	[densenet201/conv4_block22_1_relu/Relu;densenet201/conv4_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block22_1_conv/Conv2D]:209
	                 CONV_2D	          402.039	    0.819	    0.840	  0.125%	 60.108%	     0.000	        1	[densenet201/conv4_block22_2_conv/Conv2D1]:210
	           CONCATENATION	          402.880	    0.087	    0.092	  0.014%	 60.122%	     0.000	        1	[densenet201/conv4_block22_concat/concat]:211
	                     MUL	          402.972	    0.526	    0.540	  0.081%	 60.202%	     0.000	        1	[densenet201/conv4_block23_0_bn/FusedBatchNormV3]:212
	                     ADD	          403.513	    0.752	    0.762	  0.114%	 60.316%	     0.000	        1	[densenet201/conv4_block23_0_relu/Relu;densenet201/conv4_block23_0_bn/FusedBatchNormV3]:213
	                 CONV_2D	          404.276	    2.552	    2.571	  0.384%	 60.700%	     0.000	        1	[densenet201/conv4_block23_1_relu/Relu;densenet201/conv4_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block23_1_conv/Conv2D]:214
	                 CONV_2D	          406.847	    0.813	    0.833	  0.124%	 60.824%	     0.000	        1	[densenet201/conv4_block23_2_conv/Conv2D1]:215
	           CONCATENATION	          407.681	    0.063	    0.067	  0.010%	 60.834%	     0.000	        1	[densenet201/conv4_block23_concat/concat]:216
	                     MUL	          407.748	    0.546	    0.559	  0.083%	 60.917%	     0.000	        1	[densenet201/conv4_block24_0_bn/FusedBatchNormV3]:217
	                     ADD	          408.307	    0.866	    0.792	  0.118%	 61.036%	     0.000	        1	[densenet201/conv4_block24_0_relu/Relu;densenet201/conv4_block24_0_bn/FusedBatchNormV3]:218
	                 CONV_2D	          409.100	    2.621	    2.650	  0.396%	 61.431%	     0.000	        1	[densenet201/conv4_block24_1_relu/Relu;densenet201/conv4_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block24_1_conv/Conv2D]:219
	                 CONV_2D	          411.751	    0.895	    0.850	  0.127%	 61.558%	     0.000	        1	[densenet201/conv4_block24_2_conv/Conv2D1]:220
	           CONCATENATION	          412.602	    0.120	    0.104	  0.016%	 61.574%	     0.000	        1	[densenet201/conv4_block24_concat/concat]:221
	                     MUL	          412.708	    0.565	    0.577	  0.086%	 61.660%	     0.000	        1	[densenet201/conv4_block25_0_bn/FusedBatchNormV3]:222
	                     ADD	          413.285	    0.802	    0.816	  0.122%	 61.782%	     0.000	        1	[densenet201/conv4_block25_0_relu/Relu;densenet201/conv4_block25_0_bn/FusedBatchNormV3]:223
	                 CONV_2D	          414.102	    2.728	    2.741	  0.409%	 62.191%	     0.000	        1	[densenet201/conv4_block25_1_relu/Relu;densenet201/conv4_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block25_1_conv/Conv2D]:224
	                 CONV_2D	          416.844	    0.808	    0.827	  0.123%	 62.314%	     0.000	        1	[densenet201/conv4_block25_2_conv/Conv2D1]:225
	           CONCATENATION	          417.672	    0.090	    0.074	  0.011%	 62.325%	     0.000	        1	[densenet201/conv4_block25_concat/concat]:226
	                     MUL	          417.747	    0.579	    0.592	  0.088%	 62.414%	     0.000	        1	[densenet201/conv4_block26_0_bn/FusedBatchNormV3]:227
	                     ADD	          418.340	    0.825	    0.841	  0.126%	 62.539%	     0.000	        1	[densenet201/conv4_block26_0_relu/Relu;densenet201/conv4_block26_0_bn/FusedBatchNormV3]:228
	                 CONV_2D	          419.182	    2.912	    2.833	  0.423%	 62.962%	     0.000	        1	[densenet201/conv4_block26_1_relu/Relu;densenet201/conv4_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block26_1_conv/Conv2D]:229
	                 CONV_2D	          422.016	    0.843	    0.857	  0.128%	 63.090%	     0.000	        1	[densenet201/conv4_block26_2_conv/Conv2D1]:230
	           CONCATENATION	          422.874	    0.112	    0.115	  0.017%	 63.107%	     0.000	        1	[densenet201/conv4_block26_concat/concat]:231
	                     MUL	          422.989	    0.597	    0.608	  0.091%	 63.198%	     0.000	        1	[densenet201/conv4_block27_0_bn/FusedBatchNormV3]:232
	                     ADD	          423.597	    0.888	    0.869	  0.130%	 63.328%	     0.000	        1	[densenet201/conv4_block27_0_relu/Relu;densenet201/conv4_block27_0_bn/FusedBatchNormV3]:233
	                 CONV_2D	          424.467	    2.867	    2.915	  0.435%	 63.763%	     0.000	        1	[densenet201/conv4_block27_1_relu/Relu;densenet201/conv4_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block27_1_conv/Conv2D]:234
	                 CONV_2D	          427.383	    0.814	    0.843	  0.126%	 63.889%	     0.000	        1	[densenet201/conv4_block27_2_conv/Conv2D1]:235
	           CONCATENATION	          428.226	    0.102	    0.114	  0.017%	 63.906%	     0.000	        1	[densenet201/conv4_block27_concat/concat]:236
	                     MUL	          428.342	    0.639	    0.633	  0.094%	 64.000%	     0.000	        1	[densenet201/conv4_block28_0_bn/FusedBatchNormV3]:237
	                     ADD	          428.975	    0.881	    0.896	  0.134%	 64.134%	     0.000	        1	[densenet201/conv4_block28_0_relu/Relu;densenet201/conv4_block28_0_bn/FusedBatchNormV3]:238
	                 CONV_2D	          429.872	    3.053	    2.997	  0.447%	 64.581%	     0.000	        1	[densenet201/conv4_block28_1_relu/Relu;densenet201/conv4_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block28_1_conv/Conv2D]:239
	                 CONV_2D	          432.869	    0.827	    0.842	  0.126%	 64.707%	     0.000	        1	[densenet201/conv4_block28_2_conv/Conv2D1]:240
	           CONCATENATION	          433.712	    0.114	    0.110	  0.016%	 64.724%	     0.000	        1	[densenet201/conv4_block28_concat/concat]:241
	                     MUL	          433.823	    0.629	    0.644	  0.096%	 64.820%	     0.000	        1	[densenet201/conv4_block29_0_bn/FusedBatchNormV3]:242
	                     ADD	          434.468	    0.903	    0.917	  0.137%	 64.957%	     0.000	        1	[densenet201/conv4_block29_0_relu/Relu;densenet201/conv4_block29_0_bn/FusedBatchNormV3]:243
	                 CONV_2D	          435.386	    3.133	    3.083	  0.460%	 65.417%	     0.000	        1	[densenet201/conv4_block29_1_relu/Relu;densenet201/conv4_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block29_1_conv/Conv2D]:244
	                 CONV_2D	          438.470	    0.901	    0.852	  0.127%	 65.544%	     0.000	        1	[densenet201/conv4_block29_2_conv/Conv2D1]:245
	           CONCATENATION	          439.322	    0.120	    0.097	  0.015%	 65.558%	     0.000	        1	[densenet201/conv4_block29_concat/concat]:246
	                     MUL	          439.421	    0.656	    0.660	  0.098%	 65.657%	     0.000	        1	[densenet201/conv4_block30_0_bn/FusedBatchNormV3]:247
	                     ADD	          440.081	    0.980	    0.945	  0.141%	 65.798%	     0.000	        1	[densenet201/conv4_block30_0_relu/Relu;densenet201/conv4_block30_0_bn/FusedBatchNormV3]:248
	                 CONV_2D	          441.026	    3.178	    3.169	  0.473%	 66.271%	     0.000	        1	[densenet201/conv4_block30_1_relu/Relu;densenet201/conv4_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block30_1_conv/Conv2D]:249
	                 CONV_2D	          444.196	    0.897	    0.843	  0.126%	 66.397%	     0.000	        1	[densenet201/conv4_block30_2_conv/Conv2D1]:250
	           CONCATENATION	          445.040	    0.189	    0.112	  0.017%	 66.414%	     0.000	        1	[densenet201/conv4_block30_concat/concat]:251
	                     MUL	          445.153	    0.686	    0.679	  0.101%	 66.515%	     0.000	        1	[densenet201/conv4_block31_0_bn/FusedBatchNormV3]:252
	                     ADD	          445.832	    0.956	    0.971	  0.145%	 66.660%	     0.000	        1	[densenet201/conv4_block31_0_relu/Relu;densenet201/conv4_block31_0_bn/FusedBatchNormV3]:253
	                 CONV_2D	          446.804	    3.314	    3.273	  0.489%	 67.148%	     0.000	        1	[densenet201/conv4_block31_1_relu/Relu;densenet201/conv4_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block31_1_conv/Conv2D]:254
	                 CONV_2D	          450.078	    0.834	    0.834	  0.125%	 67.273%	     0.000	        1	[densenet201/conv4_block31_2_conv/Conv2D1]:255
	           CONCATENATION	          450.913	    0.101	    0.096	  0.014%	 67.287%	     0.000	        1	[densenet201/conv4_block31_concat/concat]:256
	                     MUL	          451.009	    0.679	    0.695	  0.104%	 67.391%	     0.000	        1	[densenet201/conv4_block32_0_bn/FusedBatchNormV3]:257
	                     ADD	          451.704	    1.009	    0.995	  0.149%	 67.539%	     0.000	        1	[densenet201/conv4_block32_0_relu/Relu;densenet201/conv4_block32_0_bn/FusedBatchNormV3]:258
	                 CONV_2D	          452.700	    3.369	    3.341	  0.499%	 68.038%	     0.000	        1	[densenet201/conv4_block32_1_relu/Relu;densenet201/conv4_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block32_1_conv/Conv2D]:259
	                 CONV_2D	          456.042	    0.861	    0.831	  0.124%	 68.162%	     0.000	        1	[densenet201/conv4_block32_2_conv/Conv2D1]:260
	           CONCATENATION	          456.873	    0.108	    0.085	  0.013%	 68.175%	     0.000	        1	[densenet201/conv4_block32_concat/concat]:261
	                     MUL	          456.959	    0.703	    0.714	  0.107%	 68.281%	     0.000	        1	[densenet201/conv4_block33_0_bn/FusedBatchNormV3]:262
	                     ADD	          457.674	    1.019	    1.020	  0.152%	 68.434%	     0.000	        1	[densenet201/conv4_block33_0_relu/Relu;densenet201/conv4_block33_0_bn/FusedBatchNormV3]:263
	                 CONV_2D	          458.694	    3.496	    3.431	  0.512%	 68.946%	     0.000	        1	[densenet201/conv4_block33_1_relu/Relu;densenet201/conv4_block33_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block33_1_conv/Conv2D]:264
	                 CONV_2D	          462.126	    0.893	    0.855	  0.128%	 69.073%	     0.000	        1	[densenet201/conv4_block33_2_conv/Conv2D1]:265
	           CONCATENATION	          462.982	    0.144	    0.113	  0.017%	 69.090%	     0.000	        1	[densenet201/conv4_block33_concat/concat]:266
	                     MUL	          463.095	    0.727	    0.730	  0.109%	 69.199%	     0.000	        1	[densenet201/conv4_block34_0_bn/FusedBatchNormV3]:267
	                     ADD	          463.826	    1.151	    1.048	  0.156%	 69.356%	     0.000	        1	[densenet201/conv4_block34_0_relu/Relu;densenet201/conv4_block34_0_bn/FusedBatchNormV3]:268
	                 CONV_2D	          464.875	    3.549	    3.514	  0.525%	 69.880%	     0.000	        1	[densenet201/conv4_block34_1_relu/Relu;densenet201/conv4_block34_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block34_1_conv/Conv2D]:269
	                 CONV_2D	          468.390	    0.882	    0.844	  0.126%	 70.006%	     0.000	        1	[densenet201/conv4_block34_2_conv/Conv2D1]:270
	           CONCATENATION	          469.235	    0.109	    0.096	  0.014%	 70.021%	     0.000	        1	[densenet201/conv4_block34_concat/concat]:271
	                     MUL	          469.332	    0.743	    0.752	  0.112%	 70.133%	     0.000	        1	[densenet201/conv4_block35_0_bn/FusedBatchNormV3]:272
	                     ADD	          470.084	    1.076	    1.070	  0.160%	 70.293%	     0.000	        1	[densenet201/conv4_block35_0_relu/Relu;densenet201/conv4_block35_0_bn/FusedBatchNormV3]:273
	                 CONV_2D	          471.155	    3.639	    3.590	  0.536%	 70.828%	     0.000	        1	[densenet201/conv4_block35_1_relu/Relu;densenet201/conv4_block35_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block35_1_conv/Conv2D]:274
	                 CONV_2D	          474.746	    0.854	    0.832	  0.124%	 70.953%	     0.000	        1	[densenet201/conv4_block35_2_conv/Conv2D1]:275
	           CONCATENATION	          475.579	    0.159	    0.121	  0.018%	 70.971%	     0.000	        1	[densenet201/conv4_block35_concat/concat]:276
	                     MUL	          475.701	    0.772	    0.777	  0.116%	 71.087%	     0.000	        1	[densenet201/conv4_block36_0_bn/FusedBatchNormV3]:277
	                     ADD	          476.478	    1.084	    1.097	  0.164%	 71.250%	     0.000	        1	[densenet201/conv4_block36_0_relu/Relu;densenet201/conv4_block36_0_bn/FusedBatchNormV3]:278
	                 CONV_2D	          477.576	    3.657	    3.679	  0.549%	 71.800%	     0.000	        1	[densenet201/conv4_block36_1_relu/Relu;densenet201/conv4_block36_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block36_1_conv/Conv2D]:279
	                 CONV_2D	          481.255	    0.826	    0.840	  0.125%	 71.925%	     0.000	        1	[densenet201/conv4_block36_2_conv/Conv2D1]:280
	           CONCATENATION	          482.096	    0.087	    0.105	  0.016%	 71.941%	     0.000	        1	[densenet201/conv4_block36_concat/concat]:281
	                     MUL	          482.202	    0.773	    0.790	  0.118%	 72.059%	     0.000	        1	[densenet201/conv4_block37_0_bn/FusedBatchNormV3]:282
	                     ADD	          482.992	    1.168	    1.132	  0.169%	 72.228%	     0.000	        1	[densenet201/conv4_block37_0_relu/Relu;densenet201/conv4_block37_0_bn/FusedBatchNormV3]:283
	                 CONV_2D	          484.125	    3.794	    3.765	  0.562%	 72.789%	     0.000	        1	[densenet201/conv4_block37_1_relu/Relu;densenet201/conv4_block37_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block37_1_conv/Conv2D]:284
	                 CONV_2D	          487.891	    0.823	    0.844	  0.126%	 72.915%	     0.000	        1	[densenet201/conv4_block37_2_conv/Conv2D1]:285
	           CONCATENATION	          488.735	    0.131	    0.148	  0.022%	 72.937%	     0.000	        1	[densenet201/conv4_block37_concat/concat]:286
	                     MUL	          488.883	    0.801	    0.808	  0.121%	 73.058%	     0.000	        1	[densenet201/conv4_block38_0_bn/FusedBatchNormV3]:287
	                     ADD	          489.692	    1.123	    1.146	  0.171%	 73.229%	     0.000	        1	[densenet201/conv4_block38_0_relu/Relu;densenet201/conv4_block38_0_bn/FusedBatchNormV3]:288
	                 CONV_2D	          490.839	    3.832	    3.855	  0.575%	 73.805%	     0.000	        1	[densenet201/conv4_block38_1_relu/Relu;densenet201/conv4_block38_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block38_1_conv/Conv2D]:289
	                 CONV_2D	          494.696	    0.822	    0.848	  0.127%	 73.931%	     0.000	        1	[densenet201/conv4_block38_2_conv/Conv2D1]:290
	           CONCATENATION	          495.544	    0.094	    0.117	  0.017%	 73.949%	     0.000	        1	[densenet201/conv4_block38_concat/concat]:291
	                     MUL	          495.662	    0.837	    0.825	  0.123%	 74.072%	     0.000	        1	[densenet201/conv4_block39_0_bn/FusedBatchNormV3]:292
	                     ADD	          496.487	    1.145	    1.172	  0.175%	 74.247%	     0.000	        1	[densenet201/conv4_block39_0_relu/Relu;densenet201/conv4_block39_0_bn/FusedBatchNormV3]:293
	                 CONV_2D	          497.660	    3.991	    3.931	  0.587%	 74.834%	     0.000	        1	[densenet201/conv4_block39_1_relu/Relu;densenet201/conv4_block39_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block39_1_conv/Conv2D]:294
	                 CONV_2D	          501.592	    0.825	    0.841	  0.125%	 74.959%	     0.000	        1	[densenet201/conv4_block39_2_conv/Conv2D1]:295
	           CONCATENATION	          502.433	    0.145	    0.147	  0.022%	 74.981%	     0.000	        1	[densenet201/conv4_block39_concat/concat]:296
	                     MUL	          502.581	    0.853	    0.840	  0.125%	 75.106%	     0.000	        1	[densenet201/conv4_block40_0_bn/FusedBatchNormV3]:297
	                     ADD	          503.421	    1.206	    1.202	  0.179%	 75.286%	     0.000	        1	[densenet201/conv4_block40_0_relu/Relu;densenet201/conv4_block40_0_bn/FusedBatchNormV3]:298
	                 CONV_2D	          504.624	    3.981	    4.024	  0.601%	 75.886%	     0.000	        1	[densenet201/conv4_block40_1_relu/Relu;densenet201/conv4_block40_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block40_1_conv/Conv2D]:299
	                 CONV_2D	          508.649	    0.824	    0.845	  0.126%	 76.013%	     0.000	        1	[densenet201/conv4_block40_2_conv/Conv2D1]:300
	           CONCATENATION	          509.494	    0.125	    0.127	  0.019%	 76.031%	     0.000	        1	[densenet201/conv4_block40_concat/concat]:301
	                     MUL	          509.622	    0.840	    0.853	  0.127%	 76.159%	     0.000	        1	[densenet201/conv4_block41_0_bn/FusedBatchNormV3]:302
	                     ADD	          510.476	    1.203	    1.223	  0.183%	 76.341%	     0.000	        1	[densenet201/conv4_block41_0_relu/Relu;densenet201/conv4_block41_0_bn/FusedBatchNormV3]:303
	                 CONV_2D	          511.700	    4.069	    4.105	  0.613%	 76.954%	     0.000	        1	[densenet201/conv4_block41_1_relu/Relu;densenet201/conv4_block41_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block41_1_conv/Conv2D]:304
	                 CONV_2D	          515.805	    0.855	    0.862	  0.129%	 77.083%	     0.000	        1	[densenet201/conv4_block41_2_conv/Conv2D1]:305
	           CONCATENATION	          516.668	    0.147	    0.157	  0.023%	 77.106%	     0.000	        1	[densenet201/conv4_block41_concat/concat]:306
	                     MUL	          516.826	    0.867	    0.876	  0.131%	 77.237%	     0.000	        1	[densenet201/conv4_block42_0_bn/FusedBatchNormV3]:307
	                     ADD	          517.703	    1.250	    1.254	  0.187%	 77.424%	     0.000	        1	[densenet201/conv4_block42_0_relu/Relu;densenet201/conv4_block42_0_bn/FusedBatchNormV3]:308
	                 CONV_2D	          518.958	    4.170	    4.202	  0.627%	 78.052%	     0.000	        1	[densenet201/conv4_block42_1_relu/Relu;densenet201/conv4_block42_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block42_1_conv/Conv2D]:309
	                 CONV_2D	          523.161	    0.908	    0.844	  0.126%	 78.177%	     0.000	        1	[densenet201/conv4_block42_2_conv/Conv2D1]:310
	           CONCATENATION	          524.006	    0.178	    0.149	  0.022%	 78.200%	     0.000	        1	[densenet201/conv4_block42_concat/concat]:311
	                     MUL	          524.155	    0.888	    0.891	  0.133%	 78.333%	     0.000	        1	[densenet201/conv4_block43_0_bn/FusedBatchNormV3]:312
	                     ADD	          525.047	    1.251	    1.278	  0.191%	 78.523%	     0.000	        1	[densenet201/conv4_block43_0_relu/Relu;densenet201/conv4_block43_0_bn/FusedBatchNormV3]:313
	                 CONV_2D	          526.325	    4.296	    4.273	  0.638%	 79.161%	     0.000	        1	[densenet201/conv4_block43_1_relu/Relu;densenet201/conv4_block43_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block43_1_conv/Conv2D]:314
	                 CONV_2D	          530.599	    0.842	    0.865	  0.129%	 79.290%	     0.000	        1	[densenet201/conv4_block43_2_conv/Conv2D1]:315
	           CONCATENATION	          531.465	    0.162	    0.187	  0.028%	 79.318%	     0.000	        1	[densenet201/conv4_block43_concat/concat]:316
	                     MUL	          531.653	    0.926	    0.914	  0.136%	 79.455%	     0.000	        1	[densenet201/conv4_block44_0_bn/FusedBatchNormV3]:317
	                     ADD	          532.568	    1.298	    1.305	  0.195%	 79.650%	     0.000	        1	[densenet201/conv4_block44_0_relu/Relu;densenet201/conv4_block44_0_bn/FusedBatchNormV3]:318
	                 CONV_2D	          533.873	    4.409	    4.361	  0.651%	 80.300%	     0.000	        1	[densenet201/conv4_block44_1_relu/Relu;densenet201/conv4_block44_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block44_1_conv/Conv2D]:319
	                 CONV_2D	          538.235	    0.828	    0.845	  0.126%	 80.426%	     0.000	        1	[densenet201/conv4_block44_2_conv/Conv2D1]:320
	           CONCATENATION	          539.080	    0.152	    0.156	  0.023%	 80.450%	     0.000	        1	[densenet201/conv4_block44_concat/concat]:321
	                     MUL	          539.236	    1.012	    0.933	  0.139%	 80.589%	     0.000	        1	[densenet201/conv4_block45_0_bn/FusedBatchNormV3]:322
	                     ADD	          540.170	    1.300	    1.329	  0.198%	 80.787%	     0.000	        1	[densenet201/conv4_block45_0_relu/Relu;densenet201/conv4_block45_0_bn/FusedBatchNormV3]:323
	                 CONV_2D	          541.499	    4.399	    4.451	  0.664%	 81.452%	     0.000	        1	[densenet201/conv4_block45_1_relu/Relu;densenet201/conv4_block45_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block45_1_conv/Conv2D]:324
	                 CONV_2D	          545.951	    0.859	    0.880	  0.131%	 81.583%	     0.000	        1	[densenet201/conv4_block45_2_conv/Conv2D1]:325
	           CONCATENATION	          546.831	    0.185	    0.186	  0.028%	 81.611%	     0.000	        1	[densenet201/conv4_block45_concat/concat]:326
	                     MUL	          547.018	    1.055	    0.952	  0.142%	 81.753%	     0.000	        1	[densenet201/conv4_block46_0_bn/FusedBatchNormV3]:327
	                     ADD	          547.971	    1.326	    1.353	  0.202%	 81.955%	     0.000	        1	[densenet201/conv4_block46_0_relu/Relu;densenet201/conv4_block46_0_bn/FusedBatchNormV3]:328
	                 CONV_2D	          549.324	    4.503	    4.527	  0.676%	 82.630%	     0.000	        1	[densenet201/conv4_block46_1_relu/Relu;densenet201/conv4_block46_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block46_1_conv/Conv2D]:329
	                 CONV_2D	          553.852	    0.860	    0.868	  0.130%	 82.760%	     0.000	        1	[densenet201/conv4_block46_2_conv/Conv2D1]:330
	           CONCATENATION	          554.721	    0.169	    0.192	  0.029%	 82.789%	     0.000	        1	[densenet201/conv4_block46_concat/concat]:331
	                     MUL	          554.914	    0.951	    0.967	  0.144%	 82.933%	     0.000	        1	[densenet201/conv4_block47_0_bn/FusedBatchNormV3]:332
	                     ADD	          555.882	    1.394	    1.384	  0.207%	 83.140%	     0.000	        1	[densenet201/conv4_block47_0_relu/Relu;densenet201/conv4_block47_0_bn/FusedBatchNormV3]:333
	                 CONV_2D	          557.267	    4.618	    4.620	  0.690%	 83.829%	     0.000	        1	[densenet201/conv4_block47_1_relu/Relu;densenet201/conv4_block47_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block47_1_conv/Conv2D]:334
	                 CONV_2D	          561.888	    0.893	    0.870	  0.130%	 83.959%	     0.000	        1	[densenet201/conv4_block47_2_conv/Conv2D1]:335
	           CONCATENATION	          562.759	    0.197	    0.197	  0.029%	 83.989%	     0.000	        1	[densenet201/conv4_block47_concat/concat]:336
	                     MUL	          562.957	    0.992	    0.984	  0.147%	 84.136%	     0.000	        1	[densenet201/conv4_block48_0_bn/FusedBatchNormV3]:337
	                     ADD	          563.941	    1.387	    1.408	  0.210%	 84.346%	     0.000	        1	[densenet201/conv4_block48_0_relu/Relu;densenet201/conv4_block48_0_bn/FusedBatchNormV3]:338
	                 CONV_2D	          565.350	    4.667	    4.701	  0.702%	 85.047%	     0.000	        1	[densenet201/conv4_block48_1_relu/Relu;densenet201/conv4_block48_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block48_1_conv/Conv2D]:339
	                 CONV_2D	          570.052	    0.853	    0.883	  0.132%	 85.179%	     0.000	        1	[densenet201/conv4_block48_2_conv/Conv2D1]:340
	           CONCATENATION	          570.936	    0.185	    0.202	  0.030%	 85.209%	     0.000	        1	[densenet201/conv4_block48_concat/concat]:341
	                     MUL	          571.138	    1.133	    1.004	  0.150%	 85.359%	     0.000	        1	[densenet201/pool4_bn/FusedBatchNormV3]:342
	                     ADD	          572.143	    1.413	    1.434	  0.214%	 85.573%	     0.000	        1	[densenet201/pool4_relu/Relu;densenet201/pool4_bn/FusedBatchNormV3]:343
	                 CONV_2D	          573.578	   33.664	   33.682	  5.028%	 90.601%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	         AVERAGE_POOL_2D	          607.261	    0.487	    0.462	  0.069%	 90.670%	     0.000	        1	[densenet201/pool4_pool/AvgPool]:345
	                     MUL	          607.724	    0.162	    0.133	  0.020%	 90.690%	     0.000	        1	[densenet201/conv5_block1_0_bn/FusedBatchNormV31]:346
	                     ADD	          607.858	    0.187	    0.190	  0.028%	 90.718%	     0.000	        1	[densenet201/conv5_block1_0_relu/Relu;densenet201/conv5_block1_0_bn/FusedBatchNormV3]:347
	                 CONV_2D	          608.048	    0.683	    0.710	  0.106%	 90.824%	     0.000	        1	[densenet201/conv5_block1_1_relu/Relu;densenet201/conv5_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block1_1_conv/Conv2D]:348
	                 CONV_2D	          608.759	    0.247	    0.258	  0.038%	 90.862%	     0.000	        1	[densenet201/conv5_block1_2_conv/Conv2D1]:349
	           CONCATENATION	          609.017	    0.016	    0.017	  0.003%	 90.865%	     0.000	        1	[densenet201/conv5_block1_concat/concat]:350
	                     MUL	          609.035	    0.137	    0.134	  0.020%	 90.885%	     0.000	        1	[densenet201/conv5_block2_0_bn/FusedBatchNormV31]:351
	                     ADD	          609.169	    0.187	    0.190	  0.028%	 90.913%	     0.000	        1	[densenet201/conv5_block2_0_relu/Relu;densenet201/conv5_block2_0_bn/FusedBatchNormV3]:352
	                 CONV_2D	          609.360	    0.699	    0.686	  0.102%	 91.016%	     0.000	        1	[densenet201/conv5_block2_1_relu/Relu;densenet201/conv5_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block2_1_conv/Conv2D]:353
	                 CONV_2D	          610.046	    0.248	    0.246	  0.037%	 91.053%	     0.000	        1	[densenet201/conv5_block2_2_conv/Conv2D1]:354
	           CONCATENATION	          610.293	    0.014	    0.012	  0.002%	 91.054%	     0.000	        1	[densenet201/conv5_block2_concat/concat]:355
	                     MUL	          610.305	    0.132	    0.137	  0.020%	 91.075%	     0.000	        1	[densenet201/conv5_block3_0_bn/FusedBatchNormV31]:356
	                     ADD	          610.443	    0.195	    0.195	  0.029%	 91.104%	     0.000	        1	[densenet201/conv5_block3_0_relu/Relu;densenet201/conv5_block3_0_bn/FusedBatchNormV3]:357
	                 CONV_2D	          610.638	    0.713	    0.704	  0.105%	 91.209%	     0.000	        1	[densenet201/conv5_block3_1_relu/Relu;densenet201/conv5_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block3_1_conv/Conv2D]:358
	                 CONV_2D	          611.343	    0.240	    0.241	  0.036%	 91.245%	     0.000	        1	[densenet201/conv5_block3_2_conv/Conv2D1]:359
	           CONCATENATION	          611.585	    0.013	    0.013	  0.002%	 91.247%	     0.000	        1	[densenet201/conv5_block3_concat/concat]:360
	                     MUL	          611.599	    0.136	    0.141	  0.021%	 91.268%	     0.000	        1	[densenet201/conv5_block4_0_bn/FusedBatchNormV31]:361
	                     ADD	          611.740	    0.223	    0.202	  0.030%	 91.298%	     0.000	        1	[densenet201/conv5_block4_0_relu/Relu;densenet201/conv5_block4_0_bn/FusedBatchNormV3]:362
	                 CONV_2D	          611.942	    0.721	    0.722	  0.108%	 91.406%	     0.000	        1	[densenet201/conv5_block4_1_relu/Relu;densenet201/conv5_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block4_1_conv/Conv2D]:363
	                 CONV_2D	          612.665	    0.237	    0.242	  0.036%	 91.442%	     0.000	        1	[densenet201/conv5_block4_2_conv/Conv2D1]:364
	           CONCATENATION	          612.907	    0.012	    0.013	  0.002%	 91.444%	     0.000	        1	[densenet201/conv5_block4_concat/concat]:365
	                     MUL	          612.920	    0.149	    0.146	  0.022%	 91.466%	     0.000	        1	[densenet201/conv5_block5_0_bn/FusedBatchNormV31]:366
	                     ADD	          613.066	    0.205	    0.206	  0.031%	 91.496%	     0.000	        1	[densenet201/conv5_block5_0_relu/Relu;densenet201/conv5_block5_0_bn/FusedBatchNormV3]:367
	                 CONV_2D	          613.273	    0.753	    0.749	  0.112%	 91.608%	     0.000	        1	[densenet201/conv5_block5_1_relu/Relu;densenet201/conv5_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block5_1_conv/Conv2D]:368
	                 CONV_2D	          614.023	    0.227	    0.242	  0.036%	 91.644%	     0.000	        1	[densenet201/conv5_block5_2_conv/Conv2D1]:369
	           CONCATENATION	          614.266	    0.022	    0.013	  0.002%	 91.646%	     0.000	        1	[densenet201/conv5_block5_concat/concat]:370
	                     MUL	          614.279	    0.145	    0.151	  0.022%	 91.669%	     0.000	        1	[densenet201/conv5_block6_0_bn/FusedBatchNormV31]:371
	                     ADD	          614.431	    0.212	    0.214	  0.032%	 91.701%	     0.000	        1	[densenet201/conv5_block6_0_relu/Relu;densenet201/conv5_block6_0_bn/FusedBatchNormV3]:372
	                 CONV_2D	          614.645	    0.773	    0.769	  0.115%	 91.815%	     0.000	        1	[densenet201/conv5_block6_1_relu/Relu;densenet201/conv5_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block6_1_conv/Conv2D]:373
	                 CONV_2D	          615.415	    0.238	    0.240	  0.036%	 91.851%	     0.000	        1	[densenet201/conv5_block6_2_conv/Conv2D1]:374
	           CONCATENATION	          615.655	    0.013	    0.012	  0.002%	 91.853%	     0.000	        1	[densenet201/conv5_block6_concat/concat]:375
	                     MUL	          615.668	    0.156	    0.155	  0.023%	 91.876%	     0.000	        1	[densenet201/conv5_block7_0_bn/FusedBatchNormV31]:376
	                     ADD	          615.824	    0.260	    0.219	  0.033%	 91.909%	     0.000	        1	[densenet201/conv5_block7_0_relu/Relu;densenet201/conv5_block7_0_bn/FusedBatchNormV3]:377
	                 CONV_2D	          616.044	    0.848	    0.798	  0.119%	 92.028%	     0.000	        1	[densenet201/conv5_block7_1_relu/Relu;densenet201/conv5_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block7_1_conv/Conv2D]:378
	                 CONV_2D	          616.843	    0.241	    0.239	  0.036%	 92.064%	     0.000	        1	[densenet201/conv5_block7_2_conv/Conv2D1]:379
	           CONCATENATION	          617.083	    0.014	    0.013	  0.002%	 92.066%	     0.000	        1	[densenet201/conv5_block7_concat/concat]:380
	                     MUL	          617.096	    0.163	    0.160	  0.024%	 92.090%	     0.000	        1	[densenet201/conv5_block8_0_bn/FusedBatchNormV31]:381
	                     ADD	          617.257	    0.225	    0.225	  0.034%	 92.123%	     0.000	        1	[densenet201/conv5_block8_0_relu/Relu;densenet201/conv5_block8_0_bn/FusedBatchNormV3]:382
	                 CONV_2D	          617.482	    0.798	    0.813	  0.121%	 92.245%	     0.000	        1	[densenet201/conv5_block8_1_relu/Relu;densenet201/conv5_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block8_1_conv/Conv2D]:383
	                 CONV_2D	          618.296	    0.253	    0.239	  0.036%	 92.280%	     0.000	        1	[densenet201/conv5_block8_2_conv/Conv2D1]:384
	           CONCATENATION	          618.536	    0.013	    0.013	  0.002%	 92.282%	     0.000	        1	[densenet201/conv5_block8_concat/concat]:385
	                     MUL	          618.550	    0.165	    0.164	  0.025%	 92.307%	     0.000	        1	[densenet201/conv5_block9_0_bn/FusedBatchNormV31]:386
	                     ADD	          618.715	    0.221	    0.229	  0.034%	 92.341%	     0.000	        1	[densenet201/conv5_block9_0_relu/Relu;densenet201/conv5_block9_0_bn/FusedBatchNormV3]:387
	                 CONV_2D	          618.944	    0.860	    0.838	  0.125%	 92.466%	     0.000	        1	[densenet201/conv5_block9_1_relu/Relu;densenet201/conv5_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block9_1_conv/Conv2D]:388
	                 CONV_2D	          619.782	    0.246	    0.246	  0.037%	 92.503%	     0.000	        1	[densenet201/conv5_block9_2_conv/Conv2D1]:389
	           CONCATENATION	          620.029	    0.014	    0.014	  0.002%	 92.505%	     0.000	        1	[densenet201/conv5_block9_concat/concat]:390
	                     MUL	          620.044	    0.170	    0.168	  0.025%	 92.530%	     0.000	        1	[densenet201/conv5_block10_0_bn/FusedBatchNormV31]:391
	                     ADD	          620.212	    0.236	    0.237	  0.035%	 92.565%	     0.000	        1	[densenet201/conv5_block10_0_relu/Relu;densenet201/conv5_block10_0_bn/FusedBatchNormV3]:392
	                 CONV_2D	          620.450	    0.843	    0.865	  0.129%	 92.695%	     0.000	        1	[densenet201/conv5_block10_1_relu/Relu;densenet201/conv5_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block10_1_conv/Conv2D]:393
	                 CONV_2D	          621.316	    0.245	    0.251	  0.037%	 92.732%	     0.000	        1	[densenet201/conv5_block10_2_conv/Conv2D1]:394
	           CONCATENATION	          621.567	    0.013	    0.015	  0.002%	 92.734%	     0.000	        1	[densenet201/conv5_block10_concat/concat]:395
	                     MUL	          621.582	    0.173	    0.173	  0.026%	 92.760%	     0.000	        1	[densenet201/conv5_block11_0_bn/FusedBatchNormV31]:396
	                     ADD	          621.756	    0.242	    0.245	  0.037%	 92.797%	     0.000	        1	[densenet201/conv5_block11_0_relu/Relu;densenet201/conv5_block11_0_bn/FusedBatchNormV3]:397
	                 CONV_2D	          622.001	    0.897	    0.881	  0.132%	 92.928%	     0.000	        1	[densenet201/conv5_block11_1_relu/Relu;densenet201/conv5_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block11_1_conv/Conv2D]:398
	                 CONV_2D	          622.883	    0.266	    0.245	  0.037%	 92.965%	     0.000	        1	[densenet201/conv5_block11_2_conv/Conv2D1]:399
	           CONCATENATION	          623.129	    0.019	    0.014	  0.002%	 92.967%	     0.000	        1	[densenet201/conv5_block11_concat/concat]:400
	                     MUL	          623.143	    0.181	    0.178	  0.027%	 92.993%	     0.000	        1	[densenet201/conv5_block12_0_bn/FusedBatchNormV31]:401
	                     ADD	          623.322	    0.248	    0.249	  0.037%	 93.031%	     0.000	        1	[densenet201/conv5_block12_0_relu/Relu;densenet201/conv5_block12_0_bn/FusedBatchNormV3]:402
	                 CONV_2D	          623.572	    0.925	    0.901	  0.135%	 93.165%	     0.000	        1	[densenet201/conv5_block12_1_relu/Relu;densenet201/conv5_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block12_1_conv/Conv2D]:403
	                 CONV_2D	          624.473	    0.242	    0.246	  0.037%	 93.202%	     0.000	        1	[densenet201/conv5_block12_2_conv/Conv2D1]:404
	           CONCATENATION	          624.719	    0.014	    0.014	  0.002%	 93.204%	     0.000	        1	[densenet201/conv5_block12_concat/concat]:405
	                     MUL	          624.734	    0.181	    0.181	  0.027%	 93.231%	     0.000	        1	[densenet201/conv5_block13_0_bn/FusedBatchNormV31]:406
	                     ADD	          624.916	    0.255	    0.257	  0.038%	 93.269%	     0.000	        1	[densenet201/conv5_block13_0_relu/Relu;densenet201/conv5_block13_0_bn/FusedBatchNormV3]:407
	                 CONV_2D	          625.173	    0.934	    0.927	  0.138%	 93.408%	     0.000	        1	[densenet201/conv5_block13_1_relu/Relu;densenet201/conv5_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block13_1_conv/Conv2D]:408
	                 CONV_2D	          626.101	    0.248	    0.245	  0.037%	 93.444%	     0.000	        1	[densenet201/conv5_block13_2_conv/Conv2D1]:409
	           CONCATENATION	          626.346	    0.016	    0.014	  0.002%	 93.446%	     0.000	        1	[densenet201/conv5_block13_concat/concat]:410
	                     MUL	          626.361	    0.187	    0.186	  0.028%	 93.474%	     0.000	        1	[densenet201/conv5_block14_0_bn/FusedBatchNormV31]:411
	                     ADD	          626.547	    0.259	    0.263	  0.039%	 93.513%	     0.000	        1	[densenet201/conv5_block14_0_relu/Relu;densenet201/conv5_block14_0_bn/FusedBatchNormV3]:412
	                 CONV_2D	          626.811	    0.976	    0.947	  0.141%	 93.655%	     0.000	        1	[densenet201/conv5_block14_1_relu/Relu;densenet201/conv5_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block14_1_conv/Conv2D]:413
	                 CONV_2D	          627.759	    0.246	    0.243	  0.036%	 93.691%	     0.000	        1	[densenet201/conv5_block14_2_conv/Conv2D1]:414
	           CONCATENATION	          628.003	    0.015	    0.016	  0.002%	 93.693%	     0.000	        1	[densenet201/conv5_block14_concat/concat]:415
	                     MUL	          628.019	    0.192	    0.191	  0.028%	 93.722%	     0.000	        1	[densenet201/conv5_block15_0_bn/FusedBatchNormV31]:416
	                     ADD	          628.210	    0.265	    0.270	  0.040%	 93.762%	     0.000	        1	[densenet201/conv5_block15_0_relu/Relu;densenet201/conv5_block15_0_bn/FusedBatchNormV3]:417
	                 CONV_2D	          628.481	    0.979	    0.974	  0.145%	 93.908%	     0.000	        1	[densenet201/conv5_block15_1_relu/Relu;densenet201/conv5_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block15_1_conv/Conv2D]:418
	                 CONV_2D	          629.456	    0.247	    0.246	  0.037%	 93.944%	     0.000	        1	[densenet201/conv5_block15_2_conv/Conv2D1]:419
	           CONCATENATION	          629.702	    0.016	    0.015	  0.002%	 93.947%	     0.000	        1	[densenet201/conv5_block15_concat/concat]:420
	                     MUL	          629.718	    0.210	    0.196	  0.029%	 93.976%	     0.000	        1	[densenet201/conv5_block16_0_bn/FusedBatchNormV31]:421
	                     ADD	          629.915	    0.273	    0.279	  0.042%	 94.017%	     0.000	        1	[densenet201/conv5_block16_0_relu/Relu;densenet201/conv5_block16_0_bn/FusedBatchNormV3]:422
	                 CONV_2D	          630.194	    0.984	    0.995	  0.148%	 94.166%	     0.000	        1	[densenet201/conv5_block16_1_relu/Relu;densenet201/conv5_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block16_1_conv/Conv2D]:423
	                 CONV_2D	          631.190	    0.239	    0.243	  0.036%	 94.202%	     0.000	        1	[densenet201/conv5_block16_2_conv/Conv2D1]:424
	           CONCATENATION	          631.434	    0.041	    0.016	  0.002%	 94.205%	     0.000	        1	[densenet201/conv5_block16_concat/concat]:425
	                     MUL	          631.450	    0.202	    0.199	  0.030%	 94.234%	     0.000	        1	[densenet201/conv5_block17_0_bn/FusedBatchNormV31]:426
	                     ADD	          631.649	    0.304	    0.282	  0.042%	 94.276%	     0.000	        1	[densenet201/conv5_block17_0_relu/Relu;densenet201/conv5_block17_0_bn/FusedBatchNormV3]:427
	                 CONV_2D	          631.931	    1.004	    1.015	  0.152%	 94.428%	     0.000	        1	[densenet201/conv5_block17_1_relu/Relu;densenet201/conv5_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block17_1_conv/Conv2D]:428
	                 CONV_2D	          632.947	    0.239	    0.246	  0.037%	 94.465%	     0.000	        1	[densenet201/conv5_block17_2_conv/Conv2D1]:429
	           CONCATENATION	          633.193	    0.014	    0.017	  0.002%	 94.467%	     0.000	        1	[densenet201/conv5_block17_concat/concat]:430
	                     MUL	          633.211	    0.202	    0.204	  0.030%	 94.497%	     0.000	        1	[densenet201/conv5_block18_0_bn/FusedBatchNormV31]:431
	                     ADD	          633.415	    0.282	    0.290	  0.043%	 94.541%	     0.000	        1	[densenet201/conv5_block18_0_relu/Relu;densenet201/conv5_block18_0_bn/FusedBatchNormV3]:432
	                 CONV_2D	          633.705	    1.043	    1.038	  0.155%	 94.696%	     0.000	        1	[densenet201/conv5_block18_1_relu/Relu;densenet201/conv5_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block18_1_conv/Conv2D]:433
	                 CONV_2D	          634.744	    0.242	    0.242	  0.036%	 94.732%	     0.000	        1	[densenet201/conv5_block18_2_conv/Conv2D1]:434
	           CONCATENATION	          634.987	    0.015	    0.017	  0.002%	 94.734%	     0.000	        1	[densenet201/conv5_block18_concat/concat]:435
	                     MUL	          635.004	    0.208	    0.209	  0.031%	 94.766%	     0.000	        1	[densenet201/conv5_block19_0_bn/FusedBatchNormV31]:436
	                     ADD	          635.214	    0.315	    0.293	  0.044%	 94.809%	     0.000	        1	[densenet201/conv5_block19_0_relu/Relu;densenet201/conv5_block19_0_bn/FusedBatchNormV3]:437
	                 CONV_2D	          635.507	    1.069	    1.063	  0.159%	 94.968%	     0.000	        1	[densenet201/conv5_block19_1_relu/Relu;densenet201/conv5_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block19_1_conv/Conv2D]:438
	                 CONV_2D	          636.571	    0.269	    0.247	  0.037%	 95.005%	     0.000	        1	[densenet201/conv5_block19_2_conv/Conv2D1]:439
	           CONCATENATION	          636.818	    0.031	    0.017	  0.002%	 95.007%	     0.000	        1	[densenet201/conv5_block19_concat/concat]:440
	                     MUL	          636.835	    0.206	    0.213	  0.032%	 95.039%	     0.000	        1	[densenet201/conv5_block20_0_bn/FusedBatchNormV31]:441
	                     ADD	          637.048	    0.306	    0.298	  0.044%	 95.083%	     0.000	        1	[densenet201/conv5_block20_0_relu/Relu;densenet201/conv5_block20_0_bn/FusedBatchNormV3]:442
	                 CONV_2D	          637.346	    1.080	    1.081	  0.161%	 95.245%	     0.000	        1	[densenet201/conv5_block20_1_relu/Relu;densenet201/conv5_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block20_1_conv/Conv2D]:443
	                 CONV_2D	          638.428	    0.240	    0.244	  0.036%	 95.281%	     0.000	        1	[densenet201/conv5_block20_2_conv/Conv2D1]:444
	           CONCATENATION	          638.672	    0.016	    0.016	  0.002%	 95.284%	     0.000	        1	[densenet201/conv5_block20_concat/concat]:445
	                     MUL	          638.689	    0.217	    0.217	  0.032%	 95.316%	     0.000	        1	[densenet201/conv5_block21_0_bn/FusedBatchNormV31]:446
	                     ADD	          638.907	    0.315	    0.308	  0.046%	 95.362%	     0.000	        1	[densenet201/conv5_block21_0_relu/Relu;densenet201/conv5_block21_0_bn/FusedBatchNormV3]:447
	                 CONV_2D	          639.216	    1.122	    1.102	  0.164%	 95.527%	     0.000	        1	[densenet201/conv5_block21_1_relu/Relu;densenet201/conv5_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block21_1_conv/Conv2D]:448
	                 CONV_2D	          640.319	    0.258	    0.245	  0.037%	 95.563%	     0.000	        1	[densenet201/conv5_block21_2_conv/Conv2D1]:449
	           CONCATENATION	          640.565	    0.018	    0.018	  0.003%	 95.566%	     0.000	        1	[densenet201/conv5_block21_concat/concat]:450
	                     MUL	          640.583	    0.221	    0.222	  0.033%	 95.599%	     0.000	        1	[densenet201/conv5_block22_0_bn/FusedBatchNormV31]:451
	                     ADD	          640.805	    0.308	    0.314	  0.047%	 95.646%	     0.000	        1	[densenet201/conv5_block22_0_relu/Relu;densenet201/conv5_block22_0_bn/FusedBatchNormV3]:452
	                 CONV_2D	          641.119	    1.105	    1.123	  0.168%	 95.813%	     0.000	        1	[densenet201/conv5_block22_1_relu/Relu;densenet201/conv5_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block22_1_conv/Conv2D]:453
	                 CONV_2D	          642.243	    0.240	    0.248	  0.037%	 95.850%	     0.000	        1	[densenet201/conv5_block22_2_conv/Conv2D1]:454
	           CONCATENATION	          642.491	    0.014	    0.017	  0.003%	 95.853%	     0.000	        1	[densenet201/conv5_block22_concat/concat]:455
	                     MUL	          642.509	    0.240	    0.225	  0.034%	 95.887%	     0.000	        1	[densenet201/conv5_block23_0_bn/FusedBatchNormV31]:456
	                     ADD	          642.735	    0.321	    0.319	  0.048%	 95.934%	     0.000	        1	[densenet201/conv5_block23_0_relu/Relu;densenet201/conv5_block23_0_bn/FusedBatchNormV3]:457
	                 CONV_2D	          643.055	    1.155	    1.150	  0.172%	 96.106%	     0.000	        1	[densenet201/conv5_block23_1_relu/Relu;densenet201/conv5_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block23_1_conv/Conv2D]:458
	                 CONV_2D	          644.205	    0.246	    0.243	  0.036%	 96.142%	     0.000	        1	[densenet201/conv5_block23_2_conv/Conv2D1]:459
	           CONCATENATION	          644.449	    0.018	    0.017	  0.003%	 96.145%	     0.000	        1	[densenet201/conv5_block23_concat/concat]:460
	                     MUL	          644.467	    0.229	    0.233	  0.035%	 96.180%	     0.000	        1	[densenet201/conv5_block24_0_bn/FusedBatchNormV31]:461
	                     ADD	          644.700	    0.326	    0.326	  0.049%	 96.228%	     0.000	        1	[densenet201/conv5_block24_0_relu/Relu;densenet201/conv5_block24_0_bn/FusedBatchNormV3]:462
	                 CONV_2D	          645.026	    1.181	    1.173	  0.175%	 96.403%	     0.000	        1	[densenet201/conv5_block24_1_relu/Relu;densenet201/conv5_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block24_1_conv/Conv2D]:463
	                 CONV_2D	          646.200	    0.243	    0.249	  0.037%	 96.440%	     0.000	        1	[densenet201/conv5_block24_2_conv/Conv2D1]:464
	           CONCATENATION	          646.450	    0.017	    0.019	  0.003%	 96.443%	     0.000	        1	[densenet201/conv5_block24_concat/concat]:465
	                     MUL	          646.470	    0.234	    0.234	  0.035%	 96.478%	     0.000	        1	[densenet201/conv5_block25_0_bn/FusedBatchNormV31]:466
	                     ADD	          646.705	    0.333	    0.332	  0.050%	 96.528%	     0.000	        1	[densenet201/conv5_block25_0_relu/Relu;densenet201/conv5_block25_0_bn/FusedBatchNormV3]:467
	                 CONV_2D	          647.038	    1.255	    1.195	  0.178%	 96.706%	     0.000	        1	[densenet201/conv5_block25_1_relu/Relu;densenet201/conv5_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block25_1_conv/Conv2D]:468
	                 CONV_2D	          648.233	    0.249	    0.245	  0.037%	 96.743%	     0.000	        1	[densenet201/conv5_block25_2_conv/Conv2D1]:469
	           CONCATENATION	          648.479	    0.027	    0.019	  0.003%	 96.746%	     0.000	        1	[densenet201/conv5_block25_concat/concat]:470
	                     MUL	          648.498	    0.231	    0.242	  0.036%	 96.782%	     0.000	        1	[densenet201/conv5_block26_0_bn/FusedBatchNormV31]:471
	                     ADD	          648.740	    0.339	    0.338	  0.050%	 96.832%	     0.000	        1	[densenet201/conv5_block26_0_relu/Relu;densenet201/conv5_block26_0_bn/FusedBatchNormV3]:472
	                 CONV_2D	          649.079	    1.199	    1.213	  0.181%	 97.013%	     0.000	        1	[densenet201/conv5_block26_1_relu/Relu;densenet201/conv5_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block26_1_conv/Conv2D]:473
	                 CONV_2D	          650.293	    0.272	    0.251	  0.037%	 97.051%	     0.000	        1	[densenet201/conv5_block26_2_conv/Conv2D1]:474
	           CONCATENATION	          650.544	    0.017	    0.019	  0.003%	 97.054%	     0.000	        1	[densenet201/conv5_block26_concat/concat]:475
	                     MUL	          650.564	    0.240	    0.242	  0.036%	 97.090%	     0.000	        1	[densenet201/conv5_block27_0_bn/FusedBatchNormV31]:476
	                     ADD	          650.807	    0.336	    0.345	  0.052%	 97.141%	     0.000	        1	[densenet201/conv5_block27_0_relu/Relu;densenet201/conv5_block27_0_bn/FusedBatchNormV3]:477
	                 CONV_2D	          651.153	    1.248	    1.238	  0.185%	 97.326%	     0.000	        1	[densenet201/conv5_block27_1_relu/Relu;densenet201/conv5_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block27_1_conv/Conv2D]:478
	                 CONV_2D	          652.392	    0.244	    0.248	  0.037%	 97.363%	     0.000	        1	[densenet201/conv5_block27_2_conv/Conv2D1]:479
	           CONCATENATION	          652.640	    0.019	    0.020	  0.003%	 97.366%	     0.000	        1	[densenet201/conv5_block27_concat/concat]:480
	                     MUL	          652.660	    0.246	    0.249	  0.037%	 97.403%	     0.000	        1	[densenet201/conv5_block28_0_bn/FusedBatchNormV31]:481
	                     ADD	          652.910	    0.351	    0.350	  0.052%	 97.456%	     0.000	        1	[densenet201/conv5_block28_0_relu/Relu;densenet201/conv5_block28_0_bn/FusedBatchNormV3]:482
	                 CONV_2D	          653.261	    1.236	    1.258	  0.188%	 97.643%	     0.000	        1	[densenet201/conv5_block28_1_relu/Relu;densenet201/conv5_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block28_1_conv/Conv2D]:483
	                 CONV_2D	          654.519	    0.236	    0.244	  0.036%	 97.680%	     0.000	        1	[densenet201/conv5_block28_2_conv/Conv2D1]:484
	           CONCATENATION	          654.764	    0.018	    0.020	  0.003%	 97.683%	     0.000	        1	[densenet201/conv5_block28_concat/concat]:485
	                     MUL	          654.784	    0.249	    0.251	  0.037%	 97.720%	     0.000	        1	[densenet201/conv5_block29_0_bn/FusedBatchNormV31]:486
	                     ADD	          655.036	    0.349	    0.357	  0.053%	 97.773%	     0.000	        1	[densenet201/conv5_block29_0_relu/Relu;densenet201/conv5_block29_0_bn/FusedBatchNormV3]:487
	                 CONV_2D	          655.393	    1.286	    1.278	  0.191%	 97.964%	     0.000	        1	[densenet201/conv5_block29_1_relu/Relu;densenet201/conv5_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block29_1_conv/Conv2D]:488
	                 CONV_2D	          656.672	    0.240	    0.245	  0.037%	 98.001%	     0.000	        1	[densenet201/conv5_block29_2_conv/Conv2D1]:489
	           CONCATENATION	          656.918	    0.018	    0.021	  0.003%	 98.004%	     0.000	        1	[densenet201/conv5_block29_concat/concat]:490
	                     MUL	          656.940	    0.252	    0.258	  0.038%	 98.042%	     0.000	        1	[densenet201/conv5_block30_0_bn/FusedBatchNormV31]:491
	                     ADD	          657.198	    0.362	    0.362	  0.054%	 98.097%	     0.000	        1	[densenet201/conv5_block30_0_relu/Relu;densenet201/conv5_block30_0_bn/FusedBatchNormV3]:492
	                 CONV_2D	          657.561	    1.280	    1.303	  0.194%	 98.291%	     0.000	        1	[densenet201/conv5_block30_1_relu/Relu;densenet201/conv5_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block30_1_conv/Conv2D]:493
	                 CONV_2D	          658.864	    0.235	    0.243	  0.036%	 98.327%	     0.000	        1	[densenet201/conv5_block30_2_conv/Conv2D1]:494
	           CONCATENATION	          659.108	    0.018	    0.023	  0.003%	 98.331%	     0.000	        1	[densenet201/conv5_block30_concat/concat]:495
	                     MUL	          659.131	    0.257	    0.261	  0.039%	 98.370%	     0.000	        1	[densenet201/conv5_block31_0_bn/FusedBatchNormV31]:496
	                     ADD	          659.393	    0.411	    0.368	  0.055%	 98.425%	     0.000	        1	[densenet201/conv5_block31_0_relu/Relu;densenet201/conv5_block31_0_bn/FusedBatchNormV3]:497
	                 CONV_2D	          659.761	    1.331	    1.331	  0.199%	 98.623%	     0.000	        1	[densenet201/conv5_block31_1_relu/Relu;densenet201/conv5_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block31_1_conv/Conv2D]:498
	                 CONV_2D	          661.093	    0.241	    0.248	  0.037%	 98.660%	     0.000	        1	[densenet201/conv5_block31_2_conv/Conv2D1]:499
	           CONCATENATION	          661.342	    0.025	    0.022	  0.003%	 98.664%	     0.000	        1	[densenet201/conv5_block31_concat/concat]:500
	                     MUL	          661.365	    0.265	    0.267	  0.040%	 98.704%	     0.000	        1	[densenet201/conv5_block32_0_bn/FusedBatchNormV31]:501
	                     ADD	          661.633	    0.368	    0.375	  0.056%	 98.759%	     0.000	        1	[densenet201/conv5_block32_0_relu/Relu;densenet201/conv5_block32_0_bn/FusedBatchNormV3]:502
	                 CONV_2D	          662.008	    1.332	    1.349	  0.201%	 98.961%	     0.000	        1	[densenet201/conv5_block32_1_relu/Relu;densenet201/conv5_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block32_1_conv/Conv2D]:503
	                 CONV_2D	          663.358	    0.238	    0.246	  0.037%	 98.998%	     0.000	        1	[densenet201/conv5_block32_2_conv/Conv2D210]:504
	           CONCATENATION	          663.605	    0.021	    0.020	  0.003%	 99.001%	     0.000	        1	[densenet201/conv5_block32_concat/concat]:505
	                     MUL	          663.626	    0.269	    0.272	  0.041%	 99.041%	     0.000	        1	[densenet201/bn/FusedBatchNormV31]:506
	                     ADD	          663.898	    0.371	    0.381	  0.057%	 99.098%	     0.000	        1	[densenet201/relu/Relu;densenet201/bn/FusedBatchNormV3]:507
	                    MEAN	          664.281	    5.119	    5.152	  0.769%	 99.867%	     0.000	        1	[densenet201/avg_pool/Mean]:508
	         FULLY_CONNECTED	          669.433	    0.879	    0.875	  0.131%	 99.998%	     0.000	        1	[densenet201/predictions/MatMul;densenet201/predictions/BiasAdd]:509
	                 SOFTMAX	          670.309	    0.027	    0.015	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:510

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          573.578	   33.664	   33.682	  5.028%	  5.028%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	                 CONV_2D	            1.151	   20.471	   18.873	  2.817%	  7.845%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                 CONV_2D	           53.098	   16.863	   16.698	  2.492%	 10.337%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	                 CONV_2D	          168.890	   16.475	   16.628	  2.482%	 12.819%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	                 CONV_2D	           79.293	   17.340	   16.280	  2.430%	 15.249%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	                 CONV_2D	           29.460	   18.490	   16.246	  2.425%	 17.674%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	                 CONV_2D	          107.196	   17.194	   16.121	  2.406%	 20.080%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	                 CONV_2D	          137.027	   16.331	   16.068	  2.398%	 22.479%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	                 CONV_2D	          191.725	   11.875	   11.770	  1.757%	 24.235%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	                 CONV_2D	          318.816	   11.142	   11.130	  1.661%	 25.897%	     0.000	        1	[densenet201/pool3_conv/Conv2D1]:100

Number of nodes executed: 511
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	      200	   513.739	    76.712%	    76.712%	     0.000	      200
	                     ADD	      102	    77.611	    11.589%	    88.301%	     0.000	      102
	                     MUL	      102	    54.361	     8.117%	    96.418%	     0.000	      102
	           CONCATENATION	       98	    10.750	     1.605%	    98.023%	     0.000	       98
	                    MEAN	        1	     5.151	     0.769%	    98.792%	     0.000	        1
	                     PAD	        2	     4.781	     0.714%	    99.506%	     0.000	        2
	         AVERAGE_POOL_2D	        3	     1.827	     0.273%	    99.779%	     0.000	        3
	         FULLY_CONNECTED	        1	     0.875	     0.131%	    99.910%	     0.000	        1
	             MAX_POOL_2D	        1	     0.592	     0.088%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.014	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=679838 curr=669964 min=668483 max=681570 avg=669954 std=1945
Memory (bytes): count=0
511 nodes observed



munmap_chunk(): invalid pointer
[ perf record: Woken up 190 times to write data ]
[ perf record: Captured and wrote 47.266 MB /tmp/data.record (275279 samples) ]

72.552

