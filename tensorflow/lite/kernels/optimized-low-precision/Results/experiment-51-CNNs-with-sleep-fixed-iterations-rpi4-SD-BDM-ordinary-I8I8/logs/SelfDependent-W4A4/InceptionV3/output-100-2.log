STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ) (or (22201, 27, )), Output shape (22201, 32, ), ID: 0, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (16, 32, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (32, 32, ) DONE
	Preparing Filter With Shape: (27, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 16, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 32, ) DONE
	Allocating An Output Temporary Tensor With Shape: (22204, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 32, ), Input shape (22201, 32, ) (or (21609, 288, )), Output shape (21609, 32, ), ID: 1, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 32, ) DONE
	Preparing Filter With Shape: (288, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (21609, 32, ) (or (21609, 288, )), Output shape (21609, 64, ), ID: 2, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 80, ), Input shape (5329, 64, ) (or (5329, 64, )), Output shape (5329, 80, ), ID: 3, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (5329, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 80, ) DONE
	Preparing Filter With Shape: (64, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5332, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (720, 192, ), Input shape (5329, 80, ) (or (5041, 720, )), Output shape (5041, 192, ), ID: 4, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (5041, 720, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (368, 192, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (736, 192, ) DONE
	Preparing Filter With Shape: (720, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 368, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 736, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5044, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 32, ), ID: 5, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 32, ) DONE
	Preparing Filter With Shape: (192, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 6, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 48, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 48, ), ID: 7, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 48, ) DONE
	Preparing Filter With Shape: (192, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 8, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 9, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 10, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 11, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 12, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 13, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 48, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 48, ), ID: 14, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 48, ) DONE
	Preparing Filter With Shape: (256, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 15, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 16, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 17, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 18, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 19, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 20, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 48, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 48, ), ID: 21, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 48, ) DONE
	Preparing Filter With Shape: (288, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 22, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 23, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 24, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 25, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (2592, 384, ), Input shape (1225, 288, ) (or (289, 2592, )), Output shape (289, 384, ), ID: 26, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 2592, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1296, 384, ) DONE
	Preparing Filter With Shape: (2592, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1296, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 2592, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 27, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 28, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (289, 864, )), Output shape (289, 96, ), ID: 29, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 30, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 31, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 32, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 33, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 34, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 35, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 36, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 37, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 38, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 39, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 40, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 41, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 42, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 43, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 44, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 45, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 46, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 47, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 48, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 49, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 50, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 51, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 52, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 53, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 54, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 55, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 56, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 57, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 58, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 59, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 60, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 61, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 62, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 63, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 64, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 65, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 66, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 67, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 68, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 69, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 70, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 320, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 320, ), ID: 71, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 320, ) DONE
	Preparing Filter With Shape: (1728, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 72, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 73, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 74, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 192, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 192, ), ID: 75, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 192, ) DONE
	Preparing Filter With Shape: (1728, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 192, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 192, ), ID: 76, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 192, ) DONE
	Preparing Filter With Shape: (1280, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 320, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 320, ), ID: 77, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 320, ) DONE
	Preparing Filter With Shape: (1280, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 384, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 384, ), ID: 78, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 384, ) DONE
	Preparing Filter With Shape: (1280, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 79, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 80, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 448, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 448, ), ID: 81, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 448, ) DONE
	Preparing Filter With Shape: (1280, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 82, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2016, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2016, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 83, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 84, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 192, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 192, ), ID: 85, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 192, ) DONE
	Preparing Filter With Shape: (2048, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 320, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 320, ), ID: 86, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 320, ) DONE
	Preparing Filter With Shape: (2048, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 384, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 384, ), ID: 87, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 384, ) DONE
	Preparing Filter With Shape: (2048, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 88, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 89, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 448, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 448, ), ID: 90, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 448, ) DONE
	Preparing Filter With Shape: (2048, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 91, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2016, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2016, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 92, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 93, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying FC Low-Precision for Kernel shape (2048, 1000, ), Input shape (1, 2048, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW4A4
	Allocating Filter Shape: (1024, 1000, ) DONE
	Preparing Filter With Shape: (2048, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 24.2886
Initialized session in 259.954ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=782848 curr=741847 min=741847 max=782848 avg=762348 std=20500

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=746255 curr=733429 min=731457 max=759526 avg=741982 std=4942

Inference timings in us: Init: 259954, First inference: 782848, Warmup (avg): 762348, Inference (avg): 741982
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=40.6523 overall=62.0039
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  253.842	  253.842	100.000%	100.000%	 31464.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  253.842	  253.842	100.000%	100.000%	 31464.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   253.842	   100.000%	   100.000%	 31464.000	        1

Timings (microseconds): count=1 curr=253842
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.021	    7.098	    7.098	  0.957%	  0.957%	     0.000	        1	[inception_v3/activation/Relu;inception_v3/batch_normalization/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d/Conv2D]:0
	                 CONV_2D	            7.120	   33.737	   35.029	  4.722%	  5.679%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	           42.150	   57.636	   57.738	  7.784%	 13.463%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	             MAX_POOL_2D	           99.889	    0.895	    0.969	  0.131%	 13.593%	     0.000	        1	[inception_v3/max_pooling2d/MaxPool]:3
	                 CONV_2D	          100.860	    4.753	    4.685	  0.632%	 14.225%	     0.000	        1	[inception_v3/activation_3/Relu;inception_v3/batch_normalization_3/FusedBatchNormV3;inception_v3/batch_normalization_3/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_3/Conv2D]:4
	                 CONV_2D	          105.546	   84.695	   83.856	 11.305%	 25.530%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	             MAX_POOL_2D	          189.403	    0.536	    0.546	  0.074%	 25.603%	     0.000	        1	[inception_v3/max_pooling2d_1/MaxPool]:6
	         AVERAGE_POOL_2D	          189.950	    2.131	    2.158	  0.291%	 25.894%	     0.000	        1	[inception_v3/average_pooling2d/AvgPool]:7
	                 CONV_2D	          192.110	    1.233	    1.216	  0.164%	 26.058%	     0.000	        1	[inception_v3/activation_11/Relu;inception_v3/batch_normalization_11/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_11/Conv2D]:8
	                 CONV_2D	          193.327	    2.106	    2.024	  0.273%	 26.331%	     0.000	        1	[inception_v3/activation_5/Relu;inception_v3/batch_normalization_5/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_5/Conv2D]:9
	                 CONV_2D	          195.352	    1.649	    1.604	  0.216%	 26.547%	     0.000	        1	[inception_v3/activation_6/Relu;inception_v3/batch_normalization_6/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_6/Conv2D]:10
	                 CONV_2D	          196.957	   13.041	   12.952	  1.746%	 28.293%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          209.911	    2.077	    2.094	  0.282%	 28.576%	     0.000	        1	[inception_v3/activation_8/Relu;inception_v3/batch_normalization_8/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_8/Conv2D]:12
	                 CONV_2D	          212.006	    9.046	    8.777	  1.183%	 29.759%	     0.000	        1	[inception_v3/activation_9/Relu;inception_v3/batch_normalization_9/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_9/Conv2D]:13
	                 CONV_2D	          220.785	   13.113	   12.968	  1.748%	 31.507%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	           CONCATENATION	          233.754	    0.271	    0.223	  0.030%	 31.537%	     0.000	        1	[inception_v3/mixed0/concat]:15
	         AVERAGE_POOL_2D	          233.977	    3.614	    3.577	  0.482%	 32.019%	     0.000	        1	[inception_v3/average_pooling2d_1/AvgPool]:16
	                 CONV_2D	          237.555	    2.759	    2.681	  0.361%	 32.381%	     0.000	        1	[inception_v3/activation_18/Relu;inception_v3/batch_normalization_18/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_18/Conv2D]:17
	                 CONV_2D	          240.237	    2.649	    2.678	  0.361%	 32.742%	     0.000	        1	[inception_v3/activation_12/Relu;inception_v3/batch_normalization_12/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_12/Conv2D]:18
	                 CONV_2D	          242.916	    2.267	    2.095	  0.282%	 33.024%	     0.000	        1	[inception_v3/activation_13/Relu;inception_v3/batch_normalization_13/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_13/Conv2D]:19
	                 CONV_2D	          245.013	   13.184	   13.118	  1.768%	 34.793%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          258.132	    2.699	    2.657	  0.358%	 35.151%	     0.000	        1	[inception_v3/activation_15/Relu;inception_v3/batch_normalization_15/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_15/Conv2D]:21
	                 CONV_2D	          260.790	    9.041	    8.884	  1.198%	 36.348%	     0.000	        1	[inception_v3/activation_16/Relu;inception_v3/batch_normalization_16/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_16/Conv2D]:22
	                 CONV_2D	          269.675	   13.106	   12.938	  1.744%	 38.093%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	           CONCATENATION	          282.614	    0.261	    0.258	  0.035%	 38.127%	     0.000	        1	[inception_v3/mixed1/concat]:24
	         AVERAGE_POOL_2D	          282.873	    4.224	    4.129	  0.557%	 38.684%	     0.000	        1	[inception_v3/average_pooling2d_2/AvgPool]:25
	                 CONV_2D	          287.003	    3.005	    2.961	  0.399%	 39.083%	     0.000	        1	[inception_v3/activation_25/Relu;inception_v3/batch_normalization_25/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_25/Conv2D]:26
	                 CONV_2D	          289.966	    2.996	    2.991	  0.403%	 39.486%	     0.000	        1	[inception_v3/activation_19/Relu;inception_v3/batch_normalization_19/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_19/Conv2D]:27
	                 CONV_2D	          292.958	    2.430	    2.348	  0.317%	 39.803%	     0.000	        1	[inception_v3/activation_20/Relu;inception_v3/batch_normalization_20/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_20/Conv2D]:28
	                 CONV_2D	          295.308	   12.850	   12.993	  1.752%	 41.554%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          308.302	    2.901	    2.956	  0.398%	 41.953%	     0.000	        1	[inception_v3/activation_22/Relu;inception_v3/batch_normalization_22/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_22/Conv2D]:30
	                 CONV_2D	          311.259	    8.680	    8.860	  1.194%	 43.147%	     0.000	        1	[inception_v3/activation_23/Relu;inception_v3/batch_normalization_23/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_23/Conv2D]:31
	                 CONV_2D	          320.121	   12.913	   12.985	  1.751%	 44.898%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	           CONCATENATION	          333.107	    0.247	    0.262	  0.035%	 44.933%	     0.000	        1	[inception_v3/mixed2/concat]:33
	                 CONV_2D	          333.370	   33.210	   32.474	  4.378%	 49.311%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          365.845	    3.276	    2.922	  0.394%	 49.705%	     0.000	        1	[inception_v3/activation_27/Relu;inception_v3/batch_normalization_27/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_27/Conv2D]:35
	                 CONV_2D	          368.769	    9.245	    8.894	  1.199%	 50.904%	     0.000	        1	[inception_v3/activation_28/Relu;inception_v3/batch_normalization_28/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_28/Conv2D]:36
	                 CONV_2D	          377.664	    3.107	    3.008	  0.405%	 51.309%	     0.000	        1	[inception_v3/activation_29/Relu;inception_v3/batch_normalization_29/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_29/Conv2D]:37
	             MAX_POOL_2D	          380.673	    0.234	    0.265	  0.036%	 51.345%	     0.000	        1	[inception_v3/max_pooling2d_2/MaxPool]:38
	           CONCATENATION	          380.939	    0.119	    0.133	  0.018%	 51.363%	     0.000	        1	[inception_v3/mixed3/concat]:39
	         AVERAGE_POOL_2D	          381.073	    2.393	    2.381	  0.321%	 51.684%	     0.000	        1	[inception_v3/average_pooling2d_3/AvgPool]:40
	                 CONV_2D	          383.455	    5.097	    4.880	  0.658%	 52.342%	     0.000	        1	[inception_v3/activation_39/Relu;inception_v3/batch_normalization_39/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_39/Conv2D]:41
	                 CONV_2D	          388.336	    4.941	    4.897	  0.660%	 53.002%	     0.000	        1	[inception_v3/activation_30/Relu;inception_v3/batch_normalization_30/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_30/Conv2D]:42
	                 CONV_2D	          393.235	    3.294	    3.291	  0.444%	 53.446%	     0.000	        1	[inception_v3/activation_31/Relu;inception_v3/batch_normalization_31/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_31/Conv2D]:43
	                 CONV_2D	          396.527	    3.968	    3.912	  0.527%	 53.973%	     0.000	        1	[inception_v3/activation_32/Relu;inception_v3/batch_normalization_32/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_32/Conv2D]:44
	                 CONV_2D	          400.441	    5.693	    5.719	  0.771%	 54.744%	     0.000	        1	[inception_v3/activation_33/Relu;inception_v3/batch_normalization_33/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_33/Conv2D]:45
	                 CONV_2D	          406.161	    3.312	    3.342	  0.451%	 55.195%	     0.000	        1	[inception_v3/activation_34/Relu;inception_v3/batch_normalization_34/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_34/Conv2D]:46
	                 CONV_2D	          409.504	    3.875	    3.906	  0.527%	 55.721%	     0.000	        1	[inception_v3/activation_35/Relu;inception_v3/batch_normalization_35/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_35/Conv2D]:47
	                 CONV_2D	          413.411	    3.892	    3.926	  0.529%	 56.250%	     0.000	        1	[inception_v3/activation_36/Relu;inception_v3/batch_normalization_36/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_36/Conv2D]:48
	                 CONV_2D	          417.338	    4.074	    3.933	  0.530%	 56.781%	     0.000	        1	[inception_v3/activation_37/Relu;inception_v3/batch_normalization_37/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_37/Conv2D]:49
	                 CONV_2D	          421.272	    5.666	    5.700	  0.768%	 57.549%	     0.000	        1	[inception_v3/activation_38/Relu;inception_v3/batch_normalization_38/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_38/Conv2D]:50
	           CONCATENATION	          426.973	    0.131	    0.159	  0.021%	 57.570%	     0.000	        1	[inception_v3/mixed4/concat]:51
	         AVERAGE_POOL_2D	          427.133	    2.553	    2.549	  0.344%	 57.914%	     0.000	        1	[inception_v3/average_pooling2d_4/AvgPool]:52
	                 CONV_2D	          429.683	    4.816	    4.870	  0.657%	 58.571%	     0.000	        1	[inception_v3/activation_49/Relu;inception_v3/batch_normalization_49/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_49/Conv2D]:53
	                 CONV_2D	          434.554	    4.840	    4.887	  0.659%	 59.229%	     0.000	        1	[inception_v3/activation_40/Relu;inception_v3/batch_normalization_40/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_40/Conv2D]:54
	                 CONV_2D	          439.443	    4.069	    4.064	  0.548%	 59.777%	     0.000	        1	[inception_v3/activation_41/Relu;inception_v3/batch_normalization_41/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_41/Conv2D]:55
	                 CONV_2D	          443.508	    6.126	    6.029	  0.813%	 60.590%	     0.000	        1	[inception_v3/activation_42/Relu;inception_v3/batch_normalization_42/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_42/Conv2D]:56
	                 CONV_2D	          449.538	    7.541	    7.240	  0.976%	 61.566%	     0.000	        1	[inception_v3/activation_43/Relu;inception_v3/batch_normalization_43/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_43/Conv2D]:57
	                 CONV_2D	          456.779	    4.136	    4.113	  0.555%	 62.121%	     0.000	        1	[inception_v3/activation_44/Relu;inception_v3/batch_normalization_44/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_44/Conv2D]:58
	                 CONV_2D	          460.894	    6.187	    6.025	  0.812%	 62.933%	     0.000	        1	[inception_v3/activation_45/Relu;inception_v3/batch_normalization_45/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_45/Conv2D]:59
	                 CONV_2D	          466.920	    6.412	    6.068	  0.818%	 63.751%	     0.000	        1	[inception_v3/activation_46/Relu;inception_v3/batch_normalization_46/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_46/Conv2D]:60
	                 CONV_2D	          472.989	    6.505	    6.068	  0.818%	 64.569%	     0.000	        1	[inception_v3/activation_47/Relu;inception_v3/batch_normalization_47/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_47/Conv2D]:61
	                 CONV_2D	          479.058	    7.444	    7.191	  0.969%	 65.538%	     0.000	        1	[inception_v3/activation_48/Relu;inception_v3/batch_normalization_48/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_48/Conv2D]:62
	           CONCATENATION	          486.251	    0.123	    0.149	  0.020%	 65.558%	     0.000	        1	[inception_v3/mixed5/concat]:63
	         AVERAGE_POOL_2D	          486.400	    2.533	    2.544	  0.343%	 65.901%	     0.000	        1	[inception_v3/average_pooling2d_5/AvgPool]:64
	                 CONV_2D	          488.946	    5.156	    4.889	  0.659%	 66.560%	     0.000	        1	[inception_v3/activation_59/Relu;inception_v3/batch_normalization_59/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_59/Conv2D]:65
	                 CONV_2D	          493.836	    5.244	    4.872	  0.657%	 67.217%	     0.000	        1	[inception_v3/activation_50/Relu;inception_v3/batch_normalization_50/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_50/Conv2D]:66
	                 CONV_2D	          498.710	    4.061	    4.075	  0.549%	 67.767%	     0.000	        1	[inception_v3/activation_51/Relu;inception_v3/batch_normalization_51/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_51/Conv2D]:67
	                 CONV_2D	          502.786	    6.387	    6.042	  0.815%	 68.581%	     0.000	        1	[inception_v3/activation_52/Relu;inception_v3/batch_normalization_52/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_52/Conv2D]:68
	                 CONV_2D	          508.829	    7.588	    7.243	  0.976%	 69.558%	     0.000	        1	[inception_v3/activation_53/Relu;inception_v3/batch_normalization_53/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_53/Conv2D]:69
	                 CONV_2D	          516.074	    4.331	    4.153	  0.560%	 70.117%	     0.000	        1	[inception_v3/activation_54/Relu;inception_v3/batch_normalization_54/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_54/Conv2D]:70
	                 CONV_2D	          520.227	    5.898	    6.041	  0.814%	 70.932%	     0.000	        1	[inception_v3/activation_55/Relu;inception_v3/batch_normalization_55/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_55/Conv2D]:71
	                 CONV_2D	          526.270	    5.997	    6.076	  0.819%	 71.751%	     0.000	        1	[inception_v3/activation_56/Relu;inception_v3/batch_normalization_56/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_56/Conv2D]:72
	                 CONV_2D	          532.346	    6.016	    6.119	  0.825%	 72.576%	     0.000	        1	[inception_v3/activation_57/Relu;inception_v3/batch_normalization_57/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_57/Conv2D]:73
	                 CONV_2D	          538.467	    7.121	    7.217	  0.973%	 73.549%	     0.000	        1	[inception_v3/activation_58/Relu;inception_v3/batch_normalization_58/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_58/Conv2D]:74
	           CONCATENATION	          545.685	    0.129	    0.162	  0.022%	 73.570%	     0.000	        1	[inception_v3/mixed6/concat]:75
	         AVERAGE_POOL_2D	          545.848	    2.610	    2.587	  0.349%	 73.919%	     0.000	        1	[inception_v3/average_pooling2d_6/AvgPool]:76
	                 CONV_2D	          548.436	    4.816	    4.885	  0.659%	 74.578%	     0.000	        1	[inception_v3/activation_69/Relu;inception_v3/batch_normalization_69/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_69/Conv2D]:77
	                 CONV_2D	          553.322	    4.797	    4.890	  0.659%	 75.237%	     0.000	        1	[inception_v3/activation_60/Relu;inception_v3/batch_normalization_60/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_60/Conv2D]:78
	                 CONV_2D	          558.214	    4.839	    4.896	  0.660%	 75.897%	     0.000	        1	[inception_v3/activation_61/Relu;inception_v3/batch_normalization_61/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_61/Conv2D]:79
	                 CONV_2D	          563.111	    8.563	    8.547	  1.152%	 77.049%	     0.000	        1	[inception_v3/activation_62/Relu;inception_v3/batch_normalization_62/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_62/Conv2D]:80
	                 CONV_2D	          571.659	    8.620	    8.605	  1.160%	 78.209%	     0.000	        1	[inception_v3/activation_63/Relu;inception_v3/batch_normalization_63/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_63/Conv2D]:81
	                 CONV_2D	          580.265	    4.860	    4.910	  0.662%	 78.871%	     0.000	        1	[inception_v3/activation_64/Relu;inception_v3/batch_normalization_64/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_64/Conv2D]:82
	                 CONV_2D	          585.176	    8.449	    8.551	  1.153%	 80.024%	     0.000	        1	[inception_v3/activation_65/Relu;inception_v3/batch_normalization_65/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_65/Conv2D]:83
	                 CONV_2D	          593.728	    8.456	    8.577	  1.156%	 81.180%	     0.000	        1	[inception_v3/activation_66/Relu;inception_v3/batch_normalization_66/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_66/Conv2D]:84
	                 CONV_2D	          602.306	    8.639	    8.589	  1.158%	 82.338%	     0.000	        1	[inception_v3/activation_67/Relu;inception_v3/batch_normalization_67/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_67/Conv2D]:85
	                 CONV_2D	          610.896	    8.434	    8.568	  1.155%	 83.493%	     0.000	        1	[inception_v3/activation_68/Relu;inception_v3/batch_normalization_68/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_68/Conv2D]:86
	           CONCATENATION	          619.466	    0.137	    0.157	  0.021%	 83.514%	     0.000	        1	[inception_v3/mixed7/concat]:87
	                 CONV_2D	          619.623	    4.848	    4.915	  0.663%	 84.177%	     0.000	        1	[inception_v3/activation_70/Relu;inception_v3/batch_normalization_70/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_70/Conv2D]:88
	                 CONV_2D	          624.540	    3.854	    3.900	  0.526%	 84.703%	     0.000	        1	[inception_v3/activation_71/Relu;inception_v3/batch_normalization_71/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_71/Conv2D]:89
	                 CONV_2D	          628.440	    4.840	    4.886	  0.659%	 85.361%	     0.000	        1	[inception_v3/activation_72/Relu;inception_v3/batch_normalization_72/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_72/Conv2D]:90
	                 CONV_2D	          633.327	    8.485	    8.568	  1.155%	 86.516%	     0.000	        1	[inception_v3/activation_73/Relu;inception_v3/batch_normalization_73/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_73/Conv2D]:91
	                 CONV_2D	          641.896	    8.577	    8.542	  1.152%	 87.668%	     0.000	        1	[inception_v3/activation_74/Relu;inception_v3/batch_normalization_74/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_74/Conv2D]:92
	                 CONV_2D	          650.439	    2.434	    2.392	  0.322%	 87.990%	     0.000	        1	[inception_v3/activation_75/Relu;inception_v3/batch_normalization_75/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_75/Conv2D]:93
	             MAX_POOL_2D	          652.832	    0.169	    0.188	  0.025%	 88.015%	     0.000	        1	[inception_v3/max_pooling2d_3/MaxPool]:94
	           CONCATENATION	          653.021	    0.058	    0.042	  0.006%	 88.021%	     0.000	        1	[inception_v3/mixed8/concat]:95
	         AVERAGE_POOL_2D	          653.063	    0.797	    0.821	  0.111%	 88.132%	     0.000	        1	[inception_v3/average_pooling2d_7/AvgPool]:96
	                 CONV_2D	          653.885	    1.786	    1.738	  0.234%	 88.366%	     0.000	        1	[inception_v3/activation_84/Relu;inception_v3/batch_normalization_84/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_84/Conv2D]:97
	                 CONV_2D	          655.624	    2.900	    2.863	  0.386%	 88.752%	     0.000	        1	[inception_v3/activation_76/Relu;inception_v3/batch_normalization_76/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_76/Conv2D]:98
	                 CONV_2D	          658.489	    3.514	    3.446	  0.465%	 89.217%	     0.000	        1	[inception_v3/activation_77/Relu;inception_v3/batch_normalization_77/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_77/Conv2D]:99
	                 CONV_2D	          661.937	    3.181	    3.128	  0.422%	 89.638%	     0.000	        1	[inception_v3/activation_78/Relu;inception_v3/batch_normalization_78/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_78/Conv2D]:100
	                 CONV_2D	          665.067	    3.216	    3.152	  0.425%	 90.063%	     0.000	        1	[inception_v3/activation_79/Relu;inception_v3/batch_normalization_79/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_79/Conv2D]:101
	           CONCATENATION	          668.220	    0.041	    0.040	  0.005%	 90.069%	     0.000	        1	[inception_v3/mixed9_0/concat]:102
	                 CONV_2D	          668.261	    4.044	    4.013	  0.541%	 90.610%	     0.000	        1	[inception_v3/activation_80/Relu;inception_v3/batch_normalization_80/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_80/Conv2D]:103
	                 CONV_2D	          672.276	   10.882	   10.825	  1.459%	 92.069%	     0.000	        1	[inception_v3/activation_81/Relu;inception_v3/batch_normalization_81/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_81/Conv2D]:104
	                 CONV_2D	          683.102	    3.108	    3.138	  0.423%	 92.492%	     0.000	        1	[inception_v3/activation_82/Relu;inception_v3/batch_normalization_82/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_82/Conv2D]:105
	                 CONV_2D	          686.241	    3.098	    3.136	  0.423%	 92.915%	     0.000	        1	[inception_v3/activation_83/Relu;inception_v3/batch_normalization_83/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_83/Conv2D]:106
	           CONCATENATION	          689.377	    0.036	    0.043	  0.006%	 92.920%	     0.000	        1	[inception_v3/concatenate/concat]:107
	           CONCATENATION	          689.421	    0.071	    0.081	  0.011%	 92.931%	     0.000	        1	[inception_v3/mixed9/concat]:108
	         AVERAGE_POOL_2D	          689.503	    1.537	    1.562	  0.211%	 93.142%	     0.000	        1	[inception_v3/average_pooling2d_8/AvgPool]:109
	                 CONV_2D	          691.066	    2.722	    2.742	  0.370%	 93.512%	     0.000	        1	[inception_v3/activation_93/Relu;inception_v3/batch_normalization_93/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_93/Conv2D]:110
	                 CONV_2D	          693.810	    4.600	    4.542	  0.612%	 94.124%	     0.000	        1	[inception_v3/activation_85/Relu;inception_v3/batch_normalization_85/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_85/Conv2D]:111
	                 CONV_2D	          698.353	    5.436	    5.451	  0.735%	 94.859%	     0.000	        1	[inception_v3/activation_86/Relu;inception_v3/batch_normalization_86/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_86/Conv2D]:112
	                 CONV_2D	          703.805	    3.141	    3.137	  0.423%	 95.282%	     0.000	        1	[inception_v3/activation_87/Relu;inception_v3/batch_normalization_87/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_87/Conv2D]:113
	                 CONV_2D	          706.944	    3.211	    3.151	  0.425%	 95.706%	     0.000	        1	[inception_v3/activation_88/Relu;inception_v3/batch_normalization_88/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_88/Conv2D]:114
	           CONCATENATION	          710.096	    0.037	    0.039	  0.005%	 95.712%	     0.000	        1	[inception_v3/mixed9_1/concat]:115
	                 CONV_2D	          710.136	    6.348	    6.330	  0.853%	 96.565%	     0.000	        1	[inception_v3/activation_89/Relu;inception_v3/batch_normalization_89/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_89/Conv2D]:116
	                 CONV_2D	          716.467	   10.675	   10.844	  1.462%	 98.027%	     0.000	        1	[inception_v3/activation_90/Relu;inception_v3/batch_normalization_90/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_90/Conv2D]:117
	                 CONV_2D	          727.312	    3.185	    3.155	  0.425%	 98.452%	     0.000	        1	[inception_v3/activation_91/Relu;inception_v3/batch_normalization_91/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_91/Conv2D]:118
	                 CONV_2D	          730.469	    3.109	    3.137	  0.423%	 98.875%	     0.000	        1	[inception_v3/activation_92/Relu;inception_v3/batch_normalization_92/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_92/Conv2D]:119
	           CONCATENATION	          733.607	    0.082	    0.042	  0.006%	 98.881%	     0.000	        1	[inception_v3/concatenate_1/concat]:120
	           CONCATENATION	          733.649	    0.083	    0.080	  0.011%	 98.891%	     0.000	        1	[inception_v3/mixed10/concat]:121
	                    MEAN	          733.730	    7.212	    7.249	  0.977%	 99.869%	     0.000	        1	[inception_v3/avg_pool/Mean]:122
	         FULLY_CONNECTED	          740.981	    0.917	    0.958	  0.129%	 99.998%	     0.000	        1	[inception_v3/predictions/MatMul;inception_v3/predictions/BiasAdd]:123
	                 SOFTMAX	          741.939	    0.015	    0.016	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:124

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          105.546	   84.695	   83.856	 11.305%	 11.305%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	                 CONV_2D	           42.150	   57.636	   57.738	  7.784%	 19.088%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	                 CONV_2D	            7.120	   33.737	   35.029	  4.722%	 23.811%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	          333.370	   33.210	   32.474	  4.378%	 28.188%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          245.013	   13.184	   13.118	  1.768%	 29.957%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          295.308	   12.850	   12.993	  1.752%	 31.708%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          320.121	   12.913	   12.985	  1.751%	 33.459%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	                 CONV_2D	          220.785	   13.113	   12.968	  1.748%	 35.207%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	                 CONV_2D	          196.957	   13.041	   12.952	  1.746%	 36.953%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          269.675	   13.106	   12.938	  1.744%	 38.697%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23

Number of nodes executed: 125
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       94	   707.373	    95.369%	    95.369%	     0.000	       94
	         AVERAGE_POOL_2D	        9	    22.303	     3.007%	    98.376%	     0.000	        9
	                    MEAN	        1	     7.249	     0.977%	    99.353%	     0.000	        1
	             MAX_POOL_2D	        4	     1.966	     0.265%	    99.618%	     0.000	        4
	           CONCATENATION	       15	     1.858	     0.250%	    99.869%	     0.000	       15
	         FULLY_CONNECTED	        1	     0.957	     0.129%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.016	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=746052 curr=733231 min=731279 max=759316 avg=741785 std=4942
Memory (bytes): count=0
125 nodes observed



[ perf record: Woken up 213 times to write data ]
Warning:
Processed 299292 events and lost 4 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 53.264 MB /tmp/data.record (298773 samples) ]

77.637

