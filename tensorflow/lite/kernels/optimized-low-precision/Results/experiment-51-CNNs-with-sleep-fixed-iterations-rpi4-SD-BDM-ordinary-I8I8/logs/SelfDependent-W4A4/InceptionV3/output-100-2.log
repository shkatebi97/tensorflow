STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ) (or (22201, 27, )), Output shape (22201, 32, ), ID: 0, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (16, 32, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (32, 32, ) DONE
	Preparing Filter With Shape: (27, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 16, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 32, ) DONE
	Allocating An Output Temporary Tensor With Shape: (22204, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 32, ), Input shape (22201, 32, ) (or (21609, 288, )), Output shape (21609, 32, ), ID: 1, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 32, ) DONE
	Preparing Filter With Shape: (288, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (21609, 32, ) (or (21609, 288, )), Output shape (21609, 64, ), ID: 2, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 80, ), Input shape (5329, 64, ) (or (5329, 64, )), Output shape (5329, 80, ), ID: 3, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (5329, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 80, ) DONE
	Preparing Filter With Shape: (64, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5332, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (720, 192, ), Input shape (5329, 80, ) (or (5041, 720, )), Output shape (5041, 192, ), ID: 4, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (5041, 720, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (368, 192, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (736, 192, ) DONE
	Preparing Filter With Shape: (720, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 368, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 736, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5044, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 32, ), ID: 5, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 32, ) DONE
	Preparing Filter With Shape: (192, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 6, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 48, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 48, ), ID: 7, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 48, ) DONE
	Preparing Filter With Shape: (192, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 8, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 9, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 10, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 11, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 12, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 13, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 48, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 48, ), ID: 14, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 48, ) DONE
	Preparing Filter With Shape: (256, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 15, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 16, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 17, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 18, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 19, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 20, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 48, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 48, ), ID: 21, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 48, ) DONE
	Preparing Filter With Shape: (288, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 22, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 23, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 24, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 25, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (2592, 384, ), Input shape (1225, 288, ) (or (289, 2592, )), Output shape (289, 384, ), ID: 26, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 2592, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1296, 384, ) DONE
	Preparing Filter With Shape: (2592, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1296, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 2592, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 27, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 28, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (289, 864, )), Output shape (289, 96, ), ID: 29, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 30, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 31, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 32, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 33, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 34, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 35, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 36, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 37, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 38, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 39, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 40, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 41, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 42, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 43, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 44, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 45, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 46, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 47, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 48, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 49, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 50, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 51, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 52, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 53, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 54, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 55, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 56, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 57, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 58, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 59, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 60, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 61, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 62, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 63, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 64, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 65, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 66, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 67, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 68, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 69, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 70, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 320, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 320, ), ID: 71, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 320, ) DONE
	Preparing Filter With Shape: (1728, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 72, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 73, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 74, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 192, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 192, ), ID: 75, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 192, ) DONE
	Preparing Filter With Shape: (1728, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 192, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 192, ), ID: 76, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 192, ) DONE
	Preparing Filter With Shape: (1280, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 320, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 320, ), ID: 77, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 320, ) DONE
	Preparing Filter With Shape: (1280, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 384, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 384, ), ID: 78, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 384, ) DONE
	Preparing Filter With Shape: (1280, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 79, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 80, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 448, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 448, ), ID: 81, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 448, ) DONE
	Preparing Filter With Shape: (1280, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 82, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2016, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2016, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 83, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 84, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 192, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 192, ), ID: 85, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 192, ) DONE
	Preparing Filter With Shape: (2048, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 320, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 320, ), ID: 86, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 320, ) DONE
	Preparing Filter With Shape: (2048, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 384, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 384, ), ID: 87, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 384, ) DONE
	Preparing Filter With Shape: (2048, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 88, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 89, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 448, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 448, ), ID: 90, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 448, ) DONE
	Preparing Filter With Shape: (2048, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 91, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2016, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2016, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 92, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 93, Method: SelfDependentW4A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying FC Low-Precision for Kernel shape (2048, 1000, ), Input shape (1, 2048, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW4A4
	Allocating Filter Shape: (1024, 1000, ) DONE
	Preparing Filter With Shape: (2048, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 24.2886
Initialized session in 154.991ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=762347 curr=720566 min=720566 max=762347 avg=741456 std=20890

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=719057 curr=718878 min=717324 max=721128 avg=719171 std=613

Inference timings in us: Init: 154991, First inference: 762347, Warmup (avg): 741456, Inference (avg): 719171
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=40.6602 overall=62.0117
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  150.727	  150.727	100.000%	100.000%	 31464.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  150.727	  150.727	100.000%	100.000%	 31464.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   150.727	   100.000%	   100.000%	 31464.000	        1

Timings (microseconds): count=1 curr=150727
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.014	    7.146	    6.931	  0.964%	  0.964%	     0.000	        1	[inception_v3/activation/Relu;inception_v3/batch_normalization/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d/Conv2D]:0
	                 CONV_2D	            6.946	   32.862	   32.904	  4.576%	  5.540%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	           39.852	   55.115	   55.370	  7.701%	 13.241%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	             MAX_POOL_2D	           95.224	    1.007	    0.983	  0.137%	 13.378%	     0.000	        1	[inception_v3/max_pooling2d/MaxPool]:3
	                 CONV_2D	           96.208	    4.757	    4.705	  0.654%	 14.032%	     0.000	        1	[inception_v3/activation_3/Relu;inception_v3/batch_normalization_3/FusedBatchNormV3;inception_v3/batch_normalization_3/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_3/Conv2D]:4
	                 CONV_2D	          100.914	   81.941	   82.102	 11.419%	 25.451%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	             MAX_POOL_2D	          183.016	    0.519	    0.479	  0.067%	 25.517%	     0.000	        1	[inception_v3/max_pooling2d_1/MaxPool]:6
	         AVERAGE_POOL_2D	          183.496	    2.128	    2.133	  0.297%	 25.814%	     0.000	        1	[inception_v3/average_pooling2d/AvgPool]:7
	                 CONV_2D	          185.630	    1.115	    1.133	  0.158%	 25.972%	     0.000	        1	[inception_v3/activation_11/Relu;inception_v3/batch_normalization_11/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_11/Conv2D]:8
	                 CONV_2D	          186.764	    1.877	    1.913	  0.266%	 26.238%	     0.000	        1	[inception_v3/activation_5/Relu;inception_v3/batch_normalization_5/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_5/Conv2D]:9
	                 CONV_2D	          188.678	    1.468	    1.478	  0.206%	 26.443%	     0.000	        1	[inception_v3/activation_6/Relu;inception_v3/batch_normalization_6/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_6/Conv2D]:10
	                 CONV_2D	          190.157	   12.946	   12.850	  1.787%	 28.230%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          203.008	    2.126	    2.094	  0.291%	 28.522%	     0.000	        1	[inception_v3/activation_8/Relu;inception_v3/batch_normalization_8/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_8/Conv2D]:12
	                 CONV_2D	          205.102	    8.284	    8.319	  1.157%	 29.679%	     0.000	        1	[inception_v3/activation_9/Relu;inception_v3/batch_normalization_9/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_9/Conv2D]:13
	                 CONV_2D	          213.423	   12.565	   12.595	  1.752%	 31.430%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	           CONCATENATION	          226.019	    0.278	    0.282	  0.039%	 31.469%	     0.000	        1	[inception_v3/mixed0/concat]:15
	         AVERAGE_POOL_2D	          226.301	    3.549	    3.507	  0.488%	 31.957%	     0.000	        1	[inception_v3/average_pooling2d_1/AvgPool]:16
	                 CONV_2D	          229.809	    2.557	    2.542	  0.354%	 32.311%	     0.000	        1	[inception_v3/activation_18/Relu;inception_v3/batch_normalization_18/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_18/Conv2D]:17
	                 CONV_2D	          232.352	    2.588	    2.610	  0.363%	 32.674%	     0.000	        1	[inception_v3/activation_12/Relu;inception_v3/batch_normalization_12/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_12/Conv2D]:18
	                 CONV_2D	          234.962	    1.998	    1.943	  0.270%	 32.944%	     0.000	        1	[inception_v3/activation_13/Relu;inception_v3/batch_normalization_13/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_13/Conv2D]:19
	                 CONV_2D	          236.906	   12.804	   12.825	  1.784%	 34.728%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          249.732	    2.620	    2.639	  0.367%	 35.095%	     0.000	        1	[inception_v3/activation_15/Relu;inception_v3/batch_normalization_15/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_15/Conv2D]:21
	                 CONV_2D	          252.372	    8.607	    8.427	  1.172%	 36.267%	     0.000	        1	[inception_v3/activation_16/Relu;inception_v3/batch_normalization_16/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_16/Conv2D]:22
	                 CONV_2D	          260.800	   12.531	   12.623	  1.756%	 38.022%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	           CONCATENATION	          273.425	    0.319	    0.315	  0.044%	 38.066%	     0.000	        1	[inception_v3/mixed1/concat]:24
	         AVERAGE_POOL_2D	          273.741	    4.115	    4.037	  0.561%	 38.628%	     0.000	        1	[inception_v3/average_pooling2d_2/AvgPool]:25
	                 CONV_2D	          277.779	    2.806	    2.819	  0.392%	 39.020%	     0.000	        1	[inception_v3/activation_25/Relu;inception_v3/batch_normalization_25/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_25/Conv2D]:26
	                 CONV_2D	          280.599	    2.881	    2.939	  0.409%	 39.428%	     0.000	        1	[inception_v3/activation_19/Relu;inception_v3/batch_normalization_19/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_19/Conv2D]:27
	                 CONV_2D	          283.539	    2.162	    2.206	  0.307%	 39.735%	     0.000	        1	[inception_v3/activation_20/Relu;inception_v3/batch_normalization_20/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_20/Conv2D]:28
	                 CONV_2D	          285.746	   13.024	   12.930	  1.798%	 41.533%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          298.677	    3.051	    2.943	  0.409%	 41.943%	     0.000	        1	[inception_v3/activation_22/Relu;inception_v3/batch_normalization_22/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_22/Conv2D]:30
	                 CONV_2D	          301.622	    8.392	    8.448	  1.175%	 43.118%	     0.000	        1	[inception_v3/activation_23/Relu;inception_v3/batch_normalization_23/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_23/Conv2D]:31
	                 CONV_2D	          310.071	   12.588	   12.650	  1.759%	 44.877%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	           CONCATENATION	          322.722	    0.352	    0.290	  0.040%	 44.917%	     0.000	        1	[inception_v3/mixed2/concat]:33
	                 CONV_2D	          323.013	   30.957	   31.066	  4.321%	 49.238%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          354.081	    2.906	    2.886	  0.401%	 49.639%	     0.000	        1	[inception_v3/activation_27/Relu;inception_v3/batch_normalization_27/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_27/Conv2D]:35
	                 CONV_2D	          356.967	    8.523	    8.481	  1.180%	 50.819%	     0.000	        1	[inception_v3/activation_28/Relu;inception_v3/batch_normalization_28/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_28/Conv2D]:36
	                 CONV_2D	          365.450	    2.914	    2.961	  0.412%	 51.231%	     0.000	        1	[inception_v3/activation_29/Relu;inception_v3/batch_normalization_29/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_29/Conv2D]:37
	             MAX_POOL_2D	          368.412	    0.362	    0.339	  0.047%	 51.278%	     0.000	        1	[inception_v3/max_pooling2d_2/MaxPool]:38
	           CONCATENATION	          368.751	    0.147	    0.159	  0.022%	 51.300%	     0.000	        1	[inception_v3/mixed3/concat]:39
	         AVERAGE_POOL_2D	          368.911	    2.416	    2.424	  0.337%	 51.637%	     0.000	        1	[inception_v3/average_pooling2d_3/AvgPool]:40
	                 CONV_2D	          371.336	    4.767	    4.726	  0.657%	 52.294%	     0.000	        1	[inception_v3/activation_39/Relu;inception_v3/batch_normalization_39/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_39/Conv2D]:41
	                 CONV_2D	          376.062	    4.750	    4.770	  0.663%	 52.958%	     0.000	        1	[inception_v3/activation_30/Relu;inception_v3/batch_normalization_30/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_30/Conv2D]:42
	                 CONV_2D	          380.833	    3.113	    3.145	  0.437%	 53.395%	     0.000	        1	[inception_v3/activation_31/Relu;inception_v3/batch_normalization_31/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_31/Conv2D]:43
	                 CONV_2D	          383.979	    3.835	    3.762	  0.523%	 53.918%	     0.000	        1	[inception_v3/activation_32/Relu;inception_v3/batch_normalization_32/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_32/Conv2D]:44
	                 CONV_2D	          387.741	    5.493	    5.530	  0.769%	 54.687%	     0.000	        1	[inception_v3/activation_33/Relu;inception_v3/batch_normalization_33/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_33/Conv2D]:45
	                 CONV_2D	          393.272	    3.282	    3.341	  0.465%	 55.152%	     0.000	        1	[inception_v3/activation_34/Relu;inception_v3/batch_normalization_34/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_34/Conv2D]:46
	                 CONV_2D	          396.614	    3.832	    3.770	  0.524%	 55.676%	     0.000	        1	[inception_v3/activation_35/Relu;inception_v3/batch_normalization_35/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_35/Conv2D]:47
	                 CONV_2D	          400.385	    3.700	    3.733	  0.519%	 56.196%	     0.000	        1	[inception_v3/activation_36/Relu;inception_v3/batch_normalization_36/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_36/Conv2D]:48
	                 CONV_2D	          404.119	    3.665	    3.734	  0.519%	 56.715%	     0.000	        1	[inception_v3/activation_37/Relu;inception_v3/batch_normalization_37/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_37/Conv2D]:49
	                 CONV_2D	          407.854	    5.528	    5.490	  0.764%	 57.479%	     0.000	        1	[inception_v3/activation_38/Relu;inception_v3/batch_normalization_38/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_38/Conv2D]:50
	           CONCATENATION	          413.345	    0.193	    0.192	  0.027%	 57.505%	     0.000	        1	[inception_v3/mixed4/concat]:51
	         AVERAGE_POOL_2D	          413.539	    2.487	    2.528	  0.352%	 57.857%	     0.000	        1	[inception_v3/average_pooling2d_4/AvgPool]:52
	                 CONV_2D	          416.067	    4.767	    4.734	  0.658%	 58.515%	     0.000	        1	[inception_v3/activation_49/Relu;inception_v3/batch_normalization_49/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_49/Conv2D]:53
	                 CONV_2D	          420.802	    4.767	    4.772	  0.664%	 59.179%	     0.000	        1	[inception_v3/activation_40/Relu;inception_v3/batch_normalization_40/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_40/Conv2D]:54
	                 CONV_2D	          425.575	    3.912	    3.910	  0.544%	 59.723%	     0.000	        1	[inception_v3/activation_41/Relu;inception_v3/batch_normalization_41/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_41/Conv2D]:55
	                 CONV_2D	          429.486	    5.771	    5.833	  0.811%	 60.534%	     0.000	        1	[inception_v3/activation_42/Relu;inception_v3/batch_normalization_42/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_42/Conv2D]:56
	                 CONV_2D	          435.320	    6.918	    6.964	  0.968%	 61.503%	     0.000	        1	[inception_v3/activation_43/Relu;inception_v3/batch_normalization_43/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_43/Conv2D]:57
	                 CONV_2D	          442.285	    4.184	    4.123	  0.573%	 62.076%	     0.000	        1	[inception_v3/activation_44/Relu;inception_v3/batch_normalization_44/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_44/Conv2D]:58
	                 CONV_2D	          446.409	    5.817	    5.841	  0.812%	 62.888%	     0.000	        1	[inception_v3/activation_45/Relu;inception_v3/batch_normalization_45/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_45/Conv2D]:59
	                 CONV_2D	          452.250	    5.866	    5.837	  0.812%	 63.700%	     0.000	        1	[inception_v3/activation_46/Relu;inception_v3/batch_normalization_46/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_46/Conv2D]:60
	                 CONV_2D	          458.089	    5.812	    5.833	  0.811%	 64.511%	     0.000	        1	[inception_v3/activation_47/Relu;inception_v3/batch_normalization_47/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_47/Conv2D]:61
	                 CONV_2D	          463.922	    6.905	    6.924	  0.963%	 65.474%	     0.000	        1	[inception_v3/activation_48/Relu;inception_v3/batch_normalization_48/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_48/Conv2D]:62
	           CONCATENATION	          470.848	    0.182	    0.189	  0.026%	 65.501%	     0.000	        1	[inception_v3/mixed5/concat]:63
	         AVERAGE_POOL_2D	          471.038	    2.543	    2.535	  0.353%	 65.853%	     0.000	        1	[inception_v3/average_pooling2d_5/AvgPool]:64
	                 CONV_2D	          473.574	    4.683	    4.726	  0.657%	 66.511%	     0.000	        1	[inception_v3/activation_59/Relu;inception_v3/batch_normalization_59/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_59/Conv2D]:65
	                 CONV_2D	          478.301	    4.673	    4.715	  0.656%	 67.166%	     0.000	        1	[inception_v3/activation_50/Relu;inception_v3/batch_normalization_50/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_50/Conv2D]:66
	                 CONV_2D	          483.017	    3.953	    3.943	  0.548%	 67.715%	     0.000	        1	[inception_v3/activation_51/Relu;inception_v3/batch_normalization_51/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_51/Conv2D]:67
	                 CONV_2D	          486.961	    5.788	    5.818	  0.809%	 68.524%	     0.000	        1	[inception_v3/activation_52/Relu;inception_v3/batch_normalization_52/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_52/Conv2D]:68
	                 CONV_2D	          492.779	    7.094	    6.964	  0.969%	 69.492%	     0.000	        1	[inception_v3/activation_53/Relu;inception_v3/batch_normalization_53/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_53/Conv2D]:69
	                 CONV_2D	          499.744	    4.060	    4.114	  0.572%	 70.064%	     0.000	        1	[inception_v3/activation_54/Relu;inception_v3/batch_normalization_54/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_54/Conv2D]:70
	                 CONV_2D	          503.859	    5.844	    5.847	  0.813%	 70.878%	     0.000	        1	[inception_v3/activation_55/Relu;inception_v3/batch_normalization_55/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_55/Conv2D]:71
	                 CONV_2D	          509.707	    5.869	    5.833	  0.811%	 71.689%	     0.000	        1	[inception_v3/activation_56/Relu;inception_v3/batch_normalization_56/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_56/Conv2D]:72
	                 CONV_2D	          515.540	    5.847	    5.838	  0.812%	 72.501%	     0.000	        1	[inception_v3/activation_57/Relu;inception_v3/batch_normalization_57/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_57/Conv2D]:73
	                 CONV_2D	          521.379	    6.923	    6.930	  0.964%	 73.465%	     0.000	        1	[inception_v3/activation_58/Relu;inception_v3/batch_normalization_58/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_58/Conv2D]:74
	           CONCATENATION	          528.310	    0.167	    0.187	  0.026%	 73.491%	     0.000	        1	[inception_v3/mixed6/concat]:75
	         AVERAGE_POOL_2D	          528.498	    2.514	    2.527	  0.351%	 73.842%	     0.000	        1	[inception_v3/average_pooling2d_6/AvgPool]:76
	                 CONV_2D	          531.026	    4.691	    4.740	  0.659%	 74.501%	     0.000	        1	[inception_v3/activation_69/Relu;inception_v3/batch_normalization_69/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_69/Conv2D]:77
	                 CONV_2D	          535.766	    4.723	    4.721	  0.657%	 75.158%	     0.000	        1	[inception_v3/activation_60/Relu;inception_v3/batch_normalization_60/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_60/Conv2D]:78
	                 CONV_2D	          540.488	    4.720	    4.710	  0.655%	 75.813%	     0.000	        1	[inception_v3/activation_61/Relu;inception_v3/batch_normalization_61/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_61/Conv2D]:79
	                 CONV_2D	          545.199	    8.391	    8.328	  1.158%	 76.971%	     0.000	        1	[inception_v3/activation_62/Relu;inception_v3/batch_normalization_62/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_62/Conv2D]:80
	                 CONV_2D	          553.528	    8.328	    8.329	  1.158%	 78.130%	     0.000	        1	[inception_v3/activation_63/Relu;inception_v3/batch_normalization_63/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_63/Conv2D]:81
	                 CONV_2D	          561.858	    4.850	    4.862	  0.676%	 78.806%	     0.000	        1	[inception_v3/activation_64/Relu;inception_v3/batch_normalization_64/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_64/Conv2D]:82
	                 CONV_2D	          566.721	    8.329	    8.322	  1.157%	 79.963%	     0.000	        1	[inception_v3/activation_65/Relu;inception_v3/batch_normalization_65/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_65/Conv2D]:83
	                 CONV_2D	          575.045	    8.290	    8.322	  1.157%	 81.121%	     0.000	        1	[inception_v3/activation_66/Relu;inception_v3/batch_normalization_66/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_66/Conv2D]:84
	                 CONV_2D	          583.368	    8.360	    8.308	  1.156%	 82.276%	     0.000	        1	[inception_v3/activation_67/Relu;inception_v3/batch_normalization_67/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_67/Conv2D]:85
	                 CONV_2D	          591.677	    8.325	    8.296	  1.154%	 83.430%	     0.000	        1	[inception_v3/activation_68/Relu;inception_v3/batch_normalization_68/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_68/Conv2D]:86
	           CONCATENATION	          599.974	    0.171	    0.179	  0.025%	 83.455%	     0.000	        1	[inception_v3/mixed7/concat]:87
	                 CONV_2D	          600.154	    4.835	    4.864	  0.677%	 84.131%	     0.000	        1	[inception_v3/activation_70/Relu;inception_v3/batch_normalization_70/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_70/Conv2D]:88
	                 CONV_2D	          605.020	    3.698	    3.768	  0.524%	 84.656%	     0.000	        1	[inception_v3/activation_71/Relu;inception_v3/batch_normalization_71/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_71/Conv2D]:89
	                 CONV_2D	          608.789	    4.908	    4.795	  0.667%	 85.322%	     0.000	        1	[inception_v3/activation_72/Relu;inception_v3/batch_normalization_72/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_72/Conv2D]:90
	                 CONV_2D	          613.585	    8.397	    8.307	  1.155%	 86.478%	     0.000	        1	[inception_v3/activation_73/Relu;inception_v3/batch_normalization_73/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_73/Conv2D]:91
	                 CONV_2D	          621.893	    8.333	    8.338	  1.160%	 87.637%	     0.000	        1	[inception_v3/activation_74/Relu;inception_v3/batch_normalization_74/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_74/Conv2D]:92
	                 CONV_2D	          630.232	    2.308	    2.335	  0.325%	 87.962%	     0.000	        1	[inception_v3/activation_75/Relu;inception_v3/batch_normalization_75/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_75/Conv2D]:93
	             MAX_POOL_2D	          632.568	    0.236	    0.214	  0.030%	 87.992%	     0.000	        1	[inception_v3/max_pooling2d_3/MaxPool]:94
	           CONCATENATION	          632.783	    0.034	    0.037	  0.005%	 87.997%	     0.000	        1	[inception_v3/mixed8/concat]:95
	         AVERAGE_POOL_2D	          632.820	    0.806	    0.808	  0.112%	 88.109%	     0.000	        1	[inception_v3/average_pooling2d_7/AvgPool]:96
	                 CONV_2D	          633.629	    1.669	    1.685	  0.234%	 88.344%	     0.000	        1	[inception_v3/activation_84/Relu;inception_v3/batch_normalization_84/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_84/Conv2D]:97
	                 CONV_2D	          635.314	    2.761	    2.771	  0.385%	 88.729%	     0.000	        1	[inception_v3/activation_76/Relu;inception_v3/batch_normalization_76/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_76/Conv2D]:98
	                 CONV_2D	          638.085	    3.290	    3.318	  0.461%	 89.191%	     0.000	        1	[inception_v3/activation_77/Relu;inception_v3/batch_normalization_77/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_77/Conv2D]:99
	                 CONV_2D	          641.404	    2.989	    3.023	  0.420%	 89.611%	     0.000	        1	[inception_v3/activation_78/Relu;inception_v3/batch_normalization_78/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_78/Conv2D]:100
	                 CONV_2D	          644.428	    3.072	    3.023	  0.420%	 90.031%	     0.000	        1	[inception_v3/activation_79/Relu;inception_v3/batch_normalization_79/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_79/Conv2D]:101
	           CONCATENATION	          647.451	    0.028	    0.029	  0.004%	 90.035%	     0.000	        1	[inception_v3/mixed9_0/concat]:102
	                 CONV_2D	          647.481	    3.865	    3.885	  0.540%	 90.576%	     0.000	        1	[inception_v3/activation_80/Relu;inception_v3/batch_normalization_80/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_80/Conv2D]:103
	                 CONV_2D	          651.366	   10.511	   10.503	  1.461%	 92.036%	     0.000	        1	[inception_v3/activation_81/Relu;inception_v3/batch_normalization_81/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_81/Conv2D]:104
	                 CONV_2D	          661.871	    3.053	    3.064	  0.426%	 92.463%	     0.000	        1	[inception_v3/activation_82/Relu;inception_v3/batch_normalization_82/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_82/Conv2D]:105
	                 CONV_2D	          664.935	    2.976	    3.009	  0.418%	 92.881%	     0.000	        1	[inception_v3/activation_83/Relu;inception_v3/batch_normalization_83/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_83/Conv2D]:106
	           CONCATENATION	          667.945	    0.025	    0.028	  0.004%	 92.885%	     0.000	        1	[inception_v3/concatenate/concat]:107
	           CONCATENATION	          667.974	    0.057	    0.064	  0.009%	 92.894%	     0.000	        1	[inception_v3/mixed9/concat]:108
	         AVERAGE_POOL_2D	          668.038	    1.573	    1.511	  0.210%	 93.104%	     0.000	        1	[inception_v3/average_pooling2d_8/AvgPool]:109
	                 CONV_2D	          669.551	    2.615	    2.640	  0.367%	 93.471%	     0.000	        1	[inception_v3/activation_93/Relu;inception_v3/batch_normalization_93/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_93/Conv2D]:110
	                 CONV_2D	          672.191	    4.375	    4.391	  0.611%	 94.082%	     0.000	        1	[inception_v3/activation_85/Relu;inception_v3/batch_normalization_85/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_85/Conv2D]:111
	                 CONV_2D	          676.583	    5.295	    5.283	  0.735%	 94.817%	     0.000	        1	[inception_v3/activation_86/Relu;inception_v3/batch_normalization_86/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_86/Conv2D]:112
	                 CONV_2D	          681.868	    3.033	    3.045	  0.423%	 95.240%	     0.000	        1	[inception_v3/activation_87/Relu;inception_v3/batch_normalization_87/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_87/Conv2D]:113
	                 CONV_2D	          684.913	    2.964	    3.014	  0.419%	 95.659%	     0.000	        1	[inception_v3/activation_88/Relu;inception_v3/batch_normalization_88/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_88/Conv2D]:114
	           CONCATENATION	          687.928	    0.023	    0.024	  0.003%	 95.663%	     0.000	        1	[inception_v3/mixed9_1/concat]:115
	                 CONV_2D	          687.953	    6.204	    6.183	  0.860%	 96.523%	     0.000	        1	[inception_v3/activation_89/Relu;inception_v3/batch_normalization_89/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_89/Conv2D]:116
	                 CONV_2D	          694.137	   10.679	   10.689	  1.487%	 98.009%	     0.000	        1	[inception_v3/activation_90/Relu;inception_v3/batch_normalization_90/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_90/Conv2D]:117
	                 CONV_2D	          704.828	    3.024	    3.059	  0.425%	 98.435%	     0.000	        1	[inception_v3/activation_91/Relu;inception_v3/batch_normalization_91/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_91/Conv2D]:118
	                 CONV_2D	          707.888	    3.007	    3.024	  0.421%	 98.855%	     0.000	        1	[inception_v3/activation_92/Relu;inception_v3/batch_normalization_92/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_92/Conv2D]:119
	           CONCATENATION	          710.913	    0.029	    0.029	  0.004%	 98.859%	     0.000	        1	[inception_v3/concatenate_1/concat]:120
	           CONCATENATION	          710.942	    0.072	    0.064	  0.009%	 98.868%	     0.000	        1	[inception_v3/mixed10/concat]:121
	                    MEAN	          711.007	    7.265	    7.200	  1.001%	 99.870%	     0.000	        1	[inception_v3/avg_pool/Mean]:122
	         FULLY_CONNECTED	          718.207	    0.893	    0.921	  0.128%	 99.998%	     0.000	        1	[inception_v3/predictions/MatMul;inception_v3/predictions/BiasAdd]:123
	                 SOFTMAX	          719.129	    0.015	    0.016	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:124

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          100.914	   81.941	   82.102	 11.419%	 11.419%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	                 CONV_2D	           39.852	   55.115	   55.370	  7.701%	 19.119%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	                 CONV_2D	            6.946	   32.862	   32.904	  4.576%	 23.696%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	          323.013	   30.957	   31.066	  4.321%	 28.016%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          285.746	   13.024	   12.930	  1.798%	 29.815%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          190.157	   12.946	   12.850	  1.787%	 31.602%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          236.906	   12.804	   12.825	  1.784%	 33.385%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          310.071	   12.588	   12.650	  1.759%	 35.145%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	                 CONV_2D	          260.800	   12.531	   12.623	  1.756%	 36.900%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	                 CONV_2D	          213.423	   12.565	   12.595	  1.752%	 38.652%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14

Number of nodes executed: 125
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       94	   684.739	    95.241%	    95.241%	     0.000	       94
	         AVERAGE_POOL_2D	        9	    22.004	     3.061%	    98.301%	     0.000	        9
	                    MEAN	        1	     7.199	     1.001%	    99.303%	     0.000	        1
	           CONCATENATION	       15	     2.063	     0.287%	    99.590%	     0.000	       15
	             MAX_POOL_2D	        4	     2.014	     0.280%	    99.870%	     0.000	        4
	         FULLY_CONNECTED	        1	     0.921	     0.128%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.015	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=718902 curr=718729 min=717120 max=720990 avg=719017 std=615
Memory (bytes): count=0
125 nodes observed



[ perf record: Woken up 208 times to write data ]
Warning:
Processed 290550 events and lost 2 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 51.793 MB /tmp/data.record (290047 samples) ]

74.647

