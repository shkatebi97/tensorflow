STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (147, 64, ), Input shape (52900, 3, ) (or (12544, 147, )), Output shape (12544, 64, ), ID: 0, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (12544, 147, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (160, 64, ) DONE
	Preparing Filter With Shape: (147, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 128, ), ID: 1, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 2, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (96, 128, ), Input shape (3136, 96, ) (or (3136, 96, )), Output shape (3136, 128, ), ID: 3, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 96, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (48, 128, ) DONE
	Preparing Filter With Shape: (96, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 4, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (3136, 128, ) (or (3136, 128, )), Output shape (3136, 128, ), ID: 5, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 6, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (3136, 160, ) (or (3136, 160, )), Output shape (3136, 128, ), ID: 7, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 8, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (3136, 192, ) (or (3136, 192, )), Output shape (3136, 128, ), ID: 9, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 10, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (3136, 224, ) (or (3136, 224, )), Output shape (3136, 128, ), ID: 11, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (112, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 12, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (3136, 256, ) (or (3136, 256, )), Output shape (3136, 128, ), ID: 13, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (3136, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 128, ), ID: 14, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 15, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (784, 160, ) (or (784, 160, )), Output shape (784, 128, ), ID: 16, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (80, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 17, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (784, 192, ) (or (784, 192, )), Output shape (784, 128, ), ID: 18, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 19, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (784, 224, ) (or (784, 224, )), Output shape (784, 128, ), ID: 20, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (112, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 21, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (784, 256, ) (or (784, 256, )), Output shape (784, 128, ), ID: 22, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 23, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (784, 288, ) (or (784, 288, )), Output shape (784, 128, ), ID: 24, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 25, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (784, 320, ) (or (784, 320, )), Output shape (784, 128, ), ID: 26, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 320, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 27, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (784, 352, ) (or (784, 352, )), Output shape (784, 128, ), ID: 28, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (176, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 352, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 29, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (784, 384, ) (or (784, 384, )), Output shape (784, 128, ), ID: 30, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 31, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (784, 416, ) (or (784, 416, )), Output shape (784, 128, ), ID: 32, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (208, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 416, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 33, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (784, 448, ) (or (784, 448, )), Output shape (784, 128, ), ID: 34, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 448, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 35, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (784, 480, ) (or (784, 480, )), Output shape (784, 128, ), ID: 36, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (240, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 480, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 37, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 256, ), Input shape (784, 512, ) (or (784, 512, )), Output shape (784, 256, ), ID: 38, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (784, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 256, ) DONE
	Preparing Filter With Shape: (512, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 128, ), ID: 39, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 40, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (196, 288, ) (or (196, 288, )), Output shape (196, 128, ), ID: 41, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 42, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (196, 320, ) (or (196, 320, )), Output shape (196, 128, ), ID: 43, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 320, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 44, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (196, 352, ) (or (196, 352, )), Output shape (196, 128, ), ID: 45, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (176, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 352, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 46, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (196, 384, ) (or (196, 384, )), Output shape (196, 128, ), ID: 47, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 48, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (196, 416, ) (or (196, 416, )), Output shape (196, 128, ), ID: 49, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (208, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 416, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 50, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (196, 448, ) (or (196, 448, )), Output shape (196, 128, ), ID: 51, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 448, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 52, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (196, 480, ) (or (196, 480, )), Output shape (196, 128, ), ID: 53, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (240, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 480, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 54, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 128, ), Input shape (196, 512, ) (or (196, 512, )), Output shape (196, 128, ), ID: 55, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (512, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 56, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (544, 128, ), Input shape (196, 544, ) (or (196, 544, )), Output shape (196, 128, ), ID: 57, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 544, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (272, 128, ) DONE
	Preparing Filter With Shape: (544, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 544, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 58, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 128, ), Input shape (196, 576, ) (or (196, 576, )), Output shape (196, 128, ), ID: 59, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 576, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 128, ) DONE
	Preparing Filter With Shape: (576, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 60, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (608, 128, ), Input shape (196, 608, ) (or (196, 608, )), Output shape (196, 128, ), ID: 61, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 608, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (304, 128, ) DONE
	Preparing Filter With Shape: (608, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 608, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 62, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (640, 128, ), Input shape (196, 640, ) (or (196, 640, )), Output shape (196, 128, ), ID: 63, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 640, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (320, 128, ) DONE
	Preparing Filter With Shape: (640, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 64, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (672, 128, ), Input shape (196, 672, ) (or (196, 672, )), Output shape (196, 128, ), ID: 65, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 672, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (336, 128, ) DONE
	Preparing Filter With Shape: (672, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 672, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 66, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (704, 128, ), Input shape (196, 704, ) (or (196, 704, )), Output shape (196, 128, ), ID: 67, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 704, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (352, 128, ) DONE
	Preparing Filter With Shape: (704, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 704, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 68, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (736, 128, ), Input shape (196, 736, ) (or (196, 736, )), Output shape (196, 128, ), ID: 69, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 736, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (368, 128, ) DONE
	Preparing Filter With Shape: (736, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 736, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 70, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (196, 768, ) (or (196, 768, )), Output shape (196, 128, ), ID: 71, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 768, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 768, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 72, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (800, 128, ), Input shape (196, 800, ) (or (196, 800, )), Output shape (196, 128, ), ID: 73, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 800, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (400, 128, ) DONE
	Preparing Filter With Shape: (800, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 800, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 74, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (832, 128, ), Input shape (196, 832, ) (or (196, 832, )), Output shape (196, 128, ), ID: 75, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 832, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (416, 128, ) DONE
	Preparing Filter With Shape: (832, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 832, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 76, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 128, ), Input shape (196, 864, ) (or (196, 864, )), Output shape (196, 128, ), ID: 77, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 864, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 128, ) DONE
	Preparing Filter With Shape: (864, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 78, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (196, 896, ) (or (196, 896, )), Output shape (196, 128, ), ID: 79, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 896, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 896, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 80, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (196, 928, ) (or (196, 928, )), Output shape (196, 128, ), ID: 81, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 928, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (464, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 928, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 82, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (196, 960, ) (or (196, 960, )), Output shape (196, 128, ), ID: 83, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 960, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 960, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 84, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (196, 992, ) (or (196, 992, )), Output shape (196, 128, ), ID: 85, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 992, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (496, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 992, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 86, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 128, ), ID: 87, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 88, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (196, 1056, ) (or (196, 1056, )), Output shape (196, 128, ), ID: 89, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1056, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (528, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1056, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 90, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (196, 1088, ) (or (196, 1088, )), Output shape (196, 128, ), ID: 91, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1088, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (544, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1088, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 92, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (196, 1120, ) (or (196, 1120, )), Output shape (196, 128, ), ID: 93, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1120, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1120, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 94, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (196, 1152, ) (or (196, 1152, )), Output shape (196, 128, ), ID: 95, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 96, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (196, 1184, ) (or (196, 1184, )), Output shape (196, 128, ), ID: 97, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1184, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (592, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1184, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 98, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (196, 1216, ) (or (196, 1216, )), Output shape (196, 128, ), ID: 99, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1216, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1216, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 100, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (196, 1248, ) (or (196, 1248, )), Output shape (196, 128, ), ID: 101, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1248, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (624, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1248, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 102, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (196, 1280, ) (or (196, 1280, )), Output shape (196, 128, ), ID: 103, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1280, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 104, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (196, 1312, ) (or (196, 1312, )), Output shape (196, 128, ), ID: 105, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1312, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (656, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1312, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 106, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (196, 1344, ) (or (196, 1344, )), Output shape (196, 128, ), ID: 107, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1344, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1344, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 108, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (196, 1376, ) (or (196, 1376, )), Output shape (196, 128, ), ID: 109, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1376, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (688, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1376, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 110, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (196, 1408, ) (or (196, 1408, )), Output shape (196, 128, ), ID: 111, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1408, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (704, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1408, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 112, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (196, 1440, ) (or (196, 1440, )), Output shape (196, 128, ), ID: 113, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1440, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (720, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1440, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 114, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (196, 1472, ) (or (196, 1472, )), Output shape (196, 128, ), ID: 115, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1472, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1472, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 116, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (196, 1504, ) (or (196, 1504, )), Output shape (196, 128, ), ID: 117, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1504, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (752, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1504, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 118, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (196, 1536, ) (or (196, 1536, )), Output shape (196, 128, ), ID: 119, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1536, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1536, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 120, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (196, 1568, ) (or (196, 1568, )), Output shape (196, 128, ), ID: 121, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1568, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (784, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1568, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 122, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (196, 1600, ) (or (196, 1600, )), Output shape (196, 128, ), ID: 123, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1600, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (800, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1600, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 124, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (196, 1632, ) (or (196, 1632, )), Output shape (196, 128, ), ID: 125, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1632, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (816, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1632, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 126, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (196, 1664, ) (or (196, 1664, )), Output shape (196, 128, ), ID: 127, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1664, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (832, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1664, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 128, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (196, 1696, ) (or (196, 1696, )), Output shape (196, 128, ), ID: 129, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1696, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (848, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1696, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 130, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (196, 1728, ) (or (196, 1728, )), Output shape (196, 128, ), ID: 131, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1728, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 132, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (196, 1760, ) (or (196, 1760, )), Output shape (196, 128, ), ID: 133, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1760, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (880, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1760, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 134, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 896, ), Input shape (196, 1792, ) (or (196, 1792, )), Output shape (196, 896, ), ID: 135, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (196, 1792, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 896, ) DONE
	Preparing Filter With Shape: (1792, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 1792, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (49, 896, ) (or (49, 896, )), Output shape (49, 128, ), ID: 136, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 137, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (49, 928, ) (or (49, 928, )), Output shape (49, 128, ), ID: 138, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 928, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (464, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 139, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (49, 960, ) (or (49, 960, )), Output shape (49, 128, ), ID: 140, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 960, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 960, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 960, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 141, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (49, 992, ) (or (49, 992, )), Output shape (49, 128, ), ID: 142, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 992, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (496, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 992, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 992, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 143, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (49, 1024, ) (or (49, 1024, )), Output shape (49, 128, ), ID: 144, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 145, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (49, 1056, ) (or (49, 1056, )), Output shape (49, 128, ), ID: 146, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1056, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (528, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1056, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1056, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 147, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (49, 1088, ) (or (49, 1088, )), Output shape (49, 128, ), ID: 148, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1088, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (544, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1088, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1088, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 149, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (49, 1120, ) (or (49, 1120, )), Output shape (49, 128, ), ID: 150, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 151, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (49, 1152, ) (or (49, 1152, )), Output shape (49, 128, ), ID: 152, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 153, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (49, 1184, ) (or (49, 1184, )), Output shape (49, 128, ), ID: 154, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1184, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (592, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1184, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1184, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 155, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (49, 1216, ) (or (49, 1216, )), Output shape (49, 128, ), ID: 156, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1216, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1216, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 157, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (49, 1248, ) (or (49, 1248, )), Output shape (49, 128, ), ID: 158, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1248, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (624, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1248, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1248, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 159, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (49, 1280, ) (or (49, 1280, )), Output shape (49, 128, ), ID: 160, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1280, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1280, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1280, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 161, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (49, 1312, ) (or (49, 1312, )), Output shape (49, 128, ), ID: 162, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1312, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (656, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1312, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1312, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 163, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (49, 1344, ) (or (49, 1344, )), Output shape (49, 128, ), ID: 164, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 165, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (49, 1376, ) (or (49, 1376, )), Output shape (49, 128, ), ID: 166, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1376, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (688, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1376, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1376, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 167, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (49, 1408, ) (or (49, 1408, )), Output shape (49, 128, ), ID: 168, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1408, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (704, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1408, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1408, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 169, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (49, 1440, ) (or (49, 1440, )), Output shape (49, 128, ), ID: 170, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1440, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (720, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1440, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1440, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 171, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (49, 1472, ) (or (49, 1472, )), Output shape (49, 128, ), ID: 172, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1472, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1472, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1472, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 173, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (49, 1504, ) (or (49, 1504, )), Output shape (49, 128, ), ID: 174, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1504, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (752, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1504, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1504, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 175, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (49, 1536, ) (or (49, 1536, )), Output shape (49, 128, ), ID: 176, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1536, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1536, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1536, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 177, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (49, 1568, ) (or (49, 1568, )), Output shape (49, 128, ), ID: 178, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1568, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (784, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1568, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1568, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 179, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (49, 1600, ) (or (49, 1600, )), Output shape (49, 128, ), ID: 180, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1600, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (800, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1600, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1600, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 181, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (49, 1632, ) (or (49, 1632, )), Output shape (49, 128, ), ID: 182, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1632, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (816, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1632, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1632, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 183, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (49, 1664, ) (or (49, 1664, )), Output shape (49, 128, ), ID: 184, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1664, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (832, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1664, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1664, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 185, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (49, 1696, ) (or (49, 1696, )), Output shape (49, 128, ), ID: 186, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1696, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (848, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1696, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1696, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 187, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (49, 1728, ) (or (49, 1728, )), Output shape (49, 128, ), ID: 188, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 189, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (49, 1760, ) (or (49, 1760, )), Output shape (49, 128, ), ID: 190, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1760, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (880, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1760, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1760, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 191, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 128, ), Input shape (49, 1792, ) (or (49, 1792, )), Output shape (49, 128, ), ID: 192, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1792, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (1792, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1792, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1792, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 193, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1824, 128, ), Input shape (49, 1824, ) (or (49, 1824, )), Output shape (49, 128, ), ID: 194, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1824, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (912, 128, ) DONE
	Preparing Filter With Shape: (1824, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1824, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1824, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 195, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1856, 128, ), Input shape (49, 1856, ) (or (49, 1856, )), Output shape (49, 128, ), ID: 196, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1856, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (928, 128, ) DONE
	Preparing Filter With Shape: (1856, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1856, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1856, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 197, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1888, 128, ), Input shape (49, 1888, ) (or (49, 1888, )), Output shape (49, 128, ), ID: 198, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1888, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (944, 128, ) DONE
	Preparing Filter With Shape: (1888, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1888, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1888, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 199, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying FC Low-Precision for Kernel shape (1920, 1000, ), Input shape (1, 1920, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW4A8
	Allocating Filter Shape: (960, 1000, ) DONE
	Preparing Filter With Shape: (1920, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1920, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1920, ) DONE
The input model file size (MB): 20.5199
Initialized session in 362.088ms.
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=966672 curr=881687 min=881687 max=966672 avg=924180 std=42492

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=853677 curr=853377 min=850771 max=857577 avg=854076 std=1157

Inference timings in us: Init: 362088, First inference: 966672, Warmup (avg): 924180, Inference (avg): 854076
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=35.3086 overall=49.5234
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  353.141	  353.141	100.000%	100.000%	 21376.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  353.141	  353.141	100.000%	100.000%	 21376.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   353.141	   100.000%	   100.000%	 21376.000	        1

Timings (microseconds): count=1 curr=353141
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     PAD	            0.021	    1.154	    1.123	  0.132%	  0.132%	     0.000	        1	[densenet201/zero_padding2d/Pad]:0
	                 CONV_2D	            1.145	   24.301	   24.092	  2.822%	  2.954%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                     PAD	           25.238	    3.665	    3.670	  0.430%	  3.384%	     0.000	        1	[densenet201/zero_padding2d_1/Pad]:2
	             MAX_POOL_2D	           28.909	    0.786	    0.750	  0.088%	  3.472%	     0.000	        1	[densenet201/pool1/MaxPool]:3
	                     MUL	           29.660	    0.604	    0.614	  0.072%	  3.544%	     0.000	        1	[densenet201/conv2_block1_0_bn/FusedBatchNormV31]:4
	                     ADD	           30.275	    0.875	    0.855	  0.100%	  3.644%	     0.000	        1	[densenet201/conv2_block1_0_relu/Relu;densenet201/conv2_block1_0_bn/FusedBatchNormV3]:5
	                 CONV_2D	           31.131	    4.113	    4.120	  0.483%	  4.126%	     0.000	        1	[densenet201/conv2_block1_1_relu/Relu;densenet201/conv2_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block1_1_conv/Conv2D]:6
	                 CONV_2D	           35.252	   26.921	   27.314	  3.200%	  7.326%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	           CONCATENATION	           62.567	    0.162	    0.158	  0.018%	  7.345%	     0.000	        1	[densenet201/conv2_block1_concat/concat]:8
	                     MUL	           62.726	    0.875	    0.908	  0.106%	  7.451%	     0.000	        1	[densenet201/conv2_block2_0_bn/FusedBatchNormV31]:9
	                     ADD	           63.634	    1.237	    1.260	  0.148%	  7.599%	     0.000	        1	[densenet201/conv2_block2_0_relu/Relu;densenet201/conv2_block2_0_bn/FusedBatchNormV3]:10
	                 CONV_2D	           64.895	    5.678	    5.653	  0.662%	  8.261%	     0.000	        1	[densenet201/conv2_block2_1_relu/Relu;densenet201/conv2_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block2_1_conv/Conv2D]:11
	                 CONV_2D	           70.549	   27.222	   27.072	  3.171%	 11.432%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	           CONCATENATION	           97.622	    0.192	    0.211	  0.025%	 11.457%	     0.000	        1	[densenet201/conv2_block2_concat/concat]:13
	                     MUL	           97.834	    1.149	    1.169	  0.137%	 11.594%	     0.000	        1	[densenet201/conv2_block3_0_bn/FusedBatchNormV3]:14
	                     ADD	           99.004	    1.676	    1.683	  0.197%	 11.791%	     0.000	        1	[densenet201/conv2_block3_0_relu/Relu;densenet201/conv2_block3_0_bn/FusedBatchNormV3]:15
	                 CONV_2D	          100.688	    7.300	    7.275	  0.852%	 12.643%	     0.000	        1	[densenet201/conv2_block3_1_relu/Relu;densenet201/conv2_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block3_1_conv/Conv2D]:16
	                 CONV_2D	          107.965	   27.048	   26.992	  3.162%	 15.806%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	           CONCATENATION	          134.958	    0.271	    0.284	  0.033%	 15.839%	     0.000	        1	[densenet201/conv2_block3_concat/concat]:18
	                     MUL	          135.244	    1.422	    1.460	  0.171%	 16.010%	     0.000	        1	[densenet201/conv2_block4_0_bn/FusedBatchNormV3]:19
	                     ADD	          136.705	    2.136	    2.078	  0.243%	 16.253%	     0.000	        1	[densenet201/conv2_block4_0_relu/Relu;densenet201/conv2_block4_0_bn/FusedBatchNormV3]:20
	                 CONV_2D	          138.783	    8.857	    8.873	  1.039%	 17.293%	     0.000	        1	[densenet201/conv2_block4_1_relu/Relu;densenet201/conv2_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block4_1_conv/Conv2D]:21
	                 CONV_2D	          147.658	   26.808	   26.687	  3.126%	 20.419%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	           CONCATENATION	          174.345	    0.331	    0.342	  0.040%	 20.459%	     0.000	        1	[densenet201/conv2_block4_concat/concat]:23
	                     MUL	          174.689	    1.707	    1.747	  0.205%	 20.664%	     0.000	        1	[densenet201/conv2_block5_0_bn/FusedBatchNormV3]:24
	                     ADD	          176.437	    2.575	    2.484	  0.291%	 20.955%	     0.000	        1	[densenet201/conv2_block5_0_relu/Relu;densenet201/conv2_block5_0_bn/FusedBatchNormV3]:25
	                 CONV_2D	          178.922	   10.543	   10.536	  1.234%	 22.189%	     0.000	        1	[densenet201/conv2_block5_1_relu/Relu;densenet201/conv2_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block5_1_conv/Conv2D]:26
	                 CONV_2D	          189.459	   26.682	   26.760	  3.135%	 25.324%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	           CONCATENATION	          216.220	    0.390	    0.393	  0.046%	 25.370%	     0.000	        1	[densenet201/conv2_block5_concat/concat]:28
	                     MUL	          216.614	    2.053	    2.024	  0.237%	 25.607%	     0.000	        1	[densenet201/conv2_block6_0_bn/FusedBatchNormV3]:29
	                     ADD	          218.639	    2.864	    2.892	  0.339%	 25.946%	     0.000	        1	[densenet201/conv2_block6_0_relu/Relu;densenet201/conv2_block6_0_bn/FusedBatchNormV3]:30
	                 CONV_2D	          221.532	   12.281	   12.279	  1.438%	 27.384%	     0.000	        1	[densenet201/conv2_block6_1_relu/Relu;densenet201/conv2_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block6_1_conv/Conv2D]:31
	                 CONV_2D	          233.812	   27.053	   26.858	  3.146%	 30.531%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	           CONCATENATION	          260.672	    0.482	    0.433	  0.051%	 30.581%	     0.000	        1	[densenet201/conv2_block6_concat/concat]:33
	                     MUL	          261.106	    2.260	    2.317	  0.271%	 30.853%	     0.000	        1	[densenet201/pool2_bn/FusedBatchNormV3]:34
	                     ADD	          263.423	    3.306	    3.310	  0.388%	 31.240%	     0.000	        1	[densenet201/pool2_relu/Relu;densenet201/pool2_bn/FusedBatchNormV3]:35
	                 CONV_2D	          266.735	   14.002	   13.953	  1.635%	 32.875%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	         AVERAGE_POOL_2D	          280.689	    0.983	    0.961	  0.113%	 32.988%	     0.000	        1	[densenet201/pool2_pool/AvgPool]:37
	                     MUL	          281.651	    0.293	    0.299	  0.035%	 33.023%	     0.000	        1	[densenet201/conv3_block1_0_bn/FusedBatchNormV3]:38
	                     ADD	          281.950	    0.419	    0.425	  0.050%	 33.072%	     0.000	        1	[densenet201/conv3_block1_0_relu/Relu;densenet201/conv3_block1_0_bn/FusedBatchNormV3]:39
	                 CONV_2D	          282.376	    1.783	    1.830	  0.214%	 33.287%	     0.000	        1	[densenet201/conv3_block1_1_relu/Relu;densenet201/conv3_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block1_1_conv/Conv2D]:40
	                 CONV_2D	          284.207	    6.746	    6.657	  0.780%	 34.067%	     0.000	        1	[densenet201/conv3_block1_2_conv/Conv2D1]:41
	           CONCATENATION	          290.865	    0.073	    0.075	  0.009%	 34.076%	     0.000	        1	[densenet201/conv3_block1_concat/concat]:42
	                     MUL	          290.941	    0.375	    0.380	  0.045%	 34.120%	     0.000	        1	[densenet201/conv3_block2_0_bn/FusedBatchNormV31]:43
	                     ADD	          291.322	    0.513	    0.526	  0.062%	 34.182%	     0.000	        1	[densenet201/conv3_block2_0_relu/Relu;densenet201/conv3_block2_0_bn/FusedBatchNormV3]:44
	                 CONV_2D	          291.849	    2.185	    2.190	  0.257%	 34.438%	     0.000	        1	[densenet201/conv3_block2_1_relu/Relu;densenet201/conv3_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block2_1_conv/Conv2D]:45
	                 CONV_2D	          294.040	    6.562	    6.475	  0.759%	 35.197%	     0.000	        1	[densenet201/conv3_block2_2_conv/Conv2D1]:46
	           CONCATENATION	          300.516	    0.088	    0.094	  0.011%	 35.208%	     0.000	        1	[densenet201/conv3_block2_concat/concat]:47
	                     MUL	          300.611	    0.482	    0.448	  0.052%	 35.260%	     0.000	        1	[densenet201/conv3_block3_0_bn/FusedBatchNormV31]:48
	                     ADD	          301.060	    0.608	    0.624	  0.073%	 35.333%	     0.000	        1	[densenet201/conv3_block3_0_relu/Relu;densenet201/conv3_block3_0_bn/FusedBatchNormV3]:49
	                 CONV_2D	          301.685	    2.588	    2.646	  0.310%	 35.643%	     0.000	        1	[densenet201/conv3_block3_1_relu/Relu;densenet201/conv3_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block3_1_conv/Conv2D]:50
	                 CONV_2D	          304.332	    6.611	    6.534	  0.765%	 36.409%	     0.000	        1	[densenet201/conv3_block3_2_conv/Conv2D1]:51
	           CONCATENATION	          310.867	    0.103	    0.110	  0.013%	 36.422%	     0.000	        1	[densenet201/conv3_block3_concat/concat]:52
	                     MUL	          310.977	    0.509	    0.522	  0.061%	 36.483%	     0.000	        1	[densenet201/conv3_block4_0_bn/FusedBatchNormV31]:53
	                     ADD	          311.500	    0.714	    0.733	  0.086%	 36.569%	     0.000	        1	[densenet201/conv3_block4_0_relu/Relu;densenet201/conv3_block4_0_bn/FusedBatchNormV3]:54
	                 CONV_2D	          312.234	    2.975	    2.978	  0.349%	 36.918%	     0.000	        1	[densenet201/conv3_block4_1_relu/Relu;densenet201/conv3_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block4_1_conv/Conv2D]:55
	                 CONV_2D	          315.212	    6.573	    6.543	  0.767%	 37.684%	     0.000	        1	[densenet201/conv3_block4_2_conv/Conv2D1]:56
	           CONCATENATION	          321.757	    0.127	    0.124	  0.015%	 37.699%	     0.000	        1	[densenet201/conv3_block4_concat/concat]:57
	                     MUL	          321.882	    0.570	    0.592	  0.069%	 37.768%	     0.000	        1	[densenet201/conv3_block5_0_bn/FusedBatchNormV3]:58
	                     ADD	          322.474	    0.810	    0.831	  0.097%	 37.865%	     0.000	        1	[densenet201/conv3_block5_0_relu/Relu;densenet201/conv3_block5_0_bn/FusedBatchNormV3]:59
	                 CONV_2D	          323.307	    3.390	    3.398	  0.398%	 38.263%	     0.000	        1	[densenet201/conv3_block5_1_relu/Relu;densenet201/conv3_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block5_1_conv/Conv2D]:60
	                 CONV_2D	          326.706	    6.826	    6.792	  0.796%	 39.059%	     0.000	        1	[densenet201/conv3_block5_2_conv/Conv2D1]:61
	           CONCATENATION	          333.499	    0.131	    0.135	  0.016%	 39.075%	     0.000	        1	[densenet201/conv3_block5_concat/concat]:62
	                     MUL	          333.634	    0.684	    0.654	  0.077%	 39.151%	     0.000	        1	[densenet201/conv3_block6_0_bn/FusedBatchNormV3]:63
	                     ADD	          334.289	    0.928	    0.954	  0.112%	 39.263%	     0.000	        1	[densenet201/conv3_block6_0_relu/Relu;densenet201/conv3_block6_0_bn/FusedBatchNormV3]:64
	                 CONV_2D	          335.243	    3.829	    3.851	  0.451%	 39.714%	     0.000	        1	[densenet201/conv3_block6_1_relu/Relu;densenet201/conv3_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block6_1_conv/Conv2D]:65
	                 CONV_2D	          339.096	    6.928	    6.898	  0.808%	 40.522%	     0.000	        1	[densenet201/conv3_block6_2_conv/Conv2D1]:66
	           CONCATENATION	          345.995	    0.132	    0.149	  0.017%	 40.540%	     0.000	        1	[densenet201/conv3_block6_concat/concat]:67
	                     MUL	          346.145	    0.718	    0.734	  0.086%	 40.626%	     0.000	        1	[densenet201/conv3_block7_0_bn/FusedBatchNormV3]:68
	                     ADD	          346.879	    1.036	    1.055	  0.124%	 40.749%	     0.000	        1	[densenet201/conv3_block7_0_relu/Relu;densenet201/conv3_block7_0_bn/FusedBatchNormV3]:69
	                 CONV_2D	          347.934	    4.180	    4.192	  0.491%	 41.241%	     0.000	        1	[densenet201/conv3_block7_1_relu/Relu;densenet201/conv3_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block7_1_conv/Conv2D]:70
	                 CONV_2D	          352.128	    6.825	    6.862	  0.804%	 42.044%	     0.000	        1	[densenet201/conv3_block7_2_conv/Conv2D1]:71
	           CONCATENATION	          358.991	    0.161	    0.172	  0.020%	 42.064%	     0.000	        1	[densenet201/conv3_block7_concat/concat]:72
	                     MUL	          359.163	    0.776	    0.803	  0.094%	 42.159%	     0.000	        1	[densenet201/conv3_block8_0_bn/FusedBatchNormV3]:73
	                     ADD	          359.967	    1.174	    1.157	  0.136%	 42.294%	     0.000	        1	[densenet201/conv3_block8_0_relu/Relu;densenet201/conv3_block8_0_bn/FusedBatchNormV3]:74
	                 CONV_2D	          361.125	    4.591	    4.619	  0.541%	 42.835%	     0.000	        1	[densenet201/conv3_block8_1_relu/Relu;densenet201/conv3_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block8_1_conv/Conv2D]:75
	                 CONV_2D	          365.745	    6.674	    6.856	  0.803%	 43.638%	     0.000	        1	[densenet201/conv3_block8_2_conv/Conv2D1]:76
	           CONCATENATION	          372.602	    0.176	    0.175	  0.021%	 43.659%	     0.000	        1	[densenet201/conv3_block8_concat/concat]:77
	                     MUL	          372.779	    0.935	    0.872	  0.102%	 43.761%	     0.000	        1	[densenet201/conv3_block9_0_bn/FusedBatchNormV3]:78
	                     ADD	          373.651	    1.235	    1.265	  0.148%	 43.909%	     0.000	        1	[densenet201/conv3_block9_0_relu/Relu;densenet201/conv3_block9_0_bn/FusedBatchNormV3]:79
	                 CONV_2D	          374.917	    5.061	    5.010	  0.587%	 44.496%	     0.000	        1	[densenet201/conv3_block9_1_relu/Relu;densenet201/conv3_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block9_1_conv/Conv2D]:80
	                 CONV_2D	          379.928	    6.629	    6.680	  0.783%	 45.279%	     0.000	        1	[densenet201/conv3_block9_2_conv/Conv2D1]:81
	           CONCATENATION	          386.609	    0.195	    0.196	  0.023%	 45.301%	     0.000	        1	[densenet201/conv3_block9_concat/concat]:82
	                     MUL	          386.805	    0.912	    0.943	  0.110%	 45.412%	     0.000	        1	[densenet201/conv3_block10_0_bn/FusedBatchNormV3]:83
	                     ADD	          387.749	    1.500	    1.372	  0.161%	 45.573%	     0.000	        1	[densenet201/conv3_block10_0_relu/Relu;densenet201/conv3_block10_0_bn/FusedBatchNormV3]:84
	                 CONV_2D	          389.122	    5.366	    5.411	  0.634%	 46.207%	     0.000	        1	[densenet201/conv3_block10_1_relu/Relu;densenet201/conv3_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block10_1_conv/Conv2D]:85
	                 CONV_2D	          394.534	    6.533	    6.619	  0.775%	 46.982%	     0.000	        1	[densenet201/conv3_block10_2_conv/Conv2D1]:86
	           CONCATENATION	          401.155	    0.189	    0.209	  0.024%	 47.006%	     0.000	        1	[densenet201/conv3_block10_concat/concat]:87
	                     MUL	          401.364	    0.993	    1.005	  0.118%	 47.124%	     0.000	        1	[densenet201/conv3_block11_0_bn/FusedBatchNormV3]:88
	                     ADD	          402.370	    1.474	    1.483	  0.174%	 47.298%	     0.000	        1	[densenet201/conv3_block11_0_relu/Relu;densenet201/conv3_block11_0_bn/FusedBatchNormV3]:89
	                 CONV_2D	          403.853	    5.786	    5.831	  0.683%	 47.981%	     0.000	        1	[densenet201/conv3_block11_1_relu/Relu;densenet201/conv3_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block11_1_conv/Conv2D]:90
	                 CONV_2D	          409.686	    6.711	    6.772	  0.793%	 48.774%	     0.000	        1	[densenet201/conv3_block11_2_conv/Conv2D1]:91
	           CONCATENATION	          416.460	    0.216	    0.215	  0.025%	 48.800%	     0.000	        1	[densenet201/conv3_block11_concat/concat]:92
	                     MUL	          416.675	    1.137	    1.078	  0.126%	 48.926%	     0.000	        1	[densenet201/conv3_block12_0_bn/FusedBatchNormV3]:93
	                     ADD	          417.755	    1.537	    1.582	  0.185%	 49.111%	     0.000	        1	[densenet201/conv3_block12_0_relu/Relu;densenet201/conv3_block12_0_bn/FusedBatchNormV3]:94
	                 CONV_2D	          419.337	    6.203	    6.259	  0.733%	 49.844%	     0.000	        1	[densenet201/conv3_block12_1_relu/Relu;densenet201/conv3_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block12_1_conv/Conv2D]:95
	                 CONV_2D	          425.598	    6.697	    6.745	  0.790%	 50.635%	     0.000	        1	[densenet201/conv3_block12_2_conv/Conv2D1]:96
	           CONCATENATION	          432.344	    0.202	    0.210	  0.025%	 50.659%	     0.000	        1	[densenet201/conv3_block12_concat/concat]:97
	                     MUL	          432.554	    1.185	    1.157	  0.136%	 50.795%	     0.000	        1	[densenet201/pool3_bn/FusedBatchNormV3]:98
	                     ADD	          433.712	    1.646	    1.678	  0.197%	 50.991%	     0.000	        1	[densenet201/pool3_relu/Relu;densenet201/pool3_bn/FusedBatchNormV3]:99
	                 CONV_2D	          435.391	   12.063	   12.082	  1.415%	 52.407%	     0.000	        1	[densenet201/pool3_conv/Conv2D1]:100
	         AVERAGE_POOL_2D	          447.475	    0.464	    0.484	  0.057%	 52.463%	     0.000	        1	[densenet201/pool3_pool/AvgPool]:101
	                     MUL	          447.960	    0.145	    0.152	  0.018%	 52.481%	     0.000	        1	[densenet201/conv4_block1_0_bn/FusedBatchNormV31]:102
	                     ADD	          448.113	    0.209	    0.213	  0.025%	 52.506%	     0.000	        1	[densenet201/conv4_block1_0_relu/Relu;densenet201/conv4_block1_0_bn/FusedBatchNormV3]:103
	                 CONV_2D	          448.326	    0.869	    0.887	  0.104%	 52.610%	     0.000	        1	[densenet201/conv4_block1_1_relu/Relu;densenet201/conv4_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block1_1_conv/Conv2D]:104
	                 CONV_2D	          449.214	    1.629	    1.533	  0.180%	 52.790%	     0.000	        1	[densenet201/conv4_block1_2_conv/Conv2D1]:105
	           CONCATENATION	          450.747	    0.043	    0.044	  0.005%	 52.795%	     0.000	        1	[densenet201/conv4_block1_concat/concat]:106
	                     MUL	          450.793	    0.172	    0.169	  0.020%	 52.815%	     0.000	        1	[densenet201/conv4_block2_0_bn/FusedBatchNormV31]:107
	                     ADD	          450.962	    0.237	    0.244	  0.029%	 52.843%	     0.000	        1	[densenet201/conv4_block2_0_relu/Relu;densenet201/conv4_block2_0_bn/FusedBatchNormV3]:108
	                 CONV_2D	          451.206	    0.941	    0.975	  0.114%	 52.957%	     0.000	        1	[densenet201/conv4_block2_1_relu/Relu;densenet201/conv4_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block2_1_conv/Conv2D]:109
	                 CONV_2D	          452.181	    1.444	    1.429	  0.167%	 53.125%	     0.000	        1	[densenet201/conv4_block2_2_conv/Conv2D1]:110
	           CONCATENATION	          453.611	    0.053	    0.043	  0.005%	 53.130%	     0.000	        1	[densenet201/conv4_block2_concat/concat]:111
	                     MUL	          453.655	    0.189	    0.189	  0.022%	 53.152%	     0.000	        1	[densenet201/conv4_block3_0_bn/FusedBatchNormV31]:112
	                     ADD	          453.845	    0.260	    0.266	  0.031%	 53.183%	     0.000	        1	[densenet201/conv4_block3_0_relu/Relu;densenet201/conv4_block3_0_bn/FusedBatchNormV3]:113
	                 CONV_2D	          454.111	    1.042	    1.063	  0.125%	 53.308%	     0.000	        1	[densenet201/conv4_block3_1_relu/Relu;densenet201/conv4_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block3_1_conv/Conv2D]:114
	                 CONV_2D	          455.175	    1.428	    1.442	  0.169%	 53.476%	     0.000	        1	[densenet201/conv4_block3_2_conv/Conv2D1]:115
	           CONCATENATION	          456.618	    0.048	    0.049	  0.006%	 53.482%	     0.000	        1	[densenet201/conv4_block3_concat/concat]:116
	                     MUL	          456.668	    0.240	    0.208	  0.024%	 53.506%	     0.000	        1	[densenet201/conv4_block4_0_bn/FusedBatchNormV31]:117
	                     ADD	          456.876	    0.284	    0.290	  0.034%	 53.541%	     0.000	        1	[densenet201/conv4_block4_0_relu/Relu;densenet201/conv4_block4_0_bn/FusedBatchNormV3]:118
	                 CONV_2D	          457.167	    1.172	    1.150	  0.135%	 53.675%	     0.000	        1	[densenet201/conv4_block4_1_relu/Relu;densenet201/conv4_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block4_1_conv/Conv2D]:119
	                 CONV_2D	          458.317	    1.401	    1.427	  0.167%	 53.842%	     0.000	        1	[densenet201/conv4_block4_2_conv/Conv2D1]:120
	           CONCATENATION	          459.745	    0.044	    0.052	  0.006%	 53.848%	     0.000	        1	[densenet201/conv4_block4_concat/concat]:121
	                     MUL	          459.798	    0.222	    0.230	  0.027%	 53.875%	     0.000	        1	[densenet201/conv4_block5_0_bn/FusedBatchNormV31]:122
	                     ADD	          460.028	    0.309	    0.317	  0.037%	 53.912%	     0.000	        1	[densenet201/conv4_block5_0_relu/Relu;densenet201/conv4_block5_0_bn/FusedBatchNormV3]:123
	                 CONV_2D	          460.346	    1.344	    1.242	  0.145%	 54.058%	     0.000	        1	[densenet201/conv4_block5_1_relu/Relu;densenet201/conv4_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block5_1_conv/Conv2D]:124
	                 CONV_2D	          461.588	    1.424	    1.433	  0.168%	 54.226%	     0.000	        1	[densenet201/conv4_block5_2_conv/Conv2D1]:125
	           CONCATENATION	          463.021	    0.060	    0.065	  0.008%	 54.233%	     0.000	        1	[densenet201/conv4_block5_concat/concat]:126
	                     MUL	          463.088	    0.240	    0.243	  0.028%	 54.262%	     0.000	        1	[densenet201/conv4_block6_0_bn/FusedBatchNormV31]:127
	                     ADD	          463.331	    0.335	    0.342	  0.040%	 54.302%	     0.000	        1	[densenet201/conv4_block6_0_relu/Relu;densenet201/conv4_block6_0_bn/FusedBatchNormV3]:128
	                 CONV_2D	          463.673	    1.322	    1.338	  0.157%	 54.459%	     0.000	        1	[densenet201/conv4_block6_1_relu/Relu;densenet201/conv4_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block6_1_conv/Conv2D]:129
	                 CONV_2D	          465.012	    1.503	    1.460	  0.171%	 54.630%	     0.000	        1	[densenet201/conv4_block6_2_conv/Conv2D1]:130
	           CONCATENATION	          466.473	    0.068	    0.070	  0.008%	 54.638%	     0.000	        1	[densenet201/conv4_block6_concat/concat]:131
	                     MUL	          466.543	    0.256	    0.264	  0.031%	 54.669%	     0.000	        1	[densenet201/conv4_block7_0_bn/FusedBatchNormV31]:132
	                     ADD	          466.807	    0.367	    0.367	  0.043%	 54.712%	     0.000	        1	[densenet201/conv4_block7_0_relu/Relu;densenet201/conv4_block7_0_bn/FusedBatchNormV3]:133
	                 CONV_2D	          467.176	    1.402	    1.439	  0.169%	 54.880%	     0.000	        1	[densenet201/conv4_block7_1_relu/Relu;densenet201/conv4_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block7_1_conv/Conv2D]:134
	                 CONV_2D	          468.615	    1.459	    1.462	  0.171%	 55.051%	     0.000	        1	[densenet201/conv4_block7_2_conv/Conv2D1]:135
	           CONCATENATION	          470.078	    0.067	    0.074	  0.009%	 55.060%	     0.000	        1	[densenet201/conv4_block7_concat/concat]:136
	                     MUL	          470.153	    0.273	    0.280	  0.033%	 55.093%	     0.000	        1	[densenet201/conv4_block8_0_bn/FusedBatchNormV31]:137
	                     ADD	          470.434	    0.392	    0.397	  0.046%	 55.139%	     0.000	        1	[densenet201/conv4_block8_0_relu/Relu;densenet201/conv4_block8_0_bn/FusedBatchNormV3]:138
	                 CONV_2D	          470.831	    1.504	    1.537	  0.180%	 55.320%	     0.000	        1	[densenet201/conv4_block8_1_relu/Relu;densenet201/conv4_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block8_1_conv/Conv2D]:139
	                 CONV_2D	          472.369	    1.499	    1.420	  0.166%	 55.486%	     0.000	        1	[densenet201/conv4_block8_2_conv/Conv2D1]:140
	           CONCATENATION	          473.791	    0.082	    0.072	  0.008%	 55.494%	     0.000	        1	[densenet201/conv4_block8_concat/concat]:141
	                     MUL	          473.864	    0.289	    0.299	  0.035%	 55.529%	     0.000	        1	[densenet201/conv4_block9_0_bn/FusedBatchNormV31]:142
	                     ADD	          474.164	    0.417	    0.426	  0.050%	 55.579%	     0.000	        1	[densenet201/conv4_block9_0_relu/Relu;densenet201/conv4_block9_0_bn/FusedBatchNormV3]:143
	                 CONV_2D	          474.590	    1.642	    1.636	  0.192%	 55.771%	     0.000	        1	[densenet201/conv4_block9_1_relu/Relu;densenet201/conv4_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block9_1_conv/Conv2D]:144
	                 CONV_2D	          476.226	    1.410	    1.412	  0.165%	 55.936%	     0.000	        1	[densenet201/conv4_block9_2_conv/Conv2D1]:145
	           CONCATENATION	          477.639	    0.073	    0.078	  0.009%	 55.945%	     0.000	        1	[densenet201/conv4_block9_concat/concat]:146
	                     MUL	          477.718	    0.313	    0.312	  0.037%	 55.982%	     0.000	        1	[densenet201/conv4_block10_0_bn/FusedBatchNormV31]:147
	                     ADD	          478.031	    0.425	    0.444	  0.052%	 56.034%	     0.000	        1	[densenet201/conv4_block10_0_relu/Relu;densenet201/conv4_block10_0_bn/FusedBatchNormV3]:148
	                 CONV_2D	          478.475	    1.696	    1.727	  0.202%	 56.236%	     0.000	        1	[densenet201/conv4_block10_1_relu/Relu;densenet201/conv4_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block10_1_conv/Conv2D]:149
	                 CONV_2D	          480.203	    1.517	    1.458	  0.171%	 56.407%	     0.000	        1	[densenet201/conv4_block10_2_conv/Conv2D1]:150
	           CONCATENATION	          481.662	    0.103	    0.093	  0.011%	 56.418%	     0.000	        1	[densenet201/conv4_block10_concat/concat]:151
	                     MUL	          481.756	    0.319	    0.329	  0.039%	 56.457%	     0.000	        1	[densenet201/conv4_block11_0_bn/FusedBatchNormV31]:152
	                     ADD	          482.086	    0.456	    0.467	  0.055%	 56.511%	     0.000	        1	[densenet201/conv4_block11_0_relu/Relu;densenet201/conv4_block11_0_bn/FusedBatchNormV3]:153
	                 CONV_2D	          482.554	    1.777	    1.817	  0.213%	 56.724%	     0.000	        1	[densenet201/conv4_block11_1_relu/Relu;densenet201/conv4_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block11_1_conv/Conv2D]:154
	                 CONV_2D	          484.371	    1.545	    1.469	  0.172%	 56.896%	     0.000	        1	[densenet201/conv4_block11_2_conv/Conv2D1]:155
	           CONCATENATION	          485.842	    0.124	    0.094	  0.011%	 56.907%	     0.000	        1	[densenet201/conv4_block11_concat/concat]:156
	                     MUL	          485.936	    0.355	    0.350	  0.041%	 56.948%	     0.000	        1	[densenet201/conv4_block12_0_bn/FusedBatchNormV31]:157
	                     ADD	          486.287	    0.481	    0.495	  0.058%	 57.006%	     0.000	        1	[densenet201/conv4_block12_0_relu/Relu;densenet201/conv4_block12_0_bn/FusedBatchNormV3]:158
	                 CONV_2D	          486.783	    1.877	    1.923	  0.225%	 57.232%	     0.000	        1	[densenet201/conv4_block12_1_relu/Relu;densenet201/conv4_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block12_1_conv/Conv2D]:159
	                 CONV_2D	          488.707	    1.486	    1.478	  0.173%	 57.405%	     0.000	        1	[densenet201/conv4_block12_2_conv/Conv2D1]:160
	           CONCATENATION	          490.186	    0.104	    0.103	  0.012%	 57.417%	     0.000	        1	[densenet201/conv4_block12_concat/concat]:161
	                     MUL	          490.290	    0.355	    0.373	  0.044%	 57.461%	     0.000	        1	[densenet201/conv4_block13_0_bn/FusedBatchNormV31]:162
	                     ADD	          490.664	    0.516	    0.516	  0.060%	 57.521%	     0.000	        1	[densenet201/conv4_block13_0_relu/Relu;densenet201/conv4_block13_0_bn/FusedBatchNormV3]:163
	                 CONV_2D	          491.180	    1.997	    2.009	  0.235%	 57.756%	     0.000	        1	[densenet201/conv4_block13_1_relu/Relu;densenet201/conv4_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block13_1_conv/Conv2D]:164
	                 CONV_2D	          493.190	    1.454	    1.480	  0.173%	 57.930%	     0.000	        1	[densenet201/conv4_block13_2_conv/Conv2D1]:165
	           CONCATENATION	          494.671	    0.146	    0.101	  0.012%	 57.941%	     0.000	        1	[densenet201/conv4_block13_concat/concat]:166
	                     MUL	          494.773	    0.374	    0.386	  0.045%	 57.987%	     0.000	        1	[densenet201/conv4_block14_0_bn/FusedBatchNormV31]:167
	                     ADD	          495.159	    0.531	    0.542	  0.063%	 58.050%	     0.000	        1	[densenet201/conv4_block14_0_relu/Relu;densenet201/conv4_block14_0_bn/FusedBatchNormV3]:168
	                 CONV_2D	          495.701	    2.215	    2.102	  0.246%	 58.296%	     0.000	        1	[densenet201/conv4_block14_1_relu/Relu;densenet201/conv4_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block14_1_conv/Conv2D]:169
	                 CONV_2D	          497.804	    1.419	    1.428	  0.167%	 58.464%	     0.000	        1	[densenet201/conv4_block14_2_conv/Conv2D1]:170
	           CONCATENATION	          499.233	    0.117	    0.127	  0.015%	 58.478%	     0.000	        1	[densenet201/conv4_block14_concat/concat]:171
	                     MUL	          499.361	    0.402	    0.404	  0.047%	 58.526%	     0.000	        1	[densenet201/conv4_block15_0_bn/FusedBatchNormV31]:172
	                     ADD	          499.765	    0.553	    0.571	  0.067%	 58.593%	     0.000	        1	[densenet201/conv4_block15_0_relu/Relu;densenet201/conv4_block15_0_bn/FusedBatchNormV3]:173
	                 CONV_2D	          500.336	    2.287	    2.201	  0.258%	 58.850%	     0.000	        1	[densenet201/conv4_block15_1_relu/Relu;densenet201/conv4_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block15_1_conv/Conv2D]:174
	                 CONV_2D	          502.538	    1.474	    1.461	  0.171%	 59.022%	     0.000	        1	[densenet201/conv4_block15_2_conv/Conv2D1]:175
	           CONCATENATION	          504.001	    0.133	    0.118	  0.014%	 59.035%	     0.000	        1	[densenet201/conv4_block15_concat/concat]:176
	                     MUL	          504.120	    0.403	    0.420	  0.049%	 59.085%	     0.000	        1	[densenet201/conv4_block16_0_bn/FusedBatchNormV31]:177
	                     ADD	          504.540	    0.632	    0.592	  0.069%	 59.154%	     0.000	        1	[densenet201/conv4_block16_0_relu/Relu;densenet201/conv4_block16_0_bn/FusedBatchNormV3]:178
	                 CONV_2D	          505.133	    2.300	    2.298	  0.269%	 59.423%	     0.000	        1	[densenet201/conv4_block16_1_relu/Relu;densenet201/conv4_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block16_1_conv/Conv2D]:179
	                 CONV_2D	          507.432	    1.422	    1.473	  0.173%	 59.596%	     0.000	        1	[densenet201/conv4_block16_2_conv/Conv2D1]:180
	           CONCATENATION	          508.907	    0.267	    0.137	  0.016%	 59.612%	     0.000	        1	[densenet201/conv4_block16_concat/concat]:181
	                     MUL	          509.044	    0.443	    0.435	  0.051%	 59.663%	     0.000	        1	[densenet201/conv4_block17_0_bn/FusedBatchNormV31]:182
	                     ADD	          509.479	    0.609	    0.614	  0.072%	 59.735%	     0.000	        1	[densenet201/conv4_block17_0_relu/Relu;densenet201/conv4_block17_0_bn/FusedBatchNormV3]:183
	                 CONV_2D	          510.094	    2.385	    2.411	  0.282%	 60.017%	     0.000	        1	[densenet201/conv4_block17_1_relu/Relu;densenet201/conv4_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block17_1_conv/Conv2D]:184
	                 CONV_2D	          512.506	    1.480	    1.468	  0.172%	 60.189%	     0.000	        1	[densenet201/conv4_block17_2_conv/Conv2D1]:185
	           CONCATENATION	          513.975	    0.133	    0.125	  0.015%	 60.204%	     0.000	        1	[densenet201/conv4_block17_concat/concat]:186
	                     MUL	          514.101	    0.438	    0.458	  0.054%	 60.258%	     0.000	        1	[densenet201/conv4_block18_0_bn/FusedBatchNormV31]:187
	                     ADD	          514.560	    0.644	    0.645	  0.076%	 60.333%	     0.000	        1	[densenet201/conv4_block18_0_relu/Relu;densenet201/conv4_block18_0_bn/FusedBatchNormV3]:188
	                 CONV_2D	          515.206	    2.490	    2.504	  0.293%	 60.626%	     0.000	        1	[densenet201/conv4_block18_1_relu/Relu;densenet201/conv4_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block18_1_conv/Conv2D]:189
	                 CONV_2D	          517.711	    1.435	    1.471	  0.172%	 60.799%	     0.000	        1	[densenet201/conv4_block18_2_conv/Conv2D1]:190
	           CONCATENATION	          519.183	    0.131	    0.147	  0.017%	 60.816%	     0.000	        1	[densenet201/conv4_block18_concat/concat]:191
	                     MUL	          519.331	    0.468	    0.470	  0.055%	 60.871%	     0.000	        1	[densenet201/conv4_block19_0_bn/FusedBatchNormV31]:192
	                     ADD	          519.802	    0.668	    0.672	  0.079%	 60.950%	     0.000	        1	[densenet201/conv4_block19_0_relu/Relu;densenet201/conv4_block19_0_bn/FusedBatchNormV3]:193
	                 CONV_2D	          520.474	    2.577	    2.596	  0.304%	 61.254%	     0.000	        1	[densenet201/conv4_block19_1_relu/Relu;densenet201/conv4_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block19_1_conv/Conv2D]:194
	                 CONV_2D	          523.071	    1.405	    1.441	  0.169%	 61.423%	     0.000	        1	[densenet201/conv4_block19_2_conv/Conv2D1]:195
	           CONCATENATION	          524.513	    0.125	    0.140	  0.016%	 61.439%	     0.000	        1	[densenet201/conv4_block19_concat/concat]:196
	                     MUL	          524.654	    0.561	    0.492	  0.058%	 61.497%	     0.000	        1	[densenet201/conv4_block20_0_bn/FusedBatchNormV31]:197
	                     ADD	          525.146	    0.688	    0.691	  0.081%	 61.578%	     0.000	        1	[densenet201/conv4_block20_0_relu/Relu;densenet201/conv4_block20_0_bn/FusedBatchNormV3]:198
	                 CONV_2D	          525.838	    2.649	    2.707	  0.317%	 61.895%	     0.000	        1	[densenet201/conv4_block20_1_relu/Relu;densenet201/conv4_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block20_1_conv/Conv2D]:199
	                 CONV_2D	          528.546	    1.496	    1.460	  0.171%	 62.066%	     0.000	        1	[densenet201/conv4_block20_2_conv/Conv2D1]:200
	           CONCATENATION	          530.008	    0.141	    0.153	  0.018%	 62.084%	     0.000	        1	[densenet201/conv4_block20_concat/concat]:201
	                     MUL	          530.161	    0.497	    0.511	  0.060%	 62.144%	     0.000	        1	[densenet201/conv4_block21_0_bn/FusedBatchNormV3]:202
	                     ADD	          530.673	    0.704	    0.721	  0.085%	 62.228%	     0.000	        1	[densenet201/conv4_block21_0_relu/Relu;densenet201/conv4_block21_0_bn/FusedBatchNormV3]:203
	                 CONV_2D	          531.395	    2.798	    2.782	  0.326%	 62.554%	     0.000	        1	[densenet201/conv4_block21_1_relu/Relu;densenet201/conv4_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block21_1_conv/Conv2D]:204
	                 CONV_2D	          534.178	    1.494	    1.439	  0.169%	 62.723%	     0.000	        1	[densenet201/conv4_block21_2_conv/Conv2D1]:205
	           CONCATENATION	          535.618	    0.155	    0.148	  0.017%	 62.740%	     0.000	        1	[densenet201/conv4_block21_concat/concat]:206
	                     MUL	          535.767	    0.515	    0.530	  0.062%	 62.802%	     0.000	        1	[densenet201/conv4_block22_0_bn/FusedBatchNormV3]:207
	                     ADD	          536.298	    0.844	    0.746	  0.087%	 62.889%	     0.000	        1	[densenet201/conv4_block22_0_relu/Relu;densenet201/conv4_block22_0_bn/FusedBatchNormV3]:208
	                 CONV_2D	          537.044	    2.869	    2.889	  0.338%	 63.228%	     0.000	        1	[densenet201/conv4_block22_1_relu/Relu;densenet201/conv4_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block22_1_conv/Conv2D]:209
	                 CONV_2D	          539.934	    1.459	    1.471	  0.172%	 63.400%	     0.000	        1	[densenet201/conv4_block22_2_conv/Conv2D1]:210
	           CONCATENATION	          541.405	    0.180	    0.167	  0.020%	 63.420%	     0.000	        1	[densenet201/conv4_block22_concat/concat]:211
	                     MUL	          541.573	    0.533	    0.544	  0.064%	 63.483%	     0.000	        1	[densenet201/conv4_block23_0_bn/FusedBatchNormV3]:212
	                     ADD	          542.117	    0.759	    0.773	  0.091%	 63.574%	     0.000	        1	[densenet201/conv4_block23_0_relu/Relu;densenet201/conv4_block23_0_bn/FusedBatchNormV3]:213
	                 CONV_2D	          542.891	    2.954	    2.983	  0.349%	 63.923%	     0.000	        1	[densenet201/conv4_block23_1_relu/Relu;densenet201/conv4_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block23_1_conv/Conv2D]:214
	                 CONV_2D	          545.875	    1.432	    1.477	  0.173%	 64.097%	     0.000	        1	[densenet201/conv4_block23_2_conv/Conv2D1]:215
	           CONCATENATION	          547.353	    0.156	    0.164	  0.019%	 64.116%	     0.000	        1	[densenet201/conv4_block23_concat/concat]:216
	                     MUL	          547.518	    0.550	    0.571	  0.067%	 64.183%	     0.000	        1	[densenet201/conv4_block24_0_bn/FusedBatchNormV3]:217
	                     ADD	          548.090	    0.777	    0.791	  0.093%	 64.275%	     0.000	        1	[densenet201/conv4_block24_0_relu/Relu;densenet201/conv4_block24_0_bn/FusedBatchNormV3]:218
	                 CONV_2D	          548.882	    3.106	    3.080	  0.361%	 64.636%	     0.000	        1	[densenet201/conv4_block24_1_relu/Relu;densenet201/conv4_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block24_1_conv/Conv2D]:219
	                 CONV_2D	          551.964	    1.414	    1.423	  0.167%	 64.803%	     0.000	        1	[densenet201/conv4_block24_2_conv/Conv2D1]:220
	           CONCATENATION	          553.388	    0.201	    0.179	  0.021%	 64.824%	     0.000	        1	[densenet201/conv4_block24_concat/concat]:221
	                     MUL	          553.567	    0.565	    0.577	  0.068%	 64.891%	     0.000	        1	[densenet201/conv4_block25_0_bn/FusedBatchNormV3]:222
	                     ADD	          554.144	    0.834	    0.829	  0.097%	 64.989%	     0.000	        1	[densenet201/conv4_block25_0_relu/Relu;densenet201/conv4_block25_0_bn/FusedBatchNormV3]:223
	                 CONV_2D	          554.974	    3.228	    3.174	  0.372%	 65.360%	     0.000	        1	[densenet201/conv4_block25_1_relu/Relu;densenet201/conv4_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block25_1_conv/Conv2D]:224
	                 CONV_2D	          558.149	    1.438	    1.436	  0.168%	 65.529%	     0.000	        1	[densenet201/conv4_block25_2_conv/Conv2D1]:225
	           CONCATENATION	          559.586	    0.158	    0.169	  0.020%	 65.548%	     0.000	        1	[densenet201/conv4_block25_concat/concat]:226
	                     MUL	          559.755	    0.581	    0.605	  0.071%	 65.619%	     0.000	        1	[densenet201/conv4_block26_0_bn/FusedBatchNormV3]:227
	                     ADD	          560.361	    0.858	    0.841	  0.099%	 65.718%	     0.000	        1	[densenet201/conv4_block26_0_relu/Relu;densenet201/conv4_block26_0_bn/FusedBatchNormV3]:228
	                 CONV_2D	          561.203	    3.243	    3.305	  0.387%	 66.105%	     0.000	        1	[densenet201/conv4_block26_1_relu/Relu;densenet201/conv4_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block26_1_conv/Conv2D]:229
	                 CONV_2D	          564.509	    1.427	    1.424	  0.167%	 66.272%	     0.000	        1	[densenet201/conv4_block26_2_conv/Conv2D1]:230
	           CONCATENATION	          565.934	    0.190	    0.192	  0.023%	 66.294%	     0.000	        1	[densenet201/conv4_block26_concat/concat]:231
	                     MUL	          566.127	    0.600	    0.621	  0.073%	 66.367%	     0.000	        1	[densenet201/conv4_block27_0_bn/FusedBatchNormV3]:232
	                     ADD	          566.749	    0.857	    0.875	  0.102%	 66.470%	     0.000	        1	[densenet201/conv4_block27_0_relu/Relu;densenet201/conv4_block27_0_bn/FusedBatchNormV3]:233
	                 CONV_2D	          567.625	    3.410	    3.412	  0.400%	 66.869%	     0.000	        1	[densenet201/conv4_block27_1_relu/Relu;densenet201/conv4_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block27_1_conv/Conv2D]:234
	                 CONV_2D	          571.037	    1.416	    1.470	  0.172%	 67.041%	     0.000	        1	[densenet201/conv4_block27_2_conv/Conv2D1]:235
	           CONCATENATION	          572.508	    0.194	    0.183	  0.021%	 67.063%	     0.000	        1	[densenet201/conv4_block27_concat/concat]:236
	                     MUL	          572.692	    0.658	    0.633	  0.074%	 67.137%	     0.000	        1	[densenet201/conv4_block28_0_bn/FusedBatchNormV3]:237
	                     ADD	          573.325	    0.911	    0.894	  0.105%	 67.242%	     0.000	        1	[densenet201/conv4_block28_0_relu/Relu;densenet201/conv4_block28_0_bn/FusedBatchNormV3]:238
	                 CONV_2D	          574.220	    3.451	    3.499	  0.410%	 67.652%	     0.000	        1	[densenet201/conv4_block28_1_relu/Relu;densenet201/conv4_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block28_1_conv/Conv2D]:239
	                 CONV_2D	          577.721	    1.387	    1.419	  0.166%	 67.818%	     0.000	        1	[densenet201/conv4_block28_2_conv/Conv2D1]:240
	           CONCATENATION	          579.141	    0.181	    0.179	  0.021%	 67.839%	     0.000	        1	[densenet201/conv4_block28_concat/concat]:241
	                     MUL	          579.321	    0.641	    0.652	  0.076%	 67.915%	     0.000	        1	[densenet201/conv4_block29_0_bn/FusedBatchNormV3]:242
	                     ADD	          579.973	    0.897	    0.919	  0.108%	 68.023%	     0.000	        1	[densenet201/conv4_block29_0_relu/Relu;densenet201/conv4_block29_0_bn/FusedBatchNormV3]:243
	                 CONV_2D	          580.893	    3.676	    3.614	  0.423%	 68.446%	     0.000	        1	[densenet201/conv4_block29_1_relu/Relu;densenet201/conv4_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block29_1_conv/Conv2D]:244
	                 CONV_2D	          584.509	    1.456	    1.423	  0.167%	 68.613%	     0.000	        1	[densenet201/conv4_block29_2_conv/Conv2D1]:245
	           CONCATENATION	          585.932	    0.190	    0.182	  0.021%	 68.634%	     0.000	        1	[densenet201/conv4_block29_concat/concat]:246
	                     MUL	          586.116	    0.660	    0.674	  0.079%	 68.713%	     0.000	        1	[densenet201/conv4_block30_0_bn/FusedBatchNormV3]:247
	                     ADD	          586.791	    0.928	    0.948	  0.111%	 68.824%	     0.000	        1	[densenet201/conv4_block30_0_relu/Relu;densenet201/conv4_block30_0_bn/FusedBatchNormV3]:248
	                 CONV_2D	          587.739	    3.683	    3.698	  0.433%	 69.258%	     0.000	        1	[densenet201/conv4_block30_1_relu/Relu;densenet201/conv4_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block30_1_conv/Conv2D]:249
	                 CONV_2D	          591.439	    1.428	    1.466	  0.172%	 69.429%	     0.000	        1	[densenet201/conv4_block30_2_conv/Conv2D1]:250
	           CONCATENATION	          592.906	    0.198	    0.191	  0.022%	 69.452%	     0.000	        1	[densenet201/conv4_block30_concat/concat]:251
	                     MUL	          593.098	    0.816	    0.683	  0.080%	 69.532%	     0.000	        1	[densenet201/conv4_block31_0_bn/FusedBatchNormV3]:252
	                     ADD	          593.782	    0.958	    0.974	  0.114%	 69.646%	     0.000	        1	[densenet201/conv4_block31_0_relu/Relu;densenet201/conv4_block31_0_bn/FusedBatchNormV3]:253
	                 CONV_2D	          594.756	    3.815	    3.813	  0.447%	 70.092%	     0.000	        1	[densenet201/conv4_block31_1_relu/Relu;densenet201/conv4_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block31_1_conv/Conv2D]:254
	                 CONV_2D	          598.569	    1.457	    1.479	  0.173%	 70.266%	     0.000	        1	[densenet201/conv4_block31_2_conv/Conv2D1]:255
	           CONCATENATION	          600.049	    0.210	    0.210	  0.025%	 70.290%	     0.000	        1	[densenet201/conv4_block31_concat/concat]:256
	                     MUL	          600.260	    0.690	    0.701	  0.082%	 70.372%	     0.000	        1	[densenet201/conv4_block32_0_bn/FusedBatchNormV3]:257
	                     ADD	          600.962	    1.017	    0.993	  0.116%	 70.489%	     0.000	        1	[densenet201/conv4_block32_0_relu/Relu;densenet201/conv4_block32_0_bn/FusedBatchNormV3]:258
	                 CONV_2D	          601.955	    3.854	    3.904	  0.457%	 70.946%	     0.000	        1	[densenet201/conv4_block32_1_relu/Relu;densenet201/conv4_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block32_1_conv/Conv2D]:259
	                 CONV_2D	          605.861	    1.437	    1.492	  0.175%	 71.121%	     0.000	        1	[densenet201/conv4_block32_2_conv/Conv2D1]:260
	           CONCATENATION	          607.354	    0.218	    0.211	  0.025%	 71.146%	     0.000	        1	[densenet201/conv4_block32_concat/concat]:261
	                     MUL	          607.565	    0.708	    0.725	  0.085%	 71.231%	     0.000	        1	[densenet201/conv4_block33_0_bn/FusedBatchNormV3]:262
	                     ADD	          608.291	    1.041	    1.022	  0.120%	 71.350%	     0.000	        1	[densenet201/conv4_block33_0_relu/Relu;densenet201/conv4_block33_0_bn/FusedBatchNormV3]:263
	                 CONV_2D	          609.314	    3.977	    4.007	  0.469%	 71.820%	     0.000	        1	[densenet201/conv4_block33_1_relu/Relu;densenet201/conv4_block33_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block33_1_conv/Conv2D]:264
	                 CONV_2D	          613.323	    1.424	    1.472	  0.172%	 71.992%	     0.000	        1	[densenet201/conv4_block33_2_conv/Conv2D1]:265
	           CONCATENATION	          614.796	    0.234	    0.225	  0.026%	 72.019%	     0.000	        1	[densenet201/conv4_block33_concat/concat]:266
	                     MUL	          615.022	    0.724	    0.743	  0.087%	 72.106%	     0.000	        1	[densenet201/conv4_block34_0_bn/FusedBatchNormV3]:267
	                     ADD	          615.766	    1.023	    1.049	  0.123%	 72.229%	     0.000	        1	[densenet201/conv4_block34_0_relu/Relu;densenet201/conv4_block34_0_bn/FusedBatchNormV3]:268
	                 CONV_2D	          616.816	    4.165	    4.105	  0.481%	 72.709%	     0.000	        1	[densenet201/conv4_block34_1_relu/Relu;densenet201/conv4_block34_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block34_1_conv/Conv2D]:269
	                 CONV_2D	          620.922	    1.485	    1.493	  0.175%	 72.884%	     0.000	        1	[densenet201/conv4_block34_2_conv/Conv2D1]:270
	           CONCATENATION	          622.415	    0.236	    0.240	  0.028%	 72.912%	     0.000	        1	[densenet201/conv4_block34_concat/concat]:271
	                     MUL	          622.656	    0.759	    0.757	  0.089%	 73.001%	     0.000	        1	[densenet201/conv4_block35_0_bn/FusedBatchNormV3]:272
	                     ADD	          623.414	    1.049	    1.075	  0.126%	 73.127%	     0.000	        1	[densenet201/conv4_block35_0_relu/Relu;densenet201/conv4_block35_0_bn/FusedBatchNormV3]:273
	                 CONV_2D	          624.490	    4.163	    4.224	  0.495%	 73.622%	     0.000	        1	[densenet201/conv4_block35_1_relu/Relu;densenet201/conv4_block35_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block35_1_conv/Conv2D]:274
	                 CONV_2D	          628.715	    1.515	    1.433	  0.168%	 73.790%	     0.000	        1	[densenet201/conv4_block35_2_conv/Conv2D1]:275
	           CONCATENATION	          630.149	    0.242	    0.237	  0.028%	 73.817%	     0.000	        1	[densenet201/conv4_block35_concat/concat]:276
	                     MUL	          630.387	    0.763	    0.779	  0.091%	 73.909%	     0.000	        1	[densenet201/conv4_block36_0_bn/FusedBatchNormV3]:277
	                     ADD	          631.167	    1.072	    1.103	  0.129%	 74.038%	     0.000	        1	[densenet201/conv4_block36_0_relu/Relu;densenet201/conv4_block36_0_bn/FusedBatchNormV3]:278
	                 CONV_2D	          632.270	    4.325	    4.312	  0.505%	 74.543%	     0.000	        1	[densenet201/conv4_block36_1_relu/Relu;densenet201/conv4_block36_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block36_1_conv/Conv2D]:279
	                 CONV_2D	          636.583	    1.494	    1.441	  0.169%	 74.712%	     0.000	        1	[densenet201/conv4_block36_2_conv/Conv2D1]:280
	           CONCATENATION	          638.025	    0.224	    0.242	  0.028%	 74.740%	     0.000	        1	[densenet201/conv4_block36_concat/concat]:281
	                     MUL	          638.268	    0.773	    0.793	  0.093%	 74.833%	     0.000	        1	[densenet201/conv4_block37_0_bn/FusedBatchNormV3]:282
	                     ADD	          639.061	    1.105	    1.131	  0.132%	 74.966%	     0.000	        1	[densenet201/conv4_block37_0_relu/Relu;densenet201/conv4_block37_0_bn/FusedBatchNormV3]:283
	                 CONV_2D	          640.193	    4.515	    4.422	  0.518%	 75.484%	     0.000	        1	[densenet201/conv4_block37_1_relu/Relu;densenet201/conv4_block37_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block37_1_conv/Conv2D]:284
	                 CONV_2D	          644.616	    1.536	    1.443	  0.169%	 75.653%	     0.000	        1	[densenet201/conv4_block37_2_conv/Conv2D1]:285
	           CONCATENATION	          646.060	    0.211	    0.248	  0.029%	 75.682%	     0.000	        1	[densenet201/conv4_block37_concat/concat]:286
	                     MUL	          646.309	    0.806	    0.812	  0.095%	 75.777%	     0.000	        1	[densenet201/conv4_block38_0_bn/FusedBatchNormV3]:287
	                     ADD	          647.121	    1.140	    1.152	  0.135%	 75.912%	     0.000	        1	[densenet201/conv4_block38_0_relu/Relu;densenet201/conv4_block38_0_bn/FusedBatchNormV3]:288
	                 CONV_2D	          648.274	    4.474	    4.507	  0.528%	 76.440%	     0.000	        1	[densenet201/conv4_block38_1_relu/Relu;densenet201/conv4_block38_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block38_1_conv/Conv2D]:289
	                 CONV_2D	          652.782	    1.539	    1.492	  0.175%	 76.615%	     0.000	        1	[densenet201/conv4_block38_2_conv/Conv2D1]:290
	           CONCATENATION	          654.275	    0.241	    0.274	  0.032%	 76.647%	     0.000	        1	[densenet201/conv4_block38_concat/concat]:291
	                     MUL	          654.550	    0.813	    0.833	  0.098%	 76.744%	     0.000	        1	[densenet201/conv4_block39_0_bn/FusedBatchNormV3]:292
	                     ADD	          655.384	    1.146	    1.181	  0.138%	 76.883%	     0.000	        1	[densenet201/conv4_block39_0_relu/Relu;densenet201/conv4_block39_0_bn/FusedBatchNormV3]:293
	                 CONV_2D	          656.566	    4.655	    4.611	  0.540%	 77.423%	     0.000	        1	[densenet201/conv4_block39_1_relu/Relu;densenet201/conv4_block39_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block39_1_conv/Conv2D]:294
	                 CONV_2D	          661.178	    1.476	    1.442	  0.169%	 77.592%	     0.000	        1	[densenet201/conv4_block39_2_conv/Conv2D1]:295
	           CONCATENATION	          662.621	    0.272	    0.256	  0.030%	 77.622%	     0.000	        1	[densenet201/conv4_block39_concat/concat]:296
	                     MUL	          662.878	    0.824	    0.851	  0.100%	 77.721%	     0.000	        1	[densenet201/conv4_block40_0_bn/FusedBatchNormV3]:297
	                     ADD	          663.730	    1.177	    1.201	  0.141%	 77.862%	     0.000	        1	[densenet201/conv4_block40_0_relu/Relu;densenet201/conv4_block40_0_bn/FusedBatchNormV3]:298
	                 CONV_2D	          664.931	    4.695	    4.715	  0.552%	 78.414%	     0.000	        1	[densenet201/conv4_block40_1_relu/Relu;densenet201/conv4_block40_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block40_1_conv/Conv2D]:299
	                 CONV_2D	          669.648	    1.485	    1.506	  0.176%	 78.591%	     0.000	        1	[densenet201/conv4_block40_2_conv/Conv2D1]:300
	           CONCATENATION	          671.155	    0.273	    0.282	  0.033%	 78.624%	     0.000	        1	[densenet201/conv4_block40_concat/concat]:301
	                     MUL	          671.438	    0.851	    0.869	  0.102%	 78.726%	     0.000	        1	[densenet201/conv4_block41_0_bn/FusedBatchNormV3]:302
	                     ADD	          672.307	    1.308	    1.227	  0.144%	 78.869%	     0.000	        1	[densenet201/conv4_block41_0_relu/Relu;densenet201/conv4_block41_0_bn/FusedBatchNormV3]:303
	                 CONV_2D	          673.534	    4.738	    4.794	  0.562%	 79.431%	     0.000	        1	[densenet201/conv4_block41_1_relu/Relu;densenet201/conv4_block41_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block41_1_conv/Conv2D]:304
	                 CONV_2D	          678.329	    1.430	    1.492	  0.175%	 79.606%	     0.000	        1	[densenet201/conv4_block41_2_conv/Conv2D1]:305
	           CONCATENATION	          679.822	    0.279	    0.284	  0.033%	 79.639%	     0.000	        1	[densenet201/conv4_block41_concat/concat]:306
	                     MUL	          680.107	    0.861	    0.882	  0.103%	 79.742%	     0.000	        1	[densenet201/conv4_block42_0_bn/FusedBatchNormV3]:307
	                     ADD	          680.989	    1.304	    1.253	  0.147%	 79.889%	     0.000	        1	[densenet201/conv4_block42_0_relu/Relu;densenet201/conv4_block42_0_bn/FusedBatchNormV3]:308
	                 CONV_2D	          682.243	    4.915	    4.908	  0.575%	 80.464%	     0.000	        1	[densenet201/conv4_block42_1_relu/Relu;densenet201/conv4_block42_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block42_1_conv/Conv2D]:309
	                 CONV_2D	          687.153	    1.470	    1.474	  0.173%	 80.637%	     0.000	        1	[densenet201/conv4_block42_2_conv/Conv2D1]:310
	           CONCATENATION	          688.628	    0.252	    0.280	  0.033%	 80.669%	     0.000	        1	[densenet201/conv4_block42_concat/concat]:311
	                     MUL	          688.909	    0.923	    0.896	  0.105%	 80.774%	     0.000	        1	[densenet201/conv4_block43_0_bn/FusedBatchNormV3]:312
	                     ADD	          689.806	    1.249	    1.277	  0.150%	 80.924%	     0.000	        1	[densenet201/conv4_block43_0_relu/Relu;densenet201/conv4_block43_0_bn/FusedBatchNormV3]:313
	                 CONV_2D	          691.083	    5.017	    5.022	  0.588%	 81.512%	     0.000	        1	[densenet201/conv4_block43_1_relu/Relu;densenet201/conv4_block43_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block43_1_conv/Conv2D]:314
	                 CONV_2D	          696.107	    1.574	    1.485	  0.174%	 81.686%	     0.000	        1	[densenet201/conv4_block43_2_conv/Conv2D1]:315
	           CONCATENATION	          697.593	    0.280	    0.300	  0.035%	 81.722%	     0.000	        1	[densenet201/conv4_block43_concat/concat]:316
	                     MUL	          697.894	    0.899	    0.915	  0.107%	 81.829%	     0.000	        1	[densenet201/conv4_block44_0_bn/FusedBatchNormV3]:317
	                     ADD	          698.810	    1.277	    1.312	  0.154%	 81.982%	     0.000	        1	[densenet201/conv4_block44_0_relu/Relu;densenet201/conv4_block44_0_bn/FusedBatchNormV3]:318
	                 CONV_2D	          700.122	    5.066	    5.103	  0.598%	 82.580%	     0.000	        1	[densenet201/conv4_block44_1_relu/Relu;densenet201/conv4_block44_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block44_1_conv/Conv2D]:319
	                 CONV_2D	          705.227	    1.584	    1.524	  0.178%	 82.759%	     0.000	        1	[densenet201/conv4_block44_2_conv/Conv2D1]:320
	           CONCATENATION	          706.751	    0.295	    0.308	  0.036%	 82.795%	     0.000	        1	[densenet201/conv4_block44_concat/concat]:321
	                     MUL	          707.060	    0.909	    0.939	  0.110%	 82.905%	     0.000	        1	[densenet201/conv4_block45_0_bn/FusedBatchNormV3]:322
	                     ADD	          708.000	    1.351	    1.337	  0.157%	 83.061%	     0.000	        1	[densenet201/conv4_block45_0_relu/Relu;densenet201/conv4_block45_0_bn/FusedBatchNormV3]:323
	                 CONV_2D	          709.338	    5.191	    5.210	  0.610%	 83.672%	     0.000	        1	[densenet201/conv4_block45_1_relu/Relu;densenet201/conv4_block45_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block45_1_conv/Conv2D]:324
	                 CONV_2D	          714.549	    1.447	    1.484	  0.174%	 83.846%	     0.000	        1	[densenet201/conv4_block45_2_conv/Conv2D1]:325
	           CONCATENATION	          716.034	    0.340	    0.312	  0.037%	 83.882%	     0.000	        1	[densenet201/conv4_block45_concat/concat]:326
	                     MUL	          716.347	    1.050	    0.951	  0.111%	 83.994%	     0.000	        1	[densenet201/conv4_block46_0_bn/FusedBatchNormV3]:327
	                     ADD	          717.299	    1.348	    1.354	  0.159%	 84.152%	     0.000	        1	[densenet201/conv4_block46_0_relu/Relu;densenet201/conv4_block46_0_bn/FusedBatchNormV3]:328
	                 CONV_2D	          718.654	    5.251	    5.319	  0.623%	 84.775%	     0.000	        1	[densenet201/conv4_block46_1_relu/Relu;densenet201/conv4_block46_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block46_1_conv/Conv2D]:329
	                 CONV_2D	          723.974	    1.481	    1.475	  0.173%	 84.948%	     0.000	        1	[densenet201/conv4_block46_2_conv/Conv2D1]:330
	           CONCATENATION	          725.450	    0.308	    0.287	  0.034%	 84.982%	     0.000	        1	[densenet201/conv4_block46_concat/concat]:331
	                     MUL	          725.737	    0.983	    0.970	  0.114%	 85.095%	     0.000	        1	[densenet201/conv4_block47_0_bn/FusedBatchNormV3]:332
	                     ADD	          726.709	    1.354	    1.388	  0.163%	 85.258%	     0.000	        1	[densenet201/conv4_block47_0_relu/Relu;densenet201/conv4_block47_0_bn/FusedBatchNormV3]:333
	                 CONV_2D	          728.097	    5.399	    5.426	  0.636%	 85.894%	     0.000	        1	[densenet201/conv4_block47_1_relu/Relu;densenet201/conv4_block47_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block47_1_conv/Conv2D]:334
	                 CONV_2D	          733.524	    1.475	    1.493	  0.175%	 86.068%	     0.000	        1	[densenet201/conv4_block47_2_conv/Conv2D1]:335
	           CONCATENATION	          735.018	    0.307	    0.327	  0.038%	 86.107%	     0.000	        1	[densenet201/conv4_block47_concat/concat]:336
	                     MUL	          735.346	    0.991	    0.989	  0.116%	 86.223%	     0.000	        1	[densenet201/conv4_block48_0_bn/FusedBatchNormV3]:337
	                     ADD	          736.335	    1.417	    1.407	  0.165%	 86.387%	     0.000	        1	[densenet201/conv4_block48_0_relu/Relu;densenet201/conv4_block48_0_bn/FusedBatchNormV3]:338
	                 CONV_2D	          737.743	    5.471	    5.519	  0.646%	 87.034%	     0.000	        1	[densenet201/conv4_block48_1_relu/Relu;densenet201/conv4_block48_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block48_1_conv/Conv2D]:339
	                 CONV_2D	          743.263	    1.516	    1.527	  0.179%	 87.213%	     0.000	        1	[densenet201/conv4_block48_2_conv/Conv2D1]:340
	           CONCATENATION	          744.791	    0.322	    0.333	  0.039%	 87.252%	     0.000	        1	[densenet201/conv4_block48_concat/concat]:341
	                     MUL	          745.125	    1.060	    1.002	  0.117%	 87.369%	     0.000	        1	[densenet201/pool4_bn/FusedBatchNormV3]:342
	                     ADD	          746.128	    1.404	    1.436	  0.168%	 87.537%	     0.000	        1	[densenet201/pool4_relu/Relu;densenet201/pool4_bn/FusedBatchNormV3]:343
	                 CONV_2D	          747.564	   33.919	   34.018	  3.985%	 91.523%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	         AVERAGE_POOL_2D	          781.584	    0.447	    0.474	  0.056%	 91.578%	     0.000	        1	[densenet201/pool4_pool/AvgPool]:345
	                     MUL	          782.059	    0.135	    0.135	  0.016%	 91.594%	     0.000	        1	[densenet201/conv5_block1_0_bn/FusedBatchNormV31]:346
	                     ADD	          782.194	    0.182	    0.187	  0.022%	 91.616%	     0.000	        1	[densenet201/conv5_block1_0_relu/Relu;densenet201/conv5_block1_0_bn/FusedBatchNormV3]:347
	                 CONV_2D	          782.381	    0.792	    0.815	  0.095%	 91.711%	     0.000	        1	[densenet201/conv5_block1_1_relu/Relu;densenet201/conv5_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block1_1_conv/Conv2D]:348
	                 CONV_2D	          783.197	    0.381	    0.392	  0.046%	 91.757%	     0.000	        1	[densenet201/conv5_block1_2_conv/Conv2D1]:349
	           CONCATENATION	          783.590	    0.018	    0.021	  0.002%	 91.760%	     0.000	        1	[densenet201/conv5_block1_concat/concat]:350
	                     MUL	          783.611	    0.138	    0.137	  0.016%	 91.776%	     0.000	        1	[densenet201/conv5_block2_0_bn/FusedBatchNormV31]:351
	                     ADD	          783.749	    0.185	    0.185	  0.022%	 91.797%	     0.000	        1	[densenet201/conv5_block2_0_relu/Relu;densenet201/conv5_block2_0_bn/FusedBatchNormV3]:352
	                 CONV_2D	          783.934	    0.768	    0.780	  0.091%	 91.889%	     0.000	        1	[densenet201/conv5_block2_1_relu/Relu;densenet201/conv5_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block2_1_conv/Conv2D]:353
	                 CONV_2D	          784.715	    0.384	    0.380	  0.045%	 91.933%	     0.000	        1	[densenet201/conv5_block2_2_conv/Conv2D1]:354
	           CONCATENATION	          785.096	    0.012	    0.012	  0.001%	 91.935%	     0.000	        1	[densenet201/conv5_block2_concat/concat]:355
	                     MUL	          785.109	    0.140	    0.139	  0.016%	 91.951%	     0.000	        1	[densenet201/conv5_block3_0_bn/FusedBatchNormV31]:356
	                     ADD	          785.249	    0.192	    0.193	  0.023%	 91.974%	     0.000	        1	[densenet201/conv5_block3_0_relu/Relu;densenet201/conv5_block3_0_bn/FusedBatchNormV3]:357
	                 CONV_2D	          785.442	    0.836	    0.804	  0.094%	 92.068%	     0.000	        1	[densenet201/conv5_block3_1_relu/Relu;densenet201/conv5_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block3_1_conv/Conv2D]:358
	                 CONV_2D	          786.247	    0.383	    0.381	  0.045%	 92.112%	     0.000	        1	[densenet201/conv5_block3_2_conv/Conv2D1]:359
	           CONCATENATION	          786.629	    0.015	    0.012	  0.001%	 92.114%	     0.000	        1	[densenet201/conv5_block3_concat/concat]:360
	                     MUL	          786.641	    0.138	    0.144	  0.017%	 92.131%	     0.000	        1	[densenet201/conv5_block4_0_bn/FusedBatchNormV31]:361
	                     ADD	          786.785	    0.200	    0.202	  0.024%	 92.154%	     0.000	        1	[densenet201/conv5_block4_0_relu/Relu;densenet201/conv5_block4_0_bn/FusedBatchNormV3]:362
	                 CONV_2D	          786.988	    0.825	    0.841	  0.099%	 92.253%	     0.000	        1	[densenet201/conv5_block4_1_relu/Relu;densenet201/conv5_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block4_1_conv/Conv2D]:363
	                 CONV_2D	          787.830	    0.379	    0.376	  0.044%	 92.297%	     0.000	        1	[densenet201/conv5_block4_2_conv/Conv2D1]:364
	           CONCATENATION	          788.206	    0.013	    0.014	  0.002%	 92.299%	     0.000	        1	[densenet201/conv5_block4_concat/concat]:365
	                     MUL	          788.221	    0.141	    0.148	  0.017%	 92.316%	     0.000	        1	[densenet201/conv5_block5_0_bn/FusedBatchNormV31]:366
	                     ADD	          788.370	    0.196	    0.207	  0.024%	 92.340%	     0.000	        1	[densenet201/conv5_block5_0_relu/Relu;densenet201/conv5_block5_0_bn/FusedBatchNormV3]:367
	                 CONV_2D	          788.577	    0.843	    0.846	  0.099%	 92.439%	     0.000	        1	[densenet201/conv5_block5_1_relu/Relu;densenet201/conv5_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block5_1_conv/Conv2D]:368
	                 CONV_2D	          789.424	    0.410	    0.380	  0.045%	 92.484%	     0.000	        1	[densenet201/conv5_block5_2_conv/Conv2D1]:369
	           CONCATENATION	          789.804	    0.012	    0.013	  0.002%	 92.485%	     0.000	        1	[densenet201/conv5_block5_concat/concat]:370
	                     MUL	          789.818	    0.154	    0.154	  0.018%	 92.503%	     0.000	        1	[densenet201/conv5_block6_0_bn/FusedBatchNormV31]:371
	                     ADD	          789.973	    0.210	    0.211	  0.025%	 92.528%	     0.000	        1	[densenet201/conv5_block6_0_relu/Relu;densenet201/conv5_block6_0_bn/FusedBatchNormV3]:372
	                 CONV_2D	          790.184	    0.871	    0.884	  0.104%	 92.632%	     0.000	        1	[densenet201/conv5_block6_1_relu/Relu;densenet201/conv5_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block6_1_conv/Conv2D]:373
	                 CONV_2D	          791.069	    0.379	    0.378	  0.044%	 92.676%	     0.000	        1	[densenet201/conv5_block6_2_conv/Conv2D1]:374
	           CONCATENATION	          791.447	    0.013	    0.015	  0.002%	 92.678%	     0.000	        1	[densenet201/conv5_block6_concat/concat]:375
	                     MUL	          791.463	    0.148	    0.157	  0.018%	 92.696%	     0.000	        1	[densenet201/conv5_block7_0_bn/FusedBatchNormV31]:376
	                     ADD	          791.621	    0.216	    0.219	  0.026%	 92.722%	     0.000	        1	[densenet201/conv5_block7_0_relu/Relu;densenet201/conv5_block7_0_bn/FusedBatchNormV3]:377
	                 CONV_2D	          791.840	    0.901	    0.908	  0.106%	 92.828%	     0.000	        1	[densenet201/conv5_block7_1_relu/Relu;densenet201/conv5_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block7_1_conv/Conv2D]:378
	                 CONV_2D	          792.749	    0.369	    0.378	  0.044%	 92.873%	     0.000	        1	[densenet201/conv5_block7_2_conv/Conv2D1]:379
	           CONCATENATION	          793.128	    0.024	    0.015	  0.002%	 92.874%	     0.000	        1	[densenet201/conv5_block7_concat/concat]:380
	                     MUL	          793.144	    0.154	    0.160	  0.019%	 92.893%	     0.000	        1	[densenet201/conv5_block8_0_bn/FusedBatchNormV31]:381
	                     ADD	          793.304	    0.242	    0.225	  0.026%	 92.919%	     0.000	        1	[densenet201/conv5_block8_0_relu/Relu;densenet201/conv5_block8_0_bn/FusedBatchNormV3]:382
	                 CONV_2D	          793.529	    0.935	    0.924	  0.108%	 93.028%	     0.000	        1	[densenet201/conv5_block8_1_relu/Relu;densenet201/conv5_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block8_1_conv/Conv2D]:383
	                 CONV_2D	          794.454	    0.405	    0.380	  0.045%	 93.072%	     0.000	        1	[densenet201/conv5_block8_2_conv/Conv2D1]:384
	           CONCATENATION	          794.834	    0.015	    0.015	  0.002%	 93.074%	     0.000	        1	[densenet201/conv5_block8_concat/concat]:385
	                     MUL	          794.850	    0.167	    0.165	  0.019%	 93.093%	     0.000	        1	[densenet201/conv5_block9_0_bn/FusedBatchNormV31]:386
	                     ADD	          795.015	    0.228	    0.232	  0.027%	 93.120%	     0.000	        1	[densenet201/conv5_block9_0_relu/Relu;densenet201/conv5_block9_0_bn/FusedBatchNormV3]:387
	                 CONV_2D	          795.247	    0.948	    0.959	  0.112%	 93.233%	     0.000	        1	[densenet201/conv5_block9_1_relu/Relu;densenet201/conv5_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block9_1_conv/Conv2D]:388
	                 CONV_2D	          796.207	    0.376	    0.383	  0.045%	 93.278%	     0.000	        1	[densenet201/conv5_block9_2_conv/Conv2D1]:389
	           CONCATENATION	          796.590	    0.015	    0.014	  0.002%	 93.279%	     0.000	        1	[densenet201/conv5_block9_concat/concat]:390
	                     MUL	          796.605	    0.172	    0.170	  0.020%	 93.299%	     0.000	        1	[densenet201/conv5_block10_0_bn/FusedBatchNormV31]:391
	                     ADD	          796.776	    0.233	    0.235	  0.028%	 93.327%	     0.000	        1	[densenet201/conv5_block10_0_relu/Relu;densenet201/conv5_block10_0_bn/FusedBatchNormV3]:392
	                 CONV_2D	          797.012	    1.002	    0.986	  0.115%	 93.442%	     0.000	        1	[densenet201/conv5_block10_1_relu/Relu;densenet201/conv5_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block10_1_conv/Conv2D]:393
	                 CONV_2D	          797.998	    0.387	    0.375	  0.044%	 93.486%	     0.000	        1	[densenet201/conv5_block10_2_conv/Conv2D1]:394
	           CONCATENATION	          798.374	    0.014	    0.014	  0.002%	 93.488%	     0.000	        1	[densenet201/conv5_block10_concat/concat]:395
	                     MUL	          798.389	    0.167	    0.175	  0.021%	 93.508%	     0.000	        1	[densenet201/conv5_block11_0_bn/FusedBatchNormV31]:396
	                     ADD	          798.565	    0.241	    0.244	  0.029%	 93.537%	     0.000	        1	[densenet201/conv5_block11_0_relu/Relu;densenet201/conv5_block11_0_bn/FusedBatchNormV3]:397
	                 CONV_2D	          798.809	    0.994	    1.010	  0.118%	 93.655%	     0.000	        1	[densenet201/conv5_block11_1_relu/Relu;densenet201/conv5_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block11_1_conv/Conv2D]:398
	                 CONV_2D	          799.819	    0.379	    0.379	  0.044%	 93.699%	     0.000	        1	[densenet201/conv5_block11_2_conv/Conv2D1]:399
	           CONCATENATION	          800.199	    0.014	    0.016	  0.002%	 93.701%	     0.000	        1	[densenet201/conv5_block11_concat/concat]:400
	                     MUL	          800.215	    0.178	    0.180	  0.021%	 93.722%	     0.000	        1	[densenet201/conv5_block12_0_bn/FusedBatchNormV31]:401
	                     ADD	          800.395	    0.247	    0.250	  0.029%	 93.752%	     0.000	        1	[densenet201/conv5_block12_0_relu/Relu;densenet201/conv5_block12_0_bn/FusedBatchNormV3]:402
	                 CONV_2D	          800.646	    1.053	    1.034	  0.121%	 93.873%	     0.000	        1	[densenet201/conv5_block12_1_relu/Relu;densenet201/conv5_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block12_1_conv/Conv2D]:403
	                 CONV_2D	          801.680	    0.382	    0.383	  0.045%	 93.918%	     0.000	        1	[densenet201/conv5_block12_2_conv/Conv2D1]:404
	           CONCATENATION	          802.064	    0.016	    0.015	  0.002%	 93.919%	     0.000	        1	[densenet201/conv5_block12_concat/concat]:405
	                     MUL	          802.080	    0.184	    0.181	  0.021%	 93.941%	     0.000	        1	[densenet201/conv5_block13_0_bn/FusedBatchNormV31]:406
	                     ADD	          802.261	    0.253	    0.256	  0.030%	 93.971%	     0.000	        1	[densenet201/conv5_block13_0_relu/Relu;densenet201/conv5_block13_0_bn/FusedBatchNormV3]:407
	                 CONV_2D	          802.518	    1.043	    1.066	  0.125%	 94.096%	     0.000	        1	[densenet201/conv5_block13_1_relu/Relu;densenet201/conv5_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block13_1_conv/Conv2D]:408
	                 CONV_2D	          803.584	    0.380	    0.380	  0.045%	 94.140%	     0.000	        1	[densenet201/conv5_block13_2_conv/Conv2D1]:409
	           CONCATENATION	          803.965	    0.014	    0.014	  0.002%	 94.142%	     0.000	        1	[densenet201/conv5_block13_concat/concat]:410
	                     MUL	          803.980	    0.185	    0.188	  0.022%	 94.164%	     0.000	        1	[densenet201/conv5_block14_0_bn/FusedBatchNormV31]:411
	                     ADD	          804.168	    0.260	    0.261	  0.031%	 94.194%	     0.000	        1	[densenet201/conv5_block14_0_relu/Relu;densenet201/conv5_block14_0_bn/FusedBatchNormV3]:412
	                 CONV_2D	          804.429	    1.093	    1.087	  0.127%	 94.322%	     0.000	        1	[densenet201/conv5_block14_1_relu/Relu;densenet201/conv5_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block14_1_conv/Conv2D]:413
	                 CONV_2D	          805.517	    0.387	    0.379	  0.044%	 94.366%	     0.000	        1	[densenet201/conv5_block14_2_conv/Conv2D1]:414
	           CONCATENATION	          805.896	    0.018	    0.016	  0.002%	 94.368%	     0.000	        1	[densenet201/conv5_block14_concat/concat]:415
	                     MUL	          805.913	    0.184	    0.193	  0.023%	 94.390%	     0.000	        1	[densenet201/conv5_block15_0_bn/FusedBatchNormV31]:416
	                     ADD	          806.106	    0.265	    0.266	  0.031%	 94.422%	     0.000	        1	[densenet201/conv5_block15_0_relu/Relu;densenet201/conv5_block15_0_bn/FusedBatchNormV3]:417
	                 CONV_2D	          806.373	    1.099	    1.114	  0.130%	 94.552%	     0.000	        1	[densenet201/conv5_block15_1_relu/Relu;densenet201/conv5_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block15_1_conv/Conv2D]:418
	                 CONV_2D	          807.488	    0.370	    0.381	  0.045%	 94.597%	     0.000	        1	[densenet201/conv5_block15_2_conv/Conv2D1]:419
	           CONCATENATION	          807.869	    0.014	    0.017	  0.002%	 94.599%	     0.000	        1	[densenet201/conv5_block15_concat/concat]:420
	                     MUL	          807.887	    0.196	    0.196	  0.023%	 94.622%	     0.000	        1	[densenet201/conv5_block16_0_bn/FusedBatchNormV31]:421
	                     ADD	          808.083	    0.269	    0.273	  0.032%	 94.654%	     0.000	        1	[densenet201/conv5_block16_0_relu/Relu;densenet201/conv5_block16_0_bn/FusedBatchNormV3]:422
	                 CONV_2D	          808.356	    1.126	    1.137	  0.133%	 94.787%	     0.000	        1	[densenet201/conv5_block16_1_relu/Relu;densenet201/conv5_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block16_1_conv/Conv2D]:423
	                 CONV_2D	          809.494	    0.393	    0.382	  0.045%	 94.832%	     0.000	        1	[densenet201/conv5_block16_2_conv/Conv2D1]:424
	           CONCATENATION	          809.876	    0.018	    0.018	  0.002%	 94.834%	     0.000	        1	[densenet201/conv5_block16_concat/concat]:425
	                     MUL	          809.895	    0.201	    0.202	  0.024%	 94.857%	     0.000	        1	[densenet201/conv5_block17_0_bn/FusedBatchNormV31]:426
	                     ADD	          810.097	    0.277	    0.280	  0.033%	 94.890%	     0.000	        1	[densenet201/conv5_block17_0_relu/Relu;densenet201/conv5_block17_0_bn/FusedBatchNormV3]:427
	                 CONV_2D	          810.378	    1.152	    1.169	  0.137%	 95.027%	     0.000	        1	[densenet201/conv5_block17_1_relu/Relu;densenet201/conv5_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block17_1_conv/Conv2D]:428
	                 CONV_2D	          811.548	    0.384	    0.387	  0.045%	 95.072%	     0.000	        1	[densenet201/conv5_block17_2_conv/Conv2D1]:429
	           CONCATENATION	          811.936	    0.016	    0.018	  0.002%	 95.075%	     0.000	        1	[densenet201/conv5_block17_concat/concat]:430
	                     MUL	          811.954	    0.195	    0.207	  0.024%	 95.099%	     0.000	        1	[densenet201/conv5_block18_0_bn/FusedBatchNormV31]:431
	                     ADD	          812.162	    0.289	    0.288	  0.034%	 95.132%	     0.000	        1	[densenet201/conv5_block18_0_relu/Relu;densenet201/conv5_block18_0_bn/FusedBatchNormV3]:432
	                 CONV_2D	          812.450	    1.199	    1.188	  0.139%	 95.272%	     0.000	        1	[densenet201/conv5_block18_1_relu/Relu;densenet201/conv5_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block18_1_conv/Conv2D]:433
	                 CONV_2D	          813.639	    0.394	    0.384	  0.045%	 95.317%	     0.000	        1	[densenet201/conv5_block18_2_conv/Conv2D1]:434
	           CONCATENATION	          814.024	    0.020	    0.019	  0.002%	 95.319%	     0.000	        1	[densenet201/conv5_block18_concat/concat]:435
	                     MUL	          814.044	    0.223	    0.210	  0.025%	 95.344%	     0.000	        1	[densenet201/conv5_block19_0_bn/FusedBatchNormV31]:436
	                     ADD	          814.255	    0.290	    0.293	  0.034%	 95.378%	     0.000	        1	[densenet201/conv5_block19_0_relu/Relu;densenet201/conv5_block19_0_bn/FusedBatchNormV3]:437
	                 CONV_2D	          814.549	    1.205	    1.222	  0.143%	 95.521%	     0.000	        1	[densenet201/conv5_block19_1_relu/Relu;densenet201/conv5_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block19_1_conv/Conv2D]:438
	                 CONV_2D	          815.771	    0.378	    0.383	  0.045%	 95.566%	     0.000	        1	[densenet201/conv5_block19_2_conv/Conv2D1]:439
	           CONCATENATION	          816.155	    0.035	    0.021	  0.003%	 95.569%	     0.000	        1	[densenet201/conv5_block19_concat/concat]:440
	                     MUL	          816.177	    0.206	    0.215	  0.025%	 95.594%	     0.000	        1	[densenet201/conv5_block20_0_bn/FusedBatchNormV31]:441
	                     ADD	          816.393	    0.300	    0.301	  0.035%	 95.629%	     0.000	        1	[densenet201/conv5_block20_0_relu/Relu;densenet201/conv5_block20_0_bn/FusedBatchNormV3]:442
	                 CONV_2D	          816.695	    1.264	    1.240	  0.145%	 95.774%	     0.000	        1	[densenet201/conv5_block20_1_relu/Relu;densenet201/conv5_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block20_1_conv/Conv2D]:443
	                 CONV_2D	          817.936	    0.386	    0.382	  0.045%	 95.819%	     0.000	        1	[densenet201/conv5_block20_2_conv/Conv2D1]:444
	           CONCATENATION	          818.319	    0.021	    0.019	  0.002%	 95.821%	     0.000	        1	[densenet201/conv5_block20_concat/concat]:445
	                     MUL	          818.338	    0.219	    0.219	  0.026%	 95.847%	     0.000	        1	[densenet201/conv5_block21_0_bn/FusedBatchNormV31]:446
	                     ADD	          818.558	    0.300	    0.309	  0.036%	 95.883%	     0.000	        1	[densenet201/conv5_block21_0_relu/Relu;densenet201/conv5_block21_0_bn/FusedBatchNormV3]:447
	                 CONV_2D	          818.867	    1.305	    1.272	  0.149%	 96.032%	     0.000	        1	[densenet201/conv5_block21_1_relu/Relu;densenet201/conv5_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block21_1_conv/Conv2D]:448
	                 CONV_2D	          820.140	    0.372	    0.382	  0.045%	 96.077%	     0.000	        1	[densenet201/conv5_block21_2_conv/Conv2D1]:449
	           CONCATENATION	          820.523	    0.019	    0.022	  0.003%	 96.080%	     0.000	        1	[densenet201/conv5_block21_concat/concat]:450
	                     MUL	          820.546	    0.221	    0.223	  0.026%	 96.106%	     0.000	        1	[densenet201/conv5_block22_0_bn/FusedBatchNormV31]:451
	                     ADD	          820.769	    0.305	    0.312	  0.037%	 96.142%	     0.000	        1	[densenet201/conv5_block22_0_relu/Relu;densenet201/conv5_block22_0_bn/FusedBatchNormV3]:452
	                 CONV_2D	          821.082	    1.306	    1.292	  0.151%	 96.294%	     0.000	        1	[densenet201/conv5_block22_1_relu/Relu;densenet201/conv5_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block22_1_conv/Conv2D]:453
	                 CONV_2D	          822.374	    0.393	    0.385	  0.045%	 96.339%	     0.000	        1	[densenet201/conv5_block22_2_conv/Conv2D1]:454
	           CONCATENATION	          822.760	    0.020	    0.021	  0.002%	 96.341%	     0.000	        1	[densenet201/conv5_block22_concat/concat]:455
	                     MUL	          822.782	    0.226	    0.229	  0.027%	 96.368%	     0.000	        1	[densenet201/conv5_block23_0_bn/FusedBatchNormV31]:456
	                     ADD	          823.011	    0.313	    0.323	  0.038%	 96.406%	     0.000	        1	[densenet201/conv5_block23_0_relu/Relu;densenet201/conv5_block23_0_bn/FusedBatchNormV3]:457
	                 CONV_2D	          823.335	    1.312	    1.323	  0.155%	 96.561%	     0.000	        1	[densenet201/conv5_block23_1_relu/Relu;densenet201/conv5_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block23_1_conv/Conv2D]:458
	                 CONV_2D	          824.658	    0.378	    0.384	  0.045%	 96.606%	     0.000	        1	[densenet201/conv5_block23_2_conv/Conv2D1]:459
	           CONCATENATION	          825.043	    0.021	    0.023	  0.003%	 96.609%	     0.000	        1	[densenet201/conv5_block23_concat/concat]:460
	                     MUL	          825.067	    0.231	    0.234	  0.027%	 96.636%	     0.000	        1	[densenet201/conv5_block24_0_bn/FusedBatchNormV31]:461
	                     ADD	          825.301	    0.341	    0.327	  0.038%	 96.674%	     0.000	        1	[densenet201/conv5_block24_0_relu/Relu;densenet201/conv5_block24_0_bn/FusedBatchNormV3]:462
	                 CONV_2D	          825.628	    1.347	    1.350	  0.158%	 96.832%	     0.000	        1	[densenet201/conv5_block24_1_relu/Relu;densenet201/conv5_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block24_1_conv/Conv2D]:463
	                 CONV_2D	          826.979	    0.378	    0.386	  0.045%	 96.878%	     0.000	        1	[densenet201/conv5_block24_2_conv/Conv2D1]:464
	           CONCATENATION	          827.366	    0.026	    0.025	  0.003%	 96.880%	     0.000	        1	[densenet201/conv5_block24_concat/concat]:465
	                     MUL	          827.391	    0.238	    0.237	  0.028%	 96.908%	     0.000	        1	[densenet201/conv5_block25_0_bn/FusedBatchNormV31]:466
	                     ADD	          827.629	    0.333	    0.332	  0.039%	 96.947%	     0.000	        1	[densenet201/conv5_block25_0_relu/Relu;densenet201/conv5_block25_0_bn/FusedBatchNormV3]:467
	                 CONV_2D	          827.961	    1.392	    1.377	  0.161%	 97.108%	     0.000	        1	[densenet201/conv5_block25_1_relu/Relu;densenet201/conv5_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block25_1_conv/Conv2D]:468
	                 CONV_2D	          829.339	    0.416	    0.384	  0.045%	 97.153%	     0.000	        1	[densenet201/conv5_block25_2_conv/Conv2D1]:469
	           CONCATENATION	          829.723	    0.026	    0.022	  0.003%	 97.156%	     0.000	        1	[densenet201/conv5_block25_concat/concat]:470
	                     MUL	          829.746	    0.240	    0.242	  0.028%	 97.184%	     0.000	        1	[densenet201/conv5_block26_0_bn/FusedBatchNormV31]:471
	                     ADD	          829.989	    0.333	    0.337	  0.039%	 97.224%	     0.000	        1	[densenet201/conv5_block26_0_relu/Relu;densenet201/conv5_block26_0_bn/FusedBatchNormV3]:472
	                 CONV_2D	          830.326	    1.391	    1.407	  0.165%	 97.389%	     0.000	        1	[densenet201/conv5_block26_1_relu/Relu;densenet201/conv5_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block26_1_conv/Conv2D]:473
	                 CONV_2D	          831.734	    0.381	    0.385	  0.045%	 97.434%	     0.000	        1	[densenet201/conv5_block26_2_conv/Conv2D1]:474
	           CONCATENATION	          832.120	    0.033	    0.023	  0.003%	 97.436%	     0.000	        1	[densenet201/conv5_block26_concat/concat]:475
	                     MUL	          832.143	    0.241	    0.245	  0.029%	 97.465%	     0.000	        1	[densenet201/conv5_block27_0_bn/FusedBatchNormV31]:476
	                     ADD	          832.389	    0.337	    0.345	  0.040%	 97.506%	     0.000	        1	[densenet201/conv5_block27_0_relu/Relu;densenet201/conv5_block27_0_bn/FusedBatchNormV3]:477
	                 CONV_2D	          832.735	    1.450	    1.427	  0.167%	 97.673%	     0.000	        1	[densenet201/conv5_block27_1_relu/Relu;densenet201/conv5_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block27_1_conv/Conv2D]:478
	                 CONV_2D	          834.162	    0.387	    0.385	  0.045%	 97.718%	     0.000	        1	[densenet201/conv5_block27_2_conv/Conv2D1]:479
	           CONCATENATION	          834.548	    0.028	    0.025	  0.003%	 97.721%	     0.000	        1	[densenet201/conv5_block27_concat/concat]:480
	                     MUL	          834.573	    0.251	    0.255	  0.030%	 97.751%	     0.000	        1	[densenet201/conv5_block28_0_bn/FusedBatchNormV31]:481
	                     ADD	          834.829	    0.350	    0.352	  0.041%	 97.792%	     0.000	        1	[densenet201/conv5_block28_0_relu/Relu;densenet201/conv5_block28_0_bn/FusedBatchNormV3]:482
	                 CONV_2D	          835.182	    1.443	    1.457	  0.171%	 97.963%	     0.000	        1	[densenet201/conv5_block28_1_relu/Relu;densenet201/conv5_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block28_1_conv/Conv2D]:483
	                 CONV_2D	          836.640	    0.377	    0.383	  0.045%	 98.007%	     0.000	        1	[densenet201/conv5_block28_2_conv/Conv2D1]:484
	           CONCATENATION	          837.023	    0.027	    0.025	  0.003%	 98.010%	     0.000	        1	[densenet201/conv5_block28_concat/concat]:485
	                     MUL	          837.049	    0.250	    0.255	  0.030%	 98.040%	     0.000	        1	[densenet201/conv5_block29_0_bn/FusedBatchNormV31]:486
	                     ADD	          837.305	    0.382	    0.357	  0.042%	 98.082%	     0.000	        1	[densenet201/conv5_block29_0_relu/Relu;densenet201/conv5_block29_0_bn/FusedBatchNormV3]:487
	                 CONV_2D	          837.663	    1.472	    1.482	  0.174%	 98.256%	     0.000	        1	[densenet201/conv5_block29_1_relu/Relu;densenet201/conv5_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block29_1_conv/Conv2D]:488
	                 CONV_2D	          839.145	    0.383	    0.394	  0.046%	 98.302%	     0.000	        1	[densenet201/conv5_block29_2_conv/Conv2D1]:489
	           CONCATENATION	          839.540	    0.029	    0.027	  0.003%	 98.305%	     0.000	        1	[densenet201/conv5_block29_concat/concat]:490
	                     MUL	          839.568	    0.257	    0.259	  0.030%	 98.336%	     0.000	        1	[densenet201/conv5_block30_0_bn/FusedBatchNormV31]:491
	                     ADD	          839.828	    0.362	    0.363	  0.043%	 98.378%	     0.000	        1	[densenet201/conv5_block30_0_relu/Relu;densenet201/conv5_block30_0_bn/FusedBatchNormV3]:492
	                 CONV_2D	          840.191	    1.514	    1.505	  0.176%	 98.554%	     0.000	        1	[densenet201/conv5_block30_1_relu/Relu;densenet201/conv5_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block30_1_conv/Conv2D]:493
	                 CONV_2D	          841.697	    0.380	    0.390	  0.046%	 98.600%	     0.000	        1	[densenet201/conv5_block30_2_conv/Conv2D1]:494
	           CONCATENATION	          842.088	    0.025	    0.028	  0.003%	 98.603%	     0.000	        1	[densenet201/conv5_block30_concat/concat]:495
	                     MUL	          842.116	    0.261	    0.261	  0.031%	 98.634%	     0.000	        1	[densenet201/conv5_block31_0_bn/FusedBatchNormV31]:496
	                     ADD	          842.378	    0.369	    0.372	  0.044%	 98.677%	     0.000	        1	[densenet201/conv5_block31_0_relu/Relu;densenet201/conv5_block31_0_bn/FusedBatchNormV3]:497
	                 CONV_2D	          842.750	    1.514	    1.528	  0.179%	 98.856%	     0.000	        1	[densenet201/conv5_block31_1_relu/Relu;densenet201/conv5_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block31_1_conv/Conv2D]:498
	                 CONV_2D	          844.279	    0.400	    0.391	  0.046%	 98.902%	     0.000	        1	[densenet201/conv5_block31_2_conv/Conv2D1]:499
	           CONCATENATION	          844.671	    0.046	    0.032	  0.004%	 98.906%	     0.000	        1	[densenet201/conv5_block31_concat/concat]:500
	                     MUL	          844.704	    0.267	    0.271	  0.032%	 98.938%	     0.000	        1	[densenet201/conv5_block32_0_bn/FusedBatchNormV31]:501
	                     ADD	          844.976	    0.367	    0.376	  0.044%	 98.982%	     0.000	        1	[densenet201/conv5_block32_0_relu/Relu;densenet201/conv5_block32_0_bn/FusedBatchNormV3]:502
	                 CONV_2D	          845.352	    1.585	    1.561	  0.183%	 99.165%	     0.000	        1	[densenet201/conv5_block32_1_relu/Relu;densenet201/conv5_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block32_1_conv/Conv2D]:503
	                 CONV_2D	          846.914	    0.375	    0.391	  0.046%	 99.210%	     0.000	        1	[densenet201/conv5_block32_2_conv/Conv2D210]:504
	           CONCATENATION	          847.306	    0.028	    0.032	  0.004%	 99.214%	     0.000	        1	[densenet201/conv5_block32_concat/concat]:505
	                     MUL	          847.338	    0.268	    0.272	  0.032%	 99.246%	     0.000	        1	[densenet201/bn/FusedBatchNormV31]:506
	                     ADD	          847.611	    0.381	    0.382	  0.045%	 99.291%	     0.000	        1	[densenet201/relu/Relu;densenet201/bn/FusedBatchNormV3]:507
	                    MEAN	          847.993	    5.147	    5.160	  0.605%	 99.895%	     0.000	        1	[densenet201/avg_pool/Mean]:508
	         FULLY_CONNECTED	          853.154	    0.921	    0.878	  0.103%	 99.998%	     0.000	        1	[densenet201/predictions/MatMul;densenet201/predictions/BiasAdd]:509
	                 SOFTMAX	          854.034	    0.014	    0.015	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:510

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          747.564	   33.919	   34.018	  3.985%	  3.985%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	                 CONV_2D	           35.252	   26.921	   27.314	  3.200%	  7.185%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	                 CONV_2D	           70.549	   27.222	   27.072	  3.171%	 10.356%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	                 CONV_2D	          107.965	   27.048	   26.992	  3.162%	 13.518%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	                 CONV_2D	          233.812	   27.053	   26.858	  3.146%	 16.665%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	                 CONV_2D	          189.459	   26.682	   26.760	  3.135%	 19.800%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	                 CONV_2D	          147.658	   26.808	   26.687	  3.126%	 22.926%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	                 CONV_2D	            1.145	   24.301	   24.092	  2.822%	 25.748%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                 CONV_2D	          266.735	   14.002	   13.953	  1.635%	 27.383%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	                 CONV_2D	          221.532	   12.281	   12.279	  1.438%	 28.821%	     0.000	        1	[densenet201/conv2_block6_1_relu/Relu;densenet201/conv2_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block6_1_conv/Conv2D]:31

Number of nodes executed: 511
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	      200	   694.497	    81.382%	    81.382%	     0.000	      200
	                     ADD	      102	    77.801	     9.117%	    90.498%	     0.000	      102
	                     MUL	      102	    54.812	     6.423%	    96.921%	     0.000	      102
	           CONCATENATION	       98	    12.761	     1.495%	    98.417%	     0.000	       98
	                    MEAN	        1	     5.160	     0.605%	    99.021%	     0.000	        1
	                     PAD	        2	     4.791	     0.561%	    99.583%	     0.000	        2
	         AVERAGE_POOL_2D	        3	     1.918	     0.225%	    99.807%	     0.000	        3
	         FULLY_CONNECTED	        1	     0.878	     0.103%	    99.910%	     0.000	        1
	             MAX_POOL_2D	        1	     0.750	     0.088%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.015	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=853211 curr=852950 min=850343 max=857128 avg=853630 std=1155
Memory (bytes): count=0
511 nodes observed



munmap_chunk(): invalid pointer
[ perf record: Woken up 241 times to write data ]
Warning:
Processed 350624 events and lost 1 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 60.313 MB /tmp/data.record (350056 samples) ]

91.549

