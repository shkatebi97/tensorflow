STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ) (or (22201, 27, )), Output shape (22201, 32, ), ID: 0, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (16, 32, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (32, 32, ) DONE
	Preparing Filter With Shape: (27, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 32, ) DONE
	Allocating An Output Temporary Tensor With Shape: (22204, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 32, ), Input shape (22201, 32, ) (or (21609, 288, )), Output shape (21609, 32, ), ID: 1, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 32, ) DONE
	Preparing Filter With Shape: (288, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (21609, 32, ) (or (21609, 288, )), Output shape (21609, 64, ), ID: 2, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 80, ), Input shape (5329, 64, ) (or (5329, 64, )), Output shape (5329, 80, ), ID: 3, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (5329, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 80, ) DONE
	Preparing Filter With Shape: (64, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5332, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (720, 192, ), Input shape (5329, 80, ) (or (5041, 720, )), Output shape (5041, 192, ), ID: 4, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (5041, 720, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (368, 192, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (736, 192, ) DONE
	Preparing Filter With Shape: (720, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 736, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 736, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5044, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 32, ), ID: 5, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 32, ) DONE
	Preparing Filter With Shape: (192, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 6, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 48, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 48, ), ID: 7, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 48, ) DONE
	Preparing Filter With Shape: (192, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 8, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 9, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 10, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 11, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 12, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 13, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 48, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 48, ), ID: 14, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 48, ) DONE
	Preparing Filter With Shape: (256, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 15, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 16, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 17, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 18, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 19, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 20, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 48, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 48, ), ID: 21, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 48, ) DONE
	Preparing Filter With Shape: (288, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 22, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 23, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 24, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 25, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (2592, 384, ), Input shape (1225, 288, ) (or (289, 2592, )), Output shape (289, 384, ), ID: 26, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 2592, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1296, 384, ) DONE
	Preparing Filter With Shape: (2592, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 2592, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 2592, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 27, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (144, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 28, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (289, 864, )), Output shape (289, 96, ), ID: 29, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (432, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 864, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 30, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 31, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 32, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 33, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 34, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 35, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 36, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 37, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 38, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 39, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 40, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 41, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 42, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 43, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 44, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 45, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 46, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 47, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 48, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 49, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 50, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 51, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 52, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 53, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 54, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 55, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 56, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 57, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 58, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 59, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (560, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 60, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 61, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 62, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 63, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 64, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 65, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 66, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 67, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 68, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 69, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 70, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 320, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 320, ), ID: 71, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 320, ) DONE
	Preparing Filter With Shape: (1728, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1728, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 72, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 73, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 74, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 192, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 192, ), ID: 75, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 192, ) DONE
	Preparing Filter With Shape: (1728, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1728, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 192, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 192, ), ID: 76, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 192, ) DONE
	Preparing Filter With Shape: (1280, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1280, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 320, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 320, ), ID: 77, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 320, ) DONE
	Preparing Filter With Shape: (1280, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1280, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 384, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 384, ), ID: 78, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 384, ) DONE
	Preparing Filter With Shape: (1280, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1280, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 79, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 80, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 448, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 448, ), ID: 81, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 448, ) DONE
	Preparing Filter With Shape: (1280, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1280, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 82, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2016, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 4032, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 83, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 84, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 192, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 192, ), ID: 85, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 192, ) DONE
	Preparing Filter With Shape: (2048, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2048, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 320, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 320, ), ID: 86, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 320, ) DONE
	Preparing Filter With Shape: (2048, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2048, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 384, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 384, ), ID: 87, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 384, ) DONE
	Preparing Filter With Shape: (2048, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2048, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 88, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 89, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 448, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 448, ), ID: 90, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 448, ) DONE
	Preparing Filter With Shape: (2048, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2048, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 91, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2016, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 4032, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 92, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 93, Method: SelfDependentW4A8
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1152, ) DONE
Applying FC Low-Precision for Kernel shape (2048, 1000, ), Input shape (1, 2048, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW4A8
	Allocating Filter Shape: (1024, 1000, ) DONE
	Preparing Filter With Shape: (2048, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 24.2886
Initialized session in 233.124ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=942886 curr=861032 min=861032 max=942886 avg=901959 std=40927

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=859705 curr=864897 min=845000 max=900578 avg=865472 std=6763

Inference timings in us: Init: 233124, First inference: 942886, Warmup (avg): 901959, Inference (avg): 865472
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=40.6562 overall=72.7109
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  227.282	  227.282	100.000%	100.000%	 31460.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  227.282	  227.282	100.000%	100.000%	 31460.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   227.282	   100.000%	   100.000%	 31460.000	        1

Timings (microseconds): count=1 curr=227282
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.020	    8.832	    8.711	  1.007%	  1.007%	     0.000	        1	[inception_v3/activation/Relu;inception_v3/batch_normalization/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d/Conv2D]:0
	                 CONV_2D	            8.732	   50.762	   51.217	  5.919%	  6.926%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	           59.950	   74.154	   74.058	  8.559%	 15.484%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	             MAX_POOL_2D	          134.009	    0.939	    0.927	  0.107%	 15.591%	     0.000	        1	[inception_v3/max_pooling2d/MaxPool]:3
	                 CONV_2D	          134.937	    5.491	    5.496	  0.635%	 16.227%	     0.000	        1	[inception_v3/activation_3/Relu;inception_v3/batch_normalization_3/FusedBatchNormV3;inception_v3/batch_normalization_3/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_3/Conv2D]:4
	                 CONV_2D	          140.434	   93.782	   93.007	 10.749%	 26.975%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	             MAX_POOL_2D	          233.442	    0.651	    0.562	  0.065%	 27.040%	     0.000	        1	[inception_v3/max_pooling2d_1/MaxPool]:6
	         AVERAGE_POOL_2D	          234.004	    2.223	    2.161	  0.250%	 27.290%	     0.000	        1	[inception_v3/average_pooling2d/AvgPool]:7
	                 CONV_2D	          236.166	    1.736	    1.753	  0.203%	 27.492%	     0.000	        1	[inception_v3/activation_11/Relu;inception_v3/batch_normalization_11/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_11/Conv2D]:8
	                 CONV_2D	          237.921	    2.667	    2.665	  0.308%	 27.800%	     0.000	        1	[inception_v3/activation_5/Relu;inception_v3/batch_normalization_5/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_5/Conv2D]:9
	                 CONV_2D	          240.587	    2.265	    2.171	  0.251%	 28.051%	     0.000	        1	[inception_v3/activation_6/Relu;inception_v3/batch_normalization_6/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_6/Conv2D]:10
	                 CONV_2D	          242.759	   17.482	   17.398	  2.011%	 30.062%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          260.158	    2.709	    2.614	  0.302%	 30.364%	     0.000	        1	[inception_v3/activation_8/Relu;inception_v3/batch_normalization_8/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_8/Conv2D]:12
	                 CONV_2D	          262.773	   10.997	   10.757	  1.243%	 31.607%	     0.000	        1	[inception_v3/activation_9/Relu;inception_v3/batch_normalization_9/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_9/Conv2D]:13
	                 CONV_2D	          273.531	   16.100	   15.999	  1.849%	 33.456%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	           CONCATENATION	          289.531	    0.267	    0.219	  0.025%	 33.481%	     0.000	        1	[inception_v3/mixed0/concat]:15
	         AVERAGE_POOL_2D	          289.751	    3.586	    3.623	  0.419%	 33.900%	     0.000	        1	[inception_v3/average_pooling2d_1/AvgPool]:16
	                 CONV_2D	          293.375	    3.564	    3.528	  0.408%	 34.308%	     0.000	        1	[inception_v3/activation_18/Relu;inception_v3/batch_normalization_18/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_18/Conv2D]:17
	                 CONV_2D	          296.904	    3.616	    3.421	  0.395%	 34.703%	     0.000	        1	[inception_v3/activation_12/Relu;inception_v3/batch_normalization_12/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_12/Conv2D]:18
	                 CONV_2D	          300.326	    2.892	    2.883	  0.333%	 35.036%	     0.000	        1	[inception_v3/activation_13/Relu;inception_v3/batch_normalization_13/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_13/Conv2D]:19
	                 CONV_2D	          303.210	   17.268	   17.349	  2.005%	 37.041%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          320.560	    3.372	    3.417	  0.395%	 37.436%	     0.000	        1	[inception_v3/activation_15/Relu;inception_v3/batch_normalization_15/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_15/Conv2D]:21
	                 CONV_2D	          323.978	   10.624	   10.775	  1.245%	 38.681%	     0.000	        1	[inception_v3/activation_16/Relu;inception_v3/batch_normalization_16/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_16/Conv2D]:22
	                 CONV_2D	          334.754	   15.737	   16.022	  1.852%	 40.533%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	           CONCATENATION	          350.776	    0.234	    0.253	  0.029%	 40.562%	     0.000	        1	[inception_v3/mixed1/concat]:24
	         AVERAGE_POOL_2D	          351.030	    4.149	    4.097	  0.474%	 41.036%	     0.000	        1	[inception_v3/average_pooling2d_2/AvgPool]:25
	                 CONV_2D	          355.128	    4.074	    3.896	  0.450%	 41.486%	     0.000	        1	[inception_v3/activation_25/Relu;inception_v3/batch_normalization_25/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_25/Conv2D]:26
	                 CONV_2D	          359.025	    4.021	    3.865	  0.447%	 41.933%	     0.000	        1	[inception_v3/activation_19/Relu;inception_v3/batch_normalization_19/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_19/Conv2D]:27
	                 CONV_2D	          362.892	    3.207	    3.242	  0.375%	 42.307%	     0.000	        1	[inception_v3/activation_20/Relu;inception_v3/batch_normalization_20/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_20/Conv2D]:28
	                 CONV_2D	          366.135	   17.686	   17.388	  2.010%	 44.317%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          383.524	    3.986	    3.870	  0.447%	 44.764%	     0.000	        1	[inception_v3/activation_22/Relu;inception_v3/batch_normalization_22/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_22/Conv2D]:30
	                 CONV_2D	          387.396	   11.141	   10.893	  1.259%	 46.023%	     0.000	        1	[inception_v3/activation_23/Relu;inception_v3/batch_normalization_23/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_23/Conv2D]:31
	                 CONV_2D	          398.290	   16.316	   16.006	  1.850%	 47.873%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	           CONCATENATION	          414.297	    0.255	    0.257	  0.030%	 47.902%	     0.000	        1	[inception_v3/mixed2/concat]:33
	                 CONV_2D	          414.555	   34.384	   34.387	  3.974%	 51.876%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          448.943	    3.870	    3.900	  0.451%	 52.327%	     0.000	        1	[inception_v3/activation_27/Relu;inception_v3/batch_normalization_27/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_27/Conv2D]:35
	                 CONV_2D	          452.843	   10.924	   10.823	  1.251%	 53.578%	     0.000	        1	[inception_v3/activation_28/Relu;inception_v3/batch_normalization_28/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_28/Conv2D]:36
	                 CONV_2D	          463.668	    3.577	    3.641	  0.421%	 53.999%	     0.000	        1	[inception_v3/activation_29/Relu;inception_v3/batch_normalization_29/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_29/Conv2D]:37
	             MAX_POOL_2D	          467.310	    0.220	    0.249	  0.029%	 54.027%	     0.000	        1	[inception_v3/max_pooling2d_2/MaxPool]:38
	           CONCATENATION	          467.559	    0.115	    0.126	  0.015%	 54.042%	     0.000	        1	[inception_v3/mixed3/concat]:39
	         AVERAGE_POOL_2D	          467.687	    2.375	    2.382	  0.275%	 54.317%	     0.000	        1	[inception_v3/average_pooling2d_3/AvgPool]:40
	                 CONV_2D	          470.070	    5.310	    5.372	  0.621%	 54.938%	     0.000	        1	[inception_v3/activation_39/Relu;inception_v3/batch_normalization_39/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_39/Conv2D]:41
	                 CONV_2D	          475.443	    5.278	    5.391	  0.623%	 55.561%	     0.000	        1	[inception_v3/activation_30/Relu;inception_v3/batch_normalization_30/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_30/Conv2D]:42
	                 CONV_2D	          480.836	    3.823	    3.866	  0.447%	 56.008%	     0.000	        1	[inception_v3/activation_31/Relu;inception_v3/batch_normalization_31/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_31/Conv2D]:43
	                 CONV_2D	          484.702	    4.553	    4.598	  0.531%	 56.539%	     0.000	        1	[inception_v3/activation_32/Relu;inception_v3/batch_normalization_32/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_32/Conv2D]:44
	                 CONV_2D	          489.302	    6.254	    6.367	  0.736%	 57.275%	     0.000	        1	[inception_v3/activation_33/Relu;inception_v3/batch_normalization_33/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_33/Conv2D]:45
	                 CONV_2D	          495.670	    3.823	    3.887	  0.449%	 57.724%	     0.000	        1	[inception_v3/activation_34/Relu;inception_v3/batch_normalization_34/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_34/Conv2D]:46
	                 CONV_2D	          499.558	    4.525	    4.608	  0.533%	 58.257%	     0.000	        1	[inception_v3/activation_35/Relu;inception_v3/batch_normalization_35/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_35/Conv2D]:47
	                 CONV_2D	          504.167	    4.501	    4.599	  0.531%	 58.788%	     0.000	        1	[inception_v3/activation_36/Relu;inception_v3/batch_normalization_36/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_36/Conv2D]:48
	                 CONV_2D	          508.767	    4.531	    4.630	  0.535%	 59.323%	     0.000	        1	[inception_v3/activation_37/Relu;inception_v3/batch_normalization_37/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_37/Conv2D]:49
	                 CONV_2D	          513.398	    6.385	    6.367	  0.736%	 60.059%	     0.000	        1	[inception_v3/activation_38/Relu;inception_v3/batch_normalization_38/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_38/Conv2D]:50
	           CONCATENATION	          519.765	    0.142	    0.160	  0.019%	 60.078%	     0.000	        1	[inception_v3/mixed4/concat]:51
	         AVERAGE_POOL_2D	          519.926	    2.540	    2.563	  0.296%	 60.374%	     0.000	        1	[inception_v3/average_pooling2d_4/AvgPool]:52
	                 CONV_2D	          522.490	    5.346	    5.379	  0.622%	 60.996%	     0.000	        1	[inception_v3/activation_49/Relu;inception_v3/batch_normalization_49/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_49/Conv2D]:53
	                 CONV_2D	          527.873	    5.275	    5.389	  0.623%	 61.618%	     0.000	        1	[inception_v3/activation_40/Relu;inception_v3/batch_normalization_40/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_40/Conv2D]:54
	                 CONV_2D	          533.263	    4.619	    4.620	  0.534%	 62.152%	     0.000	        1	[inception_v3/activation_41/Relu;inception_v3/batch_normalization_41/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_41/Conv2D]:55
	                 CONV_2D	          537.884	    6.734	    6.851	  0.792%	 62.944%	     0.000	        1	[inception_v3/activation_42/Relu;inception_v3/batch_normalization_42/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_42/Conv2D]:56
	                 CONV_2D	          544.736	    7.901	    7.982	  0.922%	 63.867%	     0.000	        1	[inception_v3/activation_43/Relu;inception_v3/batch_normalization_43/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_43/Conv2D]:57
	                 CONV_2D	          552.719	    4.539	    4.632	  0.535%	 64.402%	     0.000	        1	[inception_v3/activation_44/Relu;inception_v3/batch_normalization_44/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_44/Conv2D]:58
	                 CONV_2D	          557.352	    6.949	    6.887	  0.796%	 65.198%	     0.000	        1	[inception_v3/activation_45/Relu;inception_v3/batch_normalization_45/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_45/Conv2D]:59
	                 CONV_2D	          564.240	    6.840	    6.860	  0.793%	 65.990%	     0.000	        1	[inception_v3/activation_46/Relu;inception_v3/batch_normalization_46/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_46/Conv2D]:60
	                 CONV_2D	          571.100	    6.923	    6.883	  0.795%	 66.786%	     0.000	        1	[inception_v3/activation_47/Relu;inception_v3/batch_normalization_47/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_47/Conv2D]:61
	                 CONV_2D	          577.984	    7.931	    7.953	  0.919%	 67.705%	     0.000	        1	[inception_v3/activation_48/Relu;inception_v3/batch_normalization_48/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_48/Conv2D]:62
	           CONCATENATION	          585.938	    0.129	    0.158	  0.018%	 67.723%	     0.000	        1	[inception_v3/mixed5/concat]:63
	         AVERAGE_POOL_2D	          586.097	    2.537	    2.584	  0.299%	 68.022%	     0.000	        1	[inception_v3/average_pooling2d_5/AvgPool]:64
	                 CONV_2D	          588.682	    5.307	    5.416	  0.626%	 68.648%	     0.000	        1	[inception_v3/activation_59/Relu;inception_v3/batch_normalization_59/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_59/Conv2D]:65
	                 CONV_2D	          594.099	    5.369	    5.412	  0.625%	 69.273%	     0.000	        1	[inception_v3/activation_50/Relu;inception_v3/batch_normalization_50/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_50/Conv2D]:66
	                 CONV_2D	          599.512	    4.541	    4.641	  0.536%	 69.810%	     0.000	        1	[inception_v3/activation_51/Relu;inception_v3/batch_normalization_51/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_51/Conv2D]:67
	                 CONV_2D	          604.154	    6.851	    6.885	  0.796%	 70.605%	     0.000	        1	[inception_v3/activation_52/Relu;inception_v3/batch_normalization_52/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_52/Conv2D]:68
	                 CONV_2D	          611.041	    7.784	    8.000	  0.925%	 71.530%	     0.000	        1	[inception_v3/activation_53/Relu;inception_v3/batch_normalization_53/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_53/Conv2D]:69
	                 CONV_2D	          619.042	    4.537	    4.639	  0.536%	 72.066%	     0.000	        1	[inception_v3/activation_54/Relu;inception_v3/batch_normalization_54/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_54/Conv2D]:70
	                 CONV_2D	          623.682	    6.682	    6.906	  0.798%	 72.864%	     0.000	        1	[inception_v3/activation_55/Relu;inception_v3/batch_normalization_55/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_55/Conv2D]:71
	                 CONV_2D	          630.589	    6.831	    6.889	  0.796%	 73.660%	     0.000	        1	[inception_v3/activation_56/Relu;inception_v3/batch_normalization_56/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_56/Conv2D]:72
	                 CONV_2D	          637.479	    6.820	    6.924	  0.800%	 74.461%	     0.000	        1	[inception_v3/activation_57/Relu;inception_v3/batch_normalization_57/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_57/Conv2D]:73
	                 CONV_2D	          644.405	    7.831	    7.950	  0.919%	 75.379%	     0.000	        1	[inception_v3/activation_58/Relu;inception_v3/batch_normalization_58/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_58/Conv2D]:74
	           CONCATENATION	          652.356	    0.158	    0.154	  0.018%	 75.397%	     0.000	        1	[inception_v3/mixed6/concat]:75
	         AVERAGE_POOL_2D	          652.511	    2.512	    2.548	  0.294%	 75.692%	     0.000	        1	[inception_v3/average_pooling2d_6/AvgPool]:76
	                 CONV_2D	          655.060	    5.318	    5.359	  0.619%	 76.311%	     0.000	        1	[inception_v3/activation_69/Relu;inception_v3/batch_normalization_69/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_69/Conv2D]:77
	                 CONV_2D	          660.420	    5.293	    5.377	  0.621%	 76.932%	     0.000	        1	[inception_v3/activation_60/Relu;inception_v3/batch_normalization_60/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_60/Conv2D]:78
	                 CONV_2D	          665.798	    5.499	    5.384	  0.622%	 77.554%	     0.000	        1	[inception_v3/activation_61/Relu;inception_v3/batch_normalization_61/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_61/Conv2D]:79
	                 CONV_2D	          671.182	    9.600	    9.613	  1.111%	 78.665%	     0.000	        1	[inception_v3/activation_62/Relu;inception_v3/batch_normalization_62/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_62/Conv2D]:80
	                 CONV_2D	          680.796	    9.450	    9.629	  1.113%	 79.778%	     0.000	        1	[inception_v3/activation_63/Relu;inception_v3/batch_normalization_63/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_63/Conv2D]:81
	                 CONV_2D	          690.426	    5.375	    5.404	  0.625%	 80.403%	     0.000	        1	[inception_v3/activation_64/Relu;inception_v3/batch_normalization_64/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_64/Conv2D]:82
	                 CONV_2D	          695.831	    9.376	    9.615	  1.111%	 81.514%	     0.000	        1	[inception_v3/activation_65/Relu;inception_v3/batch_normalization_65/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_65/Conv2D]:83
	                 CONV_2D	          705.447	    9.298	    9.605	  1.110%	 82.624%	     0.000	        1	[inception_v3/activation_66/Relu;inception_v3/batch_normalization_66/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_66/Conv2D]:84
	                 CONV_2D	          715.053	    9.294	    9.596	  1.109%	 83.733%	     0.000	        1	[inception_v3/activation_67/Relu;inception_v3/batch_normalization_67/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_67/Conv2D]:85
	                 CONV_2D	          724.650	    9.348	    9.673	  1.118%	 84.851%	     0.000	        1	[inception_v3/activation_68/Relu;inception_v3/batch_normalization_68/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_68/Conv2D]:86
	           CONCATENATION	          734.324	    0.185	    0.151	  0.017%	 84.868%	     0.000	        1	[inception_v3/mixed7/concat]:87
	                 CONV_2D	          734.477	    5.276	    5.417	  0.626%	 85.494%	     0.000	        1	[inception_v3/activation_70/Relu;inception_v3/batch_normalization_70/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_70/Conv2D]:88
	                 CONV_2D	          739.894	    4.009	    4.167	  0.482%	 85.976%	     0.000	        1	[inception_v3/activation_71/Relu;inception_v3/batch_normalization_71/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_71/Conv2D]:89
	                 CONV_2D	          744.062	    5.276	    5.436	  0.628%	 86.604%	     0.000	        1	[inception_v3/activation_72/Relu;inception_v3/batch_normalization_72/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_72/Conv2D]:90
	                 CONV_2D	          749.499	    9.392	    9.649	  1.115%	 87.719%	     0.000	        1	[inception_v3/activation_73/Relu;inception_v3/batch_normalization_73/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_73/Conv2D]:91
	                 CONV_2D	          759.149	    9.386	    9.650	  1.115%	 88.834%	     0.000	        1	[inception_v3/activation_74/Relu;inception_v3/batch_normalization_74/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_74/Conv2D]:92
	                 CONV_2D	          768.800	    2.596	    2.663	  0.308%	 89.142%	     0.000	        1	[inception_v3/activation_75/Relu;inception_v3/batch_normalization_75/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_75/Conv2D]:93
	             MAX_POOL_2D	          771.464	    0.191	    0.186	  0.022%	 89.164%	     0.000	        1	[inception_v3/max_pooling2d_3/MaxPool]:94
	           CONCATENATION	          771.651	    0.029	    0.040	  0.005%	 89.168%	     0.000	        1	[inception_v3/mixed8/concat]:95
	         AVERAGE_POOL_2D	          771.692	    0.776	    0.810	  0.094%	 89.262%	     0.000	        1	[inception_v3/average_pooling2d_7/AvgPool]:96
	                 CONV_2D	          772.503	    1.915	    1.933	  0.223%	 89.485%	     0.000	        1	[inception_v3/activation_84/Relu;inception_v3/batch_normalization_84/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_84/Conv2D]:97
	                 CONV_2D	          774.437	    2.860	    3.025	  0.350%	 89.835%	     0.000	        1	[inception_v3/activation_76/Relu;inception_v3/batch_normalization_76/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_76/Conv2D]:98
	                 CONV_2D	          777.463	    3.544	    3.586	  0.414%	 90.249%	     0.000	        1	[inception_v3/activation_77/Relu;inception_v3/batch_normalization_77/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_77/Conv2D]:99
	                 CONV_2D	          781.050	    3.154	    3.303	  0.382%	 90.631%	     0.000	        1	[inception_v3/activation_78/Relu;inception_v3/batch_normalization_78/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_78/Conv2D]:100
	                 CONV_2D	          784.354	    3.111	    3.291	  0.380%	 91.011%	     0.000	        1	[inception_v3/activation_79/Relu;inception_v3/batch_normalization_79/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_79/Conv2D]:101
	           CONCATENATION	          787.646	    0.028	    0.041	  0.005%	 91.016%	     0.000	        1	[inception_v3/mixed9_0/concat]:102
	                 CONV_2D	          787.688	    4.083	    4.170	  0.482%	 91.498%	     0.000	        1	[inception_v3/activation_80/Relu;inception_v3/batch_normalization_80/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_80/Conv2D]:103
	                 CONV_2D	          791.859	   11.320	   11.543	  1.334%	 92.832%	     0.000	        1	[inception_v3/activation_81/Relu;inception_v3/batch_normalization_81/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_81/Conv2D]:104
	                 CONV_2D	          803.403	    3.178	    3.311	  0.383%	 93.215%	     0.000	        1	[inception_v3/activation_82/Relu;inception_v3/batch_normalization_82/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_82/Conv2D]:105
	                 CONV_2D	          806.715	    3.101	    3.304	  0.382%	 93.597%	     0.000	        1	[inception_v3/activation_83/Relu;inception_v3/batch_normalization_83/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_83/Conv2D]:106
	           CONCATENATION	          810.020	    0.022	    0.038	  0.004%	 93.601%	     0.000	        1	[inception_v3/concatenate/concat]:107
	           CONCATENATION	          810.060	    0.051	    0.077	  0.009%	 93.610%	     0.000	        1	[inception_v3/mixed9/concat]:108
	         AVERAGE_POOL_2D	          810.137	    1.486	    1.531	  0.177%	 93.787%	     0.000	        1	[inception_v3/average_pooling2d_8/AvgPool]:109
	                 CONV_2D	          811.669	    2.916	    3.084	  0.356%	 94.143%	     0.000	        1	[inception_v3/activation_93/Relu;inception_v3/batch_normalization_93/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_93/Conv2D]:110
	                 CONV_2D	          814.754	    4.708	    4.862	  0.562%	 94.705%	     0.000	        1	[inception_v3/activation_85/Relu;inception_v3/batch_normalization_85/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_85/Conv2D]:111
	                 CONV_2D	          819.617	    5.501	    5.832	  0.674%	 95.379%	     0.000	        1	[inception_v3/activation_86/Relu;inception_v3/batch_normalization_86/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_86/Conv2D]:112
	                 CONV_2D	          825.450	    3.230	    3.334	  0.385%	 95.764%	     0.000	        1	[inception_v3/activation_87/Relu;inception_v3/batch_normalization_87/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_87/Conv2D]:113
	                 CONV_2D	          828.785	    3.139	    3.305	  0.382%	 96.146%	     0.000	        1	[inception_v3/activation_88/Relu;inception_v3/batch_normalization_88/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_88/Conv2D]:114
	           CONCATENATION	          832.090	    0.027	    0.040	  0.005%	 96.151%	     0.000	        1	[inception_v3/mixed9_1/concat]:115
	                 CONV_2D	          832.132	    6.384	    6.690	  0.773%	 96.924%	     0.000	        1	[inception_v3/activation_89/Relu;inception_v3/batch_normalization_89/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_89/Conv2D]:116
	                 CONV_2D	          838.823	   11.343	   11.640	  1.345%	 98.269%	     0.000	        1	[inception_v3/activation_90/Relu;inception_v3/batch_normalization_90/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_90/Conv2D]:117
	                 CONV_2D	          850.464	    3.266	    3.300	  0.381%	 98.651%	     0.000	        1	[inception_v3/activation_91/Relu;inception_v3/batch_normalization_91/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_91/Conv2D]:118
	                 CONV_2D	          853.766	    3.167	    3.302	  0.382%	 99.032%	     0.000	        1	[inception_v3/activation_92/Relu;inception_v3/batch_normalization_92/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_92/Conv2D]:119
	           CONCATENATION	          857.069	    0.026	    0.041	  0.005%	 99.037%	     0.000	        1	[inception_v3/concatenate_1/concat]:120
	           CONCATENATION	          857.111	    0.061	    0.078	  0.009%	 99.046%	     0.000	        1	[inception_v3/mixed10/concat]:121
	                    MEAN	          857.191	    7.127	    7.260	  0.839%	 99.885%	     0.000	        1	[inception_v3/avg_pool/Mean]:122
	         FULLY_CONNECTED	          864.452	    0.938	    0.979	  0.113%	 99.998%	     0.000	        1	[inception_v3/predictions/MatMul;inception_v3/predictions/BiasAdd]:123
	                 SOFTMAX	          865.432	    0.015	    0.016	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:124

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          140.434	   93.782	   93.007	 10.749%	 10.749%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	                 CONV_2D	           59.950	   74.154	   74.058	  8.559%	 19.307%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	                 CONV_2D	            8.732	   50.762	   51.217	  5.919%	 25.226%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	          414.555	   34.384	   34.387	  3.974%	 29.200%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          242.759	   17.482	   17.398	  2.011%	 31.211%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          366.135	   17.686	   17.388	  2.010%	 33.220%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          303.210	   17.268	   17.349	  2.005%	 35.225%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          334.754	   15.737	   16.022	  1.852%	 37.077%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	                 CONV_2D	          398.290	   16.316	   16.006	  1.850%	 38.927%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	                 CONV_2D	          273.531	   16.100	   15.999	  1.849%	 40.776%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14

Number of nodes executed: 125
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       94	   830.945	    96.036%	    96.036%	     0.000	       94
	         AVERAGE_POOL_2D	        9	    22.292	     2.576%	    98.613%	     0.000	        9
	                    MEAN	        1	     7.260	     0.839%	    99.452%	     0.000	        1
	             MAX_POOL_2D	        4	     1.922	     0.222%	    99.674%	     0.000	        4
	           CONCATENATION	       15	     1.828	     0.211%	    99.885%	     0.000	       15
	         FULLY_CONNECTED	        1	     0.978	     0.113%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.016	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=859529 curr=864725 min=844840 max=900183 avg=865298 std=6749
Memory (bytes): count=0
125 nodes observed



[ perf record: Woken up 242 times to write data ]
Warning:
Processed 340756 events and lost 3 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 60.509 MB /tmp/data.record (340190 samples) ]

90.633

