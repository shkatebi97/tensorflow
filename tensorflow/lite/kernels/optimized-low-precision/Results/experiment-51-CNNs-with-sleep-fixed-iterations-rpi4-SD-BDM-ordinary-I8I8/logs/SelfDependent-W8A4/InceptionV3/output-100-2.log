STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/InceptionV3.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ) (or (22201, 27, )), Output shape (22201, 32, ), ID: 0, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 32, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (32, 32, ) DONE
	Preparing Filter With Shape: (27, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 16, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22204, 32, ) DONE
	Allocating An Output Temporary Tensor With Shape: (22204, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 32, ), Input shape (22201, 32, ) (or (21609, 288, )), Output shape (21609, 32, ), ID: 1, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 32, ) DONE
	Preparing Filter With Shape: (288, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (21609, 32, ) (or (21609, 288, )), Output shape (21609, 64, ), ID: 2, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21612, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21612, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 80, ), Input shape (5329, 64, ) (or (5329, 64, )), Output shape (5329, 80, ), ID: 3, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (5329, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 80, ) DONE
	Preparing Filter With Shape: (64, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5332, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5332, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (720, 192, ), Input shape (5329, 80, ) (or (5041, 720, )), Output shape (5041, 192, ), ID: 4, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (5041, 720, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 192, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (736, 192, ) DONE
	Preparing Filter With Shape: (720, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 368, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5044, 736, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5044, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 32, ), ID: 5, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 32, ) DONE
	Preparing Filter With Shape: (192, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 6, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 48, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 48, ), ID: 7, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 48, ) DONE
	Preparing Filter With Shape: (192, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 8, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (1216, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 64, ), Input shape (1225, 192, ) (or (1225, 192, )), Output shape (1225, 64, ), ID: 9, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 192, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 64, ) DONE
	Preparing Filter With Shape: (192, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 192, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 10, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 11, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 12, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 13, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 48, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 48, ), ID: 14, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 48, ) DONE
	Preparing Filter With Shape: (256, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 15, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (1216, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 64, ), Input shape (1225, 256, ) (or (1225, 256, )), Output shape (1225, 64, ), ID: 16, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 64, ) DONE
	Preparing Filter With Shape: (256, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 17, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 18, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 19, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 20, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 48, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 48, ), ID: 21, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 48, ) DONE
	Preparing Filter With Shape: (288, 48, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1200, 64, ), Input shape (1225, 48, ) (or (1225, 1200, )), Output shape (1225, 64, ), ID: 22, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 1200, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (1216, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (1216, 64, ) DONE
	Preparing Filter With Shape: (1200, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 23, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 24, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (1225, 864, )), Output shape (1225, 96, ), ID: 25, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (2592, 384, ), Input shape (1225, 288, ) (or (289, 2592, )), Output shape (289, 384, ), ID: 26, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 2592, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (2592, 384, ) DONE
	Preparing Filter With Shape: (2592, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1296, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 2592, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (1225, 288, ) (or (1225, 288, )), Output shape (1225, 64, ), ID: 27, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 144, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (1225, 64, ) (or (1225, 576, )), Output shape (1225, 96, ), ID: 28, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (1225, 576, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 96, ) DONE
	Preparing Filter With Shape: (576, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1228, 576, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1228, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 96, ), Input shape (1225, 96, ) (or (289, 864, )), Output shape (289, 96, ), ID: 29, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 864, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 96, ) DONE
	Preparing Filter With Shape: (864, 96, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 432, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 864, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 30, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 31, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 32, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 33, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 34, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 128, ), ID: 35, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 36, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 37, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 128, ), ID: 38, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 192, ), Input shape (289, 128, ) (or (289, 896, )), Output shape (289, 192, ), ID: 39, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 192, ) DONE
	Preparing Filter With Shape: (896, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 40, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 41, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 42, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 43, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 44, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 45, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 46, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 47, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 48, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 49, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 50, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 51, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 52, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 53, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 54, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 160, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 160, ), ID: 55, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 160, ) DONE
	Preparing Filter With Shape: (768, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 56, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 57, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 160, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 160, ), ID: 58, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 160, ) DONE
	Preparing Filter With Shape: (1120, 160, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 192, ), Input shape (289, 160, ) (or (289, 1120, )), Output shape (289, 192, ), ID: 59, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 192, ) DONE
	Preparing Filter With Shape: (1120, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 60, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 61, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 62, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 63, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 64, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 65, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 66, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 67, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 68, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 69, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 70, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 320, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 320, ), ID: 71, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1728, 320, ) DONE
	Preparing Filter With Shape: (1728, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (289, 768, ) (or (289, 768, )), Output shape (289, 192, ), ID: 72, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 768, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 192, ) DONE
	Preparing Filter With Shape: (768, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 768, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 73, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 192, ), Input shape (289, 192, ) (or (289, 1344, )), Output shape (289, 192, ), ID: 74, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (289, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 192, ) DONE
	Preparing Filter With Shape: (1344, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (292, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (292, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 192, ), Input shape (289, 192, ) (or (64, 1728, )), Output shape (64, 192, ), ID: 75, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1728, 192, ) DONE
	Preparing Filter With Shape: (1728, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 192, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 192, ), ID: 76, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1280, 192, ) DONE
	Preparing Filter With Shape: (1280, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 320, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 320, ), ID: 77, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1280, 320, ) DONE
	Preparing Filter With Shape: (1280, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 384, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 384, ), ID: 78, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1280, 384, ) DONE
	Preparing Filter With Shape: (1280, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 79, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 80, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 448, ), Input shape (64, 1280, ) (or (64, 1280, )), Output shape (64, 448, ), ID: 81, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1280, 448, ) DONE
	Preparing Filter With Shape: (1280, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 82, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (4032, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2016, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 83, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 84, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 192, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 192, ), ID: 85, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2048, 192, ) DONE
	Preparing Filter With Shape: (2048, 192, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 320, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 320, ), ID: 86, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2048, 320, ) DONE
	Preparing Filter With Shape: (2048, 320, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 384, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 384, ), ID: 87, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2048, 384, ) DONE
	Preparing Filter With Shape: (2048, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 88, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 89, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (2048, 448, ), Input shape (64, 2048, ) (or (64, 2048, )), Output shape (64, 448, ), ID: 90, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 2048, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (2048, 448, ) DONE
	Preparing Filter With Shape: (2048, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (4032, 384, ), Input shape (64, 448, ) (or (64, 4032, )), Output shape (64, 384, ), ID: 91, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 4032, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (4032, 384, ) DONE
	Preparing Filter With Shape: (4032, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 2016, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 92, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 384, ), Input shape (64, 384, ) (or (64, 1152, )), Output shape (64, 384, ), ID: 93, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (64, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 384, ) DONE
	Preparing Filter With Shape: (1152, 384, ) DONE
	Allocating An Input Temporary Tensor With Shape: (64, 576, ) DONE
Applying FC Low-Precision for Kernel shape (2048, 1000, ), Input shape (1, 2048, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW8A4
	Allocating Filter Shape: (2048, 1000, ) DONE
	Preparing Filter With Shape: (2048, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 24.2886
Initialized session in 349.762ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=806031 curr=754993 min=754993 max=806031 avg=780512 std=25519

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=738207 curr=759941 min=729415 max=784031 avg=757517 std=7623

Inference timings in us: Init: 349762, First inference: 806031, Warmup (avg): 780512, Inference (avg): 757517
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=53.5039 overall=111.496
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  344.179	  344.179	100.000%	100.000%	 44620.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  344.179	  344.179	100.000%	100.000%	 44620.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   344.179	   100.000%	   100.000%	 44620.000	        1

Timings (microseconds): count=1 curr=344179
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.022	    7.270	    7.202	  0.951%	  0.951%	     0.000	        1	[inception_v3/activation/Relu;inception_v3/batch_normalization/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d/Conv2D]:0
	                 CONV_2D	            7.225	   34.315	   34.843	  4.601%	  5.552%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	           42.069	   58.905	   58.320	  7.701%	 13.252%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	             MAX_POOL_2D	          100.390	    0.897	    0.939	  0.124%	 13.376%	     0.000	        1	[inception_v3/max_pooling2d/MaxPool]:3
	                 CONV_2D	          101.330	    4.906	    4.765	  0.629%	 14.006%	     0.000	        1	[inception_v3/activation_3/Relu;inception_v3/batch_normalization_3/FusedBatchNormV3;inception_v3/batch_normalization_3/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_3/Conv2D]:4
	                 CONV_2D	          106.097	   83.744	   83.929	 11.082%	 25.088%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	             MAX_POOL_2D	          190.026	    0.486	    0.539	  0.071%	 25.159%	     0.000	        1	[inception_v3/max_pooling2d_1/MaxPool]:6
	         AVERAGE_POOL_2D	          190.567	    2.250	    2.237	  0.295%	 25.454%	     0.000	        1	[inception_v3/average_pooling2d/AvgPool]:7
	                 CONV_2D	          192.804	    1.279	    1.231	  0.163%	 25.617%	     0.000	        1	[inception_v3/activation_11/Relu;inception_v3/batch_normalization_11/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_11/Conv2D]:8
	                 CONV_2D	          194.037	    2.119	    2.106	  0.278%	 25.895%	     0.000	        1	[inception_v3/activation_5/Relu;inception_v3/batch_normalization_5/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_5/Conv2D]:9
	                 CONV_2D	          196.144	    1.559	    1.619	  0.214%	 26.109%	     0.000	        1	[inception_v3/activation_6/Relu;inception_v3/batch_normalization_6/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_6/Conv2D]:10
	                 CONV_2D	          197.764	   12.869	   12.953	  1.710%	 27.819%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          210.718	    2.089	    2.131	  0.281%	 28.100%	     0.000	        1	[inception_v3/activation_8/Relu;inception_v3/batch_normalization_8/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_8/Conv2D]:12
	                 CONV_2D	          212.850	    8.696	    8.827	  1.166%	 29.266%	     0.000	        1	[inception_v3/activation_9/Relu;inception_v3/batch_normalization_9/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_9/Conv2D]:13
	                 CONV_2D	          221.678	   12.713	   12.909	  1.705%	 30.970%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	           CONCATENATION	          234.589	    0.194	    0.220	  0.029%	 30.999%	     0.000	        1	[inception_v3/mixed0/concat]:15
	         AVERAGE_POOL_2D	          234.809	    3.424	    3.463	  0.457%	 31.457%	     0.000	        1	[inception_v3/average_pooling2d_1/AvgPool]:16
	                 CONV_2D	          238.273	    2.813	    2.745	  0.362%	 31.819%	     0.000	        1	[inception_v3/activation_18/Relu;inception_v3/batch_normalization_18/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_18/Conv2D]:17
	                 CONV_2D	          241.019	    2.569	    2.676	  0.353%	 32.172%	     0.000	        1	[inception_v3/activation_12/Relu;inception_v3/batch_normalization_12/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_12/Conv2D]:18
	                 CONV_2D	          243.696	    2.140	    2.121	  0.280%	 32.453%	     0.000	        1	[inception_v3/activation_13/Relu;inception_v3/batch_normalization_13/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_13/Conv2D]:19
	                 CONV_2D	          245.819	   12.808	   12.990	  1.715%	 34.168%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          258.810	    2.785	    2.807	  0.371%	 34.538%	     0.000	        1	[inception_v3/activation_15/Relu;inception_v3/batch_normalization_15/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_15/Conv2D]:21
	                 CONV_2D	          261.617	    8.607	    8.831	  1.166%	 35.704%	     0.000	        1	[inception_v3/activation_16/Relu;inception_v3/batch_normalization_16/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_16/Conv2D]:22
	                 CONV_2D	          270.449	   12.827	   12.897	  1.703%	 37.407%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	           CONCATENATION	          283.348	    0.206	    0.238	  0.031%	 37.439%	     0.000	        1	[inception_v3/mixed1/concat]:24
	         AVERAGE_POOL_2D	          283.586	    4.097	    4.154	  0.549%	 37.987%	     0.000	        1	[inception_v3/average_pooling2d_2/AvgPool]:25
	                 CONV_2D	          287.742	    2.972	    3.026	  0.400%	 38.387%	     0.000	        1	[inception_v3/activation_25/Relu;inception_v3/batch_normalization_25/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_25/Conv2D]:26
	                 CONV_2D	          290.769	    3.195	    3.164	  0.418%	 38.805%	     0.000	        1	[inception_v3/activation_19/Relu;inception_v3/batch_normalization_19/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_19/Conv2D]:27
	                 CONV_2D	          293.935	    2.318	    2.377	  0.314%	 39.118%	     0.000	        1	[inception_v3/activation_20/Relu;inception_v3/batch_normalization_20/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_20/Conv2D]:28
	                 CONV_2D	          296.312	   12.830	   12.938	  1.708%	 40.827%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          309.252	    2.946	    3.012	  0.398%	 41.225%	     0.000	        1	[inception_v3/activation_22/Relu;inception_v3/batch_normalization_22/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_22/Conv2D]:30
	                 CONV_2D	          312.264	    8.628	    8.856	  1.169%	 42.394%	     0.000	        1	[inception_v3/activation_23/Relu;inception_v3/batch_normalization_23/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_23/Conv2D]:31
	                 CONV_2D	          321.122	   12.785	   12.883	  1.701%	 44.095%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	           CONCATENATION	          334.006	    0.239	    0.248	  0.033%	 44.128%	     0.000	        1	[inception_v3/mixed2/concat]:33
	                 CONV_2D	          334.254	   33.318	   34.188	  4.514%	 48.642%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          368.444	    3.031	    2.996	  0.396%	 49.038%	     0.000	        1	[inception_v3/activation_27/Relu;inception_v3/batch_normalization_27/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_27/Conv2D]:35
	                 CONV_2D	          371.441	    8.694	    8.854	  1.169%	 50.207%	     0.000	        1	[inception_v3/activation_28/Relu;inception_v3/batch_normalization_28/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_28/Conv2D]:36
	                 CONV_2D	          380.296	    2.943	    3.005	  0.397%	 50.604%	     0.000	        1	[inception_v3/activation_29/Relu;inception_v3/batch_normalization_29/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_29/Conv2D]:37
	             MAX_POOL_2D	          383.302	    0.227	    0.257	  0.034%	 50.637%	     0.000	        1	[inception_v3/max_pooling2d_2/MaxPool]:38
	           CONCATENATION	          383.560	    0.120	    0.129	  0.017%	 50.654%	     0.000	        1	[inception_v3/mixed3/concat]:39
	         AVERAGE_POOL_2D	          383.690	    2.370	    2.408	  0.318%	 50.972%	     0.000	        1	[inception_v3/average_pooling2d_3/AvgPool]:40
	                 CONV_2D	          386.098	    4.953	    4.973	  0.657%	 51.629%	     0.000	        1	[inception_v3/activation_39/Relu;inception_v3/batch_normalization_39/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_39/Conv2D]:41
	                 CONV_2D	          391.073	    4.866	    5.010	  0.662%	 52.291%	     0.000	        1	[inception_v3/activation_30/Relu;inception_v3/batch_normalization_30/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_30/Conv2D]:42
	                 CONV_2D	          396.084	    3.306	    3.349	  0.442%	 52.733%	     0.000	        1	[inception_v3/activation_31/Relu;inception_v3/batch_normalization_31/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_31/Conv2D]:43
	                 CONV_2D	          399.434	    3.875	    3.934	  0.519%	 53.252%	     0.000	        1	[inception_v3/activation_32/Relu;inception_v3/batch_normalization_32/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_32/Conv2D]:44
	                 CONV_2D	          403.370	    5.663	    5.847	  0.772%	 54.024%	     0.000	        1	[inception_v3/activation_33/Relu;inception_v3/batch_normalization_33/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_33/Conv2D]:45
	                 CONV_2D	          409.218	    3.262	    3.383	  0.447%	 54.471%	     0.000	        1	[inception_v3/activation_34/Relu;inception_v3/batch_normalization_34/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_34/Conv2D]:46
	                 CONV_2D	          412.602	    3.791	    4.020	  0.531%	 55.002%	     0.000	        1	[inception_v3/activation_35/Relu;inception_v3/batch_normalization_35/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_35/Conv2D]:47
	                 CONV_2D	          416.622	    3.780	    3.997	  0.528%	 55.530%	     0.000	        1	[inception_v3/activation_36/Relu;inception_v3/batch_normalization_36/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_36/Conv2D]:48
	                 CONV_2D	          420.620	    3.866	    4.001	  0.528%	 56.058%	     0.000	        1	[inception_v3/activation_37/Relu;inception_v3/batch_normalization_37/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_37/Conv2D]:49
	                 CONV_2D	          424.623	    5.502	    5.793	  0.765%	 56.823%	     0.000	        1	[inception_v3/activation_38/Relu;inception_v3/batch_normalization_38/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_38/Conv2D]:50
	           CONCATENATION	          430.417	    0.182	    0.157	  0.021%	 56.844%	     0.000	        1	[inception_v3/mixed4/concat]:51
	         AVERAGE_POOL_2D	          430.575	    2.525	    2.566	  0.339%	 57.182%	     0.000	        1	[inception_v3/average_pooling2d_4/AvgPool]:52
	                 CONV_2D	          433.142	    4.747	    4.966	  0.656%	 57.838%	     0.000	        1	[inception_v3/activation_49/Relu;inception_v3/batch_normalization_49/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_49/Conv2D]:53
	                 CONV_2D	          438.109	    4.738	    4.944	  0.653%	 58.491%	     0.000	        1	[inception_v3/activation_40/Relu;inception_v3/batch_normalization_40/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_40/Conv2D]:54
	                 CONV_2D	          443.055	    4.031	    4.133	  0.546%	 59.037%	     0.000	        1	[inception_v3/activation_41/Relu;inception_v3/batch_normalization_41/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_41/Conv2D]:55
	                 CONV_2D	          447.188	    5.830	    6.237	  0.824%	 59.860%	     0.000	        1	[inception_v3/activation_42/Relu;inception_v3/batch_normalization_42/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_42/Conv2D]:56
	                 CONV_2D	          453.426	    7.081	    7.395	  0.976%	 60.837%	     0.000	        1	[inception_v3/activation_43/Relu;inception_v3/batch_normalization_43/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_43/Conv2D]:57
	                 CONV_2D	          460.822	    4.054	    4.116	  0.543%	 61.380%	     0.000	        1	[inception_v3/activation_44/Relu;inception_v3/batch_normalization_44/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_44/Conv2D]:58
	                 CONV_2D	          464.938	    5.912	    6.179	  0.816%	 62.196%	     0.000	        1	[inception_v3/activation_45/Relu;inception_v3/batch_normalization_45/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_45/Conv2D]:59
	                 CONV_2D	          471.118	    5.852	    6.194	  0.818%	 63.014%	     0.000	        1	[inception_v3/activation_46/Relu;inception_v3/batch_normalization_46/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_46/Conv2D]:60
	                 CONV_2D	          477.314	    5.939	    6.209	  0.820%	 63.834%	     0.000	        1	[inception_v3/activation_47/Relu;inception_v3/batch_normalization_47/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_47/Conv2D]:61
	                 CONV_2D	          483.524	    7.034	    7.393	  0.976%	 64.810%	     0.000	        1	[inception_v3/activation_48/Relu;inception_v3/batch_normalization_48/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_48/Conv2D]:62
	           CONCATENATION	          490.918	    0.178	    0.153	  0.020%	 64.830%	     0.000	        1	[inception_v3/mixed5/concat]:63
	         AVERAGE_POOL_2D	          491.072	    2.502	    2.575	  0.340%	 65.170%	     0.000	        1	[inception_v3/average_pooling2d_5/AvgPool]:64
	                 CONV_2D	          493.649	    4.764	    4.906	  0.648%	 65.818%	     0.000	        1	[inception_v3/activation_59/Relu;inception_v3/batch_normalization_59/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_59/Conv2D]:65
	                 CONV_2D	          498.556	    4.778	    4.949	  0.654%	 66.472%	     0.000	        1	[inception_v3/activation_50/Relu;inception_v3/batch_normalization_50/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_50/Conv2D]:66
	                 CONV_2D	          503.507	    3.952	    4.102	  0.542%	 67.013%	     0.000	        1	[inception_v3/activation_51/Relu;inception_v3/batch_normalization_51/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_51/Conv2D]:67
	                 CONV_2D	          507.610	    5.812	    6.189	  0.817%	 67.830%	     0.000	        1	[inception_v3/activation_52/Relu;inception_v3/batch_normalization_52/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_52/Conv2D]:68
	                 CONV_2D	          513.800	    7.053	    7.483	  0.988%	 68.818%	     0.000	        1	[inception_v3/activation_53/Relu;inception_v3/batch_normalization_53/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_53/Conv2D]:69
	                 CONV_2D	          521.284	    4.093	    4.118	  0.544%	 69.362%	     0.000	        1	[inception_v3/activation_54/Relu;inception_v3/batch_normalization_54/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_54/Conv2D]:70
	                 CONV_2D	          525.403	    5.797	    6.228	  0.822%	 70.185%	     0.000	        1	[inception_v3/activation_55/Relu;inception_v3/batch_normalization_55/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_55/Conv2D]:71
	                 CONV_2D	          531.632	    5.983	    6.197	  0.818%	 71.003%	     0.000	        1	[inception_v3/activation_56/Relu;inception_v3/batch_normalization_56/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_56/Conv2D]:72
	                 CONV_2D	          537.831	    5.838	    6.215	  0.821%	 71.823%	     0.000	        1	[inception_v3/activation_57/Relu;inception_v3/batch_normalization_57/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_57/Conv2D]:73
	                 CONV_2D	          544.047	    7.021	    7.470	  0.986%	 72.810%	     0.000	        1	[inception_v3/activation_58/Relu;inception_v3/batch_normalization_58/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_58/Conv2D]:74
	           CONCATENATION	          551.517	    0.189	    0.153	  0.020%	 72.830%	     0.000	        1	[inception_v3/mixed6/concat]:75
	         AVERAGE_POOL_2D	          551.671	    2.509	    2.538	  0.335%	 73.165%	     0.000	        1	[inception_v3/average_pooling2d_6/AvgPool]:76
	                 CONV_2D	          554.211	    4.697	    4.912	  0.649%	 73.814%	     0.000	        1	[inception_v3/activation_69/Relu;inception_v3/batch_normalization_69/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_69/Conv2D]:77
	                 CONV_2D	          559.123	    4.704	    4.918	  0.649%	 74.463%	     0.000	        1	[inception_v3/activation_60/Relu;inception_v3/batch_normalization_60/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_60/Conv2D]:78
	                 CONV_2D	          564.043	    4.711	    4.917	  0.649%	 75.112%	     0.000	        1	[inception_v3/activation_61/Relu;inception_v3/batch_normalization_61/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_61/Conv2D]:79
	                 CONV_2D	          568.960	    8.302	    9.024	  1.192%	 76.304%	     0.000	        1	[inception_v3/activation_62/Relu;inception_v3/batch_normalization_62/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_62/Conv2D]:80
	                 CONV_2D	          577.986	    8.461	    8.953	  1.182%	 77.486%	     0.000	        1	[inception_v3/activation_63/Relu;inception_v3/batch_normalization_63/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_63/Conv2D]:81
	                 CONV_2D	          586.940	    4.823	    4.949	  0.653%	 78.139%	     0.000	        1	[inception_v3/activation_64/Relu;inception_v3/batch_normalization_64/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_64/Conv2D]:82
	                 CONV_2D	          591.890	    8.345	    8.965	  1.184%	 79.323%	     0.000	        1	[inception_v3/activation_65/Relu;inception_v3/batch_normalization_65/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_65/Conv2D]:83
	                 CONV_2D	          600.856	    8.647	    9.148	  1.208%	 80.531%	     0.000	        1	[inception_v3/activation_66/Relu;inception_v3/batch_normalization_66/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_66/Conv2D]:84
	                 CONV_2D	          610.005	    8.804	    9.004	  1.189%	 81.720%	     0.000	        1	[inception_v3/activation_67/Relu;inception_v3/batch_normalization_67/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_67/Conv2D]:85
	                 CONV_2D	          619.010	    8.907	    8.948	  1.182%	 82.902%	     0.000	        1	[inception_v3/activation_68/Relu;inception_v3/batch_normalization_68/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_68/Conv2D]:86
	           CONCATENATION	          627.959	    0.166	    0.153	  0.020%	 82.922%	     0.000	        1	[inception_v3/mixed7/concat]:87
	                 CONV_2D	          628.113	    4.962	    4.915	  0.649%	 83.571%	     0.000	        1	[inception_v3/activation_70/Relu;inception_v3/batch_normalization_70/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_70/Conv2D]:88
	                 CONV_2D	          633.029	    4.057	    4.187	  0.553%	 84.124%	     0.000	        1	[inception_v3/activation_71/Relu;inception_v3/batch_normalization_71/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_71/Conv2D]:89
	                 CONV_2D	          637.216	    4.780	    4.925	  0.650%	 84.774%	     0.000	        1	[inception_v3/activation_72/Relu;inception_v3/batch_normalization_72/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_72/Conv2D]:90
	                 CONV_2D	          642.142	    8.465	    8.967	  1.184%	 85.958%	     0.000	        1	[inception_v3/activation_73/Relu;inception_v3/batch_normalization_73/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_73/Conv2D]:91
	                 CONV_2D	          651.110	    8.320	    8.963	  1.183%	 87.141%	     0.000	        1	[inception_v3/activation_74/Relu;inception_v3/batch_normalization_74/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_74/Conv2D]:92
	                 CONV_2D	          660.074	    2.492	    2.613	  0.345%	 87.486%	     0.000	        1	[inception_v3/activation_75/Relu;inception_v3/batch_normalization_75/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_75/Conv2D]:93
	             MAX_POOL_2D	          662.688	    0.178	    0.192	  0.025%	 87.512%	     0.000	        1	[inception_v3/max_pooling2d_3/MaxPool]:94
	           CONCATENATION	          662.880	    0.029	    0.040	  0.005%	 87.517%	     0.000	        1	[inception_v3/mixed8/concat]:95
	         AVERAGE_POOL_2D	          662.921	    0.784	    0.817	  0.108%	 87.625%	     0.000	        1	[inception_v3/average_pooling2d_7/AvgPool]:96
	                 CONV_2D	          663.739	    1.707	    1.845	  0.244%	 87.868%	     0.000	        1	[inception_v3/activation_84/Relu;inception_v3/batch_normalization_84/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_84/Conv2D]:97
	                 CONV_2D	          665.585	    2.967	    3.102	  0.410%	 88.278%	     0.000	        1	[inception_v3/activation_76/Relu;inception_v3/batch_normalization_76/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_76/Conv2D]:98
	                 CONV_2D	          668.688	    3.424	    3.680	  0.486%	 88.764%	     0.000	        1	[inception_v3/activation_77/Relu;inception_v3/batch_normalization_77/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_77/Conv2D]:99
	                 CONV_2D	          672.369	    3.162	    3.385	  0.447%	 89.211%	     0.000	        1	[inception_v3/activation_78/Relu;inception_v3/batch_normalization_78/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_78/Conv2D]:100
	                 CONV_2D	          675.755	    3.097	    3.346	  0.442%	 89.653%	     0.000	        1	[inception_v3/activation_79/Relu;inception_v3/batch_normalization_79/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_79/Conv2D]:101
	           CONCATENATION	          679.102	    0.040	    0.041	  0.005%	 89.658%	     0.000	        1	[inception_v3/mixed9_0/concat]:102
	                 CONV_2D	          679.144	    4.214	    4.274	  0.564%	 90.222%	     0.000	        1	[inception_v3/activation_80/Relu;inception_v3/batch_normalization_80/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_80/Conv2D]:103
	                 CONV_2D	          683.419	   10.918	   11.695	  1.544%	 91.767%	     0.000	        1	[inception_v3/activation_81/Relu;inception_v3/batch_normalization_81/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_81/Conv2D]:104
	                 CONV_2D	          695.116	    3.145	    3.381	  0.446%	 92.213%	     0.000	        1	[inception_v3/activation_82/Relu;inception_v3/batch_normalization_82/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_82/Conv2D]:105
	                 CONV_2D	          698.497	    3.083	    3.352	  0.443%	 92.656%	     0.000	        1	[inception_v3/activation_83/Relu;inception_v3/batch_normalization_83/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_83/Conv2D]:106
	           CONCATENATION	          701.851	    0.033	    0.040	  0.005%	 92.661%	     0.000	        1	[inception_v3/concatenate/concat]:107
	           CONCATENATION	          701.892	    0.058	    0.076	  0.010%	 92.671%	     0.000	        1	[inception_v3/mixed9/concat]:108
	         AVERAGE_POOL_2D	          701.969	    1.516	    1.576	  0.208%	 92.879%	     0.000	        1	[inception_v3/average_pooling2d_8/AvgPool]:109
	                 CONV_2D	          703.547	    2.711	    2.950	  0.390%	 93.269%	     0.000	        1	[inception_v3/activation_93/Relu;inception_v3/batch_normalization_93/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_93/Conv2D]:110
	                 CONV_2D	          706.498	    4.616	    4.900	  0.647%	 93.916%	     0.000	        1	[inception_v3/activation_85/Relu;inception_v3/batch_normalization_85/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_85/Conv2D]:111
	                 CONV_2D	          711.399	    5.598	    5.756	  0.760%	 94.676%	     0.000	        1	[inception_v3/activation_86/Relu;inception_v3/batch_normalization_86/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_86/Conv2D]:112
	                 CONV_2D	          717.156	    3.269	    3.341	  0.441%	 95.117%	     0.000	        1	[inception_v3/activation_87/Relu;inception_v3/batch_normalization_87/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_87/Conv2D]:113
	                 CONV_2D	          720.498	    3.349	    3.382	  0.447%	 95.564%	     0.000	        1	[inception_v3/activation_88/Relu;inception_v3/batch_normalization_88/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_88/Conv2D]:114
	           CONCATENATION	          723.881	    0.039	    0.041	  0.005%	 95.569%	     0.000	        1	[inception_v3/mixed9_1/concat]:115
	                 CONV_2D	          723.923	    6.536	    6.759	  0.892%	 96.461%	     0.000	        1	[inception_v3/activation_89/Relu;inception_v3/batch_normalization_89/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_89/Conv2D]:116
	                 CONV_2D	          730.683	   11.129	   11.638	  1.537%	 97.998%	     0.000	        1	[inception_v3/activation_90/Relu;inception_v3/batch_normalization_90/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_90/Conv2D]:117
	                 CONV_2D	          742.322	    3.036	    3.368	  0.445%	 98.443%	     0.000	        1	[inception_v3/activation_91/Relu;inception_v3/batch_normalization_91/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_91/Conv2D]:118
	                 CONV_2D	          745.691	    3.047	    3.333	  0.440%	 98.883%	     0.000	        1	[inception_v3/activation_92/Relu;inception_v3/batch_normalization_92/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_92/Conv2D]:119
	           CONCATENATION	          749.024	    0.035	    0.040	  0.005%	 98.888%	     0.000	        1	[inception_v3/concatenate_1/concat]:120
	           CONCATENATION	          749.066	    0.059	    0.080	  0.011%	 98.899%	     0.000	        1	[inception_v3/mixed10/concat]:121
	                    MEAN	          749.147	    7.189	    7.275	  0.961%	 99.860%	     0.000	        1	[inception_v3/avg_pool/Mean]:122
	         FULLY_CONNECTED	          756.423	    0.958	    1.048	  0.138%	 99.998%	     0.000	        1	[inception_v3/predictions/MatMul;inception_v3/predictions/BiasAdd]:123
	                 SOFTMAX	          757.472	    0.014	    0.016	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:124

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          106.097	   83.744	   83.929	 11.082%	 11.082%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	                 CONV_2D	           42.069	   58.905	   58.320	  7.701%	 18.783%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	                 CONV_2D	            7.225	   34.315	   34.843	  4.601%	 23.384%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	          334.254	   33.318	   34.188	  4.514%	 27.898%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	          245.819	   12.808	   12.990	  1.715%	 29.613%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	          197.764	   12.869	   12.953	  1.710%	 31.323%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	          296.312	   12.830	   12.938	  1.708%	 33.032%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	          221.678	   12.713	   12.909	  1.705%	 34.736%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	                 CONV_2D	          270.449	   12.827	   12.897	  1.703%	 36.439%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	                 CONV_2D	          321.122	   12.785	   12.883	  1.701%	 38.140%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32

Number of nodes executed: 125
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       94	   722.880	    95.458%	    95.458%	     0.000	       94
	         AVERAGE_POOL_2D	        9	    22.330	     2.949%	    98.407%	     0.000	        9
	                    MEAN	        1	     7.274	     0.961%	    99.368%	     0.000	        1
	             MAX_POOL_2D	        4	     1.923	     0.254%	    99.622%	     0.000	        4
	           CONCATENATION	       15	     1.803	     0.238%	    99.860%	     0.000	       15
	         FULLY_CONNECTED	        1	     1.048	     0.138%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.015	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=738024 curr=759770 min=729258 max=783833 avg=757336 std=7622
Memory (bytes): count=0
125 nodes observed



[ perf record: Woken up 219 times to write data ]
Warning:
Processed 308333 events and lost 1 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 54.907 MB /tmp/data.record (307798 samples) ]

79.653

