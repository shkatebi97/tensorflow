STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [100]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/CNNs-ResNet101-DenseNet201-InceptionV3/models/i8i8/DenseNet201.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (147, 64, ), Input shape (52900, 3, ) (or (12544, 147, )), Output shape (12544, 64, ), ID: 0, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (12544, 147, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 64, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (160, 64, ) DONE
	Preparing Filter With Shape: (147, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 80, ) DONE
	Allocating An Input Temporary Tensor With Shape: (12544, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (3136, 64, ) (or (3136, 64, )), Output shape (3136, 128, ), ID: 1, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 64, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 2, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (96, 128, ), Input shape (3136, 96, ) (or (3136, 96, )), Output shape (3136, 128, ), ID: 3, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 96, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (96, 128, ) DONE
	Preparing Filter With Shape: (96, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 48, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 4, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (3136, 128, ) (or (3136, 128, )), Output shape (3136, 128, ), ID: 5, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 6, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (3136, 160, ) (or (3136, 160, )), Output shape (3136, 128, ), ID: 7, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 8, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (3136, 192, ) (or (3136, 192, )), Output shape (3136, 128, ), ID: 9, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 10, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (3136, 224, ) (or (3136, 224, )), Output shape (3136, 128, ), ID: 11, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 112, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (3136, 128, ) (or (3136, 1152, )), Output shape (3136, 32, ), ID: 12, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (3136, 256, ) (or (3136, 256, )), Output shape (3136, 128, ), ID: 13, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (3136, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (3136, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (784, 128, ) (or (784, 128, )), Output shape (784, 128, ), ID: 14, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 128, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 15, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (160, 128, ), Input shape (784, 160, ) (or (784, 160, )), Output shape (784, 128, ), ID: 16, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 160, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (160, 128, ) DONE
	Preparing Filter With Shape: (160, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 80, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 17, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (192, 128, ), Input shape (784, 192, ) (or (784, 192, )), Output shape (784, 128, ), ID: 18, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 192, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (192, 128, ) DONE
	Preparing Filter With Shape: (192, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 96, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 19, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (224, 128, ), Input shape (784, 224, ) (or (784, 224, )), Output shape (784, 128, ), ID: 20, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 224, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (224, 128, ) DONE
	Preparing Filter With Shape: (224, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 112, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 21, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (784, 256, ) (or (784, 256, )), Output shape (784, 128, ), ID: 22, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 23, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (784, 288, ) (or (784, 288, )), Output shape (784, 128, ), ID: 24, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 144, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 25, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (784, 320, ) (or (784, 320, )), Output shape (784, 128, ), ID: 26, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (320, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 27, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (784, 352, ) (or (784, 352, )), Output shape (784, 128, ), ID: 28, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (352, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 176, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 29, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (784, 384, ) (or (784, 384, )), Output shape (784, 128, ), ID: 30, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 31, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (784, 416, ) (or (784, 416, )), Output shape (784, 128, ), ID: 32, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (416, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 208, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 33, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (784, 448, ) (or (784, 448, )), Output shape (784, 128, ), ID: 34, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 35, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (784, 480, ) (or (784, 480, )), Output shape (784, 128, ), ID: 36, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 240, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (784, 128, ) (or (784, 1152, )), Output shape (784, 32, ), ID: 37, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 256, ), Input shape (784, 512, ) (or (784, 512, )), Output shape (784, 256, ), ID: 38, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (784, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 256, ) DONE
	Preparing Filter With Shape: (512, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (784, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 128, ), Input shape (196, 256, ) (or (196, 256, )), Output shape (196, 128, ), ID: 39, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 256, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 128, ) DONE
	Preparing Filter With Shape: (256, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 40, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 128, ), Input shape (196, 288, ) (or (196, 288, )), Output shape (196, 128, ), ID: 41, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 288, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 128, ) DONE
	Preparing Filter With Shape: (288, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 144, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 42, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (320, 128, ), Input shape (196, 320, ) (or (196, 320, )), Output shape (196, 128, ), ID: 43, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 320, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (320, 128, ) DONE
	Preparing Filter With Shape: (320, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 160, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 44, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (352, 128, ), Input shape (196, 352, ) (or (196, 352, )), Output shape (196, 128, ), ID: 45, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 352, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (352, 128, ) DONE
	Preparing Filter With Shape: (352, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 176, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 46, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (384, 128, ), Input shape (196, 384, ) (or (196, 384, )), Output shape (196, 128, ), ID: 47, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 384, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (384, 128, ) DONE
	Preparing Filter With Shape: (384, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 192, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 48, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (416, 128, ), Input shape (196, 416, ) (or (196, 416, )), Output shape (196, 128, ), ID: 49, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 416, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (416, 128, ) DONE
	Preparing Filter With Shape: (416, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 208, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 50, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (448, 128, ), Input shape (196, 448, ) (or (196, 448, )), Output shape (196, 128, ), ID: 51, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 448, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (448, 128, ) DONE
	Preparing Filter With Shape: (448, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 224, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 52, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (480, 128, ), Input shape (196, 480, ) (or (196, 480, )), Output shape (196, 128, ), ID: 53, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 480, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (480, 128, ) DONE
	Preparing Filter With Shape: (480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 240, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 54, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (512, 128, ), Input shape (196, 512, ) (or (196, 512, )), Output shape (196, 128, ), ID: 55, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 512, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (512, 128, ) DONE
	Preparing Filter With Shape: (512, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 56, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (544, 128, ), Input shape (196, 544, ) (or (196, 544, )), Output shape (196, 128, ), ID: 57, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 544, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (544, 128, ) DONE
	Preparing Filter With Shape: (544, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 272, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 58, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (576, 128, ), Input shape (196, 576, ) (or (196, 576, )), Output shape (196, 128, ), ID: 59, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 576, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (576, 128, ) DONE
	Preparing Filter With Shape: (576, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 288, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 60, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (608, 128, ), Input shape (196, 608, ) (or (196, 608, )), Output shape (196, 128, ), ID: 61, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 608, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (608, 128, ) DONE
	Preparing Filter With Shape: (608, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 304, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 62, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (640, 128, ), Input shape (196, 640, ) (or (196, 640, )), Output shape (196, 128, ), ID: 63, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 640, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (640, 128, ) DONE
	Preparing Filter With Shape: (640, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 320, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 64, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (672, 128, ), Input shape (196, 672, ) (or (196, 672, )), Output shape (196, 128, ), ID: 65, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 672, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (672, 128, ) DONE
	Preparing Filter With Shape: (672, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 336, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 66, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (704, 128, ), Input shape (196, 704, ) (or (196, 704, )), Output shape (196, 128, ), ID: 67, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 704, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (704, 128, ) DONE
	Preparing Filter With Shape: (704, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 352, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 68, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (736, 128, ), Input shape (196, 736, ) (or (196, 736, )), Output shape (196, 128, ), ID: 69, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 736, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 128, ) DONE
	Preparing Filter With Shape: (736, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 368, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 70, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (768, 128, ), Input shape (196, 768, ) (or (196, 768, )), Output shape (196, 128, ), ID: 71, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 768, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (768, 128, ) DONE
	Preparing Filter With Shape: (768, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 384, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 72, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (800, 128, ), Input shape (196, 800, ) (or (196, 800, )), Output shape (196, 128, ), ID: 73, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 800, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (800, 128, ) DONE
	Preparing Filter With Shape: (800, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 400, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 74, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (832, 128, ), Input shape (196, 832, ) (or (196, 832, )), Output shape (196, 128, ), ID: 75, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 832, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (832, 128, ) DONE
	Preparing Filter With Shape: (832, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 416, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 76, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (864, 128, ), Input shape (196, 864, ) (or (196, 864, )), Output shape (196, 128, ), ID: 77, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 864, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (864, 128, ) DONE
	Preparing Filter With Shape: (864, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 432, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 78, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (196, 896, ) (or (196, 896, )), Output shape (196, 128, ), ID: 79, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 896, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 448, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 80, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (196, 928, ) (or (196, 928, )), Output shape (196, 128, ), ID: 81, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 928, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (928, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 464, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 82, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (196, 960, ) (or (196, 960, )), Output shape (196, 128, ), ID: 83, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 960, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (960, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 480, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 84, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (196, 992, ) (or (196, 992, )), Output shape (196, 128, ), ID: 85, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 992, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (992, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 496, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 86, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (196, 1024, ) (or (196, 1024, )), Output shape (196, 128, ), ID: 87, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1024, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 512, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 88, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (196, 1056, ) (or (196, 1056, )), Output shape (196, 128, ), ID: 89, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1056, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1056, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 528, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 90, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (196, 1088, ) (or (196, 1088, )), Output shape (196, 128, ), ID: 91, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1088, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1088, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 544, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 92, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (196, 1120, ) (or (196, 1120, )), Output shape (196, 128, ), ID: 93, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1120, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 560, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 94, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (196, 1152, ) (or (196, 1152, )), Output shape (196, 128, ), ID: 95, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 96, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (196, 1184, ) (or (196, 1184, )), Output shape (196, 128, ), ID: 97, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1184, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1184, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 592, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 98, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (196, 1216, ) (or (196, 1216, )), Output shape (196, 128, ), ID: 99, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1216, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1216, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 608, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 100, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (196, 1248, ) (or (196, 1248, )), Output shape (196, 128, ), ID: 101, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1248, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1248, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 624, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 102, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (196, 1280, ) (or (196, 1280, )), Output shape (196, 128, ), ID: 103, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1280, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1280, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 640, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 104, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (196, 1312, ) (or (196, 1312, )), Output shape (196, 128, ), ID: 105, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1312, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1312, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 656, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 106, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (196, 1344, ) (or (196, 1344, )), Output shape (196, 128, ), ID: 107, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1344, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 672, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 108, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (196, 1376, ) (or (196, 1376, )), Output shape (196, 128, ), ID: 109, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1376, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1376, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 688, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 110, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (196, 1408, ) (or (196, 1408, )), Output shape (196, 128, ), ID: 111, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1408, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1408, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 704, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 112, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (196, 1440, ) (or (196, 1440, )), Output shape (196, 128, ), ID: 113, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1440, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1440, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 720, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 114, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (196, 1472, ) (or (196, 1472, )), Output shape (196, 128, ), ID: 115, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1472, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1472, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 736, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 116, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (196, 1504, ) (or (196, 1504, )), Output shape (196, 128, ), ID: 117, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1504, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1504, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 752, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 118, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (196, 1536, ) (or (196, 1536, )), Output shape (196, 128, ), ID: 119, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1536, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1536, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 768, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 120, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (196, 1568, ) (or (196, 1568, )), Output shape (196, 128, ), ID: 121, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1568, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1568, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 784, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 122, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (196, 1600, ) (or (196, 1600, )), Output shape (196, 128, ), ID: 123, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1600, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1600, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 800, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 124, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (196, 1632, ) (or (196, 1632, )), Output shape (196, 128, ), ID: 125, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1632, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1632, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 816, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 126, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (196, 1664, ) (or (196, 1664, )), Output shape (196, 128, ), ID: 127, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1664, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1664, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 832, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 128, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (196, 1696, ) (or (196, 1696, )), Output shape (196, 128, ), ID: 129, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1696, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1696, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 848, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 130, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (196, 1728, ) (or (196, 1728, )), Output shape (196, 128, ), ID: 131, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1728, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1728, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 864, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 132, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (196, 1760, ) (or (196, 1760, )), Output shape (196, 128, ), ID: 133, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1760, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1760, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 880, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (196, 128, ) (or (196, 1152, )), Output shape (196, 32, ), ID: 134, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1152, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 576, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 896, ), Input shape (196, 1792, ) (or (196, 1792, )), Output shape (196, 896, ), ID: 135, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (196, 1792, )
	No Changes To Appliability.
	Reserving 2 LowPrecision Tensors In Total
	Allocating Filter Shape: (1792, 896, ) DONE
	Preparing Filter With Shape: (1792, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (196, 896, ) DONE
Applying Conv Low-Precision for Kernel shape (896, 128, ), Input shape (49, 896, ) (or (49, 896, )), Output shape (49, 128, ), ID: 136, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 896, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (896, 128, ) DONE
	Preparing Filter With Shape: (896, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 448, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 137, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (928, 128, ), Input shape (49, 928, ) (or (49, 928, )), Output shape (49, 128, ), ID: 138, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 928, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (928, 128, ) DONE
	Preparing Filter With Shape: (928, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 464, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 139, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (960, 128, ), Input shape (49, 960, ) (or (49, 960, )), Output shape (49, 128, ), ID: 140, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 960, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (960, 128, ) DONE
	Preparing Filter With Shape: (960, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 480, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 960, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 141, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (992, 128, ), Input shape (49, 992, ) (or (49, 992, )), Output shape (49, 128, ), ID: 142, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 992, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (992, 128, ) DONE
	Preparing Filter With Shape: (992, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 496, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 992, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 143, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 128, ), Input shape (49, 1024, ) (or (49, 1024, )), Output shape (49, 128, ), ID: 144, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 128, ) DONE
	Preparing Filter With Shape: (1024, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 512, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 145, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1056, 128, ), Input shape (49, 1056, ) (or (49, 1056, )), Output shape (49, 128, ), ID: 146, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1056, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1056, 128, ) DONE
	Preparing Filter With Shape: (1056, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 528, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1056, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 147, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1088, 128, ), Input shape (49, 1088, ) (or (49, 1088, )), Output shape (49, 128, ), ID: 148, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1088, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1088, 128, ) DONE
	Preparing Filter With Shape: (1088, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 544, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1088, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 149, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1120, 128, ), Input shape (49, 1120, ) (or (49, 1120, )), Output shape (49, 128, ), ID: 150, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1120, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1120, 128, ) DONE
	Preparing Filter With Shape: (1120, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 560, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1120, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 151, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 128, ), Input shape (49, 1152, ) (or (49, 1152, )), Output shape (49, 128, ), ID: 152, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 128, ) DONE
	Preparing Filter With Shape: (1152, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 153, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1184, 128, ), Input shape (49, 1184, ) (or (49, 1184, )), Output shape (49, 128, ), ID: 154, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1184, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1184, 128, ) DONE
	Preparing Filter With Shape: (1184, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 592, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1184, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 155, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1216, 128, ), Input shape (49, 1216, ) (or (49, 1216, )), Output shape (49, 128, ), ID: 156, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1216, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1216, 128, ) DONE
	Preparing Filter With Shape: (1216, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 608, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1216, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 157, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1248, 128, ), Input shape (49, 1248, ) (or (49, 1248, )), Output shape (49, 128, ), ID: 158, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1248, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1248, 128, ) DONE
	Preparing Filter With Shape: (1248, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 624, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1248, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 159, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1280, 128, ), Input shape (49, 1280, ) (or (49, 1280, )), Output shape (49, 128, ), ID: 160, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1280, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1280, 128, ) DONE
	Preparing Filter With Shape: (1280, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 640, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1280, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 161, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1312, 128, ), Input shape (49, 1312, ) (or (49, 1312, )), Output shape (49, 128, ), ID: 162, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1312, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1312, 128, ) DONE
	Preparing Filter With Shape: (1312, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 656, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1312, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 163, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1344, 128, ), Input shape (49, 1344, ) (or (49, 1344, )), Output shape (49, 128, ), ID: 164, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1344, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1344, 128, ) DONE
	Preparing Filter With Shape: (1344, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 672, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1344, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 165, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1376, 128, ), Input shape (49, 1376, ) (or (49, 1376, )), Output shape (49, 128, ), ID: 166, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1376, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1376, 128, ) DONE
	Preparing Filter With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 688, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1376, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 167, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1408, 128, ), Input shape (49, 1408, ) (or (49, 1408, )), Output shape (49, 128, ), ID: 168, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1408, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1408, 128, ) DONE
	Preparing Filter With Shape: (1408, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 704, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1408, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 169, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1440, 128, ), Input shape (49, 1440, ) (or (49, 1440, )), Output shape (49, 128, ), ID: 170, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1440, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1440, 128, ) DONE
	Preparing Filter With Shape: (1440, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 720, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1440, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 171, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1472, 128, ), Input shape (49, 1472, ) (or (49, 1472, )), Output shape (49, 128, ), ID: 172, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1472, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1472, 128, ) DONE
	Preparing Filter With Shape: (1472, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 736, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1472, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 173, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1504, 128, ), Input shape (49, 1504, ) (or (49, 1504, )), Output shape (49, 128, ), ID: 174, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1504, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1504, 128, ) DONE
	Preparing Filter With Shape: (1504, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 752, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1504, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 175, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 128, ), Input shape (49, 1536, ) (or (49, 1536, )), Output shape (49, 128, ), ID: 176, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1536, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1536, 128, ) DONE
	Preparing Filter With Shape: (1536, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 768, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1536, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 177, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1568, 128, ), Input shape (49, 1568, ) (or (49, 1568, )), Output shape (49, 128, ), ID: 178, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1568, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1568, 128, ) DONE
	Preparing Filter With Shape: (1568, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 784, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1568, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 179, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1600, 128, ), Input shape (49, 1600, ) (or (49, 1600, )), Output shape (49, 128, ), ID: 180, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1600, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1600, 128, ) DONE
	Preparing Filter With Shape: (1600, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 800, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1600, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 181, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1632, 128, ), Input shape (49, 1632, ) (or (49, 1632, )), Output shape (49, 128, ), ID: 182, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1632, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1632, 128, ) DONE
	Preparing Filter With Shape: (1632, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 816, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1632, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 183, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1664, 128, ), Input shape (49, 1664, ) (or (49, 1664, )), Output shape (49, 128, ), ID: 184, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1664, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1664, 128, ) DONE
	Preparing Filter With Shape: (1664, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 832, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1664, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 185, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1696, 128, ), Input shape (49, 1696, ) (or (49, 1696, )), Output shape (49, 128, ), ID: 186, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1696, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1696, 128, ) DONE
	Preparing Filter With Shape: (1696, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 848, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1696, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 187, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1728, 128, ), Input shape (49, 1728, ) (or (49, 1728, )), Output shape (49, 128, ), ID: 188, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1728, 128, ) DONE
	Preparing Filter With Shape: (1728, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 864, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 189, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1760, 128, ), Input shape (49, 1760, ) (or (49, 1760, )), Output shape (49, 128, ), ID: 190, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1760, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1760, 128, ) DONE
	Preparing Filter With Shape: (1760, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 880, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1760, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 191, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1792, 128, ), Input shape (49, 1792, ) (or (49, 1792, )), Output shape (49, 128, ), ID: 192, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1792, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1792, 128, ) DONE
	Preparing Filter With Shape: (1792, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 896, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1792, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 193, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1824, 128, ), Input shape (49, 1824, ) (or (49, 1824, )), Output shape (49, 128, ), ID: 194, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1824, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1824, 128, ) DONE
	Preparing Filter With Shape: (1824, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 912, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1824, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 195, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1856, 128, ), Input shape (49, 1856, ) (or (49, 1856, )), Output shape (49, 128, ), ID: 196, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1856, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1856, 128, ) DONE
	Preparing Filter With Shape: (1856, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 928, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1856, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 197, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (1888, 128, ), Input shape (49, 1888, ) (or (49, 1888, )), Output shape (49, 128, ), ID: 198, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1888, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1888, 128, ) DONE
	Preparing Filter With Shape: (1888, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 944, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1888, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (1152, 32, ), Input shape (49, 128, ) (or (49, 1152, )), Output shape (49, 32, ), ID: 199, Method: SelfDependentW8A4
	Changing Input Shape
	New Input Shape: (49, 1152, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1152, 32, ) DONE
	Preparing Filter With Shape: (1152, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 576, ) DONE
	Allocating An Input Temporary Tensor With Shape: (52, 1152, ) DONE
	Allocating An Output Temporary Tensor With Shape: (52, 32, ) DONE
Applying FC Low-Precision for Kernel shape (1920, 1000, ), Input shape (1, 1920, ), Output shape (1, 1000, ), ID: 0, Method: SelfDependentW8A4
	Allocating Filter Shape: (1920, 1000, ) DONE
	Preparing Filter With Shape: (1920, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 960, ) DONE
	Allocating An Input Temporary Tensor With Shape: (4, 1920, ) DONE
	Allocating An Output Temporary Tensor With Shape: (4, 1000, ) DONE
The input model file size (MB): 20.5199
Initialized session in 257.474ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=693473 curr=680104 min=680104 max=693473 avg=686788 std=6684

Running benchmark for at least 100 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=100 first=680258 curr=679629 min=678862 max=681780 avg=679813 std=525

Inference timings in us: Init: 257474, First inference: 693473, Warmup (avg): 686788, Inference (avg): 679813
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=45.7461 overall=133.699
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  250.662	  250.662	100.000%	100.000%	 32064.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  250.662	  250.662	100.000%	100.000%	 32064.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   250.662	   100.000%	   100.000%	 32064.000	        1

Timings (microseconds): count=1 curr=250662
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     PAD	            0.024	    1.105	    1.127	  0.166%	  0.166%	     0.000	        1	[densenet201/zero_padding2d/Pad]:0
	                 CONV_2D	            1.151	   18.712	   18.626	  2.742%	  2.907%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                     PAD	           19.779	    3.703	    3.649	  0.537%	  3.445%	     0.000	        1	[densenet201/zero_padding2d_1/Pad]:2
	             MAX_POOL_2D	           23.429	    0.557	    0.585	  0.086%	  3.531%	     0.000	        1	[densenet201/pool1/MaxPool]:3
	                     MUL	           24.015	    0.600	    0.611	  0.090%	  3.621%	     0.000	        1	[densenet201/conv2_block1_0_bn/FusedBatchNormV31]:4
	                     ADD	           24.627	    0.877	    0.862	  0.127%	  3.747%	     0.000	        1	[densenet201/conv2_block1_0_relu/Relu;densenet201/conv2_block1_0_bn/FusedBatchNormV3]:5
	                 CONV_2D	           25.489	    3.681	    3.720	  0.548%	  4.295%	     0.000	        1	[densenet201/conv2_block1_1_relu/Relu;densenet201/conv2_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block1_1_conv/Conv2D]:6
	                 CONV_2D	           29.210	   16.440	   16.431	  2.419%	  6.713%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	           CONCATENATION	           45.643	    0.170	    0.168	  0.025%	  6.738%	     0.000	        1	[densenet201/conv2_block1_concat/concat]:8
	                     MUL	           45.811	    0.882	    0.901	  0.133%	  6.871%	     0.000	        1	[densenet201/conv2_block2_0_bn/FusedBatchNormV31]:9
	                     ADD	           46.712	    1.261	    1.264	  0.186%	  7.057%	     0.000	        1	[densenet201/conv2_block2_0_relu/Relu;densenet201/conv2_block2_0_bn/FusedBatchNormV3]:10
	                 CONV_2D	           47.977	    5.011	    5.030	  0.740%	  7.797%	     0.000	        1	[densenet201/conv2_block2_1_relu/Relu;densenet201/conv2_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block2_1_conv/Conv2D]:11
	                 CONV_2D	           53.008	   16.583	   16.618	  2.446%	 10.243%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	           CONCATENATION	           69.628	    0.224	    0.222	  0.033%	 10.276%	     0.000	        1	[densenet201/conv2_block2_concat/concat]:13
	                     MUL	           69.850	    1.141	    1.168	  0.172%	 10.448%	     0.000	        1	[densenet201/conv2_block3_0_bn/FusedBatchNormV3]:14
	                     ADD	           71.019	    1.681	    1.680	  0.247%	 10.695%	     0.000	        1	[densenet201/conv2_block3_0_relu/Relu;densenet201/conv2_block3_0_bn/FusedBatchNormV3]:15
	                 CONV_2D	           72.700	    6.412	    6.448	  0.949%	 11.644%	     0.000	        1	[densenet201/conv2_block3_1_relu/Relu;densenet201/conv2_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block3_1_conv/Conv2D]:16
	                 CONV_2D	           79.148	   16.303	   16.174	  2.381%	 14.025%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	           CONCATENATION	           95.324	    0.327	    0.328	  0.048%	 14.073%	     0.000	        1	[densenet201/conv2_block3_concat/concat]:18
	                     MUL	           95.652	    1.463	    1.459	  0.215%	 14.288%	     0.000	        1	[densenet201/conv2_block4_0_bn/FusedBatchNormV3]:19
	                     ADD	           97.112	    2.081	    2.083	  0.307%	 14.594%	     0.000	        1	[densenet201/conv2_block4_0_relu/Relu;densenet201/conv2_block4_0_bn/FusedBatchNormV3]:20
	                 CONV_2D	           99.196	    7.675	    7.661	  1.128%	 15.722%	     0.000	        1	[densenet201/conv2_block4_1_relu/Relu;densenet201/conv2_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block4_1_conv/Conv2D]:21
	                 CONV_2D	          106.858	   16.339	   16.348	  2.406%	 18.128%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	           CONCATENATION	          123.206	    0.340	    0.400	  0.059%	 18.187%	     0.000	        1	[densenet201/conv2_block4_concat/concat]:23
	                     MUL	          123.607	    1.709	    1.742	  0.256%	 18.443%	     0.000	        1	[densenet201/conv2_block5_0_bn/FusedBatchNormV3]:24
	                     ADD	          125.350	    2.513	    2.488	  0.366%	 18.810%	     0.000	        1	[densenet201/conv2_block5_0_relu/Relu;densenet201/conv2_block5_0_bn/FusedBatchNormV3]:25
	                 CONV_2D	          127.839	    9.198	    9.243	  1.360%	 20.170%	     0.000	        1	[densenet201/conv2_block5_1_relu/Relu;densenet201/conv2_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block5_1_conv/Conv2D]:26
	                 CONV_2D	          137.083	   16.335	   16.354	  2.407%	 22.577%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	           CONCATENATION	          153.438	    0.552	    0.451	  0.066%	 22.644%	     0.000	        1	[densenet201/conv2_block5_concat/concat]:28
	                     MUL	          153.891	    2.011	    2.028	  0.299%	 22.942%	     0.000	        1	[densenet201/conv2_block6_0_bn/FusedBatchNormV3]:29
	                     ADD	          155.920	    2.881	    2.894	  0.426%	 23.368%	     0.000	        1	[densenet201/conv2_block6_0_relu/Relu;densenet201/conv2_block6_0_bn/FusedBatchNormV3]:30
	                 CONV_2D	          158.815	   10.510	   10.507	  1.547%	 24.915%	     0.000	        1	[densenet201/conv2_block6_1_relu/Relu;densenet201/conv2_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv2_block6_1_conv/Conv2D]:31
	                 CONV_2D	          169.324	   16.455	   16.483	  2.426%	 27.341%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	           CONCATENATION	          185.808	    0.489	    0.488	  0.072%	 27.413%	     0.000	        1	[densenet201/conv2_block6_concat/concat]:33
	                     MUL	          186.297	    2.263	    2.312	  0.340%	 27.753%	     0.000	        1	[densenet201/pool2_bn/FusedBatchNormV3]:34
	                     ADD	          188.610	    3.387	    3.311	  0.487%	 28.240%	     0.000	        1	[densenet201/pool2_relu/Relu;densenet201/pool2_bn/FusedBatchNormV3]:35
	                 CONV_2D	          191.922	   11.797	   11.887	  1.750%	 29.990%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	         AVERAGE_POOL_2D	          203.810	    0.925	    0.913	  0.134%	 30.124%	     0.000	        1	[densenet201/pool2_pool/AvgPool]:37
	                     MUL	          204.724	    0.299	    0.297	  0.044%	 30.168%	     0.000	        1	[densenet201/conv3_block1_0_bn/FusedBatchNormV3]:38
	                     ADD	          205.021	    0.410	    0.428	  0.063%	 30.231%	     0.000	        1	[densenet201/conv3_block1_0_relu/Relu;densenet201/conv3_block1_0_bn/FusedBatchNormV3]:39
	                 CONV_2D	          205.450	    1.694	    1.678	  0.247%	 30.478%	     0.000	        1	[densenet201/conv3_block1_1_relu/Relu;densenet201/conv3_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block1_1_conv/Conv2D]:40
	                 CONV_2D	          207.128	    4.088	    4.097	  0.603%	 31.081%	     0.000	        1	[densenet201/conv3_block1_2_conv/Conv2D1]:41
	           CONCATENATION	          211.226	    0.100	    0.107	  0.016%	 31.096%	     0.000	        1	[densenet201/conv3_block1_concat/concat]:42
	                     MUL	          211.334	    0.370	    0.377	  0.055%	 31.152%	     0.000	        1	[densenet201/conv3_block2_0_bn/FusedBatchNormV31]:43
	                     ADD	          211.712	    0.511	    0.520	  0.077%	 31.228%	     0.000	        1	[densenet201/conv3_block2_0_relu/Relu;densenet201/conv3_block2_0_bn/FusedBatchNormV3]:44
	                 CONV_2D	          212.233	    2.103	    2.017	  0.297%	 31.525%	     0.000	        1	[densenet201/conv3_block2_1_relu/Relu;densenet201/conv3_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block2_1_conv/Conv2D]:45
	                 CONV_2D	          214.250	    4.189	    3.967	  0.584%	 32.109%	     0.000	        1	[densenet201/conv3_block2_2_conv/Conv2D1]:46
	           CONCATENATION	          218.218	    0.105	    0.145	  0.021%	 32.131%	     0.000	        1	[densenet201/conv3_block2_concat/concat]:47
	                     MUL	          218.365	    0.437	    0.445	  0.065%	 32.196%	     0.000	        1	[densenet201/conv3_block3_0_bn/FusedBatchNormV31]:48
	                     ADD	          218.810	    0.649	    0.624	  0.092%	 32.288%	     0.000	        1	[densenet201/conv3_block3_0_relu/Relu;densenet201/conv3_block3_0_bn/FusedBatchNormV3]:49
	                 CONV_2D	          219.435	    2.366	    2.397	  0.353%	 32.641%	     0.000	        1	[densenet201/conv3_block3_1_relu/Relu;densenet201/conv3_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block3_1_conv/Conv2D]:50
	                 CONV_2D	          221.833	    4.062	    4.011	  0.590%	 33.231%	     0.000	        1	[densenet201/conv3_block3_2_conv/Conv2D1]:51
	           CONCATENATION	          225.845	    0.160	    0.164	  0.024%	 33.255%	     0.000	        1	[densenet201/conv3_block3_concat/concat]:52
	                     MUL	          226.010	    0.500	    0.514	  0.076%	 33.331%	     0.000	        1	[densenet201/conv3_block4_0_bn/FusedBatchNormV31]:53
	                     ADD	          226.524	    0.712	    0.726	  0.107%	 33.438%	     0.000	        1	[densenet201/conv3_block4_0_relu/Relu;densenet201/conv3_block4_0_bn/FusedBatchNormV3]:54
	                 CONV_2D	          227.252	    2.684	    2.686	  0.395%	 33.833%	     0.000	        1	[densenet201/conv3_block4_1_relu/Relu;densenet201/conv3_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block4_1_conv/Conv2D]:55
	                 CONV_2D	          229.939	    3.959	    3.992	  0.588%	 34.421%	     0.000	        1	[densenet201/conv3_block4_2_conv/Conv2D1]:56
	           CONCATENATION	          233.932	    0.209	    0.204	  0.030%	 34.451%	     0.000	        1	[densenet201/conv3_block4_concat/concat]:57
	                     MUL	          234.137	    0.575	    0.583	  0.086%	 34.537%	     0.000	        1	[densenet201/conv3_block5_0_bn/FusedBatchNormV3]:58
	                     ADD	          234.721	    0.808	    0.826	  0.122%	 34.658%	     0.000	        1	[densenet201/conv3_block5_0_relu/Relu;densenet201/conv3_block5_0_bn/FusedBatchNormV3]:59
	                 CONV_2D	          235.548	    2.990	    3.009	  0.443%	 35.101%	     0.000	        1	[densenet201/conv3_block5_1_relu/Relu;densenet201/conv3_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block5_1_conv/Conv2D]:60
	                 CONV_2D	          238.558	    4.071	    4.064	  0.598%	 35.699%	     0.000	        1	[densenet201/conv3_block5_2_conv/Conv2D1]:61
	           CONCATENATION	          242.624	    0.201	    0.200	  0.029%	 35.729%	     0.000	        1	[densenet201/conv3_block5_concat/concat]:62
	                     MUL	          242.824	    0.634	    0.658	  0.097%	 35.825%	     0.000	        1	[densenet201/conv3_block6_0_bn/FusedBatchNormV3]:63
	                     ADD	          243.483	    0.961	    0.950	  0.140%	 35.965%	     0.000	        1	[densenet201/conv3_block6_0_relu/Relu;densenet201/conv3_block6_0_bn/FusedBatchNormV3]:64
	                 CONV_2D	          244.433	    3.296	    3.325	  0.489%	 36.455%	     0.000	        1	[densenet201/conv3_block6_1_relu/Relu;densenet201/conv3_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block6_1_conv/Conv2D]:65
	                 CONV_2D	          247.759	    4.120	    4.064	  0.598%	 37.053%	     0.000	        1	[densenet201/conv3_block6_2_conv/Conv2D1]:66
	           CONCATENATION	          251.825	    0.236	    0.232	  0.034%	 37.087%	     0.000	        1	[densenet201/conv3_block6_concat/concat]:67
	                     MUL	          252.058	    0.703	    0.730	  0.108%	 37.195%	     0.000	        1	[densenet201/conv3_block7_0_bn/FusedBatchNormV3]:68
	                     ADD	          252.789	    1.110	    1.057	  0.156%	 37.350%	     0.000	        1	[densenet201/conv3_block7_0_relu/Relu;densenet201/conv3_block7_0_bn/FusedBatchNormV3]:69
	                 CONV_2D	          253.847	    3.601	    3.647	  0.537%	 37.887%	     0.000	        1	[densenet201/conv3_block7_1_relu/Relu;densenet201/conv3_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block7_1_conv/Conv2D]:70
	                 CONV_2D	          257.495	    4.084	    4.017	  0.591%	 38.478%	     0.000	        1	[densenet201/conv3_block7_2_conv/Conv2D1]:71
	           CONCATENATION	          261.513	    0.259	    0.254	  0.037%	 38.516%	     0.000	        1	[densenet201/conv3_block7_concat/concat]:72
	                     MUL	          261.769	    0.777	    0.798	  0.117%	 38.633%	     0.000	        1	[densenet201/conv3_block8_0_bn/FusedBatchNormV3]:73
	                     ADD	          262.568	    1.166	    1.156	  0.170%	 38.803%	     0.000	        1	[densenet201/conv3_block8_0_relu/Relu;densenet201/conv3_block8_0_bn/FusedBatchNormV3]:74
	                 CONV_2D	          263.725	    3.992	    4.026	  0.593%	 39.396%	     0.000	        1	[densenet201/conv3_block8_1_relu/Relu;densenet201/conv3_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block8_1_conv/Conv2D]:75
	                 CONV_2D	          267.752	    4.037	    4.064	  0.598%	 39.994%	     0.000	        1	[densenet201/conv3_block8_2_conv/Conv2D1]:76
	           CONCATENATION	          271.817	    0.295	    0.294	  0.043%	 40.037%	     0.000	        1	[densenet201/conv3_block8_concat/concat]:77
	                     MUL	          272.112	    0.889	    0.868	  0.128%	 40.165%	     0.000	        1	[densenet201/conv3_block9_0_bn/FusedBatchNormV3]:78
	                     ADD	          272.980	    1.351	    1.264	  0.186%	 40.351%	     0.000	        1	[densenet201/conv3_block9_0_relu/Relu;densenet201/conv3_block9_0_bn/FusedBatchNormV3]:79
	                 CONV_2D	          274.245	    4.351	    4.380	  0.645%	 40.996%	     0.000	        1	[densenet201/conv3_block9_1_relu/Relu;densenet201/conv3_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block9_1_conv/Conv2D]:80
	                 CONV_2D	          278.626	    4.011	    4.042	  0.595%	 41.591%	     0.000	        1	[densenet201/conv3_block9_2_conv/Conv2D1]:81
	           CONCATENATION	          282.670	    0.353	    0.313	  0.046%	 41.637%	     0.000	        1	[densenet201/conv3_block9_concat/concat]:82
	                     MUL	          282.984	    0.920	    0.935	  0.138%	 41.775%	     0.000	        1	[densenet201/conv3_block10_0_bn/FusedBatchNormV3]:83
	                     ADD	          283.920	    1.442	    1.366	  0.201%	 41.976%	     0.000	        1	[densenet201/conv3_block10_0_relu/Relu;densenet201/conv3_block10_0_bn/FusedBatchNormV3]:84
	                 CONV_2D	          285.286	    4.650	    4.667	  0.687%	 42.663%	     0.000	        1	[densenet201/conv3_block10_1_relu/Relu;densenet201/conv3_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block10_1_conv/Conv2D]:85
	                 CONV_2D	          289.954	    4.050	    4.054	  0.597%	 43.259%	     0.000	        1	[densenet201/conv3_block10_2_conv/Conv2D1]:86
	           CONCATENATION	          294.009	    0.328	    0.324	  0.048%	 43.307%	     0.000	        1	[densenet201/conv3_block10_concat/concat]:87
	                     MUL	          294.334	    0.990	    1.010	  0.149%	 43.456%	     0.000	        1	[densenet201/conv3_block11_0_bn/FusedBatchNormV3]:88
	                     ADD	          295.345	    1.438	    1.472	  0.217%	 43.672%	     0.000	        1	[densenet201/conv3_block11_0_relu/Relu;densenet201/conv3_block11_0_bn/FusedBatchNormV3]:89
	                 CONV_2D	          296.818	    5.105	    5.016	  0.738%	 44.411%	     0.000	        1	[densenet201/conv3_block11_1_relu/Relu;densenet201/conv3_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block11_1_conv/Conv2D]:90
	                 CONV_2D	          301.835	    3.961	    3.980	  0.586%	 44.996%	     0.000	        1	[densenet201/conv3_block11_2_conv/Conv2D1]:91
	           CONCATENATION	          305.816	    0.323	    0.339	  0.050%	 45.046%	     0.000	        1	[densenet201/conv3_block11_concat/concat]:92
	                     MUL	          306.156	    1.099	    1.080	  0.159%	 45.205%	     0.000	        1	[densenet201/conv3_block12_0_bn/FusedBatchNormV3]:93
	                     ADD	          307.237	    1.541	    1.576	  0.232%	 45.437%	     0.000	        1	[densenet201/conv3_block12_0_relu/Relu;densenet201/conv3_block12_0_bn/FusedBatchNormV3]:94
	                 CONV_2D	          308.814	    5.378	    5.325	  0.784%	 46.221%	     0.000	        1	[densenet201/conv3_block12_1_relu/Relu;densenet201/conv3_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv3_block12_1_conv/Conv2D]:95
	                 CONV_2D	          314.141	    3.949	    3.990	  0.587%	 46.808%	     0.000	        1	[densenet201/conv3_block12_2_conv/Conv2D1]:96
	           CONCATENATION	          318.132	    0.309	    0.337	  0.050%	 46.858%	     0.000	        1	[densenet201/conv3_block12_concat/concat]:97
	                     MUL	          318.470	    1.132	    1.154	  0.170%	 47.028%	     0.000	        1	[densenet201/pool3_bn/FusedBatchNormV3]:98
	                     ADD	          319.624	    1.692	    1.679	  0.247%	 47.275%	     0.000	        1	[densenet201/pool3_relu/Relu;densenet201/pool3_bn/FusedBatchNormV3]:99
	                 CONV_2D	          321.304	   10.991	   11.016	  1.621%	 48.896%	     0.000	        1	[densenet201/pool3_conv/Conv2D1]:100
	         AVERAGE_POOL_2D	          332.322	    0.443	    0.448	  0.066%	 48.962%	     0.000	        1	[densenet201/pool3_pool/AvgPool]:101
	                     MUL	          332.771	    0.154	    0.151	  0.022%	 48.985%	     0.000	        1	[densenet201/conv4_block1_0_bn/FusedBatchNormV31]:102
	                     ADD	          332.922	    0.209	    0.212	  0.031%	 49.016%	     0.000	        1	[densenet201/conv4_block1_0_relu/Relu;densenet201/conv4_block1_0_bn/FusedBatchNormV3]:103
	                 CONV_2D	          333.135	    0.903	    0.836	  0.123%	 49.139%	     0.000	        1	[densenet201/conv4_block1_1_relu/Relu;densenet201/conv4_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block1_1_conv/Conv2D]:104
	                 CONV_2D	          333.972	    0.969	    0.984	  0.145%	 49.284%	     0.000	        1	[densenet201/conv4_block1_2_conv/Conv2D1]:105
	           CONCATENATION	          334.956	    0.023	    0.025	  0.004%	 49.287%	     0.000	        1	[densenet201/conv4_block1_concat/concat]:106
	                     MUL	          334.982	    0.169	    0.167	  0.025%	 49.312%	     0.000	        1	[densenet201/conv4_block2_0_bn/FusedBatchNormV31]:107
	                     ADD	          335.149	    0.235	    0.238	  0.035%	 49.347%	     0.000	        1	[densenet201/conv4_block2_0_relu/Relu;densenet201/conv4_block2_0_bn/FusedBatchNormV3]:108
	                 CONV_2D	          335.389	    0.838	    0.851	  0.125%	 49.472%	     0.000	        1	[densenet201/conv4_block2_1_relu/Relu;densenet201/conv4_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block2_1_conv/Conv2D]:109
	                 CONV_2D	          336.240	    0.877	    0.862	  0.127%	 49.599%	     0.000	        1	[densenet201/conv4_block2_2_conv/Conv2D1]:110
	           CONCATENATION	          337.102	    0.020	    0.023	  0.003%	 49.602%	     0.000	        1	[densenet201/conv4_block2_concat/concat]:111
	                     MUL	          337.125	    0.216	    0.187	  0.027%	 49.630%	     0.000	        1	[densenet201/conv4_block3_0_bn/FusedBatchNormV31]:112
	                     ADD	          337.312	    0.261	    0.264	  0.039%	 49.669%	     0.000	        1	[densenet201/conv4_block3_0_relu/Relu;densenet201/conv4_block3_0_bn/FusedBatchNormV3]:113
	                 CONV_2D	          337.577	    0.910	    0.927	  0.136%	 49.805%	     0.000	        1	[densenet201/conv4_block3_1_relu/Relu;densenet201/conv4_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block3_1_conv/Conv2D]:114
	                 CONV_2D	          338.504	    0.852	    0.867	  0.128%	 49.933%	     0.000	        1	[densenet201/conv4_block3_2_conv/Conv2D1]:115
	           CONCATENATION	          339.372	    0.020	    0.023	  0.003%	 49.936%	     0.000	        1	[densenet201/conv4_block3_concat/concat]:116
	                     MUL	          339.395	    0.200	    0.202	  0.030%	 49.966%	     0.000	        1	[densenet201/conv4_block4_0_bn/FusedBatchNormV31]:117
	                     ADD	          339.597	    0.283	    0.288	  0.042%	 50.008%	     0.000	        1	[densenet201/conv4_block4_0_relu/Relu;densenet201/conv4_block4_0_bn/FusedBatchNormV3]:118
	                 CONV_2D	          339.885	    0.990	    1.007	  0.148%	 50.156%	     0.000	        1	[densenet201/conv4_block4_1_relu/Relu;densenet201/conv4_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block4_1_conv/Conv2D]:119
	                 CONV_2D	          340.893	    0.905	    0.875	  0.129%	 50.285%	     0.000	        1	[densenet201/conv4_block4_2_conv/Conv2D1]:120
	           CONCATENATION	          341.769	    0.023	    0.025	  0.004%	 50.289%	     0.000	        1	[densenet201/conv4_block4_concat/concat]:121
	                     MUL	          341.795	    0.215	    0.220	  0.032%	 50.321%	     0.000	        1	[densenet201/conv4_block5_0_bn/FusedBatchNormV31]:122
	                     ADD	          342.015	    0.308	    0.313	  0.046%	 50.367%	     0.000	        1	[densenet201/conv4_block5_0_relu/Relu;densenet201/conv4_block5_0_bn/FusedBatchNormV3]:123
	                 CONV_2D	          342.329	    1.079	    1.088	  0.160%	 50.527%	     0.000	        1	[densenet201/conv4_block5_1_relu/Relu;densenet201/conv4_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block5_1_conv/Conv2D]:124
	                 CONV_2D	          343.417	    0.846	    0.874	  0.129%	 50.656%	     0.000	        1	[densenet201/conv4_block5_2_conv/Conv2D1]:125
	           CONCATENATION	          344.292	    0.022	    0.027	  0.004%	 50.660%	     0.000	        1	[densenet201/conv4_block5_concat/concat]:126
	                     MUL	          344.319	    0.234	    0.236	  0.035%	 50.695%	     0.000	        1	[densenet201/conv4_block6_0_bn/FusedBatchNormV31]:127
	                     ADD	          344.556	    0.340	    0.340	  0.050%	 50.745%	     0.000	        1	[densenet201/conv4_block6_0_relu/Relu;densenet201/conv4_block6_0_bn/FusedBatchNormV3]:128
	                 CONV_2D	          344.897	    1.236	    1.177	  0.173%	 50.918%	     0.000	        1	[densenet201/conv4_block6_1_relu/Relu;densenet201/conv4_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block6_1_conv/Conv2D]:129
	                 CONV_2D	          346.074	    0.877	    0.860	  0.127%	 51.045%	     0.000	        1	[densenet201/conv4_block6_2_conv/Conv2D1]:130
	           CONCATENATION	          346.935	    0.027	    0.029	  0.004%	 51.049%	     0.000	        1	[densenet201/conv4_block6_concat/concat]:131
	                     MUL	          346.965	    0.251	    0.256	  0.038%	 51.087%	     0.000	        1	[densenet201/conv4_block7_0_bn/FusedBatchNormV31]:132
	                     ADD	          347.221	    0.358	    0.367	  0.054%	 51.141%	     0.000	        1	[densenet201/conv4_block7_0_relu/Relu;densenet201/conv4_block7_0_bn/FusedBatchNormV3]:133
	                 CONV_2D	          347.589	    1.225	    1.245	  0.183%	 51.324%	     0.000	        1	[densenet201/conv4_block7_1_relu/Relu;densenet201/conv4_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block7_1_conv/Conv2D]:134
	                 CONV_2D	          348.834	    0.872	    0.866	  0.127%	 51.451%	     0.000	        1	[densenet201/conv4_block7_2_conv/Conv2D1]:135
	           CONCATENATION	          349.701	    0.029	    0.034	  0.005%	 51.456%	     0.000	        1	[densenet201/conv4_block7_concat/concat]:136
	                     MUL	          349.737	    0.268	    0.272	  0.040%	 51.496%	     0.000	        1	[densenet201/conv4_block8_0_bn/FusedBatchNormV31]:137
	                     ADD	          350.009	    0.390	    0.392	  0.058%	 51.554%	     0.000	        1	[densenet201/conv4_block8_0_relu/Relu;densenet201/conv4_block8_0_bn/FusedBatchNormV3]:138
	                 CONV_2D	          350.402	    1.318	    1.333	  0.196%	 51.750%	     0.000	        1	[densenet201/conv4_block8_1_relu/Relu;densenet201/conv4_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block8_1_conv/Conv2D]:139
	                 CONV_2D	          351.735	    0.836	    0.864	  0.127%	 51.877%	     0.000	        1	[densenet201/conv4_block8_2_conv/Conv2D1]:140
	           CONCATENATION	          352.600	    0.030	    0.034	  0.005%	 51.882%	     0.000	        1	[densenet201/conv4_block8_concat/concat]:141
	                     MUL	          352.634	    0.291	    0.291	  0.043%	 51.925%	     0.000	        1	[densenet201/conv4_block9_0_bn/FusedBatchNormV31]:142
	                     ADD	          352.926	    0.433	    0.423	  0.062%	 51.987%	     0.000	        1	[densenet201/conv4_block9_0_relu/Relu;densenet201/conv4_block9_0_bn/FusedBatchNormV3]:143
	                 CONV_2D	          353.349	    1.401	    1.411	  0.208%	 52.195%	     0.000	        1	[densenet201/conv4_block9_1_relu/Relu;densenet201/conv4_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block9_1_conv/Conv2D]:144
	                 CONV_2D	          354.760	    0.840	    0.870	  0.128%	 52.323%	     0.000	        1	[densenet201/conv4_block9_2_conv/Conv2D1]:145
	           CONCATENATION	          355.630	    0.031	    0.037	  0.005%	 52.329%	     0.000	        1	[densenet201/conv4_block9_concat/concat]:146
	                     MUL	          355.668	    0.309	    0.307	  0.045%	 52.374%	     0.000	        1	[densenet201/conv4_block10_0_bn/FusedBatchNormV31]:147
	                     ADD	          355.975	    0.434	    0.436	  0.064%	 52.438%	     0.000	        1	[densenet201/conv4_block10_0_relu/Relu;densenet201/conv4_block10_0_bn/FusedBatchNormV3]:148
	                 CONV_2D	          356.412	    1.568	    1.495	  0.220%	 52.658%	     0.000	        1	[densenet201/conv4_block10_1_relu/Relu;densenet201/conv4_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block10_1_conv/Conv2D]:149
	                 CONV_2D	          357.907	    0.865	    0.866	  0.127%	 52.785%	     0.000	        1	[densenet201/conv4_block10_2_conv/Conv2D1]:150
	           CONCATENATION	          358.774	    0.039	    0.039	  0.006%	 52.791%	     0.000	        1	[densenet201/conv4_block10_concat/concat]:151
	                     MUL	          358.813	    0.319	    0.325	  0.048%	 52.839%	     0.000	        1	[densenet201/conv4_block11_0_bn/FusedBatchNormV31]:152
	                     ADD	          359.139	    0.456	    0.462	  0.068%	 52.907%	     0.000	        1	[densenet201/conv4_block11_0_relu/Relu;densenet201/conv4_block11_0_bn/FusedBatchNormV3]:153
	                 CONV_2D	          359.602	    1.543	    1.573	  0.231%	 53.138%	     0.000	        1	[densenet201/conv4_block11_1_relu/Relu;densenet201/conv4_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block11_1_conv/Conv2D]:154
	                 CONV_2D	          361.175	    0.887	    0.879	  0.129%	 53.268%	     0.000	        1	[densenet201/conv4_block11_2_conv/Conv2D1]:155
	           CONCATENATION	          362.054	    0.035	    0.038	  0.006%	 53.273%	     0.000	        1	[densenet201/conv4_block11_concat/concat]:156
	                     MUL	          362.093	    0.334	    0.341	  0.050%	 53.324%	     0.000	        1	[densenet201/conv4_block12_0_bn/FusedBatchNormV31]:157
	                     ADD	          362.435	    0.480	    0.486	  0.071%	 53.395%	     0.000	        1	[densenet201/conv4_block12_0_relu/Relu;densenet201/conv4_block12_0_bn/FusedBatchNormV3]:158
	                 CONV_2D	          362.921	    1.643	    1.659	  0.244%	 53.639%	     0.000	        1	[densenet201/conv4_block12_1_relu/Relu;densenet201/conv4_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block12_1_conv/Conv2D]:159
	                 CONV_2D	          364.581	    0.879	    0.879	  0.129%	 53.769%	     0.000	        1	[densenet201/conv4_block12_2_conv/Conv2D1]:160
	           CONCATENATION	          365.461	    0.044	    0.047	  0.007%	 53.776%	     0.000	        1	[densenet201/conv4_block12_concat/concat]:161
	                     MUL	          365.508	    0.361	    0.359	  0.053%	 53.828%	     0.000	        1	[densenet201/conv4_block13_0_bn/FusedBatchNormV31]:162
	                     ADD	          365.868	    0.526	    0.511	  0.075%	 53.904%	     0.000	        1	[densenet201/conv4_block13_0_relu/Relu;densenet201/conv4_block13_0_bn/FusedBatchNormV3]:163
	                 CONV_2D	          366.380	    1.772	    1.752	  0.258%	 54.162%	     0.000	        1	[densenet201/conv4_block13_1_relu/Relu;densenet201/conv4_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block13_1_conv/Conv2D]:164
	                 CONV_2D	          368.133	    0.936	    0.873	  0.129%	 54.290%	     0.000	        1	[densenet201/conv4_block13_2_conv/Conv2D1]:165
	           CONCATENATION	          369.007	    0.070	    0.050	  0.007%	 54.298%	     0.000	        1	[densenet201/conv4_block13_concat/concat]:166
	                     MUL	          369.058	    0.409	    0.379	  0.056%	 54.353%	     0.000	        1	[densenet201/conv4_block14_0_bn/FusedBatchNormV31]:167
	                     ADD	          369.438	    0.533	    0.545	  0.080%	 54.434%	     0.000	        1	[densenet201/conv4_block14_0_relu/Relu;densenet201/conv4_block14_0_bn/FusedBatchNormV3]:168
	                 CONV_2D	          369.983	    1.816	    1.817	  0.267%	 54.701%	     0.000	        1	[densenet201/conv4_block14_1_relu/Relu;densenet201/conv4_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block14_1_conv/Conv2D]:169
	                 CONV_2D	          371.801	    0.918	    0.894	  0.132%	 54.833%	     0.000	        1	[densenet201/conv4_block14_2_conv/Conv2D1]:170
	           CONCATENATION	          372.696	    0.053	    0.056	  0.008%	 54.841%	     0.000	        1	[densenet201/conv4_block14_concat/concat]:171
	                     MUL	          372.753	    0.422	    0.399	  0.059%	 54.900%	     0.000	        1	[densenet201/conv4_block15_0_bn/FusedBatchNormV31]:172
	                     ADD	          373.152	    0.556	    0.565	  0.083%	 54.983%	     0.000	        1	[densenet201/conv4_block15_0_relu/Relu;densenet201/conv4_block15_0_bn/FusedBatchNormV3]:173
	                 CONV_2D	          373.717	    1.899	    1.914	  0.282%	 55.264%	     0.000	        1	[densenet201/conv4_block15_1_relu/Relu;densenet201/conv4_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block15_1_conv/Conv2D]:174
	                 CONV_2D	          375.632	    0.845	    0.867	  0.128%	 55.392%	     0.000	        1	[densenet201/conv4_block15_2_conv/Conv2D1]:175
	           CONCATENATION	          376.499	    0.041	    0.048	  0.007%	 55.399%	     0.000	        1	[densenet201/conv4_block15_concat/concat]:176
	                     MUL	          376.548	    0.409	    0.413	  0.061%	 55.460%	     0.000	        1	[densenet201/conv4_block16_0_bn/FusedBatchNormV31]:177
	                     ADD	          376.961	    0.606	    0.593	  0.087%	 55.547%	     0.000	        1	[densenet201/conv4_block16_0_relu/Relu;densenet201/conv4_block16_0_bn/FusedBatchNormV3]:178
	                 CONV_2D	          377.555	    1.959	    1.983	  0.292%	 55.839%	     0.000	        1	[densenet201/conv4_block16_1_relu/Relu;densenet201/conv4_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block16_1_conv/Conv2D]:179
	                 CONV_2D	          379.538	    0.872	    0.887	  0.131%	 55.969%	     0.000	        1	[densenet201/conv4_block16_2_conv/Conv2D1]:180
	           CONCATENATION	          380.426	    0.059	    0.067	  0.010%	 55.979%	     0.000	        1	[densenet201/conv4_block16_concat/concat]:181
	                     MUL	          380.494	    0.462	    0.432	  0.064%	 56.043%	     0.000	        1	[densenet201/conv4_block17_0_bn/FusedBatchNormV31]:182
	                     ADD	          380.926	    0.705	    0.615	  0.091%	 56.133%	     0.000	        1	[densenet201/conv4_block17_0_relu/Relu;densenet201/conv4_block17_0_bn/FusedBatchNormV3]:183
	                 CONV_2D	          381.542	    2.066	    2.077	  0.306%	 56.439%	     0.000	        1	[densenet201/conv4_block17_1_relu/Relu;densenet201/conv4_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block17_1_conv/Conv2D]:184
	                 CONV_2D	          383.619	    0.852	    0.882	  0.130%	 56.569%	     0.000	        1	[densenet201/conv4_block17_2_conv/Conv2D1]:185
	           CONCATENATION	          384.502	    0.060	    0.064	  0.009%	 56.578%	     0.000	        1	[densenet201/conv4_block17_concat/concat]:186
	                     MUL	          384.567	    0.443	    0.448	  0.066%	 56.644%	     0.000	        1	[densenet201/conv4_block18_0_bn/FusedBatchNormV31]:187
	                     ADD	          385.016	    0.669	    0.641	  0.094%	 56.739%	     0.000	        1	[densenet201/conv4_block18_0_relu/Relu;densenet201/conv4_block18_0_bn/FusedBatchNormV3]:188
	                 CONV_2D	          385.658	    2.125	    2.161	  0.318%	 57.057%	     0.000	        1	[densenet201/conv4_block18_1_relu/Relu;densenet201/conv4_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block18_1_conv/Conv2D]:189
	                 CONV_2D	          387.820	    0.870	    0.899	  0.132%	 57.189%	     0.000	        1	[densenet201/conv4_block18_2_conv/Conv2D1]:190
	           CONCATENATION	          388.720	    0.067	    0.073	  0.011%	 57.200%	     0.000	        1	[densenet201/conv4_block18_concat/concat]:191
	                     MUL	          388.793	    0.494	    0.470	  0.069%	 57.269%	     0.000	        1	[densenet201/conv4_block19_0_bn/FusedBatchNormV31]:192
	                     ADD	          389.263	    0.659	    0.666	  0.098%	 57.367%	     0.000	        1	[densenet201/conv4_block19_0_relu/Relu;densenet201/conv4_block19_0_bn/FusedBatchNormV3]:193
	                 CONV_2D	          389.930	    2.220	    2.238	  0.329%	 57.696%	     0.000	        1	[densenet201/conv4_block19_1_relu/Relu;densenet201/conv4_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block19_1_conv/Conv2D]:194
	                 CONV_2D	          392.168	    0.855	    0.889	  0.131%	 57.827%	     0.000	        1	[densenet201/conv4_block19_2_conv/Conv2D1]:195
	           CONCATENATION	          393.058	    0.057	    0.064	  0.009%	 57.837%	     0.000	        1	[densenet201/conv4_block19_concat/concat]:196
	                     MUL	          393.123	    0.588	    0.489	  0.072%	 57.909%	     0.000	        1	[densenet201/conv4_block20_0_bn/FusedBatchNormV31]:197
	                     ADD	          393.612	    0.683	    0.692	  0.102%	 58.011%	     0.000	        1	[densenet201/conv4_block20_0_relu/Relu;densenet201/conv4_block20_0_bn/FusedBatchNormV3]:198
	                 CONV_2D	          394.304	    2.301	    2.325	  0.342%	 58.353%	     0.000	        1	[densenet201/conv4_block20_1_relu/Relu;densenet201/conv4_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block20_1_conv/Conv2D]:199
	                 CONV_2D	          396.630	    0.919	    0.913	  0.134%	 58.487%	     0.000	        1	[densenet201/conv4_block20_2_conv/Conv2D1]:200
	           CONCATENATION	          397.543	    0.077	    0.083	  0.012%	 58.499%	     0.000	        1	[densenet201/conv4_block20_concat/concat]:201
	                     MUL	          397.626	    0.496	    0.504	  0.074%	 58.573%	     0.000	        1	[densenet201/conv4_block21_0_bn/FusedBatchNormV3]:202
	                     ADD	          398.131	    0.705	    0.715	  0.105%	 58.679%	     0.000	        1	[densenet201/conv4_block21_0_relu/Relu;densenet201/conv4_block21_0_bn/FusedBatchNormV3]:203
	                 CONV_2D	          398.847	    2.402	    2.415	  0.356%	 59.034%	     0.000	        1	[densenet201/conv4_block21_1_relu/Relu;densenet201/conv4_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block21_1_conv/Conv2D]:204
	                 CONV_2D	          401.263	    0.875	    0.885	  0.130%	 59.164%	     0.000	        1	[densenet201/conv4_block21_2_conv/Conv2D1]:205
	           CONCATENATION	          402.149	    0.093	    0.072	  0.011%	 59.175%	     0.000	        1	[densenet201/conv4_block21_concat/concat]:206
	                     MUL	          402.222	    0.524	    0.521	  0.077%	 59.252%	     0.000	        1	[densenet201/conv4_block22_0_bn/FusedBatchNormV3]:207
	                     ADD	          402.743	    0.729	    0.739	  0.109%	 59.361%	     0.000	        1	[densenet201/conv4_block22_0_relu/Relu;densenet201/conv4_block22_0_bn/FusedBatchNormV3]:208
	                 CONV_2D	          403.483	    2.595	    2.502	  0.368%	 59.729%	     0.000	        1	[densenet201/conv4_block22_1_relu/Relu;densenet201/conv4_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block22_1_conv/Conv2D]:209
	                 CONV_2D	          405.986	    0.917	    0.909	  0.134%	 59.863%	     0.000	        1	[densenet201/conv4_block22_2_conv/Conv2D1]:210
	           CONCATENATION	          406.896	    0.099	    0.096	  0.014%	 59.877%	     0.000	        1	[densenet201/conv4_block22_concat/concat]:211
	                     MUL	          406.992	    0.530	    0.542	  0.080%	 59.957%	     0.000	        1	[densenet201/conv4_block23_0_bn/FusedBatchNormV3]:212
	                     ADD	          407.535	    0.756	    0.765	  0.113%	 60.069%	     0.000	        1	[densenet201/conv4_block23_0_relu/Relu;densenet201/conv4_block23_0_bn/FusedBatchNormV3]:213
	                 CONV_2D	          408.300	    2.577	    2.589	  0.381%	 60.450%	     0.000	        1	[densenet201/conv4_block23_1_relu/Relu;densenet201/conv4_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block23_1_conv/Conv2D]:214
	                 CONV_2D	          410.890	    0.873	    0.896	  0.132%	 60.582%	     0.000	        1	[densenet201/conv4_block23_2_conv/Conv2D1]:215
	           CONCATENATION	          411.786	    0.071	    0.079	  0.012%	 60.594%	     0.000	        1	[densenet201/conv4_block23_concat/concat]:216
	                     MUL	          411.866	    0.549	    0.560	  0.082%	 60.676%	     0.000	        1	[densenet201/conv4_block24_0_bn/FusedBatchNormV3]:217
	                     ADD	          412.426	    0.818	    0.792	  0.117%	 60.793%	     0.000	        1	[densenet201/conv4_block24_0_relu/Relu;densenet201/conv4_block24_0_bn/FusedBatchNormV3]:218
	                 CONV_2D	          413.219	    2.643	    2.661	  0.392%	 61.184%	     0.000	        1	[densenet201/conv4_block24_1_relu/Relu;densenet201/conv4_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block24_1_conv/Conv2D]:219
	                 CONV_2D	          415.880	    0.895	    0.911	  0.134%	 61.318%	     0.000	        1	[densenet201/conv4_block24_2_conv/Conv2D1]:220
	           CONCATENATION	          416.792	    0.124	    0.110	  0.016%	 61.335%	     0.000	        1	[densenet201/conv4_block24_concat/concat]:221
	                     MUL	          416.903	    0.605	    0.581	  0.086%	 61.420%	     0.000	        1	[densenet201/conv4_block25_0_bn/FusedBatchNormV3]:222
	                     ADD	          417.485	    0.805	    0.822	  0.121%	 61.541%	     0.000	        1	[densenet201/conv4_block25_0_relu/Relu;densenet201/conv4_block25_0_bn/FusedBatchNormV3]:223
	                 CONV_2D	          418.307	    2.706	    2.754	  0.405%	 61.946%	     0.000	        1	[densenet201/conv4_block25_1_relu/Relu;densenet201/conv4_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block25_1_conv/Conv2D]:224
	                 CONV_2D	          421.062	    0.899	    0.911	  0.134%	 62.080%	     0.000	        1	[densenet201/conv4_block25_2_conv/Conv2D1]:225
	           CONCATENATION	          421.974	    0.091	    0.093	  0.014%	 62.094%	     0.000	        1	[densenet201/conv4_block25_concat/concat]:226
	                     MUL	          422.067	    0.580	    0.593	  0.087%	 62.181%	     0.000	        1	[densenet201/conv4_block26_0_bn/FusedBatchNormV3]:227
	                     ADD	          422.660	    0.825	    0.843	  0.124%	 62.305%	     0.000	        1	[densenet201/conv4_block26_0_relu/Relu;densenet201/conv4_block26_0_bn/FusedBatchNormV3]:228
	                 CONV_2D	          423.504	    2.844	    2.847	  0.419%	 62.724%	     0.000	        1	[densenet201/conv4_block26_1_relu/Relu;densenet201/conv4_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block26_1_conv/Conv2D]:229
	                 CONV_2D	          426.351	    0.873	    0.909	  0.134%	 62.858%	     0.000	        1	[densenet201/conv4_block26_2_conv/Conv2D1]:230
	           CONCATENATION	          427.261	    0.100	    0.117	  0.017%	 62.876%	     0.000	        1	[densenet201/conv4_block26_concat/concat]:231
	                     MUL	          427.379	    0.605	    0.613	  0.090%	 62.966%	     0.000	        1	[densenet201/conv4_block27_0_bn/FusedBatchNormV3]:232
	                     ADD	          427.993	    0.850	    0.867	  0.128%	 63.093%	     0.000	        1	[densenet201/conv4_block27_0_relu/Relu;densenet201/conv4_block27_0_bn/FusedBatchNormV3]:233
	                 CONV_2D	          428.860	    3.010	    2.942	  0.433%	 63.526%	     0.000	        1	[densenet201/conv4_block27_1_relu/Relu;densenet201/conv4_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block27_1_conv/Conv2D]:234
	                 CONV_2D	          431.803	    0.918	    0.917	  0.135%	 63.661%	     0.000	        1	[densenet201/conv4_block27_2_conv/Conv2D1]:235
	           CONCATENATION	          432.721	    0.124	    0.128	  0.019%	 63.680%	     0.000	        1	[densenet201/conv4_block27_concat/concat]:236
	                     MUL	          432.850	    0.656	    0.629	  0.093%	 63.773%	     0.000	        1	[densenet201/conv4_block28_0_bn/FusedBatchNormV3]:237
	                     ADD	          433.479	    0.901	    0.898	  0.132%	 63.905%	     0.000	        1	[densenet201/conv4_block28_0_relu/Relu;densenet201/conv4_block28_0_bn/FusedBatchNormV3]:238
	                 CONV_2D	          434.378	    2.995	    3.027	  0.446%	 64.351%	     0.000	        1	[densenet201/conv4_block28_1_relu/Relu;densenet201/conv4_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block28_1_conv/Conv2D]:239
	                 CONV_2D	          437.406	    0.896	    0.915	  0.135%	 64.485%	     0.000	        1	[densenet201/conv4_block28_2_conv/Conv2D1]:240
	           CONCATENATION	          438.322	    0.095	    0.107	  0.016%	 64.501%	     0.000	        1	[densenet201/conv4_block28_concat/concat]:241
	                     MUL	          438.430	    0.638	    0.645	  0.095%	 64.596%	     0.000	        1	[densenet201/conv4_block29_0_bn/FusedBatchNormV3]:242
	                     ADD	          439.076	    0.909	    0.915	  0.135%	 64.731%	     0.000	        1	[densenet201/conv4_block29_0_relu/Relu;densenet201/conv4_block29_0_bn/FusedBatchNormV3]:243
	                 CONV_2D	          439.992	    3.183	    3.130	  0.461%	 65.191%	     0.000	        1	[densenet201/conv4_block29_1_relu/Relu;densenet201/conv4_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block29_1_conv/Conv2D]:244
	                 CONV_2D	          443.122	    0.924	    0.916	  0.135%	 65.326%	     0.000	        1	[densenet201/conv4_block29_2_conv/Conv2D1]:245
	           CONCATENATION	          444.039	    0.110	    0.108	  0.016%	 65.342%	     0.000	        1	[densenet201/conv4_block29_concat/concat]:246
	                     MUL	          444.148	    0.666	    0.663	  0.098%	 65.440%	     0.000	        1	[densenet201/conv4_block30_0_bn/FusedBatchNormV3]:247
	                     ADD	          444.811	    0.961	    0.945	  0.139%	 65.579%	     0.000	        1	[densenet201/conv4_block30_0_relu/Relu;densenet201/conv4_block30_0_bn/FusedBatchNormV3]:248
	                 CONV_2D	          445.757	    3.154	    3.201	  0.471%	 66.050%	     0.000	        1	[densenet201/conv4_block30_1_relu/Relu;densenet201/conv4_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block30_1_conv/Conv2D]:249
	                 CONV_2D	          448.958	    0.940	    0.909	  0.134%	 66.184%	     0.000	        1	[densenet201/conv4_block30_2_conv/Conv2D1]:250
	           CONCATENATION	          449.868	    0.114	    0.111	  0.016%	 66.200%	     0.000	        1	[densenet201/conv4_block30_concat/concat]:251
	                     MUL	          449.979	    0.664	    0.678	  0.100%	 66.300%	     0.000	        1	[densenet201/conv4_block31_0_bn/FusedBatchNormV3]:252
	                     ADD	          450.658	    0.952	    0.972	  0.143%	 66.443%	     0.000	        1	[densenet201/conv4_block31_0_relu/Relu;densenet201/conv4_block31_0_bn/FusedBatchNormV3]:253
	                 CONV_2D	          451.631	    3.383	    3.300	  0.486%	 66.928%	     0.000	        1	[densenet201/conv4_block31_1_relu/Relu;densenet201/conv4_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block31_1_conv/Conv2D]:254
	                 CONV_2D	          454.931	    0.911	    0.929	  0.137%	 67.065%	     0.000	        1	[densenet201/conv4_block31_2_conv/Conv2D1]:255
	           CONCATENATION	          455.861	    0.107	    0.110	  0.016%	 67.081%	     0.000	        1	[densenet201/conv4_block31_concat/concat]:256
	                     MUL	          455.972	    0.681	    0.700	  0.103%	 67.184%	     0.000	        1	[densenet201/conv4_block32_0_bn/FusedBatchNormV3]:257
	                     ADD	          456.672	    1.009	    0.994	  0.146%	 67.331%	     0.000	        1	[densenet201/conv4_block32_0_relu/Relu;densenet201/conv4_block32_0_bn/FusedBatchNormV3]:258
	                 CONV_2D	          457.667	    3.331	    3.364	  0.495%	 67.826%	     0.000	        1	[densenet201/conv4_block32_1_relu/Relu;densenet201/conv4_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block32_1_conv/Conv2D]:259
	                 CONV_2D	          461.031	    0.906	    0.908	  0.134%	 67.959%	     0.000	        1	[densenet201/conv4_block32_2_conv/Conv2D1]:260
	           CONCATENATION	          461.940	    0.100	    0.096	  0.014%	 67.974%	     0.000	        1	[densenet201/conv4_block32_concat/concat]:261
	                     MUL	          462.037	    0.704	    0.715	  0.105%	 68.079%	     0.000	        1	[densenet201/conv4_block33_0_bn/FusedBatchNormV3]:262
	                     ADD	          462.753	    1.025	    1.022	  0.150%	 68.229%	     0.000	        1	[densenet201/conv4_block33_0_relu/Relu;densenet201/conv4_block33_0_bn/FusedBatchNormV3]:263
	                 CONV_2D	          463.775	    3.530	    3.457	  0.509%	 68.738%	     0.000	        1	[densenet201/conv4_block33_1_relu/Relu;densenet201/conv4_block33_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block33_1_conv/Conv2D]:264
	                 CONV_2D	          467.233	    0.942	    0.918	  0.135%	 68.873%	     0.000	        1	[densenet201/conv4_block33_2_conv/Conv2D1]:265
	           CONCATENATION	          468.151	    0.129	    0.130	  0.019%	 68.892%	     0.000	        1	[densenet201/conv4_block33_concat/concat]:266
	                     MUL	          468.282	    0.740	    0.734	  0.108%	 69.000%	     0.000	        1	[densenet201/conv4_block34_0_bn/FusedBatchNormV3]:267
	                     ADD	          469.017	    1.060	    1.048	  0.154%	 69.155%	     0.000	        1	[densenet201/conv4_block34_0_relu/Relu;densenet201/conv4_block34_0_bn/FusedBatchNormV3]:268
	                 CONV_2D	          470.066	    3.508	    3.553	  0.523%	 69.678%	     0.000	        1	[densenet201/conv4_block34_1_relu/Relu;densenet201/conv4_block34_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block34_1_conv/Conv2D]:269
	                 CONV_2D	          473.620	    0.891	    0.921	  0.136%	 69.813%	     0.000	        1	[densenet201/conv4_block34_2_conv/Conv2D1]:270
	           CONCATENATION	          474.542	    0.096	    0.108	  0.016%	 69.829%	     0.000	        1	[densenet201/conv4_block34_concat/concat]:271
	                     MUL	          474.651	    0.740	    0.755	  0.111%	 69.940%	     0.000	        1	[densenet201/conv4_block35_0_bn/FusedBatchNormV3]:272
	                     ADD	          475.407	    1.046	    1.065	  0.157%	 70.097%	     0.000	        1	[densenet201/conv4_block35_0_relu/Relu;densenet201/conv4_block35_0_bn/FusedBatchNormV3]:273
	                 CONV_2D	          476.473	    3.700	    3.629	  0.534%	 70.631%	     0.000	        1	[densenet201/conv4_block35_1_relu/Relu;densenet201/conv4_block35_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block35_1_conv/Conv2D]:274
	                 CONV_2D	          480.102	    0.915	    0.918	  0.135%	 70.766%	     0.000	        1	[densenet201/conv4_block35_2_conv/Conv2D1]:275
	           CONCATENATION	          481.020	    0.126	    0.133	  0.020%	 70.786%	     0.000	        1	[densenet201/conv4_block35_concat/concat]:276
	                     MUL	          481.154	    0.796	    0.776	  0.114%	 70.900%	     0.000	        1	[densenet201/conv4_block36_0_bn/FusedBatchNormV3]:277
	                     ADD	          481.931	    1.082	    1.097	  0.161%	 71.062%	     0.000	        1	[densenet201/conv4_block36_0_relu/Relu;densenet201/conv4_block36_0_bn/FusedBatchNormV3]:278
	                 CONV_2D	          483.029	    3.749	    3.736	  0.550%	 71.612%	     0.000	        1	[densenet201/conv4_block36_1_relu/Relu;densenet201/conv4_block36_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block36_1_conv/Conv2D]:279
	                 CONV_2D	          486.766	    0.869	    0.901	  0.133%	 71.744%	     0.000	        1	[densenet201/conv4_block36_2_conv/Conv2D1]:280
	           CONCATENATION	          487.668	    0.113	    0.118	  0.017%	 71.761%	     0.000	        1	[densenet201/conv4_block36_concat/concat]:281
	                     MUL	          487.786	    0.794	    0.788	  0.116%	 71.877%	     0.000	        1	[densenet201/conv4_block37_0_bn/FusedBatchNormV3]:282
	                     ADD	          488.575	    1.211	    1.124	  0.165%	 72.043%	     0.000	        1	[densenet201/conv4_block37_0_relu/Relu;densenet201/conv4_block37_0_bn/FusedBatchNormV3]:283
	                 CONV_2D	          489.700	    3.842	    3.838	  0.565%	 72.608%	     0.000	        1	[densenet201/conv4_block37_1_relu/Relu;densenet201/conv4_block37_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block37_1_conv/Conv2D]:284
	                 CONV_2D	          493.538	    0.883	    0.912	  0.134%	 72.742%	     0.000	        1	[densenet201/conv4_block37_2_conv/Conv2D1]:285
	           CONCATENATION	          494.451	    0.140	    0.142	  0.021%	 72.763%	     0.000	        1	[densenet201/conv4_block37_concat/concat]:286
	                     MUL	          494.594	    0.789	    0.811	  0.119%	 72.882%	     0.000	        1	[densenet201/conv4_block38_0_bn/FusedBatchNormV3]:287
	                     ADD	          495.406	    1.128	    1.150	  0.169%	 73.052%	     0.000	        1	[densenet201/conv4_block38_0_relu/Relu;densenet201/conv4_block38_0_bn/FusedBatchNormV3]:288
	                 CONV_2D	          496.557	    3.924	    3.923	  0.577%	 73.629%	     0.000	        1	[densenet201/conv4_block38_1_relu/Relu;densenet201/conv4_block38_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block38_1_conv/Conv2D]:289
	                 CONV_2D	          500.481	    0.988	    0.904	  0.133%	 73.762%	     0.000	        1	[densenet201/conv4_block38_2_conv/Conv2D1]:290
	           CONCATENATION	          501.386	    0.142	    0.135	  0.020%	 73.782%	     0.000	        1	[densenet201/conv4_block38_concat/concat]:291
	                     MUL	          501.522	    0.815	    0.827	  0.122%	 73.904%	     0.000	        1	[densenet201/conv4_block39_0_bn/FusedBatchNormV3]:292
	                     ADD	          502.350	    1.176	    1.176	  0.173%	 74.077%	     0.000	        1	[densenet201/conv4_block39_0_relu/Relu;densenet201/conv4_block39_0_bn/FusedBatchNormV3]:293
	                 CONV_2D	          503.526	    4.046	    4.005	  0.589%	 74.666%	     0.000	        1	[densenet201/conv4_block39_1_relu/Relu;densenet201/conv4_block39_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block39_1_conv/Conv2D]:294
	                 CONV_2D	          507.532	    0.938	    0.923	  0.136%	 74.802%	     0.000	        1	[densenet201/conv4_block39_2_conv/Conv2D1]:295
	           CONCATENATION	          508.455	    0.154	    0.165	  0.024%	 74.827%	     0.000	        1	[densenet201/conv4_block39_concat/concat]:296
	                     MUL	          508.621	    0.863	    0.844	  0.124%	 74.951%	     0.000	        1	[densenet201/conv4_block40_0_bn/FusedBatchNormV3]:297
	                     ADD	          509.466	    1.177	    1.198	  0.176%	 75.127%	     0.000	        1	[densenet201/conv4_block40_0_relu/Relu;densenet201/conv4_block40_0_bn/FusedBatchNormV3]:298
	                 CONV_2D	          510.665	    4.080	    4.116	  0.606%	 75.733%	     0.000	        1	[densenet201/conv4_block40_1_relu/Relu;densenet201/conv4_block40_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block40_1_conv/Conv2D]:299
	                 CONV_2D	          514.781	    0.882	    0.907	  0.133%	 75.866%	     0.000	        1	[densenet201/conv4_block40_2_conv/Conv2D1]:300
	           CONCATENATION	          515.689	    0.138	    0.141	  0.021%	 75.887%	     0.000	        1	[densenet201/conv4_block40_concat/concat]:301
	                     MUL	          515.831	    0.839	    0.858	  0.126%	 76.013%	     0.000	        1	[densenet201/conv4_block41_0_bn/FusedBatchNormV3]:302
	                     ADD	          516.689	    1.256	    1.225	  0.180%	 76.194%	     0.000	        1	[densenet201/conv4_block41_0_relu/Relu;densenet201/conv4_block41_0_bn/FusedBatchNormV3]:303
	                 CONV_2D	          517.915	    4.154	    4.178	  0.615%	 76.809%	     0.000	        1	[densenet201/conv4_block41_1_relu/Relu;densenet201/conv4_block41_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block41_1_conv/Conv2D]:304
	                 CONV_2D	          522.094	    0.905	    0.912	  0.134%	 76.943%	     0.000	        1	[densenet201/conv4_block41_2_conv/Conv2D1]:305
	           CONCATENATION	          523.007	    0.154	    0.158	  0.023%	 76.966%	     0.000	        1	[densenet201/conv4_block41_concat/concat]:306
	                     MUL	          523.165	    0.856	    0.874	  0.129%	 77.095%	     0.000	        1	[densenet201/conv4_block42_0_bn/FusedBatchNormV3]:307
	                     ADD	          524.040	    1.334	    1.253	  0.184%	 77.279%	     0.000	        1	[densenet201/conv4_block42_0_relu/Relu;densenet201/conv4_block42_0_bn/FusedBatchNormV3]:308
	                 CONV_2D	          525.293	    4.296	    4.277	  0.629%	 77.909%	     0.000	        1	[densenet201/conv4_block42_1_relu/Relu;densenet201/conv4_block42_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block42_1_conv/Conv2D]:309
	                 CONV_2D	          529.571	    0.886	    0.911	  0.134%	 78.043%	     0.000	        1	[densenet201/conv4_block42_2_conv/Conv2D1]:310
	           CONCATENATION	          530.483	    0.153	    0.157	  0.023%	 78.066%	     0.000	        1	[densenet201/conv4_block42_concat/concat]:311
	                     MUL	          530.641	    0.872	    0.898	  0.132%	 78.198%	     0.000	        1	[densenet201/conv4_block43_0_bn/FusedBatchNormV3]:312
	                     ADD	          531.539	    1.277	    1.277	  0.188%	 78.386%	     0.000	        1	[densenet201/conv4_block43_0_relu/Relu;densenet201/conv4_block43_0_bn/FusedBatchNormV3]:313
	                 CONV_2D	          532.816	    4.350	    4.366	  0.643%	 79.028%	     0.000	        1	[densenet201/conv4_block43_1_relu/Relu;densenet201/conv4_block43_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block43_1_conv/Conv2D]:314
	                 CONV_2D	          537.183	    0.894	    0.911	  0.134%	 79.163%	     0.000	        1	[densenet201/conv4_block43_2_conv/Conv2D1]:315
	           CONCATENATION	          538.095	    0.160	    0.163	  0.024%	 79.187%	     0.000	        1	[densenet201/conv4_block43_concat/concat]:316
	                     MUL	          538.258	    0.898	    0.918	  0.135%	 79.322%	     0.000	        1	[densenet201/conv4_block44_0_bn/FusedBatchNormV3]:317
	                     ADD	          539.177	    1.275	    1.298	  0.191%	 79.513%	     0.000	        1	[densenet201/conv4_block44_0_relu/Relu;densenet201/conv4_block44_0_bn/FusedBatchNormV3]:318
	                 CONV_2D	          540.476	    4.406	    4.440	  0.653%	 80.166%	     0.000	        1	[densenet201/conv4_block44_1_relu/Relu;densenet201/conv4_block44_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block44_1_conv/Conv2D]:319
	                 CONV_2D	          544.916	    0.916	    0.898	  0.132%	 80.298%	     0.000	        1	[densenet201/conv4_block44_2_conv/Conv2D1]:320
	           CONCATENATION	          545.815	    0.161	    0.176	  0.026%	 80.324%	     0.000	        1	[densenet201/conv4_block44_concat/concat]:321
	                     MUL	          545.991	    0.948	    0.931	  0.137%	 80.461%	     0.000	        1	[densenet201/conv4_block45_0_bn/FusedBatchNormV3]:322
	                     ADD	          546.923	    1.307	    1.325	  0.195%	 80.656%	     0.000	        1	[densenet201/conv4_block45_0_relu/Relu;densenet201/conv4_block45_0_bn/FusedBatchNormV3]:323
	                 CONV_2D	          548.249	    4.595	    4.530	  0.667%	 81.323%	     0.000	        1	[densenet201/conv4_block45_1_relu/Relu;densenet201/conv4_block45_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block45_1_conv/Conv2D]:324
	                 CONV_2D	          552.779	    0.919	    0.913	  0.134%	 81.457%	     0.000	        1	[densenet201/conv4_block45_2_conv/Conv2D1]:325
	           CONCATENATION	          553.693	    0.187	    0.180	  0.027%	 81.484%	     0.000	        1	[densenet201/conv4_block45_concat/concat]:326
	                     MUL	          553.875	    0.933	    0.950	  0.140%	 81.624%	     0.000	        1	[densenet201/conv4_block46_0_bn/FusedBatchNormV3]:327
	                     ADD	          554.825	    1.322	    1.352	  0.199%	 81.823%	     0.000	        1	[densenet201/conv4_block46_0_relu/Relu;densenet201/conv4_block46_0_bn/FusedBatchNormV3]:328
	                 CONV_2D	          556.178	    4.611	    4.637	  0.682%	 82.505%	     0.000	        1	[densenet201/conv4_block46_1_relu/Relu;densenet201/conv4_block46_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block46_1_conv/Conv2D]:329
	                 CONV_2D	          560.816	    1.012	    0.913	  0.134%	 82.640%	     0.000	        1	[densenet201/conv4_block46_2_conv/Conv2D1]:330
	           CONCATENATION	          561.729	    0.202	    0.171	  0.025%	 82.665%	     0.000	        1	[densenet201/conv4_block46_concat/concat]:331
	                     MUL	          561.902	    0.947	    0.968	  0.142%	 82.807%	     0.000	        1	[densenet201/conv4_block47_0_bn/FusedBatchNormV3]:332
	                     ADD	          562.870	    1.352	    1.380	  0.203%	 83.010%	     0.000	        1	[densenet201/conv4_block47_0_relu/Relu;densenet201/conv4_block47_0_bn/FusedBatchNormV3]:333
	                 CONV_2D	          564.251	    4.682	    4.728	  0.696%	 83.706%	     0.000	        1	[densenet201/conv4_block47_1_relu/Relu;densenet201/conv4_block47_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block47_1_conv/Conv2D]:334
	                 CONV_2D	          568.980	    0.936	    0.927	  0.136%	 83.843%	     0.000	        1	[densenet201/conv4_block47_2_conv/Conv2D1]:335
	           CONCATENATION	          569.908	    0.183	    0.189	  0.028%	 83.870%	     0.000	        1	[densenet201/conv4_block47_concat/concat]:336
	                     MUL	          570.097	    0.966	    0.987	  0.145%	 84.016%	     0.000	        1	[densenet201/conv4_block48_0_bn/FusedBatchNormV3]:337
	                     ADD	          571.085	    1.398	    1.405	  0.207%	 84.222%	     0.000	        1	[densenet201/conv4_block48_0_relu/Relu;densenet201/conv4_block48_0_bn/FusedBatchNormV3]:338
	                 CONV_2D	          572.490	    4.904	    4.808	  0.708%	 84.930%	     0.000	        1	[densenet201/conv4_block48_1_relu/Relu;densenet201/conv4_block48_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv4_block48_1_conv/Conv2D]:339
	                 CONV_2D	          577.299	    0.920	    0.928	  0.137%	 85.067%	     0.000	        1	[densenet201/conv4_block48_2_conv/Conv2D1]:340
	           CONCATENATION	          578.227	    0.174	    0.175	  0.026%	 85.092%	     0.000	        1	[densenet201/conv4_block48_concat/concat]:341
	                     MUL	          578.403	    0.981	    1.004	  0.148%	 85.240%	     0.000	        1	[densenet201/pool4_bn/FusedBatchNormV3]:342
	                     ADD	          579.408	    1.419	    1.429	  0.210%	 85.451%	     0.000	        1	[densenet201/pool4_relu/Relu;densenet201/pool4_bn/FusedBatchNormV3]:343
	                 CONV_2D	          580.839	   34.543	   34.396	  5.063%	 90.513%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	         AVERAGE_POOL_2D	          615.236	    0.456	    0.459	  0.068%	 90.581%	     0.000	        1	[densenet201/pool4_pool/AvgPool]:345
	                     MUL	          615.696	    0.136	    0.136	  0.020%	 90.601%	     0.000	        1	[densenet201/conv5_block1_0_bn/FusedBatchNormV31]:346
	                     ADD	          615.832	    0.176	    0.186	  0.027%	 90.628%	     0.000	        1	[densenet201/conv5_block1_0_relu/Relu;densenet201/conv5_block1_0_bn/FusedBatchNormV3]:347
	                 CONV_2D	          616.019	    0.713	    0.728	  0.107%	 90.735%	     0.000	        1	[densenet201/conv5_block1_1_relu/Relu;densenet201/conv5_block1_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block1_1_conv/Conv2D]:348
	                 CONV_2D	          616.747	    0.257	    0.265	  0.039%	 90.774%	     0.000	        1	[densenet201/conv5_block1_2_conv/Conv2D1]:349
	           CONCATENATION	          617.013	    0.016	    0.017	  0.002%	 90.777%	     0.000	        1	[densenet201/conv5_block1_concat/concat]:350
	                     MUL	          617.030	    0.180	    0.137	  0.020%	 90.797%	     0.000	        1	[densenet201/conv5_block2_0_bn/FusedBatchNormV31]:351
	                     ADD	          617.167	    0.180	    0.188	  0.028%	 90.825%	     0.000	        1	[densenet201/conv5_block2_0_relu/Relu;densenet201/conv5_block2_0_bn/FusedBatchNormV3]:352
	                 CONV_2D	          617.356	    0.684	    0.686	  0.101%	 90.926%	     0.000	        1	[densenet201/conv5_block2_1_relu/Relu;densenet201/conv5_block2_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block2_1_conv/Conv2D]:353
	                 CONV_2D	          618.042	    0.286	    0.254	  0.037%	 90.963%	     0.000	        1	[densenet201/conv5_block2_2_conv/Conv2D1]:354
	           CONCATENATION	          618.297	    0.014	    0.015	  0.002%	 90.965%	     0.000	        1	[densenet201/conv5_block2_concat/concat]:355
	                     MUL	          618.312	    0.141	    0.137	  0.020%	 90.985%	     0.000	        1	[densenet201/conv5_block3_0_bn/FusedBatchNormV31]:356
	                     ADD	          618.449	    0.195	    0.195	  0.029%	 91.014%	     0.000	        1	[densenet201/conv5_block3_0_relu/Relu;densenet201/conv5_block3_0_bn/FusedBatchNormV3]:357
	                 CONV_2D	          618.645	    0.720	    0.724	  0.107%	 91.121%	     0.000	        1	[densenet201/conv5_block3_1_relu/Relu;densenet201/conv5_block3_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block3_1_conv/Conv2D]:358
	                 CONV_2D	          619.370	    0.252	    0.268	  0.039%	 91.160%	     0.000	        1	[densenet201/conv5_block3_2_conv/Conv2D1]:359
	           CONCATENATION	          619.638	    0.012	    0.013	  0.002%	 91.162%	     0.000	        1	[densenet201/conv5_block3_concat/concat]:360
	                     MUL	          619.652	    0.137	    0.144	  0.021%	 91.183%	     0.000	        1	[densenet201/conv5_block4_0_bn/FusedBatchNormV31]:361
	                     ADD	          619.797	    0.200	    0.201	  0.030%	 91.213%	     0.000	        1	[densenet201/conv5_block4_0_relu/Relu;densenet201/conv5_block4_0_bn/FusedBatchNormV3]:362
	                 CONV_2D	          619.999	    0.752	    0.726	  0.107%	 91.320%	     0.000	        1	[densenet201/conv5_block4_1_relu/Relu;densenet201/conv5_block4_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block4_1_conv/Conv2D]:363
	                 CONV_2D	          620.725	    0.248	    0.254	  0.037%	 91.357%	     0.000	        1	[densenet201/conv5_block4_2_conv/Conv2D1]:364
	           CONCATENATION	          620.980	    0.104	    0.013	  0.002%	 91.359%	     0.000	        1	[densenet201/conv5_block4_concat/concat]:365
	                     MUL	          620.993	    0.154	    0.150	  0.022%	 91.381%	     0.000	        1	[densenet201/conv5_block5_0_bn/FusedBatchNormV31]:366
	                     ADD	          621.144	    0.207	    0.208	  0.031%	 91.412%	     0.000	        1	[densenet201/conv5_block5_0_relu/Relu;densenet201/conv5_block5_0_bn/FusedBatchNormV3]:367
	                 CONV_2D	          621.352	    0.747	    0.751	  0.111%	 91.522%	     0.000	        1	[densenet201/conv5_block5_1_relu/Relu;densenet201/conv5_block5_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block5_1_conv/Conv2D]:368
	                 CONV_2D	          622.104	    0.269	    0.271	  0.040%	 91.562%	     0.000	        1	[densenet201/conv5_block5_2_conv/Conv2D1]:369
	           CONCATENATION	          622.375	    0.013	    0.014	  0.002%	 91.564%	     0.000	        1	[densenet201/conv5_block5_concat/concat]:370
	                     MUL	          622.389	    0.144	    0.150	  0.022%	 91.586%	     0.000	        1	[densenet201/conv5_block6_0_bn/FusedBatchNormV31]:371
	                     ADD	          622.539	    0.211	    0.214	  0.031%	 91.618%	     0.000	        1	[densenet201/conv5_block6_0_relu/Relu;densenet201/conv5_block6_0_bn/FusedBatchNormV3]:372
	                 CONV_2D	          622.753	    0.759	    0.786	  0.116%	 91.733%	     0.000	        1	[densenet201/conv5_block6_1_relu/Relu;densenet201/conv5_block6_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block6_1_conv/Conv2D]:373
	                 CONV_2D	          623.540	    0.240	    0.255	  0.037%	 91.771%	     0.000	        1	[densenet201/conv5_block6_2_conv/Conv2D1]:374
	           CONCATENATION	          623.795	    0.021	    0.013	  0.002%	 91.773%	     0.000	        1	[densenet201/conv5_block6_concat/concat]:375
	                     MUL	          623.809	    0.148	    0.158	  0.023%	 91.796%	     0.000	        1	[densenet201/conv5_block7_0_bn/FusedBatchNormV31]:376
	                     ADD	          623.968	    0.217	    0.220	  0.032%	 91.828%	     0.000	        1	[densenet201/conv5_block7_0_relu/Relu;densenet201/conv5_block7_0_bn/FusedBatchNormV3]:377
	                 CONV_2D	          624.188	    0.812	    0.799	  0.118%	 91.946%	     0.000	        1	[densenet201/conv5_block7_1_relu/Relu;densenet201/conv5_block7_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block7_1_conv/Conv2D]:378
	                 CONV_2D	          624.987	    0.258	    0.259	  0.038%	 91.984%	     0.000	        1	[densenet201/conv5_block7_2_conv/Conv2D1]:379
	           CONCATENATION	          625.247	    0.013	    0.013	  0.002%	 91.986%	     0.000	        1	[densenet201/conv5_block7_concat/concat]:380
	                     MUL	          625.261	    0.161	    0.160	  0.024%	 92.010%	     0.000	        1	[densenet201/conv5_block8_0_bn/FusedBatchNormV31]:381
	                     ADD	          625.422	    0.223	    0.225	  0.033%	 92.043%	     0.000	        1	[densenet201/conv5_block8_0_relu/Relu;densenet201/conv5_block8_0_bn/FusedBatchNormV3]:382
	                 CONV_2D	          625.647	    0.816	    0.831	  0.122%	 92.165%	     0.000	        1	[densenet201/conv5_block8_1_relu/Relu;densenet201/conv5_block8_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block8_1_conv/Conv2D]:383
	                 CONV_2D	          626.479	    0.252	    0.267	  0.039%	 92.204%	     0.000	        1	[densenet201/conv5_block8_2_conv/Conv2D1]:384
	           CONCATENATION	          626.746	    0.013	    0.015	  0.002%	 92.207%	     0.000	        1	[densenet201/conv5_block8_concat/concat]:385
	                     MUL	          626.762	    0.165	    0.164	  0.024%	 92.231%	     0.000	        1	[densenet201/conv5_block9_0_bn/FusedBatchNormV31]:386
	                     ADD	          626.926	    0.228	    0.233	  0.034%	 92.265%	     0.000	        1	[densenet201/conv5_block9_0_relu/Relu;densenet201/conv5_block9_0_bn/FusedBatchNormV3]:387
	                 CONV_2D	          627.160	    0.825	    0.844	  0.124%	 92.389%	     0.000	        1	[densenet201/conv5_block9_1_relu/Relu;densenet201/conv5_block9_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block9_1_conv/Conv2D]:388
	                 CONV_2D	          628.005	    0.261	    0.260	  0.038%	 92.427%	     0.000	        1	[densenet201/conv5_block9_2_conv/Conv2D1]:389
	           CONCATENATION	          628.265	    0.013	    0.015	  0.002%	 92.430%	     0.000	        1	[densenet201/conv5_block9_concat/concat]:390
	                     MUL	          628.281	    0.169	    0.171	  0.025%	 92.455%	     0.000	        1	[densenet201/conv5_block10_0_bn/FusedBatchNormV31]:391
	                     ADD	          628.453	    0.235	    0.238	  0.035%	 92.490%	     0.000	        1	[densenet201/conv5_block10_0_relu/Relu;densenet201/conv5_block10_0_bn/FusedBatchNormV3]:392
	                 CONV_2D	          628.691	    0.891	    0.866	  0.128%	 92.617%	     0.000	        1	[densenet201/conv5_block10_1_relu/Relu;densenet201/conv5_block10_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block10_1_conv/Conv2D]:393
	                 CONV_2D	          629.558	    0.285	    0.275	  0.040%	 92.658%	     0.000	        1	[densenet201/conv5_block10_2_conv/Conv2D1]:394
	           CONCATENATION	          629.834	    0.037	    0.016	  0.002%	 92.660%	     0.000	        1	[densenet201/conv5_block10_concat/concat]:395
	                     MUL	          629.851	    0.166	    0.173	  0.025%	 92.686%	     0.000	        1	[densenet201/conv5_block11_0_bn/FusedBatchNormV31]:396
	                     ADD	          630.024	    0.243	    0.246	  0.036%	 92.722%	     0.000	        1	[densenet201/conv5_block11_0_relu/Relu;densenet201/conv5_block11_0_bn/FusedBatchNormV3]:397
	                 CONV_2D	          630.271	    0.873	    0.890	  0.131%	 92.853%	     0.000	        1	[densenet201/conv5_block11_1_relu/Relu;densenet201/conv5_block11_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block11_1_conv/Conv2D]:398
	                 CONV_2D	          631.162	    0.250	    0.258	  0.038%	 92.891%	     0.000	        1	[densenet201/conv5_block11_2_conv/Conv2D1]:399
	           CONCATENATION	          631.420	    0.013	    0.016	  0.002%	 92.893%	     0.000	        1	[densenet201/conv5_block11_concat/concat]:400
	                     MUL	          631.436	    0.178	    0.178	  0.026%	 92.920%	     0.000	        1	[densenet201/conv5_block12_0_bn/FusedBatchNormV31]:401
	                     ADD	          631.615	    0.247	    0.251	  0.037%	 92.956%	     0.000	        1	[densenet201/conv5_block12_0_relu/Relu;densenet201/conv5_block12_0_bn/FusedBatchNormV3]:402
	                 CONV_2D	          631.866	    0.887	    0.909	  0.134%	 93.090%	     0.000	        1	[densenet201/conv5_block12_1_relu/Relu;densenet201/conv5_block12_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block12_1_conv/Conv2D]:403
	                 CONV_2D	          632.776	    0.342	    0.261	  0.038%	 93.129%	     0.000	        1	[densenet201/conv5_block12_2_conv/Conv2D1]:404
	           CONCATENATION	          633.037	    0.018	    0.016	  0.002%	 93.131%	     0.000	        1	[densenet201/conv5_block12_concat/concat]:405
	                     MUL	          633.054	    0.189	    0.184	  0.027%	 93.158%	     0.000	        1	[densenet201/conv5_block13_0_bn/FusedBatchNormV31]:406
	                     ADD	          633.238	    0.255	    0.263	  0.039%	 93.197%	     0.000	        1	[densenet201/conv5_block13_0_relu/Relu;densenet201/conv5_block13_0_bn/FusedBatchNormV3]:407
	                 CONV_2D	          633.502	    0.949	    0.944	  0.139%	 93.336%	     0.000	        1	[densenet201/conv5_block13_1_relu/Relu;densenet201/conv5_block13_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block13_1_conv/Conv2D]:408
	                 CONV_2D	          634.447	    0.264	    0.270	  0.040%	 93.375%	     0.000	        1	[densenet201/conv5_block13_2_conv/Conv2D1]:409
	           CONCATENATION	          634.717	    0.015	    0.017	  0.002%	 93.378%	     0.000	        1	[densenet201/conv5_block13_concat/concat]:410
	                     MUL	          634.734	    0.186	    0.189	  0.028%	 93.406%	     0.000	        1	[densenet201/conv5_block14_0_bn/FusedBatchNormV31]:411
	                     ADD	          634.924	    0.258	    0.264	  0.039%	 93.445%	     0.000	        1	[densenet201/conv5_block14_0_relu/Relu;densenet201/conv5_block14_0_bn/FusedBatchNormV3]:412
	                 CONV_2D	          635.189	    0.957	    0.956	  0.141%	 93.585%	     0.000	        1	[densenet201/conv5_block14_1_relu/Relu;densenet201/conv5_block14_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block14_1_conv/Conv2D]:413
	                 CONV_2D	          636.145	    0.257	    0.260	  0.038%	 93.624%	     0.000	        1	[densenet201/conv5_block14_2_conv/Conv2D1]:414
	           CONCATENATION	          636.406	    0.018	    0.016	  0.002%	 93.626%	     0.000	        1	[densenet201/conv5_block14_concat/concat]:415
	                     MUL	          636.423	    0.191	    0.191	  0.028%	 93.654%	     0.000	        1	[densenet201/conv5_block15_0_bn/FusedBatchNormV31]:416
	                     ADD	          636.615	    0.265	    0.271	  0.040%	 93.694%	     0.000	        1	[densenet201/conv5_block15_0_relu/Relu;densenet201/conv5_block15_0_bn/FusedBatchNormV3]:417
	                 CONV_2D	          636.886	    0.998	    0.986	  0.145%	 93.839%	     0.000	        1	[densenet201/conv5_block15_1_relu/Relu;densenet201/conv5_block15_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block15_1_conv/Conv2D]:418
	                 CONV_2D	          637.873	    0.285	    0.275	  0.040%	 93.880%	     0.000	        1	[densenet201/conv5_block15_2_conv/Conv2D1]:419
	           CONCATENATION	          638.148	    0.015	    0.017	  0.003%	 93.882%	     0.000	        1	[densenet201/conv5_block15_concat/concat]:420
	                     MUL	          638.166	    0.197	    0.200	  0.029%	 93.912%	     0.000	        1	[densenet201/conv5_block16_0_bn/FusedBatchNormV31]:421
	                     ADD	          638.366	    0.274	    0.279	  0.041%	 93.953%	     0.000	        1	[densenet201/conv5_block16_0_relu/Relu;densenet201/conv5_block16_0_bn/FusedBatchNormV3]:422
	                 CONV_2D	          638.646	    0.980	    1.007	  0.148%	 94.101%	     0.000	        1	[densenet201/conv5_block16_1_relu/Relu;densenet201/conv5_block16_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block16_1_conv/Conv2D]:423
	                 CONV_2D	          639.653	    0.253	    0.265	  0.039%	 94.140%	     0.000	        1	[densenet201/conv5_block16_2_conv/Conv2D1]:424
	           CONCATENATION	          639.918	    0.014	    0.017	  0.002%	 94.142%	     0.000	        1	[densenet201/conv5_block16_concat/concat]:425
	                     MUL	          639.935	    0.199	    0.201	  0.030%	 94.172%	     0.000	        1	[densenet201/conv5_block17_0_bn/FusedBatchNormV31]:426
	                     ADD	          640.137	    0.277	    0.284	  0.042%	 94.214%	     0.000	        1	[densenet201/conv5_block17_0_relu/Relu;densenet201/conv5_block17_0_bn/FusedBatchNormV3]:427
	                 CONV_2D	          640.421	    1.039	    1.023	  0.151%	 94.364%	     0.000	        1	[densenet201/conv5_block17_1_relu/Relu;densenet201/conv5_block17_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block17_1_conv/Conv2D]:428
	                 CONV_2D	          641.445	    0.292	    0.273	  0.040%	 94.404%	     0.000	        1	[densenet201/conv5_block17_2_conv/Conv2D1]:429
	           CONCATENATION	          641.718	    0.018	    0.018	  0.003%	 94.407%	     0.000	        1	[densenet201/conv5_block17_concat/concat]:430
	                     MUL	          641.736	    0.204	    0.208	  0.031%	 94.437%	     0.000	        1	[densenet201/conv5_block18_0_bn/FusedBatchNormV31]:431
	                     ADD	          641.945	    0.284	    0.287	  0.042%	 94.480%	     0.000	        1	[densenet201/conv5_block18_0_relu/Relu;densenet201/conv5_block18_0_bn/FusedBatchNormV3]:432
	                 CONV_2D	          642.232	    1.020	    1.053	  0.155%	 94.635%	     0.000	        1	[densenet201/conv5_block18_1_relu/Relu;densenet201/conv5_block18_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block18_1_conv/Conv2D]:433
	                 CONV_2D	          643.285	    0.251	    0.262	  0.039%	 94.673%	     0.000	        1	[densenet201/conv5_block18_2_conv/Conv2D1]:434
	           CONCATENATION	          643.548	    0.016	    0.017	  0.003%	 94.676%	     0.000	        1	[densenet201/conv5_block18_concat/concat]:435
	                     MUL	          643.566	    0.208	    0.211	  0.031%	 94.707%	     0.000	        1	[densenet201/conv5_block19_0_bn/FusedBatchNormV31]:436
	                     ADD	          643.777	    0.289	    0.296	  0.044%	 94.750%	     0.000	        1	[densenet201/conv5_block19_0_relu/Relu;densenet201/conv5_block19_0_bn/FusedBatchNormV3]:437
	                 CONV_2D	          644.074	    1.164	    1.063	  0.157%	 94.907%	     0.000	        1	[densenet201/conv5_block19_1_relu/Relu;densenet201/conv5_block19_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block19_1_conv/Conv2D]:438
	                 CONV_2D	          645.138	    0.294	    0.279	  0.041%	 94.948%	     0.000	        1	[densenet201/conv5_block19_2_conv/Conv2D1]:439
	           CONCATENATION	          645.418	    0.021	    0.019	  0.003%	 94.951%	     0.000	        1	[densenet201/conv5_block19_concat/concat]:440
	                     MUL	          645.437	    0.214	    0.216	  0.032%	 94.983%	     0.000	        1	[densenet201/conv5_block20_0_bn/FusedBatchNormV31]:441
	                     ADD	          645.654	    0.295	    0.302	  0.044%	 95.027%	     0.000	        1	[densenet201/conv5_block20_0_relu/Relu;densenet201/conv5_block20_0_bn/FusedBatchNormV3]:442
	                 CONV_2D	          645.956	    1.074	    1.100	  0.162%	 95.189%	     0.000	        1	[densenet201/conv5_block20_1_relu/Relu;densenet201/conv5_block20_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block20_1_conv/Conv2D]:443
	                 CONV_2D	          647.057	    0.259	    0.271	  0.040%	 95.229%	     0.000	        1	[densenet201/conv5_block20_2_conv/Conv2D1]:444
	           CONCATENATION	          647.328	    0.017	    0.019	  0.003%	 95.232%	     0.000	        1	[densenet201/conv5_block20_concat/concat]:445
	                     MUL	          647.348	    0.216	    0.217	  0.032%	 95.264%	     0.000	        1	[densenet201/conv5_block21_0_bn/FusedBatchNormV31]:446
	                     ADD	          647.566	    0.310	    0.306	  0.045%	 95.309%	     0.000	        1	[densenet201/conv5_block21_0_relu/Relu;densenet201/conv5_block21_0_bn/FusedBatchNormV3]:447
	                 CONV_2D	          647.873	    1.126	    1.121	  0.165%	 95.474%	     0.000	        1	[densenet201/conv5_block21_1_relu/Relu;densenet201/conv5_block21_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block21_1_conv/Conv2D]:448
	                 CONV_2D	          648.994	    0.284	    0.279	  0.041%	 95.515%	     0.000	        1	[densenet201/conv5_block21_2_conv/Conv2D1]:449
	           CONCATENATION	          649.274	    0.018	    0.019	  0.003%	 95.517%	     0.000	        1	[densenet201/conv5_block21_concat/concat]:450
	                     MUL	          649.293	    0.232	    0.223	  0.033%	 95.550%	     0.000	        1	[densenet201/conv5_block22_0_bn/FusedBatchNormV31]:451
	                     ADD	          649.517	    0.308	    0.315	  0.046%	 95.597%	     0.000	        1	[densenet201/conv5_block22_0_relu/Relu;densenet201/conv5_block22_0_bn/FusedBatchNormV3]:452
	                 CONV_2D	          649.833	    1.119	    1.143	  0.168%	 95.765%	     0.000	        1	[densenet201/conv5_block22_1_relu/Relu;densenet201/conv5_block22_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block22_1_conv/Conv2D]:453
	                 CONV_2D	          650.977	    0.257	    0.269	  0.040%	 95.804%	     0.000	        1	[densenet201/conv5_block22_2_conv/Conv2D1]:454
	           CONCATENATION	          651.246	    0.016	    0.020	  0.003%	 95.807%	     0.000	        1	[densenet201/conv5_block22_concat/concat]:455
	                     MUL	          651.267	    0.224	    0.229	  0.034%	 95.841%	     0.000	        1	[densenet201/conv5_block23_0_bn/FusedBatchNormV31]:456
	                     ADD	          651.496	    0.314	    0.324	  0.048%	 95.889%	     0.000	        1	[densenet201/conv5_block23_0_relu/Relu;densenet201/conv5_block23_0_bn/FusedBatchNormV3]:457
	                 CONV_2D	          651.820	    1.134	    1.155	  0.170%	 96.059%	     0.000	        1	[densenet201/conv5_block23_1_relu/Relu;densenet201/conv5_block23_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block23_1_conv/Conv2D]:458
	                 CONV_2D	          652.976	    0.322	    0.281	  0.041%	 96.100%	     0.000	        1	[densenet201/conv5_block23_2_conv/Conv2D1]:459
	           CONCATENATION	          653.258	    0.019	    0.020	  0.003%	 96.103%	     0.000	        1	[densenet201/conv5_block23_concat/concat]:460
	                     MUL	          653.279	    0.230	    0.233	  0.034%	 96.137%	     0.000	        1	[densenet201/conv5_block24_0_bn/FusedBatchNormV31]:461
	                     ADD	          653.512	    0.320	    0.327	  0.048%	 96.185%	     0.000	        1	[densenet201/conv5_block24_0_relu/Relu;densenet201/conv5_block24_0_bn/FusedBatchNormV3]:462
	                 CONV_2D	          653.839	    1.183	    1.189	  0.175%	 96.361%	     0.000	        1	[densenet201/conv5_block24_1_relu/Relu;densenet201/conv5_block24_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block24_1_conv/Conv2D]:463
	                 CONV_2D	          655.029	    0.270	    0.273	  0.040%	 96.401%	     0.000	        1	[densenet201/conv5_block24_2_conv/Conv2D1]:464
	           CONCATENATION	          655.302	    0.018	    0.020	  0.003%	 96.404%	     0.000	        1	[densenet201/conv5_block24_concat/concat]:465
	                     MUL	          655.323	    0.234	    0.237	  0.035%	 96.439%	     0.000	        1	[densenet201/conv5_block25_0_bn/FusedBatchNormV31]:466
	                     ADD	          655.561	    0.327	    0.333	  0.049%	 96.488%	     0.000	        1	[densenet201/conv5_block25_0_relu/Relu;densenet201/conv5_block25_0_bn/FusedBatchNormV3]:467
	                 CONV_2D	          655.895	    1.293	    1.203	  0.177%	 96.665%	     0.000	        1	[densenet201/conv5_block25_1_relu/Relu;densenet201/conv5_block25_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block25_1_conv/Conv2D]:468
	                 CONV_2D	          657.098	    0.297	    0.279	  0.041%	 96.706%	     0.000	        1	[densenet201/conv5_block25_2_conv/Conv2D1]:469
	           CONCATENATION	          657.378	    0.023	    0.023	  0.003%	 96.709%	     0.000	        1	[densenet201/conv5_block25_concat/concat]:470
	                     MUL	          657.403	    0.239	    0.241	  0.035%	 96.745%	     0.000	        1	[densenet201/conv5_block26_0_bn/FusedBatchNormV31]:471
	                     ADD	          657.644	    0.340	    0.342	  0.050%	 96.795%	     0.000	        1	[densenet201/conv5_block26_0_relu/Relu;densenet201/conv5_block26_0_bn/FusedBatchNormV3]:472
	                 CONV_2D	          657.986	    1.214	    1.235	  0.182%	 96.977%	     0.000	        1	[densenet201/conv5_block26_1_relu/Relu;densenet201/conv5_block26_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block26_1_conv/Conv2D]:473
	                 CONV_2D	          659.222	    0.260	    0.271	  0.040%	 97.017%	     0.000	        1	[densenet201/conv5_block26_2_conv/Conv2D1]:474
	           CONCATENATION	          659.493	    0.020	    0.023	  0.003%	 97.020%	     0.000	        1	[densenet201/conv5_block26_concat/concat]:475
	                     MUL	          659.517	    0.241	    0.243	  0.036%	 97.056%	     0.000	        1	[densenet201/conv5_block27_0_bn/FusedBatchNormV31]:476
	                     ADD	          659.761	    0.337	    0.347	  0.051%	 97.107%	     0.000	        1	[densenet201/conv5_block27_0_relu/Relu;densenet201/conv5_block27_0_bn/FusedBatchNormV3]:477
	                 CONV_2D	          660.109	    1.259	    1.254	  0.185%	 97.292%	     0.000	        1	[densenet201/conv5_block27_1_relu/Relu;densenet201/conv5_block27_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block27_1_conv/Conv2D]:478
	                 CONV_2D	          661.364	    0.287	    0.284	  0.042%	 97.333%	     0.000	        1	[densenet201/conv5_block27_2_conv/Conv2D1]:479
	           CONCATENATION	          661.649	    0.022	    0.024	  0.004%	 97.337%	     0.000	        1	[densenet201/conv5_block27_concat/concat]:480
	                     MUL	          661.674	    0.247	    0.255	  0.038%	 97.374%	     0.000	        1	[densenet201/conv5_block28_0_bn/FusedBatchNormV31]:481
	                     ADD	          661.929	    0.351	    0.351	  0.052%	 97.426%	     0.000	        1	[densenet201/conv5_block28_0_relu/Relu;densenet201/conv5_block28_0_bn/FusedBatchNormV3]:482
	                 CONV_2D	          662.281	    1.242	    1.282	  0.189%	 97.615%	     0.000	        1	[densenet201/conv5_block28_1_relu/Relu;densenet201/conv5_block28_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block28_1_conv/Conv2D]:483
	                 CONV_2D	          663.564	    0.262	    0.270	  0.040%	 97.655%	     0.000	        1	[densenet201/conv5_block28_2_conv/Conv2D1]:484
	           CONCATENATION	          663.834	    0.020	    0.025	  0.004%	 97.658%	     0.000	        1	[densenet201/conv5_block28_concat/concat]:485
	                     MUL	          663.860	    0.253	    0.259	  0.038%	 97.696%	     0.000	        1	[densenet201/conv5_block29_0_bn/FusedBatchNormV31]:486
	                     ADD	          664.120	    0.385	    0.360	  0.053%	 97.749%	     0.000	        1	[densenet201/conv5_block29_0_relu/Relu;densenet201/conv5_block29_0_bn/FusedBatchNormV3]:487
	                 CONV_2D	          664.480	    1.383	    1.298	  0.191%	 97.940%	     0.000	        1	[densenet201/conv5_block29_1_relu/Relu;densenet201/conv5_block29_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block29_1_conv/Conv2D]:488
	                 CONV_2D	          665.778	    0.311	    0.288	  0.042%	 97.983%	     0.000	        1	[densenet201/conv5_block29_2_conv/Conv2D1]:489
	           CONCATENATION	          666.067	    0.028	    0.025	  0.004%	 97.987%	     0.000	        1	[densenet201/conv5_block29_concat/concat]:490
	                     MUL	          666.092	    0.255	    0.259	  0.038%	 98.025%	     0.000	        1	[densenet201/conv5_block30_0_bn/FusedBatchNormV31]:491
	                     ADD	          666.352	    0.362	    0.364	  0.054%	 98.078%	     0.000	        1	[densenet201/conv5_block30_0_relu/Relu;densenet201/conv5_block30_0_bn/FusedBatchNormV3]:492
	                 CONV_2D	          666.716	    1.286	    1.329	  0.196%	 98.274%	     0.000	        1	[densenet201/conv5_block30_1_relu/Relu;densenet201/conv5_block30_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block30_1_conv/Conv2D]:493
	                 CONV_2D	          668.046	    0.259	    0.270	  0.040%	 98.314%	     0.000	        1	[densenet201/conv5_block30_2_conv/Conv2D1]:494
	           CONCATENATION	          668.317	    0.023	    0.026	  0.004%	 98.317%	     0.000	        1	[densenet201/conv5_block30_concat/concat]:495
	                     MUL	          668.343	    0.260	    0.262	  0.039%	 98.356%	     0.000	        1	[densenet201/conv5_block31_0_bn/FusedBatchNormV31]:496
	                     ADD	          668.606	    0.440	    0.375	  0.055%	 98.411%	     0.000	        1	[densenet201/conv5_block31_0_relu/Relu;densenet201/conv5_block31_0_bn/FusedBatchNormV3]:497
	                 CONV_2D	          668.981	    1.325	    1.346	  0.198%	 98.609%	     0.000	        1	[densenet201/conv5_block31_1_relu/Relu;densenet201/conv5_block31_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block31_1_conv/Conv2D]:498
	                 CONV_2D	          670.328	    0.284	    0.286	  0.042%	 98.651%	     0.000	        1	[densenet201/conv5_block31_2_conv/Conv2D1]:499
	           CONCATENATION	          670.614	    0.023	    0.026	  0.004%	 98.655%	     0.000	        1	[densenet201/conv5_block31_concat/concat]:500
	                     MUL	          670.640	    0.264	    0.271	  0.040%	 98.695%	     0.000	        1	[densenet201/conv5_block32_0_bn/FusedBatchNormV31]:501
	                     ADD	          670.912	    0.375	    0.379	  0.056%	 98.751%	     0.000	        1	[densenet201/conv5_block32_0_relu/Relu;densenet201/conv5_block32_0_bn/FusedBatchNormV3]:502
	                 CONV_2D	          671.292	    1.347	    1.375	  0.202%	 98.953%	     0.000	        1	[densenet201/conv5_block32_1_relu/Relu;densenet201/conv5_block32_1_bn/FusedBatchNormV3;densenet201/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv5_block32_1_conv/Conv2D]:503
	                 CONV_2D	          672.667	    0.256	    0.273	  0.040%	 98.993%	     0.000	        1	[densenet201/conv5_block32_2_conv/Conv2D210]:504
	           CONCATENATION	          672.941	    0.069	    0.025	  0.004%	 98.997%	     0.000	        1	[densenet201/conv5_block32_concat/concat]:505
	                     MUL	          672.966	    0.266	    0.275	  0.040%	 99.037%	     0.000	        1	[densenet201/bn/FusedBatchNormV31]:506
	                     ADD	          673.242	    0.373	    0.380	  0.056%	 99.093%	     0.000	        1	[densenet201/relu/Relu;densenet201/bn/FusedBatchNormV3]:507
	                    MEAN	          673.623	    5.126	    5.160	  0.759%	 99.853%	     0.000	        1	[densenet201/avg_pool/Mean]:508
	         FULLY_CONNECTED	          678.783	    0.976	    0.984	  0.145%	 99.998%	     0.000	        1	[densenet201/predictions/MatMul;densenet201/predictions/BiasAdd]:509
	                 SOFTMAX	          679.768	    0.015	    0.016	  0.002%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:510

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          580.839	   34.543	   34.396	  5.063%	  5.063%	     0.000	        1	[densenet201/pool4_conv/Conv2D1]:344
	                 CONV_2D	            1.151	   18.712	   18.626	  2.742%	  7.804%	     0.000	        1	[densenet201/conv1/relu/Relu;densenet201/conv1/bn/FusedBatchNormV3;densenet201/conv1/bn/FusedBatchNormV3/ReadVariableOp;densenet201/conv1/conv/Conv2D]:1
	                 CONV_2D	           53.008	   16.583	   16.618	  2.446%	 10.250%	     0.000	        1	[densenet201/conv2_block2_2_conv/Conv2D1]:12
	                 CONV_2D	          169.324	   16.455	   16.483	  2.426%	 12.676%	     0.000	        1	[densenet201/conv2_block6_2_conv/Conv2D1]:32
	                 CONV_2D	           29.210	   16.440	   16.431	  2.419%	 15.095%	     0.000	        1	[densenet201/conv2_block1_2_conv/Conv2D1]:7
	                 CONV_2D	          137.083	   16.335	   16.354	  2.407%	 17.502%	     0.000	        1	[densenet201/conv2_block5_2_conv/Conv2D1]:27
	                 CONV_2D	          106.858	   16.339	   16.348	  2.406%	 19.908%	     0.000	        1	[densenet201/conv2_block4_2_conv/Conv2D1]:22
	                 CONV_2D	           79.148	   16.303	   16.174	  2.381%	 22.289%	     0.000	        1	[densenet201/conv2_block3_2_conv/Conv2D1]:17
	                 CONV_2D	          191.922	   11.797	   11.887	  1.750%	 24.039%	     0.000	        1	[densenet201/pool2_conv/Conv2D1]:36
	                 CONV_2D	          321.304	   10.991	   11.016	  1.621%	 25.660%	     0.000	        1	[densenet201/pool3_conv/Conv2D1]:100

Number of nodes executed: 511
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	      200	   523.589	    77.095%	    77.095%	     0.000	      200
	                     ADD	      102	    77.660	    11.435%	    88.530%	     0.000	      102
	                     MUL	      102	    54.494	     8.024%	    96.554%	     0.000	      102
	           CONCATENATION	       98	    10.069	     1.483%	    98.036%	     0.000	       98
	                    MEAN	        1	     5.159	     0.760%	    98.796%	     0.000	        1
	                     PAD	        2	     4.775	     0.703%	    99.499%	     0.000	        2
	         AVERAGE_POOL_2D	        3	     1.819	     0.268%	    99.767%	     0.000	        3
	         FULLY_CONNECTED	        1	     0.984	     0.145%	    99.912%	     0.000	        1
	             MAX_POOL_2D	        1	     0.584	     0.086%	    99.998%	     0.000	        1
	                 SOFTMAX	        1	     0.015	     0.002%	   100.000%	     0.000	        1

Timings (microseconds): count=100 first=679838 curr=679206 min=678406 max=681372 avg=679401 std=528
Memory (bytes): count=0
511 nodes observed



munmap_chunk(): invalid pointer
[ perf record: Woken up 192 times to write data ]
Warning:
Processed 278649 events and lost 1 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 47.803 MB /tmp/data.record (278190 samples) ]

72.033

