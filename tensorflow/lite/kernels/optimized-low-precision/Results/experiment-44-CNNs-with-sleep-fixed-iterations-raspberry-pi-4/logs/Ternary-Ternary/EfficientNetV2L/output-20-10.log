STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/f32i8/EfficientNetV2L.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/f32i8/EfficientNetV2L.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (230400, 3, ), and Output shape (57600, 32, ), and the ID is 0
	Changing Input Shape
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 1
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 2
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 3
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 80)
4
	Allocating LowPrecision Activations Tensors with Shape of (57600, 80)
Applying Conv Low-Precision for Kernel shape (128, 288, ), Input shape (57600, 32, ), and Output shape (14400, 128, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (128, 80)
5
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (14400, 128, ), and Output shape (14400, 64, ), and the ID is 6
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
(14400, 256, ), and the ID is 7
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 8
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
9
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 10
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 11	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)

	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 12
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 13	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)

	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 14
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 15	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)

	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 16
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)
(14400, 256, ), and the ID is 17
	Allocating LowPrecision Activations Tensors with Shape of (14400, 144)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 18
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 64)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 64)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (3600, 256, ), and the ID is 19	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 144)

	Allocating LowPrecision Activations Tensors with Shape of (3600, 144)
Applying Conv Low-Precision for Kernel shape (96, 256, ), Input shape (3600, 256, ), and Output shape (3600, 96, ), and the ID is 20
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 64)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 64)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
(3600, 384, ), and the ID is 21
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 22
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 23
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 24
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 25
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 26
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
, and the ID is 27
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 28
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 29
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 30
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 31
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 224)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 224)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 32
	Allocating LowPrecision Weight Tensors with Shape of (96, 96)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 96)
Applying Conv Low-Precision for Kernel shape (384, 96, ), Input shape (3600, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 32)
(3600, 384, ), and the ID is 33
	Allocating LowPrecision Activations Tensors with Shape of (3600, 32)
The input model file size (MB): 122.772
Initialized session in 134.377ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
Applying Conv Low-Precision for Kernel shape (24, 384, ), Input shape (1, 384, ), and Output shape (1, 24, ), and the ID is 34
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (24, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 16)
Applying Conv Low-Precision for Kernel shape (384, 24, ), Input shape (1, 24, ), and Output shape (1, 384, ), and the ID is 35
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 384, ), Input shape (900, 384, ), and Output shape (900, 192, ), and the ID is 36
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 37
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 38
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
, and Output shape (1, 768, ), and the ID is 39
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 40
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 41
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 42
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
(1, 768, ), and the ID is 43
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 44
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 45
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 46	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)

	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
(1, 768, ), and the ID is 47
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 48	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)

	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 49
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 50
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
51
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 52
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 53
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 54
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 55
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
(900, 192, ), and the ID is 56
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 57
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 58
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
(1, 768, ), and the ID is 59
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 60
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 61	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)

	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 62
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 63
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 64
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 65
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 66
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
(1, 768, ), and the ID is 67
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 68
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 69
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 70
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 192)
	Allocating LowPrecision Activations Tensors with Shape of (1, 192)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
, and the ID is 71
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 72
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 192)
	Allocating LowPrecision Activations Tensors with Shape of (900, 192)
Applying Conv Low-Precision for Kernel shape (1152, 192, ), Input shape (900, 192, ), and Output shape (900, 1152, ), and the ID is 73
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1152, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
Applying Conv Low-Precision for Kernel shape (48, 1152, ), Input shape (1, 1152, ), and Output shape (1, 48, ), and the ID is 74
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (1152, 48, ), Input shape (1, 48, ), and Output shape (1, 1152, ), and the ID is 75
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1152, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 288)
Applying Conv Low-Precision for Kernel shape (224, 1152, ), Input shape (900, 1152, ), and Output shape (900, 224, ), and the ID is 76
	Allocating LowPrecision Activations Tensors with Shape of (900, 288)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 77
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 78
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 79
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 80
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 81
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 82
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 83
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 84
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 85
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 86	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 87
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 88
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 89
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 90
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 91
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 92
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 93
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 94
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 95
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 96
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 97
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 98
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 99
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 100
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 101
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 102	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 103
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 104
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 105
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 106
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 107
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 108
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 109
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 110	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 111
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 112
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 113
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 114	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 115
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 116
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 117
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 118
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 119
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 120
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 121
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 122	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 123
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 124
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 125
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 126
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 127
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 128
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 129
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 130
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 131
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 132
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 133
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 134	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 135
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 136
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 137
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 138	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 139
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 140
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 141
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 142	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)

	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 143
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 144	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)

	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 145
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 146
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 147
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 148
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 336)
	Allocating LowPrecision Activations Tensors with Shape of (900, 336)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 149
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 64)
	Allocating LowPrecision Activations Tensors with Shape of (900, 64)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 150
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 336)
	Allocating LowPrecision Activations Tensors with Shape of (1, 336)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 151
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 1344, ), Input shape (225, 1344, ), and Output shape (225, 384, ), and the ID is 152
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 336)
	Allocating LowPrecision Activations Tensors with Shape of (228, 336)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 153
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
154
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 155
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 156
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 157
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
158
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 159
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 160
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 161
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 162	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 163
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 164
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 165
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 166	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 167
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 168
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 169
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 170	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 171
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 172
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 173
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 174	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 175
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 176
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 177
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 178
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 179
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 180
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 181
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 182	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 183
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
184
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 185
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 186
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 187
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 188
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 189
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 190	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 191
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 192
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 193
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 194	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
(1, 2304, ), and the ID is 195
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 196
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 197
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 198	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 199
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 200
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 201
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 202
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 203
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 204
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 205
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 206
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 207
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 208
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 209
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 210	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 211
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 212
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 213
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
214
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 215
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 216
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 217
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 218	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 219
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 220
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 221
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 222
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 223
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 224
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 225
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 226
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 227
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 228
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 229
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 230
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 231
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 232
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 233
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 234	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 235
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 236
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 237
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 238
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 239
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 240
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 241
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 242	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)

	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 243
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 244
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 245
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 246
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 247
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 248
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 249
	Allocating LowPrecision Weight Tensors with Shape of (2304, 96)
	Allocating LowPrecision Activations Tensors with Shape of (228, 96)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 250
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 576)
	Allocating LowPrecision Activations Tensors with Shape of (1, 576)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 251
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 2304, ), Input shape (225, 2304, ), and Output shape (225, 640, ), and the ID is 252
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 576)
	Allocating LowPrecision Activations Tensors with Shape of (228, 576)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 253
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 254
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 255
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 256
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 257
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 258
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 259
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 260
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 261
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 262	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)

	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 263
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 264
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 265
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 266
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 267
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 268
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 269
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)
, and the ID is 270
	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 271
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 272
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 273
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 160)
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 274	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 960)

	Allocating LowPrecision Activations Tensors with Shape of (1, 960)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 275
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 276
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 960)
	Allocating LowPrecision Activations Tensors with Shape of (228, 960)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1280, 160)
Applying Conv Low-Precision for Kernel shape (1280, 640, ), Input shape (225, 640, ), and Output shape (225, 1280, ), and the ID is 277
	Allocating LowPrecision Activations Tensors with Shape of (228, 160)
Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 7 Number of Temporaries Tensors
	Transformed Filter Shape: (1000, 320)
	Transformed Activation Shape From: (1, 1280) To: (1, 320)
count=2 first=92020781 curr=91686627 min=91686627 max=92020781 avg=9.18537e+07 std=167077

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=91610178 curr=91361062 min=91361062 max=91610178 avg=9.14856e+07 std=124558

Inference timings in us: Init: 134377, First inference: 92020781, Warmup (avg): 9.18537e+07, Inference (avg): 9.14856e+07
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=29.6055 overall=224
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   31.247	   31.247	100.000%	100.000%	  3140.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   31.247	   31.247	100.000%	100.000%	  3140.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    31.247	   100.000%	   100.000%	  3140.000	        1

Timings (microseconds): count=1 curr=31247
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	            0.028	    7.143	    7.104	  0.008%	  0.008%	     0.000	        1	[efficientnetv2-l/rescaling/mul]:0
	                     ADD	            7.143	    7.145	    7.120	  0.008%	  0.016%	     0.000	        1	[efficientnetv2-l/rescaling/add]:1
	                 CONV_2D	           14.274	   35.804	   35.577	  0.039%	  0.054%	     0.000	        1	[efficientnetv2-l/stem_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/stem_conv/Conv2D]:2
	                LOGISTIC	           49.864	  295.945	  295.777	  0.323%	  0.378%	     0.000	        1	[efficientnetv2-l/stem_activation/Sigmoid]:3
	                     MUL	          345.654	   17.635	   17.631	  0.019%	  0.397%	     0.000	        1	[efficientnetv2-l/stem_activation/mul_1]:4
	                 CONV_2D	          363.298	 1047.708	 1046.580	  1.144%	  1.541%	     0.000	        1	[efficientnetv2-l/block1a_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1a_project_conv/Conv2D]:5
	                LOGISTIC	         1409.889	  298.571	  297.307	  0.325%	  1.866%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/Sigmoid]:6
	                     MUL	         1707.207	   17.658	   17.640	  0.019%	  1.886%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/mul_1]:7
	                     ADD	         1724.859	   17.355	   17.316	  0.019%	  1.904%	     0.000	        1	[efficientnetv2-l/block1a_add/add]:8
	                 CONV_2D	         1742.188	 1045.399	 1044.288	  1.142%	  3.046%	     0.000	        1	[efficientnetv2-l/block1b_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1b_project_conv/Conv2D]:9
	                LOGISTIC	         2786.488	  552.433	  550.082	  0.601%	  3.647%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/Sigmoid]:10
	                     MUL	         3336.582	   17.634	   17.620	  0.019%	  3.667%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/mul_1]:11
	                     ADD	         3354.213	   17.344	   17.374	  0.019%	  3.686%	     0.000	        1	[efficientnetv2-l/block1b_add/add]:12
	                 CONV_2D	         3371.600	 1057.007	 1052.000	  1.150%	  4.836%	     0.000	        1	[efficientnetv2-l/block1c_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1c_project_conv/Conv2D]:13
	                LOGISTIC	         4423.612	  571.627	  571.154	  0.624%	  5.460%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/Sigmoid]:14
	                     MUL	         4994.779	   17.703	   17.671	  0.019%	  5.479%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/mul_1]:15
	                     ADD	         5012.461	   17.379	   17.453	  0.019%	  5.499%	     0.000	        1	[efficientnetv2-l/block1c_add/add]:16
	                 CONV_2D	         5029.926	 1046.487	 1045.545	  1.143%	  6.642%	     0.000	        1	[efficientnetv2-l/block1d_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1d_project_conv/Conv2D]:17
	                LOGISTIC	         6075.484	  459.972	  458.525	  0.501%	  7.143%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/Sigmoid]:18
	                     MUL	         6534.028	   17.616	   17.616	  0.019%	  7.162%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/mul_1]:19
	                     ADD	         6551.655	   17.394	   17.367	  0.019%	  7.181%	     0.000	        1	[efficientnetv2-l/block1d_add/add]:20
	                 CONV_2D	         6569.035	  729.170	  727.769	  0.796%	  7.977%	     0.000	        1	[efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_expand_conv/Conv2D]:21
	                LOGISTIC	         7296.816	  486.094	  486.717	  0.532%	  8.509%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/Sigmoid]:22
	                     MUL	         7783.547	   17.654	   17.714	  0.019%	  8.528%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/mul_1]:23
	                 CONV_2D	         7801.272	  400.935	  401.221	  0.439%	  8.967%	     0.000	        1	[efficientnetv2-l/block2a_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_project_conv/Conv2D]:24
	                 CONV_2D	         8202.504	 1385.462	 1380.547	  1.509%	 10.476%	     0.000	        1	[efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_expand_conv/Conv2D]:25
	                LOGISTIC	         9583.062	 1027.692	 1025.431	  1.121%	 11.597%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/Sigmoid]:26
	                     MUL	        10608.505	   35.301	   35.257	  0.039%	 11.635%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                 CONV_2D	        10643.775	  400.664	  398.461	  0.436%	 12.071%	     0.000	        1	[efficientnetv2-l/block2b_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_project_conv/Conv2D]:28
	                     ADD	        11042.248	    8.778	    8.710	  0.010%	 12.081%	     0.000	        1	[efficientnetv2-l/block2b_add/add]:29
	                 CONV_2D	        11050.970	 1386.927	 1382.853	  1.512%	 13.592%	     0.000	        1	[efficientnetv2-l/block2c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_expand_conv/Conv2D]:30
	                LOGISTIC	        12433.835	 1160.436	 1158.084	  1.266%	 14.858%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/Sigmoid]:31
	                     MUL	        13591.931	   35.235	   35.227	  0.039%	 14.897%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                 CONV_2D	        13627.169	  397.494	  396.617	  0.434%	 15.330%	     0.000	        1	[efficientnetv2-l/block2c_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_project_conv/Conv2D]:33
	                     ADD	        14023.799	    8.743	    8.721	  0.010%	 15.340%	     0.000	        1	[efficientnetv2-l/block2c_add/add]:34
	                 CONV_2D	        14032.531	 1388.602	 1386.194	  1.515%	 16.855%	     0.000	        1	[efficientnetv2-l/block2d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_expand_conv/Conv2D]:35
	                LOGISTIC	        15418.738	 1148.913	 1145.747	  1.253%	 18.108%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/Sigmoid]:36
	                     MUL	        16564.499	   35.221	   35.144	  0.038%	 18.146%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                 CONV_2D	        16599.654	  397.615	  396.700	  0.434%	 18.580%	     0.000	        1	[efficientnetv2-l/block2d_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_project_conv/Conv2D]:38
	                     ADD	        16996.365	    8.678	    8.688	  0.009%	 18.590%	     0.000	        1	[efficientnetv2-l/block2d_add/add]:39
	                 CONV_2D	        17005.065	 1385.317	 1382.239	  1.511%	 20.101%	     0.000	        1	[efficientnetv2-l/block2e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_expand_conv/Conv2D]:40
	                LOGISTIC	        18387.316	 1160.281	 1159.081	  1.267%	 21.368%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/Sigmoid]:41
	                     MUL	        19546.410	   35.230	   35.344	  0.039%	 21.406%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                 CONV_2D	        19581.766	  397.941	  398.413	  0.436%	 21.842%	     0.000	        1	[efficientnetv2-l/block2e_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_project_conv/Conv2D]:43
	                     ADD	        19980.191	    8.670	    8.662	  0.009%	 21.851%	     0.000	        1	[efficientnetv2-l/block2e_add/add]:44
	                 CONV_2D	        19988.864	 1396.423	 1390.891	  1.521%	 23.372%	     0.000	        1	[efficientnetv2-l/block2f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_expand_conv/Conv2D]:45
	                LOGISTIC	        21379.768	 1148.828	 1146.699	  1.254%	 24.626%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/Sigmoid]:46
	                     MUL	        22526.478	   35.209	   35.198	  0.038%	 24.664%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                 CONV_2D	        22561.688	  401.250	  398.924	  0.436%	 25.100%	     0.000	        1	[efficientnetv2-l/block2f_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_project_conv/Conv2D]:48
	                     ADD	        22960.623	    8.780	    8.697	  0.010%	 25.110%	     0.000	        1	[efficientnetv2-l/block2f_add/add]:49
	                 CONV_2D	        22969.332	 1387.105	 1382.924	  1.512%	 26.621%	     0.000	        1	[efficientnetv2-l/block2g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_expand_conv/Conv2D]:50
	                LOGISTIC	        24352.269	 1165.021	 1163.143	  1.272%	 27.893%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/Sigmoid]:51
	                     MUL	        25515.424	   36.184	   35.703	  0.039%	 27.932%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                 CONV_2D	        25551.140	  399.188	  398.175	  0.435%	 28.367%	     0.000	        1	[efficientnetv2-l/block2g_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_project_conv/Conv2D]:53
	                     ADD	        25949.327	    8.739	    8.717	  0.010%	 28.377%	     0.000	        1	[efficientnetv2-l/block2g_add/add]:54
	                 CONV_2D	        25958.057	  346.508	  345.991	  0.378%	 28.755%	     0.000	        1	[efficientnetv2-l/block3a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_expand_conv/Conv2D]:55
	                LOGISTIC	        26304.060	  278.047	  277.776	  0.304%	 29.059%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/Sigmoid]:56
	                     MUL	        26581.848	    8.825	    8.832	  0.010%	 29.068%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/mul_1]:57
	                 CONV_2D	        26590.692	  137.865	  137.332	  0.150%	 29.219%	     0.000	        1	[efficientnetv2-l/block3a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_project_conv/Conv2D]:58
	                 CONV_2D	        26728.036	  517.997	  518.778	  0.567%	 29.786%	     0.000	        1	[efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_expand_conv/Conv2D]:59
	                LOGISTIC	        27246.826	  439.513	  438.151	  0.479%	 30.265%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/Sigmoid]:60
	                     MUL	        27684.988	   13.429	   13.368	  0.015%	 30.279%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/mul_1]:61
	                 CONV_2D	        27698.368	  147.492	  145.495	  0.159%	 30.438%	     0.000	        1	[efficientnetv2-l/block3b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_project_conv/Conv2D]:62
	                     ADD	        27843.875	    3.277	    3.296	  0.004%	 30.442%	     0.000	        1	[efficientnetv2-l/block3b_add/add]:63
	                 CONV_2D	        27847.182	  517.466	  516.438	  0.565%	 31.007%	     0.000	        1	[efficientnetv2-l/block3c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_expand_conv/Conv2D]:64
	                LOGISTIC	        28363.633	  432.645	  432.178	  0.472%	 31.479%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/Sigmoid]:65
	                     MUL	        28795.823	   13.204	   13.226	  0.014%	 31.493%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/mul_1]:66
	                 CONV_2D	        28809.059	  144.228	  144.028	  0.157%	 31.651%	     0.000	        1	[efficientnetv2-l/block3c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_project_conv/Conv2D]:67
	                     ADD	        28953.099	    3.204	    3.189	  0.003%	 31.654%	     0.000	        1	[efficientnetv2-l/block3c_add/add]:68
	                 CONV_2D	        28956.299	  518.143	  518.949	  0.567%	 32.222%	     0.000	        1	[efficientnetv2-l/block3d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_expand_conv/Conv2D]:69
	                LOGISTIC	        29475.261	  301.365	  300.863	  0.329%	 32.551%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/Sigmoid]:70
	                     MUL	        29776.137	   13.240	   13.219	  0.014%	 32.565%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/mul_1]:71
	                 CONV_2D	        29789.367	  145.219	  144.586	  0.158%	 32.723%	     0.000	        1	[efficientnetv2-l/block3d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_project_conv/Conv2D]:72
	                     ADD	        29933.964	    3.374	    3.321	  0.004%	 32.727%	     0.000	        1	[efficientnetv2-l/block3d_add/add]:73
	                 CONV_2D	        29937.295	  524.738	  522.600	  0.571%	 33.298%	     0.000	        1	[efficientnetv2-l/block3e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_expand_conv/Conv2D]:74
	                LOGISTIC	        30459.908	  432.855	  431.920	  0.472%	 33.770%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/Sigmoid]:75
	                     MUL	        30891.839	   13.281	   13.261	  0.014%	 33.785%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/mul_1]:76
	                 CONV_2D	        30905.111	  143.677	  143.613	  0.157%	 33.942%	     0.000	        1	[efficientnetv2-l/block3e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_project_conv/Conv2D]:77
	                     ADD	        31048.736	    3.202	    3.189	  0.003%	 33.945%	     0.000	        1	[efficientnetv2-l/block3e_add/add]:78
	                 CONV_2D	        31051.935	  516.986	  516.525	  0.565%	 34.510%	     0.000	        1	[efficientnetv2-l/block3f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_expand_conv/Conv2D]:79
	                LOGISTIC	        31568.473	  435.736	  435.546	  0.476%	 34.986%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/Sigmoid]:80
	                     MUL	        32004.031	   13.110	   13.181	  0.014%	 35.000%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/mul_1]:81
	                 CONV_2D	        32017.223	  144.812	  144.396	  0.158%	 35.158%	     0.000	        1	[efficientnetv2-l/block3f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_project_conv/Conv2D]:82
	                     ADD	        32161.631	    3.251	    3.213	  0.004%	 35.162%	     0.000	        1	[efficientnetv2-l/block3f_add/add]:83
	                 CONV_2D	        32164.855	  524.269	  519.907	  0.568%	 35.730%	     0.000	        1	[efficientnetv2-l/block3g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_expand_conv/Conv2D]:84
	                LOGISTIC	        32684.773	  262.213	  261.591	  0.286%	 36.016%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/Sigmoid]:85
	                     MUL	        32946.376	   13.764	   13.509	  0.015%	 36.031%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/mul_1]:86
	                 CONV_2D	        32959.899	  145.429	  145.049	  0.159%	 36.190%	     0.000	        1	[efficientnetv2-l/block3g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_project_conv/Conv2D]:87
	                     ADD	        33104.961	    3.433	    3.394	  0.004%	 36.193%	     0.000	        1	[efficientnetv2-l/block3g_add/add]:88
	                 CONV_2D	        33108.367	  489.550	  489.065	  0.535%	 36.728%	     0.000	        1	[efficientnetv2-l/block4a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_expand_conv/Conv2D]:89
	                LOGISTIC	        33597.444	  427.735	  426.425	  0.466%	 37.194%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/Sigmoid]:90
	                     MUL	        34023.881	   13.374	   13.309	  0.015%	 37.209%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/mul_1]:91
	       DEPTHWISE_CONV_2D	        34037.202	  127.906	  128.094	  0.140%	 37.349%	     0.000	        1	[efficientnetv2-l/block4a_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_dwconv2/depthwise;efficientnetv2-l/block6y_project_bn/FusedBatchNormV3]:92
	                LOGISTIC	        34165.308	  110.929	  111.080	  0.121%	 37.470%	     0.000	        1	[efficientnetv2-l/block4a_activation/Sigmoid]:93
	                     MUL	        34276.399	    3.279	    3.308	  0.004%	 37.474%	     0.000	        1	[efficientnetv2-l/block4a_activation/mul_1]:94
	                    MEAN	        34279.719	   56.112	   56.198	  0.061%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_squeeze/Mean]:95
	                   SHAPE	        34335.929	    0.009	    0.009	  0.000%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Shape]:96
	           STRIDED_SLICE	        34335.944	    0.021	    0.021	  0.000%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/strided_slice]:97
	                    PACK	        34335.971	    0.029	    0.028	  0.000%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape/shape]:98
	                 RESHAPE	        34336.005	    0.014	    0.015	  0.000%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape]:99
	                 CONV_2D	        34336.026	    0.094	    0.097	  0.000%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/BiasAdd;efficientnetv2-l/block4a_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4a_se_reduce/Conv2D]:100
	                LOGISTIC	        34336.130	    0.025	    0.025	  0.000%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/Sigmoid]:101
	                     MUL	        34336.162	    0.012	    0.012	  0.000%	 37.535%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/mul_1]:102
	                 CONV_2D	        34336.180	    0.170	    0.170	  0.000%	 37.536%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/BiasAdd;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_se_expand/Conv2D]:103
	                LOGISTIC	        34336.357	    0.070	    0.070	  0.000%	 37.536%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/Sigmoid]:104
	                     MUL	        34336.434	    3.448	    3.465	  0.004%	 37.539%	     0.000	        1	[efficientnetv2-l/block4a_se_excite/mul]:105
	                 CONV_2D	        34339.910	   65.565	   65.509	  0.072%	 37.611%	     0.000	        1	[efficientnetv2-l/block4a_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_project_conv/Conv2D]:106
	                 CONV_2D	        34405.429	  240.307	  239.742	  0.262%	 37.873%	     0.000	        1	[efficientnetv2-l/block4b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_expand_conv/Conv2D]:107
	                LOGISTIC	        34645.183	  215.609	  214.839	  0.235%	 38.108%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/Sigmoid]:108
	                     MUL	        34860.033	    6.972	    6.793	  0.007%	 38.115%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/mul_1]:109
	       DEPTHWISE_CONV_2D	        34866.838	    6.046	    5.827	  0.006%	 38.122%	     0.000	        1	[efficientnetv2-l/block4b_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:110
	                LOGISTIC	        34872.677	  210.043	  209.384	  0.229%	 38.351%	     0.000	        1	[efficientnetv2-l/block4b_activation/Sigmoid]:111
	                     MUL	        35082.074	    6.644	    6.637	  0.007%	 38.358%	     0.000	        1	[efficientnetv2-l/block4b_activation/mul_1]:112
	                    MEAN	        35088.723	  112.522	  112.391	  0.123%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_squeeze/Mean]:113
	                   SHAPE	        35201.126	    0.009	    0.009	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Shape]:114
	           STRIDED_SLICE	        35201.141	    0.021	    0.021	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/strided_slice]:115
	                    PACK	        35201.169	    0.029	    0.028	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape/shape]:116
	                 RESHAPE	        35201.204	    0.013	    0.014	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape]:117
	                 CONV_2D	        35201.224	    0.105	    0.107	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4b_se_reduce/Conv2D]:118
	                LOGISTIC	        35201.338	    0.029	    0.029	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/Sigmoid]:119
	                     MUL	        35201.373	    0.013	    0.013	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/mul_1]:120
	                 CONV_2D	        35201.392	    0.299	    0.298	  0.000%	 38.481%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_se_expand/Conv2D]:121
	                LOGISTIC	        35201.698	    0.128	    0.129	  0.000%	 38.482%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/Sigmoid]:122
	                     MUL	        35201.832	    6.759	    6.724	  0.007%	 38.489%	     0.000	        1	[efficientnetv2-l/block4b_se_excite/mul]:123
	                 CONV_2D	        35208.568	   68.123	   67.690	  0.074%	 38.563%	     0.000	        1	[efficientnetv2-l/block4b_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_project_conv/Conv2D]:124
	                     ADD	        35276.270	    1.570	    1.577	  0.002%	 38.565%	     0.000	        1	[efficientnetv2-l/block4b_add/add]:125
	                 CONV_2D	        35277.856	  245.921	  245.419	  0.268%	 38.833%	     0.000	        1	[efficientnetv2-l/block4c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_expand_conv/Conv2D]:126
	                LOGISTIC	        35523.287	  215.249	  214.451	  0.234%	 39.067%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/Sigmoid]:127
	                     MUL	        35737.749	    6.632	    6.618	  0.007%	 39.075%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/mul_1]:128
	       DEPTHWISE_CONV_2D	        35744.379	    4.716	    4.775	  0.005%	 39.080%	     0.000	        1	[efficientnetv2-l/block4c_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:129
	                LOGISTIC	        35749.166	  109.455	  108.534	  0.119%	 39.198%	     0.000	        1	[efficientnetv2-l/block4c_activation/Sigmoid]:130
	                     MUL	        35857.714	    6.745	    6.676	  0.007%	 39.206%	     0.000	        1	[efficientnetv2-l/block4c_activation/mul_1]:131
	                    MEAN	        35864.402	  112.831	  112.548	  0.123%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_squeeze/Mean]:132
	                   SHAPE	        35976.961	    0.009	    0.009	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Shape]:133
	           STRIDED_SLICE	        35976.976	    0.021	    0.021	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/strided_slice]:134
	                    PACK	        35977.004	    0.029	    0.027	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape/shape]:135
	                 RESHAPE	        35977.037	    0.014	    0.014	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape]:136
	                 CONV_2D	        35977.058	    0.102	    0.103	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4c_se_reduce/Conv2D]:137
	                LOGISTIC	        35977.169	    0.028	    0.028	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/Sigmoid]:138
	                     MUL	        35977.203	    0.013	    0.013	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/mul_1]:139
	                 CONV_2D	        35977.222	    0.297	    0.296	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_se_expand/Conv2D]:140
	                LOGISTIC	        35977.526	    0.128	    0.130	  0.000%	 39.329%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/Sigmoid]:141
	                     MUL	        35977.662	    6.907	    6.875	  0.008%	 39.337%	     0.000	        1	[efficientnetv2-l/block4c_se_excite/mul]:142
	                 CONV_2D	        35984.550	   66.453	   66.251	  0.072%	 39.409%	     0.000	        1	[efficientnetv2-l/block4c_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_project_conv/Conv2D]:143
	                     ADD	        36050.813	    1.669	    1.669	  0.002%	 39.411%	     0.000	        1	[efficientnetv2-l/block4c_add/add]:144
	                 CONV_2D	        36052.491	  241.478	  240.721	  0.263%	 39.674%	     0.000	        1	[efficientnetv2-l/block4d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_expand_conv/Conv2D]:145
	                LOGISTIC	        36293.226	  222.625	  222.714	  0.243%	 39.918%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/Sigmoid]:146
	                     MUL	        36515.952	    6.611	    6.684	  0.007%	 39.925%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/mul_1]:147
	       DEPTHWISE_CONV_2D	        36522.647	    5.650	    6.160	  0.007%	 39.932%	     0.000	        1	[efficientnetv2-l/block4d_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:148
	                LOGISTIC	        36528.820	  188.149	  188.135	  0.206%	 40.138%	     0.000	        1	[efficientnetv2-l/block4d_activation/Sigmoid]:149
	                     MUL	        36716.967	    6.607	    6.686	  0.007%	 40.145%	     0.000	        1	[efficientnetv2-l/block4d_activation/mul_1]:150
	                    MEAN	        36723.664	  113.708	  112.994	  0.124%	 40.268%	     0.000	        1	[efficientnetv2-l/block4d_se_squeeze/Mean]:151
	                   SHAPE	        36836.670	    0.010	    0.009	  0.000%	 40.268%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Shape]:152
	           STRIDED_SLICE	        36836.685	    0.021	    0.021	  0.000%	 40.268%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/strided_slice]:153
	                    PACK	        36836.713	    0.029	    0.027	  0.000%	 40.268%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape/shape]:154
	                 RESHAPE	        36836.747	    0.014	    0.014	  0.000%	 40.268%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape]:155
	                 CONV_2D	        36836.768	    0.102	    0.104	  0.000%	 40.269%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4d_se_reduce/Conv2D]:156
	                LOGISTIC	        36836.880	    0.028	    0.029	  0.000%	 40.269%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/Sigmoid]:157
	                     MUL	        36836.915	    0.012	    0.012	  0.000%	 40.269%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/mul_1]:158
	                 CONV_2D	        36836.933	    0.297	    0.296	  0.000%	 40.269%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_se_expand/Conv2D]:159
	                LOGISTIC	        36837.238	    0.129	    0.130	  0.000%	 40.269%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/Sigmoid]:160
	                     MUL	        36837.374	    6.885	    6.808	  0.007%	 40.277%	     0.000	        1	[efficientnetv2-l/block4d_se_excite/mul]:161
	                 CONV_2D	        36844.195	   67.689	   67.582	  0.074%	 40.350%	     0.000	        1	[efficientnetv2-l/block4d_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_project_conv/Conv2D]:162
	                     ADD	        36911.789	    1.573	    1.579	  0.002%	 40.352%	     0.000	        1	[efficientnetv2-l/block4d_add/add]:163
	                 CONV_2D	        36913.376	  241.946	  241.220	  0.264%	 40.616%	     0.000	        1	[efficientnetv2-l/block4e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_expand_conv/Conv2D]:164
	                LOGISTIC	        37154.609	  217.109	  216.552	  0.237%	 40.853%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/Sigmoid]:165
	                     MUL	        37371.173	    6.606	    6.617	  0.007%	 40.860%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/mul_1]:166
	       DEPTHWISE_CONV_2D	        37377.802	    4.776	    4.763	  0.005%	 40.865%	     0.000	        1	[efficientnetv2-l/block4e_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:167
	                LOGISTIC	        37382.577	  109.620	  108.545	  0.119%	 40.984%	     0.000	        1	[efficientnetv2-l/block4e_activation/Sigmoid]:168
	                     MUL	        37491.135	    7.241	    6.938	  0.008%	 40.991%	     0.000	        1	[efficientnetv2-l/block4e_activation/mul_1]:169
	                    MEAN	        37498.086	  112.912	  112.748	  0.123%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_squeeze/Mean]:170
	                   SHAPE	        37610.845	    0.009	    0.009	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Shape]:171
	           STRIDED_SLICE	        37610.860	    0.022	    0.021	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/strided_slice]:172
	                    PACK	        37610.889	    0.028	    0.026	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape/shape]:173
	                 RESHAPE	        37610.922	    0.013	    0.013	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape]:174
	                 CONV_2D	        37610.942	    0.101	    0.103	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4e_se_reduce/Conv2D]:175
	                LOGISTIC	        37611.054	    0.029	    0.029	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/Sigmoid]:176
	                     MUL	        37611.088	    0.013	    0.013	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/mul_1]:177
	                 CONV_2D	        37611.107	    0.296	    0.295	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_se_expand/Conv2D]:178
	                LOGISTIC	        37611.410	    0.132	    0.133	  0.000%	 41.115%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/Sigmoid]:179
	                     MUL	        37611.548	    6.735	    6.728	  0.007%	 41.123%	     0.000	        1	[efficientnetv2-l/block4e_se_excite/mul]:180
	                 CONV_2D	        37618.287	   67.372	   66.729	  0.073%	 41.196%	     0.000	        1	[efficientnetv2-l/block4e_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_project_conv/Conv2D]:181
	                     ADD	        37685.028	    1.667	    1.685	  0.002%	 41.197%	     0.000	        1	[efficientnetv2-l/block4e_add/add]:182
	                 CONV_2D	        37686.724	  242.165	  242.148	  0.265%	 41.462%	     0.000	        1	[efficientnetv2-l/block4f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_expand_conv/Conv2D]:183
	                LOGISTIC	        37928.884	  217.469	  217.082	  0.237%	 41.699%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/Sigmoid]:184
	                     MUL	        38145.976	    6.622	    6.630	  0.007%	 41.707%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/mul_1]:185
	       DEPTHWISE_CONV_2D	        38152.616	    4.811	    4.810	  0.005%	 41.712%	     0.000	        1	[efficientnetv2-l/block4f_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:186
	                LOGISTIC	        38157.440	  107.698	  107.913	  0.118%	 41.830%	     0.000	        1	[efficientnetv2-l/block4f_activation/Sigmoid]:187
	                     MUL	        38265.366	    6.604	    6.614	  0.007%	 41.837%	     0.000	        1	[efficientnetv2-l/block4f_activation/mul_1]:188
	                    MEAN	        38271.991	  112.511	  112.374	  0.123%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_squeeze/Mean]:189
	                   SHAPE	        38384.378	    0.009	    0.009	  0.000%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Shape]:190
	           STRIDED_SLICE	        38384.392	    0.021	    0.021	  0.000%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/strided_slice]:191
	                    PACK	        38384.420	    0.028	    0.026	  0.000%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape/shape]:192
	                 RESHAPE	        38384.454	    0.014	    0.014	  0.000%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape]:193
	                 CONV_2D	        38384.474	    0.104	    0.106	  0.000%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4f_se_reduce/Conv2D]:194
	                LOGISTIC	        38384.588	    0.028	    0.029	  0.000%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/Sigmoid]:195
	                     MUL	        38384.624	    0.012	    0.013	  0.000%	 41.960%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/mul_1]:196
	                 CONV_2D	        38384.643	    0.302	    0.302	  0.000%	 41.961%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_se_expand/Conv2D]:197
	                LOGISTIC	        38384.952	    0.131	    0.132	  0.000%	 41.961%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/Sigmoid]:198
	                     MUL	        38385.090	    6.747	    6.755	  0.007%	 41.968%	     0.000	        1	[efficientnetv2-l/block4f_se_excite/mul]:199
	                 CONV_2D	        38391.857	   66.217	   66.171	  0.072%	 42.040%	     0.000	        1	[efficientnetv2-l/block4f_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_project_conv/Conv2D]:200
	                     ADD	        38458.039	    1.610	    1.637	  0.002%	 42.042%	     0.000	        1	[efficientnetv2-l/block4f_add/add]:201
	                 CONV_2D	        38459.686	  243.120	  242.329	  0.265%	 42.307%	     0.000	        1	[efficientnetv2-l/block4g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_expand_conv/Conv2D]:202
	                LOGISTIC	        38702.029	  222.641	  222.563	  0.243%	 42.550%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/Sigmoid]:203
	                     MUL	        38924.603	    6.656	    6.650	  0.007%	 42.558%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/mul_1]:204
	       DEPTHWISE_CONV_2D	        38931.265	    4.767	    4.969	  0.005%	 42.563%	     0.000	        1	[efficientnetv2-l/block4g_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:205
	                LOGISTIC	        38936.246	  109.210	  108.847	  0.119%	 42.682%	     0.000	        1	[efficientnetv2-l/block4g_activation/Sigmoid]:206
	                     MUL	        39045.105	    6.676	    6.641	  0.007%	 42.689%	     0.000	        1	[efficientnetv2-l/block4g_activation/mul_1]:207
	                    MEAN	        39051.758	  112.270	  112.412	  0.123%	 42.812%	     0.000	        1	[efficientnetv2-l/block4g_se_squeeze/Mean]:208
	                   SHAPE	        39164.182	    0.009	    0.009	  0.000%	 42.812%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Shape]:209
	           STRIDED_SLICE	        39164.197	    0.022	    0.021	  0.000%	 42.812%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/strided_slice]:210
	                    PACK	        39164.225	    0.029	    0.027	  0.000%	 42.812%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape/shape]:211
	                 RESHAPE	        39164.259	    0.014	    0.014	  0.000%	 42.812%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape]:212
	                 CONV_2D	        39164.279	    0.104	    0.126	  0.000%	 42.812%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4g_se_reduce/Conv2D]:213
	                LOGISTIC	        39164.412	    0.028	    0.028	  0.000%	 42.813%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/Sigmoid]:214
	                     MUL	        39164.447	    0.012	    0.012	  0.000%	 42.813%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/mul_1]:215
	                 CONV_2D	        39164.465	    0.299	    0.299	  0.000%	 42.813%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_se_expand/Conv2D]:216
	                LOGISTIC	        39164.772	    0.128	    0.128	  0.000%	 42.813%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/Sigmoid]:217
	                     MUL	        39164.906	    6.799	    6.765	  0.007%	 42.820%	     0.000	        1	[efficientnetv2-l/block4g_se_excite/mul]:218
	                 CONV_2D	        39171.683	   65.983	   65.993	  0.072%	 42.893%	     0.000	        1	[efficientnetv2-l/block4g_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_project_conv/Conv2D]:219
	                     ADD	        39237.688	    1.650	    1.659	  0.002%	 42.894%	     0.000	        1	[efficientnetv2-l/block4g_add/add]:220
	                 CONV_2D	        39239.357	  245.094	  244.638	  0.267%	 43.162%	     0.000	        1	[efficientnetv2-l/block4h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_expand_conv/Conv2D]:221
	                LOGISTIC	        39484.007	  223.054	  222.375	  0.243%	 43.405%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/Sigmoid]:222
	                     MUL	        39706.393	    6.642	    6.624	  0.007%	 43.412%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/mul_1]:223
	       DEPTHWISE_CONV_2D	        39713.027	    5.145	    4.958	  0.005%	 43.418%	     0.000	        1	[efficientnetv2-l/block4h_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:224
	                LOGISTIC	        39717.998	  111.489	  110.103	  0.120%	 43.538%	     0.000	        1	[efficientnetv2-l/block4h_activation/Sigmoid]:225
	                     MUL	        39828.113	    6.713	    6.669	  0.007%	 43.545%	     0.000	        1	[efficientnetv2-l/block4h_activation/mul_1]:226
	                    MEAN	        39834.793	  112.511	  112.405	  0.123%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_squeeze/Mean]:227
	                   SHAPE	        39947.209	    0.009	    0.009	  0.000%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Shape]:228
	           STRIDED_SLICE	        39947.224	    0.021	    0.021	  0.000%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/strided_slice]:229
	                    PACK	        39947.252	    0.029	    0.027	  0.000%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape/shape]:230
	                 RESHAPE	        39947.285	    0.014	    0.015	  0.000%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape]:231
	                 CONV_2D	        39947.306	    0.105	    0.107	  0.000%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4h_se_reduce/Conv2D]:232
	                LOGISTIC	        39947.421	    0.028	    0.029	  0.000%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/Sigmoid]:233
	                     MUL	        39947.456	    0.012	    0.013	  0.000%	 43.668%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/mul_1]:234
	                 CONV_2D	        39947.474	    0.299	    0.300	  0.000%	 43.669%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_se_expand/Conv2D]:235
	                LOGISTIC	        39947.781	    0.130	    0.131	  0.000%	 43.669%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/Sigmoid]:236
	                     MUL	        39947.918	    6.701	    6.719	  0.007%	 43.676%	     0.000	        1	[efficientnetv2-l/block4h_se_excite/mul]:237
	                 CONV_2D	        39954.649	   65.929	   65.965	  0.072%	 43.748%	     0.000	        1	[efficientnetv2-l/block4h_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_project_conv/Conv2D]:238
	                     ADD	        40020.625	    1.610	    1.596	  0.002%	 43.750%	     0.000	        1	[efficientnetv2-l/block4h_add/add]:239
	                 CONV_2D	        40022.230	  240.753	  240.655	  0.263%	 44.013%	     0.000	        1	[efficientnetv2-l/block4i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_expand_conv/Conv2D]:240
	                LOGISTIC	        40262.898	  222.524	  222.380	  0.243%	 44.256%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/Sigmoid]:241
	                     MUL	        40485.291	    6.627	    6.629	  0.007%	 44.263%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/mul_1]:242
	       DEPTHWISE_CONV_2D	        40491.931	    5.683	    5.675	  0.006%	 44.270%	     0.000	        1	[efficientnetv2-l/block4i_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:243
	                LOGISTIC	        40497.618	  194.067	  193.629	  0.212%	 44.481%	     0.000	        1	[efficientnetv2-l/block4i_activation/Sigmoid]:244
	                     MUL	        40691.260	    6.619	    6.614	  0.007%	 44.489%	     0.000	        1	[efficientnetv2-l/block4i_activation/mul_1]:245
	                    MEAN	        40697.885	  112.204	  112.168	  0.123%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_squeeze/Mean]:246
	                   SHAPE	        40810.063	    0.008	    0.009	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Shape]:247
	           STRIDED_SLICE	        40810.078	    0.021	    0.021	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/strided_slice]:248
	                    PACK	        40810.106	    0.030	    0.028	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape/shape]:249
	                 RESHAPE	        40810.141	    0.014	    0.014	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape]:250
	                 CONV_2D	        40810.161	    0.108	    0.108	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4i_se_reduce/Conv2D]:251
	                LOGISTIC	        40810.278	    0.029	    0.029	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/Sigmoid]:252
	                     MUL	        40810.312	    0.012	    0.013	  0.000%	 44.611%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/mul_1]:253
	                 CONV_2D	        40810.331	    0.304	    0.303	  0.000%	 44.612%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_se_expand/Conv2D]:254
	                LOGISTIC	        40810.642	    0.133	    0.133	  0.000%	 44.612%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/Sigmoid]:255
	                     MUL	        40810.781	    6.693	    6.734	  0.007%	 44.619%	     0.000	        1	[efficientnetv2-l/block4i_se_excite/mul]:256
	                 CONV_2D	        40817.527	   67.746	   67.475	  0.074%	 44.693%	     0.000	        1	[efficientnetv2-l/block4i_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_project_conv/Conv2D]:257
	                     ADD	        40885.015	    1.668	    1.667	  0.002%	 44.695%	     0.000	        1	[efficientnetv2-l/block4i_add/add]:258
	                 CONV_2D	        40886.692	  243.897	  243.859	  0.267%	 44.961%	     0.000	        1	[efficientnetv2-l/block4j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_expand_conv/Conv2D]:259
	                LOGISTIC	        41130.562	  216.220	  216.315	  0.236%	 45.198%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/Sigmoid]:260
	                     MUL	        41346.889	    6.643	    6.676	  0.007%	 45.205%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/mul_1]:261
	       DEPTHWISE_CONV_2D	        41353.576	    4.751	    4.911	  0.005%	 45.211%	     0.000	        1	[efficientnetv2-l/block4j_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_dwconv2/depthwise]:262
	                LOGISTIC	        41358.501	  109.545	  109.100	  0.119%	 45.330%	     0.000	        1	[efficientnetv2-l/block4j_activation/Sigmoid]:263
	                     MUL	        41467.614	    6.690	    6.704	  0.007%	 45.337%	     0.000	        1	[efficientnetv2-l/block4j_activation/mul_1]:264
	                    MEAN	        41474.330	  112.520	  112.443	  0.123%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_squeeze/Mean]:265
	                   SHAPE	        41586.785	    0.009	    0.009	  0.000%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Shape]:266
	           STRIDED_SLICE	        41586.800	    0.021	    0.021	  0.000%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/strided_slice]:267
	                    PACK	        41586.827	    0.029	    0.027	  0.000%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape/shape]:268
	                 RESHAPE	        41586.861	    0.014	    0.015	  0.000%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape]:269
	                 CONV_2D	        41586.882	    0.103	    0.105	  0.000%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4j_se_reduce/Conv2D]:270
	                LOGISTIC	        41586.995	    0.045	    0.037	  0.000%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/Sigmoid]:271
	                     MUL	        41587.039	    0.012	    0.013	  0.000%	 45.460%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/mul_1]:272
	                 CONV_2D	        41587.058	    0.302	    0.298	  0.000%	 45.461%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_se_expand/Conv2D]:273
	                LOGISTIC	        41587.363	    0.129	    0.130	  0.000%	 45.461%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/Sigmoid]:274
	                     MUL	        41587.499	    6.833	    6.757	  0.007%	 45.468%	     0.000	        1	[efficientnetv2-l/block4j_se_excite/mul]:275
	                 CONV_2D	        41594.268	   66.871	   66.464	  0.073%	 45.541%	     0.000	        1	[efficientnetv2-l/block4j_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_project_conv/Conv2D]:276
	                     ADD	        41660.744	    1.572	    1.571	  0.002%	 45.543%	     0.000	        1	[efficientnetv2-l/block4j_add/add]:277
	                 CONV_2D	        41662.325	  360.048	  358.392	  0.392%	 45.934%	     0.000	        1	[efficientnetv2-l/block5a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_expand_conv/Conv2D]:278
	                LOGISTIC	        42020.730	  219.966	  218.918	  0.239%	 46.174%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/Sigmoid]:279
	                     MUL	        42239.660	    9.967	    9.881	  0.011%	 46.185%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/mul_1]:280
	       DEPTHWISE_CONV_2D	        42249.554	    8.544	    8.531	  0.009%	 46.194%	     0.000	        1	[efficientnetv2-l/block5a_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_dwconv2/depthwise]:281
	                LOGISTIC	        42258.099	  328.831	  328.632	  0.359%	 46.553%	     0.000	        1	[efficientnetv2-l/block5a_activation/Sigmoid]:282
	                     MUL	        42586.745	    9.833	    9.755	  0.011%	 46.564%	     0.000	        1	[efficientnetv2-l/block5a_activation/mul_1]:283
	                    MEAN	        42596.512	  168.783	  168.548	  0.184%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_squeeze/Mean]:284
	                   SHAPE	        42765.071	    0.009	    0.009	  0.000%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Shape]:285
	           STRIDED_SLICE	        42765.086	    0.022	    0.022	  0.000%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/strided_slice]:286
	                    PACK	        42765.115	    0.029	    0.027	  0.000%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape/shape]:287
	                 RESHAPE	        42765.148	    0.014	    0.014	  0.000%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape]:288
	                 CONV_2D	        42765.169	    0.110	    0.112	  0.000%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5a_se_reduce/Conv2D]:289
	                LOGISTIC	        42765.289	    0.028	    0.029	  0.000%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/Sigmoid]:290
	                     MUL	        42765.323	    0.012	    0.013	  0.000%	 46.748%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/mul_1]:291
	                 CONV_2D	        42765.342	    0.426	    0.426	  0.000%	 46.749%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/BiasAdd;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_se_expand/Conv2D]:292
	                LOGISTIC	        42765.776	    0.195	    0.194	  0.000%	 46.749%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/Sigmoid]:293
	                     MUL	        42765.976	    9.938	    9.953	  0.011%	 46.760%	     0.000	        1	[efficientnetv2-l/block5a_se_excite/mul]:294
	                 CONV_2D	        42775.942	   85.955	   85.403	  0.093%	 46.853%	     0.000	        1	[efficientnetv2-l/block5a_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_project_conv/Conv2D]:295
	                 CONV_2D	        42861.357	  419.229	  419.353	  0.458%	 47.312%	     0.000	        1	[efficientnetv2-l/block5b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_expand_conv/Conv2D]:296
	                LOGISTIC	        43280.721	  376.022	  375.502	  0.411%	 47.722%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/Sigmoid]:297
	                     MUL	        43656.235	   11.137	   11.253	  0.012%	 47.734%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/mul_1]:298
	       DEPTHWISE_CONV_2D	        43667.501	    8.439	    8.895	  0.010%	 47.744%	     0.000	        1	[efficientnetv2-l/block5b_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:299
	                LOGISTIC	        43676.408	  189.822	  190.685	  0.208%	 47.953%	     0.000	        1	[efficientnetv2-l/block5b_activation/Sigmoid]:300
	                     MUL	        43867.107	   11.783	   11.616	  0.013%	 47.965%	     0.000	        1	[efficientnetv2-l/block5b_activation/mul_1]:301
	                    MEAN	        43878.736	  196.951	  196.856	  0.215%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_squeeze/Mean]:302
	                   SHAPE	        44075.603	    0.009	    0.009	  0.000%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Shape]:303
	           STRIDED_SLICE	        44075.618	    0.022	    0.022	  0.000%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/strided_slice]:304
	                    PACK	        44075.647	    0.026	    0.025	  0.000%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape/shape]:305
	                 RESHAPE	        44075.679	    0.015	    0.015	  0.000%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape]:306
	                 CONV_2D	        44075.700	    0.114	    0.115	  0.000%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5b_se_reduce/Conv2D]:307
	                LOGISTIC	        44075.823	    0.030	    0.029	  0.000%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/Sigmoid]:308
	                     MUL	        44075.859	    0.012	    0.012	  0.000%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/mul_1]:309
	                 CONV_2D	        44075.878	    0.488	    0.487	  0.001%	 48.181%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_se_expand/Conv2D]:310
	                LOGISTIC	        44076.372	    0.218	    0.221	  0.000%	 48.182%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/Sigmoid]:311
	                     MUL	        44076.599	   11.690	   11.668	  0.013%	 48.194%	     0.000	        1	[efficientnetv2-l/block5b_se_excite/mul]:312
	                 CONV_2D	        44088.279	   83.492	   83.443	  0.091%	 48.286%	     0.000	        1	[efficientnetv2-l/block5b_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_project_conv/Conv2D]:313
	                     ADD	        44171.736	    1.956	    1.917	  0.002%	 48.288%	     0.000	        1	[efficientnetv2-l/block5b_add/add]:314
	                 CONV_2D	        44173.662	  427.483	  424.897	  0.465%	 48.752%	     0.000	        1	[efficientnetv2-l/block5c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_expand_conv/Conv2D]:315
	                LOGISTIC	        44598.571	  390.481	  389.707	  0.426%	 49.178%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/Sigmoid]:316
	                     MUL	        44988.289	   11.241	   11.229	  0.012%	 49.190%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/mul_1]:317
	       DEPTHWISE_CONV_2D	        44999.529	    9.855	    9.857	  0.011%	 49.201%	     0.000	        1	[efficientnetv2-l/block5c_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:318
	                LOGISTIC	        45009.401	  338.124	  338.201	  0.370%	 49.571%	     0.000	        1	[efficientnetv2-l/block5c_activation/Sigmoid]:319
	                     MUL	        45347.615	   11.176	   11.258	  0.012%	 49.583%	     0.000	        1	[efficientnetv2-l/block5c_activation/mul_1]:320
	                    MEAN	        45358.884	  196.501	  196.410	  0.215%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_squeeze/Mean]:321
	                   SHAPE	        45555.305	    0.009	    0.009	  0.000%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Shape]:322
	           STRIDED_SLICE	        45555.320	    0.022	    0.022	  0.000%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/strided_slice]:323
	                    PACK	        45555.349	    0.027	    0.026	  0.000%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape/shape]:324
	                 RESHAPE	        45555.380	    0.015	    0.015	  0.000%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape]:325
	                 CONV_2D	        45555.402	    0.112	    0.115	  0.000%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5c_se_reduce/Conv2D]:326
	                LOGISTIC	        45555.525	    0.030	    0.029	  0.000%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/Sigmoid]:327
	                     MUL	        45555.561	    0.013	    0.013	  0.000%	 49.798%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/mul_1]:328
	                 CONV_2D	        45555.579	    0.518	    0.508	  0.001%	 49.799%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_se_expand/Conv2D]:329
	                LOGISTIC	        45556.095	    0.227	    0.225	  0.000%	 49.799%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/Sigmoid]:330
	                     MUL	        45556.325	   11.794	   11.804	  0.013%	 49.812%	     0.000	        1	[efficientnetv2-l/block5c_se_excite/mul]:331
	                 CONV_2D	        45568.140	   85.883	   85.675	  0.094%	 49.906%	     0.000	        1	[efficientnetv2-l/block5c_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_project_conv/Conv2D]:332
	                     ADD	        45653.827	    1.870	    1.893	  0.002%	 49.908%	     0.000	        1	[efficientnetv2-l/block5c_add/add]:333
	                 CONV_2D	        45655.730	  420.855	  420.600	  0.460%	 50.367%	     0.000	        1	[efficientnetv2-l/block5d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_expand_conv/Conv2D]:334
	                LOGISTIC	        46076.342	  374.966	  375.111	  0.410%	 50.778%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/Sigmoid]:335
	                     MUL	        46451.465	   11.287	   11.231	  0.012%	 50.790%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/mul_1]:336
	       DEPTHWISE_CONV_2D	        46462.707	    8.344	    8.343	  0.009%	 50.799%	     0.000	        1	[efficientnetv2-l/block5d_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:337
	                LOGISTIC	        46471.062	  191.886	  191.501	  0.209%	 51.008%	     0.000	        1	[efficientnetv2-l/block5d_activation/Sigmoid]:338
	                     MUL	        46662.575	   11.311	   11.316	  0.012%	 51.021%	     0.000	        1	[efficientnetv2-l/block5d_activation/mul_1]:339
	                    MEAN	        46673.904	  197.898	  197.220	  0.216%	 51.236%	     0.000	        1	[efficientnetv2-l/block5d_se_squeeze/Mean]:340
	                   SHAPE	        46871.136	    0.010	    0.009	  0.000%	 51.236%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Shape]:341
	           STRIDED_SLICE	        46871.151	    0.023	    0.022	  0.000%	 51.236%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/strided_slice]:342
	                    PACK	        46871.180	    0.029	    0.028	  0.000%	 51.236%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape/shape]:343
	                 RESHAPE	        46871.213	    0.016	    0.015	  0.000%	 51.236%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape]:344
	                 CONV_2D	        46871.236	    0.116	    0.115	  0.000%	 51.236%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5d_se_reduce/Conv2D]:345
	                LOGISTIC	        46871.359	    0.031	    0.030	  0.000%	 51.237%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/Sigmoid]:346
	                     MUL	        46871.395	    0.014	    0.013	  0.000%	 51.237%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/mul_1]:347
	                 CONV_2D	        46871.414	    0.505	    0.504	  0.001%	 51.237%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_se_expand/Conv2D]:348
	                LOGISTIC	        46871.927	    0.227	    0.225	  0.000%	 51.237%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/Sigmoid]:349
	                     MUL	        46872.158	   11.646	   11.610	  0.013%	 51.250%	     0.000	        1	[efficientnetv2-l/block5d_se_excite/mul]:350
	                 CONV_2D	        46883.779	   84.882	   84.180	  0.092%	 51.342%	     0.000	        1	[efficientnetv2-l/block5d_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_project_conv/Conv2D]:351
	                     ADD	        46967.971	    1.884	    1.882	  0.002%	 51.344%	     0.000	        1	[efficientnetv2-l/block5d_add/add]:352
	                 CONV_2D	        46969.863	  427.292	  427.476	  0.467%	 51.811%	     0.000	        1	[efficientnetv2-l/block5e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_expand_conv/Conv2D]:353
	                LOGISTIC	        47397.353	  386.271	  386.091	  0.422%	 52.233%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/Sigmoid]:354
	                     MUL	        47783.455	   11.208	   11.249	  0.012%	 52.246%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/mul_1]:355
	       DEPTHWISE_CONV_2D	        47794.738	    8.452	    8.433	  0.009%	 52.255%	     0.000	        1	[efficientnetv2-l/block5e_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:356
	                LOGISTIC	        47803.183	  192.271	  191.840	  0.210%	 52.465%	     0.000	        1	[efficientnetv2-l/block5e_activation/Sigmoid]:357
	                     MUL	        47995.036	   11.397	   11.388	  0.012%	 52.477%	     0.000	        1	[efficientnetv2-l/block5e_activation/mul_1]:358
	                    MEAN	        48006.437	  196.724	  196.529	  0.215%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_squeeze/Mean]:359
	                   SHAPE	        48202.978	    0.010	    0.009	  0.000%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Shape]:360
	           STRIDED_SLICE	        48202.993	    0.021	    0.021	  0.000%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/strided_slice]:361
	                    PACK	        48203.022	    0.027	    0.026	  0.000%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape/shape]:362
	                 RESHAPE	        48203.054	    0.015	    0.015	  0.000%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape]:363
	                 CONV_2D	        48203.075	    0.111	    0.113	  0.000%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5e_se_reduce/Conv2D]:364
	                LOGISTIC	        48203.196	    0.029	    0.030	  0.000%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/Sigmoid]:365
	                     MUL	        48203.232	    0.014	    0.013	  0.000%	 52.692%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/mul_1]:366
	                 CONV_2D	        48203.252	    0.500	    0.500	  0.001%	 52.693%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_se_expand/Conv2D]:367
	                LOGISTIC	        48203.760	    0.223	    0.224	  0.000%	 52.693%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/Sigmoid]:368
	                     MUL	        48203.990	   11.841	   11.816	  0.013%	 52.706%	     0.000	        1	[efficientnetv2-l/block5e_se_excite/mul]:369
	                 CONV_2D	        48215.819	   83.363	   83.490	  0.091%	 52.797%	     0.000	        1	[efficientnetv2-l/block5e_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_project_conv/Conv2D]:370
	                     ADD	        48299.321	    2.002	    1.986	  0.002%	 52.799%	     0.000	        1	[efficientnetv2-l/block5e_add/add]:371
	                 CONV_2D	        48301.316	  419.255	  420.369	  0.460%	 53.259%	     0.000	        1	[efficientnetv2-l/block5f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_expand_conv/Conv2D]:372
	                LOGISTIC	        48721.698	  388.978	  387.633	  0.424%	 53.683%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/Sigmoid]:373
	                     MUL	        49109.342	   11.506	   11.434	  0.013%	 53.695%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/mul_1]:374
	       DEPTHWISE_CONV_2D	        49120.790	    9.484	    8.966	  0.010%	 53.705%	     0.000	        1	[efficientnetv2-l/block5f_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:375
	                LOGISTIC	        49129.770	  190.112	  190.025	  0.208%	 53.913%	     0.000	        1	[efficientnetv2-l/block5f_activation/Sigmoid]:376
	                     MUL	        49319.807	   11.670	   11.503	  0.013%	 53.925%	     0.000	        1	[efficientnetv2-l/block5f_activation/mul_1]:377
	                    MEAN	        49331.323	  196.818	  196.623	  0.215%	 54.140%	     0.000	        1	[efficientnetv2-l/block5f_se_squeeze/Mean]:378
	                   SHAPE	        49527.958	    0.009	    0.009	  0.000%	 54.140%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Shape]:379
	           STRIDED_SLICE	        49527.973	    0.021	    0.021	  0.000%	 54.140%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/strided_slice]:380
	                    PACK	        49528.001	    0.028	    0.026	  0.000%	 54.140%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape/shape]:381
	                 RESHAPE	        49528.033	    0.015	    0.015	  0.000%	 54.140%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape]:382
	                 CONV_2D	        49528.055	    0.135	    0.125	  0.000%	 54.141%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5f_se_reduce/Conv2D]:383
	                LOGISTIC	        49528.188	    0.030	    0.030	  0.000%	 54.141%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/Sigmoid]:384
	                     MUL	        49528.224	    0.013	    0.013	  0.000%	 54.141%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/mul_1]:385
	                 CONV_2D	        49528.243	    0.499	    0.498	  0.001%	 54.141%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_se_expand/Conv2D]:386
	                LOGISTIC	        49528.749	    0.221	    0.219	  0.000%	 54.141%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/Sigmoid]:387
	                     MUL	        49528.974	   11.653	   11.670	  0.013%	 54.154%	     0.000	        1	[efficientnetv2-l/block5f_se_excite/mul]:388
	                 CONV_2D	        49540.656	   84.226	   83.776	  0.092%	 54.246%	     0.000	        1	[efficientnetv2-l/block5f_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_project_conv/Conv2D]:389
	                     ADD	        49624.446	    1.828	    1.829	  0.002%	 54.248%	     0.000	        1	[efficientnetv2-l/block5f_add/add]:390
	                 CONV_2D	        49626.285	  419.676	  419.774	  0.459%	 54.707%	     0.000	        1	[efficientnetv2-l/block5g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_expand_conv/Conv2D]:391
	                LOGISTIC	        50046.071	  386.692	  386.312	  0.422%	 55.129%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/Sigmoid]:392
	                     MUL	        50432.395	   11.329	   11.240	  0.012%	 55.141%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/mul_1]:393
	       DEPTHWISE_CONV_2D	        50443.647	    9.930	    9.889	  0.011%	 55.152%	     0.000	        1	[efficientnetv2-l/block5g_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:394
	                LOGISTIC	        50453.550	  330.661	  330.204	  0.361%	 55.513%	     0.000	        1	[efficientnetv2-l/block5g_activation/Sigmoid]:395
	                     MUL	        50783.766	   11.339	   11.267	  0.012%	 55.525%	     0.000	        1	[efficientnetv2-l/block5g_activation/mul_1]:396
	                    MEAN	        50795.044	  197.225	  197.124	  0.215%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_squeeze/Mean]:397
	                   SHAPE	        50992.180	    0.009	    0.009	  0.000%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Shape]:398
	           STRIDED_SLICE	        50992.194	    0.022	    0.022	  0.000%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/strided_slice]:399
	                    PACK	        50992.224	    0.027	    0.026	  0.000%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape/shape]:400
	                 RESHAPE	        50992.256	    0.014	    0.015	  0.000%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape]:401
	                 CONV_2D	        50992.277	    0.114	    0.132	  0.000%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5g_se_reduce/Conv2D]:402
	                LOGISTIC	        50992.416	    0.030	    0.030	  0.000%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/Sigmoid]:403
	                     MUL	        50992.452	    0.013	    0.013	  0.000%	 55.741%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/mul_1]:404
	                 CONV_2D	        50992.473	    0.504	    0.501	  0.001%	 55.742%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_se_expand/Conv2D]:405
	                LOGISTIC	        50992.982	    0.223	    0.223	  0.000%	 55.742%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/Sigmoid]:406
	                     MUL	        50993.212	   11.762	   11.796	  0.013%	 55.755%	     0.000	        1	[efficientnetv2-l/block5g_se_excite/mul]:407
	                 CONV_2D	        51005.020	   85.109	   85.284	  0.093%	 55.848%	     0.000	        1	[efficientnetv2-l/block5g_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_project_conv/Conv2D]:408
	                     ADD	        51090.315	    1.898	    1.964	  0.002%	 55.850%	     0.000	        1	[efficientnetv2-l/block5g_add/add]:409
	                 CONV_2D	        51092.289	  422.223	  421.925	  0.461%	 56.311%	     0.000	        1	[efficientnetv2-l/block5h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_expand_conv/Conv2D]:410
	                LOGISTIC	        51514.227	  395.757	  393.724	  0.430%	 56.742%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/Sigmoid]:411
	                     MUL	        51907.963	   11.349	   11.251	  0.012%	 56.754%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/mul_1]:412
	       DEPTHWISE_CONV_2D	        51919.224	    8.573	    8.544	  0.009%	 56.763%	     0.000	        1	[efficientnetv2-l/block5h_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:413
	                LOGISTIC	        51927.783	  191.221	  191.190	  0.209%	 56.972%	     0.000	        1	[efficientnetv2-l/block5h_activation/Sigmoid]:414
	                     MUL	        52118.985	   11.346	   11.267	  0.012%	 56.985%	     0.000	        1	[efficientnetv2-l/block5h_activation/mul_1]:415
	                    MEAN	        52130.263	  196.609	  196.603	  0.215%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_squeeze/Mean]:416
	                   SHAPE	        52326.878	    0.009	    0.009	  0.000%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Shape]:417
	           STRIDED_SLICE	        52326.893	    0.021	    0.021	  0.000%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/strided_slice]:418
	                    PACK	        52326.921	    0.029	    0.027	  0.000%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape/shape]:419
	                 RESHAPE	        52326.955	    0.014	    0.015	  0.000%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape]:420
	                 CONV_2D	        52326.976	    0.111	    0.112	  0.000%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5h_se_reduce/Conv2D]:421
	                LOGISTIC	        52327.096	    0.029	    0.029	  0.000%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/Sigmoid]:422
	                     MUL	        52327.132	    0.013	    0.013	  0.000%	 57.200%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/mul_1]:423
	                 CONV_2D	        52327.151	    0.498	    0.495	  0.001%	 57.201%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_se_expand/Conv2D]:424
	                LOGISTIC	        52327.654	    0.217	    0.221	  0.000%	 57.201%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/Sigmoid]:425
	                     MUL	        52327.880	   11.624	   11.656	  0.013%	 57.214%	     0.000	        1	[efficientnetv2-l/block5h_se_excite/mul]:426
	                 CONV_2D	        52339.548	   83.527	   83.473	  0.091%	 57.305%	     0.000	        1	[efficientnetv2-l/block5h_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_project_conv/Conv2D]:427
	                     ADD	        52423.033	    1.915	    1.898	  0.002%	 57.307%	     0.000	        1	[efficientnetv2-l/block5h_add/add]:428
	                 CONV_2D	        52424.940	  420.190	  419.704	  0.459%	 57.766%	     0.000	        1	[efficientnetv2-l/block5i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_expand_conv/Conv2D]:429
	                LOGISTIC	        52844.657	  385.600	  385.084	  0.421%	 58.187%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/Sigmoid]:430
	                     MUL	        53229.753	   11.331	   11.328	  0.012%	 58.199%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/mul_1]:431
	       DEPTHWISE_CONV_2D	        53241.092	   10.048	   10.437	  0.011%	 58.210%	     0.000	        1	[efficientnetv2-l/block5i_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:432
	                LOGISTIC	        53251.541	  329.174	  329.185	  0.360%	 58.570%	     0.000	        1	[efficientnetv2-l/block5i_activation/Sigmoid]:433
	                     MUL	        53580.738	   11.466	   11.380	  0.012%	 58.583%	     0.000	        1	[efficientnetv2-l/block5i_activation/mul_1]:434
	                    MEAN	        53592.130	  198.436	  197.430	  0.216%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_squeeze/Mean]:435
	                   SHAPE	        53789.571	    0.009	    0.009	  0.000%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Shape]:436
	           STRIDED_SLICE	        53789.587	    0.021	    0.021	  0.000%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/strided_slice]:437
	                    PACK	        53789.615	    0.029	    0.027	  0.000%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape/shape]:438
	                 RESHAPE	        53789.649	    0.014	    0.015	  0.000%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape]:439
	                 CONV_2D	        53789.670	    0.113	    0.114	  0.000%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5i_se_reduce/Conv2D]:440
	                LOGISTIC	        53789.791	    0.030	    0.029	  0.000%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/Sigmoid]:441
	                     MUL	        53789.827	    0.013	    0.013	  0.000%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/mul_1]:442
	                 CONV_2D	        53789.846	    0.492	    0.493	  0.001%	 58.799%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_se_expand/Conv2D]:443
	                LOGISTIC	        53790.347	    0.216	    0.220	  0.000%	 58.800%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/Sigmoid]:444
	                     MUL	        53790.573	   11.860	   11.852	  0.013%	 58.813%	     0.000	        1	[efficientnetv2-l/block5i_se_excite/mul]:445
	                 CONV_2D	        53802.438	   86.865	   85.898	  0.094%	 58.906%	     0.000	        1	[efficientnetv2-l/block5i_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_project_conv/Conv2D]:446
	                     ADD	        53888.348	    1.915	    1.899	  0.002%	 58.909%	     0.000	        1	[efficientnetv2-l/block5i_add/add]:447
	                 CONV_2D	        53890.259	  425.020	  422.238	  0.462%	 59.370%	     0.000	        1	[efficientnetv2-l/block5j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_expand_conv/Conv2D]:448
	                LOGISTIC	        54312.509	  376.215	  375.491	  0.410%	 59.781%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/Sigmoid]:449
	                     MUL	        54688.012	   11.338	   11.377	  0.012%	 59.793%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/mul_1]:450
	       DEPTHWISE_CONV_2D	        54699.401	    9.944	    9.954	  0.011%	 59.804%	     0.000	        1	[efficientnetv2-l/block5j_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:451
	                LOGISTIC	        54709.368	  386.569	  386.141	  0.422%	 60.226%	     0.000	        1	[efficientnetv2-l/block5j_activation/Sigmoid]:452
	                     MUL	        55095.522	   11.345	   11.329	  0.012%	 60.238%	     0.000	        1	[efficientnetv2-l/block5j_activation/mul_1]:453
	                    MEAN	        55106.863	  196.449	  196.476	  0.215%	 60.453%	     0.000	        1	[efficientnetv2-l/block5j_se_squeeze/Mean]:454
	                   SHAPE	        55303.351	    0.010	    0.009	  0.000%	 60.453%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Shape]:455
	           STRIDED_SLICE	        55303.366	    0.021	    0.021	  0.000%	 60.453%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/strided_slice]:456
	                    PACK	        55303.394	    0.028	    0.026	  0.000%	 60.453%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape/shape]:457
	                 RESHAPE	        55303.427	    0.015	    0.015	  0.000%	 60.453%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape]:458
	                 CONV_2D	        55303.448	    0.115	    0.138	  0.000%	 60.453%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5j_se_reduce/Conv2D]:459
	                LOGISTIC	        55303.594	    0.030	    0.029	  0.000%	 60.454%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/Sigmoid]:460
	                     MUL	        55303.630	    0.012	    0.013	  0.000%	 60.454%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/mul_1]:461
	                 CONV_2D	        55303.649	    0.493	    0.495	  0.001%	 60.454%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_se_expand/Conv2D]:462
	                LOGISTIC	        55304.151	    0.224	    0.222	  0.000%	 60.454%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/Sigmoid]:463
	                     MUL	        55304.379	   11.725	   11.691	  0.013%	 60.467%	     0.000	        1	[efficientnetv2-l/block5j_se_excite/mul]:464
	                 CONV_2D	        55316.084	   84.990	   85.007	  0.093%	 60.560%	     0.000	        1	[efficientnetv2-l/block5j_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_project_conv/Conv2D]:465
	                     ADD	        55401.103	    1.912	    1.905	  0.002%	 60.562%	     0.000	        1	[efficientnetv2-l/block5j_add/add]:466
	                 CONV_2D	        55403.020	  420.854	  421.469	  0.461%	 61.023%	     0.000	        1	[efficientnetv2-l/block5k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_expand_conv/Conv2D]:467
	                LOGISTIC	        55824.499	  376.013	  375.603	  0.411%	 61.433%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/Sigmoid]:468
	                     MUL	        56200.114	   11.621	   11.458	  0.013%	 61.446%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/mul_1]:469
	       DEPTHWISE_CONV_2D	        56211.585	    9.884	    9.909	  0.011%	 61.457%	     0.000	        1	[efficientnetv2-l/block5k_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:470
	                LOGISTIC	        56221.507	  384.906	  383.538	  0.419%	 61.876%	     0.000	        1	[efficientnetv2-l/block5k_activation/Sigmoid]:471
	                     MUL	        56605.058	   11.524	   11.450	  0.013%	 61.889%	     0.000	        1	[efficientnetv2-l/block5k_activation/mul_1]:472
	                    MEAN	        56616.520	  196.453	  196.407	  0.215%	 62.103%	     0.000	        1	[efficientnetv2-l/block5k_se_squeeze/Mean]:473
	                   SHAPE	        56812.940	    0.009	    0.009	  0.000%	 62.103%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Shape]:474
	           STRIDED_SLICE	        56812.955	    0.023	    0.022	  0.000%	 62.103%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/strided_slice]:475
	                    PACK	        56812.984	    0.029	    0.027	  0.000%	 62.103%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape/shape]:476
	                 RESHAPE	        56813.018	    0.015	    0.015	  0.000%	 62.103%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape]:477
	                 CONV_2D	        56813.039	    0.114	    0.115	  0.000%	 62.104%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5k_se_reduce/Conv2D]:478
	                LOGISTIC	        56813.161	    0.030	    0.030	  0.000%	 62.104%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/Sigmoid]:479
	                     MUL	        56813.197	    0.013	    0.013	  0.000%	 62.104%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/mul_1]:480
	                 CONV_2D	        56813.217	    0.493	    0.493	  0.001%	 62.104%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_se_expand/Conv2D]:481
	                LOGISTIC	        56813.717	    0.224	    0.224	  0.000%	 62.104%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/Sigmoid]:482
	                     MUL	        56813.947	   12.004	   11.868	  0.013%	 62.117%	     0.000	        1	[efficientnetv2-l/block5k_se_excite/mul]:483
	                 CONV_2D	        56825.827	   87.717	   87.471	  0.096%	 62.213%	     0.000	        1	[efficientnetv2-l/block5k_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_project_conv/Conv2D]:484
	                     ADD	        56913.310	    1.958	    1.992	  0.002%	 62.215%	     0.000	        1	[efficientnetv2-l/block5k_add/add]:485
	                 CONV_2D	        56915.312	  423.852	  424.521	  0.464%	 62.679%	     0.000	        1	[efficientnetv2-l/block5l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_expand_conv/Conv2D]:486
	                LOGISTIC	        57339.845	  374.803	  374.398	  0.409%	 63.089%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/Sigmoid]:487
	                     MUL	        57714.257	   11.411	   11.357	  0.012%	 63.101%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/mul_1]:488
	       DEPTHWISE_CONV_2D	        57725.626	    8.397	    8.437	  0.009%	 63.110%	     0.000	        1	[efficientnetv2-l/block5l_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:489
	                LOGISTIC	        57734.075	  192.015	  191.181	  0.209%	 63.319%	     0.000	        1	[efficientnetv2-l/block5l_activation/Sigmoid]:490
	                     MUL	        57925.268	   11.274	   11.344	  0.012%	 63.332%	     0.000	        1	[efficientnetv2-l/block5l_activation/mul_1]:491
	                    MEAN	        57936.624	  196.647	  196.796	  0.215%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_squeeze/Mean]:492
	                   SHAPE	        58133.433	    0.009	    0.009	  0.000%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Shape]:493
	           STRIDED_SLICE	        58133.448	    0.022	    0.022	  0.000%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/strided_slice]:494
	                    PACK	        58133.476	    0.029	    0.027	  0.000%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape/shape]:495
	                 RESHAPE	        58133.510	    0.015	    0.015	  0.000%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape]:496
	                 CONV_2D	        58133.532	    0.112	    0.117	  0.000%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5l_se_reduce/Conv2D]:497
	                LOGISTIC	        58133.656	    0.029	    0.030	  0.000%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/Sigmoid]:498
	                     MUL	        58133.694	    0.013	    0.013	  0.000%	 63.547%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/mul_1]:499
	                 CONV_2D	        58133.713	    0.492	    0.495	  0.001%	 63.548%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_se_expand/Conv2D]:500
	                LOGISTIC	        58134.215	    0.223	    0.227	  0.000%	 63.548%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/Sigmoid]:501
	                     MUL	        58134.448	   11.653	   11.649	  0.013%	 63.561%	     0.000	        1	[efficientnetv2-l/block5l_se_excite/mul]:502
	                 CONV_2D	        58146.109	   85.133	   85.469	  0.093%	 63.654%	     0.000	        1	[efficientnetv2-l/block5l_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_project_conv/Conv2D]:503
	                     ADD	        58231.592	    1.878	    1.863	  0.002%	 63.656%	     0.000	        1	[efficientnetv2-l/block5l_add/add]:504
	                 CONV_2D	        58233.466	  423.300	  422.301	  0.462%	 64.118%	     0.000	        1	[efficientnetv2-l/block5m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_expand_conv/Conv2D]:505
	                LOGISTIC	        58655.779	  390.738	  389.118	  0.425%	 64.543%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/Sigmoid]:506
	                     MUL	        59044.910	   11.250	   11.322	  0.012%	 64.555%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/mul_1]:507
	       DEPTHWISE_CONV_2D	        59056.245	   10.032	   10.005	  0.011%	 64.566%	     0.000	        1	[efficientnetv2-l/block5m_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:508
	                LOGISTIC	        59066.262	  334.792	  334.530	  0.366%	 64.932%	     0.000	        1	[efficientnetv2-l/block5m_activation/Sigmoid]:509
	                     MUL	        59400.806	   11.441	   11.377	  0.012%	 64.945%	     0.000	        1	[efficientnetv2-l/block5m_activation/mul_1]:510
	                    MEAN	        59412.194	  197.225	  196.841	  0.215%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_squeeze/Mean]:511
	                   SHAPE	        59609.048	    0.009	    0.009	  0.000%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Shape]:512
	           STRIDED_SLICE	        59609.062	    0.022	    0.022	  0.000%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/strided_slice]:513
	                    PACK	        59609.092	    0.029	    0.027	  0.000%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape/shape]:514
	                 RESHAPE	        59609.125	    0.016	    0.016	  0.000%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape]:515
	                 CONV_2D	        59609.147	    0.115	    0.116	  0.000%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5m_se_reduce/Conv2D]:516
	                LOGISTIC	        59609.270	    0.029	    0.030	  0.000%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/Sigmoid]:517
	                     MUL	        59609.307	    0.013	    0.013	  0.000%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/mul_1]:518
	                 CONV_2D	        59609.326	    0.490	    0.493	  0.001%	 65.160%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_se_expand/Conv2D]:519
	                LOGISTIC	        59609.826	    0.217	    0.216	  0.000%	 65.161%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/Sigmoid]:520
	                     MUL	        59610.048	   11.746	   11.771	  0.013%	 65.174%	     0.000	        1	[efficientnetv2-l/block5m_se_excite/mul]:521
	                 CONV_2D	        59621.832	   85.284	   85.376	  0.093%	 65.267%	     0.000	        1	[efficientnetv2-l/block5m_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_project_conv/Conv2D]:522
	                     ADD	        59707.220	    1.913	    1.897	  0.002%	 65.269%	     0.000	        1	[efficientnetv2-l/block5m_add/add]:523
	                 CONV_2D	        59709.126	  422.873	  422.560	  0.462%	 65.731%	     0.000	        1	[efficientnetv2-l/block5n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_expand_conv/Conv2D]:524
	                LOGISTIC	        60131.698	  377.503	  377.511	  0.413%	 66.144%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/Sigmoid]:525
	                     MUL	        60509.222	   11.322	   11.289	  0.012%	 66.156%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/mul_1]:526
	       DEPTHWISE_CONV_2D	        60520.522	    8.371	    8.719	  0.010%	 66.166%	     0.000	        1	[efficientnetv2-l/block5n_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:527
	                LOGISTIC	        60529.255	  190.885	  190.560	  0.208%	 66.374%	     0.000	        1	[efficientnetv2-l/block5n_activation/Sigmoid]:528
	                     MUL	        60719.827	   11.333	   11.290	  0.012%	 66.386%	     0.000	        1	[efficientnetv2-l/block5n_activation/mul_1]:529
	                    MEAN	        60731.128	  198.339	  197.392	  0.216%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_squeeze/Mean]:530
	                   SHAPE	        60928.531	    0.011	    0.010	  0.000%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Shape]:531
	           STRIDED_SLICE	        60928.548	    0.023	    0.022	  0.000%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/strided_slice]:532
	                    PACK	        60928.577	    0.030	    0.028	  0.000%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape/shape]:533
	                 RESHAPE	        60928.611	    0.015	    0.015	  0.000%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape]:534
	                 CONV_2D	        60928.632	    0.122	    0.118	  0.000%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5n_se_reduce/Conv2D]:535
	                LOGISTIC	        60928.758	    0.031	    0.032	  0.000%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/Sigmoid]:536
	                     MUL	        60928.796	    0.014	    0.013	  0.000%	 66.602%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/mul_1]:537
	                 CONV_2D	        60928.815	    0.500	    0.503	  0.001%	 66.603%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_se_expand/Conv2D]:538
	                LOGISTIC	        60929.325	    0.220	    0.222	  0.000%	 66.603%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/Sigmoid]:539
	                     MUL	        60929.554	   11.849	   11.749	  0.013%	 66.616%	     0.000	        1	[efficientnetv2-l/block5n_se_excite/mul]:540
	                 CONV_2D	        60941.316	   83.608	   83.487	  0.091%	 66.707%	     0.000	        1	[efficientnetv2-l/block5n_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_project_conv/Conv2D]:541
	                     ADD	        61024.815	    1.833	    1.855	  0.002%	 66.709%	     0.000	        1	[efficientnetv2-l/block5n_add/add]:542
	                 CONV_2D	        61026.681	  428.202	  426.909	  0.467%	 67.176%	     0.000	        1	[efficientnetv2-l/block5o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_expand_conv/Conv2D]:543
	                LOGISTIC	        61453.601	  386.740	  386.198	  0.422%	 67.598%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/Sigmoid]:544
	                     MUL	        61839.812	   11.219	   11.229	  0.012%	 67.610%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/mul_1]:545
	       DEPTHWISE_CONV_2D	        61851.052	    8.461	    8.453	  0.009%	 67.620%	     0.000	        1	[efficientnetv2-l/block5o_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:546
	                LOGISTIC	        61859.518	  190.998	  190.723	  0.209%	 67.828%	     0.000	        1	[efficientnetv2-l/block5o_activation/Sigmoid]:547
	                     MUL	        62050.255	   11.266	   11.278	  0.012%	 67.840%	     0.000	        1	[efficientnetv2-l/block5o_activation/mul_1]:548
	                    MEAN	        62061.544	  196.632	  196.537	  0.215%	 68.055%	     0.000	        1	[efficientnetv2-l/block5o_se_squeeze/Mean]:549
	                   SHAPE	        62258.094	    0.009	    0.009	  0.000%	 68.055%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Shape]:550
	           STRIDED_SLICE	        62258.109	    0.021	    0.021	  0.000%	 68.055%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/strided_slice]:551
	                    PACK	        62258.136	    0.029	    0.027	  0.000%	 68.055%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape/shape]:552
	                 RESHAPE	        62258.170	    0.015	    0.015	  0.000%	 68.055%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape]:553
	                 CONV_2D	        62258.190	    0.112	    0.112	  0.000%	 68.055%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5o_se_reduce/Conv2D]:554
	                LOGISTIC	        62258.310	    0.030	    0.030	  0.000%	 68.056%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/Sigmoid]:555
	                     MUL	        62258.346	    0.013	    0.013	  0.000%	 68.056%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/mul_1]:556
	                 CONV_2D	        62258.365	    0.500	    0.499	  0.001%	 68.056%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_se_expand/Conv2D]:557
	                LOGISTIC	        62258.872	    0.222	    0.220	  0.000%	 68.056%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/Sigmoid]:558
	                     MUL	        62259.098	   11.783	   11.787	  0.013%	 68.069%	     0.000	        1	[efficientnetv2-l/block5o_se_excite/mul]:559
	                 CONV_2D	        62270.899	   83.914	   83.808	  0.092%	 68.161%	     0.000	        1	[efficientnetv2-l/block5o_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_project_conv/Conv2D]:560
	                     ADD	        62354.718	    1.831	    1.831	  0.002%	 68.163%	     0.000	        1	[efficientnetv2-l/block5o_add/add]:561
	                 CONV_2D	        62356.559	  424.431	  424.450	  0.464%	 68.627%	     0.000	        1	[efficientnetv2-l/block5p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_expand_conv/Conv2D]:562
	                LOGISTIC	        62781.022	  388.775	  389.012	  0.425%	 69.052%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/Sigmoid]:563
	                     MUL	        63170.045	   11.310	   11.244	  0.012%	 69.064%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/mul_1]:564
	       DEPTHWISE_CONV_2D	        63181.301	    9.912	    9.915	  0.011%	 69.075%	     0.000	        1	[efficientnetv2-l/block5p_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:565
	                LOGISTIC	        63191.229	  327.961	  327.690	  0.358%	 69.433%	     0.000	        1	[efficientnetv2-l/block5p_activation/Sigmoid]:566
	                     MUL	        63518.931	   11.343	   11.347	  0.012%	 69.446%	     0.000	        1	[efficientnetv2-l/block5p_activation/mul_1]:567
	                    MEAN	        63530.289	  196.855	  196.721	  0.215%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_squeeze/Mean]:568
	                   SHAPE	        63727.022	    0.008	    0.008	  0.000%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Shape]:569
	           STRIDED_SLICE	        63727.037	    0.022	    0.022	  0.000%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/strided_slice]:570
	                    PACK	        63727.065	    0.030	    0.028	  0.000%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape/shape]:571
	                 RESHAPE	        63727.099	    0.014	    0.015	  0.000%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape]:572
	                 CONV_2D	        63727.120	    0.112	    0.113	  0.000%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5p_se_reduce/Conv2D]:573
	                LOGISTIC	        63727.240	    0.030	    0.029	  0.000%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/Sigmoid]:574
	                     MUL	        63727.276	    0.013	    0.013	  0.000%	 69.661%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/mul_1]:575
	                 CONV_2D	        63727.296	    0.500	    0.496	  0.001%	 69.662%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_se_expand/Conv2D]:576
	                LOGISTIC	        63727.800	    0.224	    0.224	  0.000%	 69.662%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/Sigmoid]:577
	                     MUL	        63728.029	   11.720	   11.707	  0.013%	 69.675%	     0.000	        1	[efficientnetv2-l/block5p_se_excite/mul]:578
	                 CONV_2D	        63739.750	   84.963	   84.983	  0.093%	 69.768%	     0.000	        1	[efficientnetv2-l/block5p_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_project_conv/Conv2D]:579
	                     ADD	        63824.746	    2.018	    1.950	  0.002%	 69.770%	     0.000	        1	[efficientnetv2-l/block5p_add/add]:580
	                 CONV_2D	        63826.708	  421.387	  421.402	  0.461%	 70.230%	     0.000	        1	[efficientnetv2-l/block5q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_expand_conv/Conv2D]:581
	                LOGISTIC	        64248.121	  374.326	  374.276	  0.409%	 70.640%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/Sigmoid]:582
	                     MUL	        64622.408	   11.365	   11.305	  0.012%	 70.652%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/mul_1]:583
	       DEPTHWISE_CONV_2D	        64633.725	    8.367	    8.376	  0.009%	 70.661%	     0.000	        1	[efficientnetv2-l/block5q_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:584
	                LOGISTIC	        64642.114	  191.179	  190.836	  0.209%	 70.870%	     0.000	        1	[efficientnetv2-l/block5q_activation/Sigmoid]:585
	                     MUL	        64832.963	   11.344	   11.409	  0.012%	 70.882%	     0.000	        1	[efficientnetv2-l/block5q_activation/mul_1]:586
	                    MEAN	        64844.385	  196.560	  196.496	  0.215%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_squeeze/Mean]:587
	                   SHAPE	        65040.893	    0.009	    0.009	  0.000%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Shape]:588
	           STRIDED_SLICE	        65040.908	    0.021	    0.021	  0.000%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/strided_slice]:589
	                    PACK	        65040.936	    0.029	    0.027	  0.000%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape/shape]:590
	                 RESHAPE	        65040.969	    0.015	    0.040	  0.000%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape]:591
	                 CONV_2D	        65041.015	    0.111	    0.115	  0.000%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5q_se_reduce/Conv2D]:592
	                LOGISTIC	        65041.138	    0.029	    0.030	  0.000%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/Sigmoid]:593
	                     MUL	        65041.175	    0.013	    0.013	  0.000%	 71.097%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/mul_1]:594
	                 CONV_2D	        65041.194	    0.494	    0.496	  0.001%	 71.098%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_se_expand/Conv2D]:595
	                LOGISTIC	        65041.699	    0.223	    0.225	  0.000%	 71.098%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/Sigmoid]:596
	                     MUL	        65041.930	   11.754	   11.812	  0.013%	 71.111%	     0.000	        1	[efficientnetv2-l/block5q_se_excite/mul]:597
	                 CONV_2D	        65053.754	   83.496	   83.769	  0.092%	 71.203%	     0.000	        1	[efficientnetv2-l/block5q_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_project_conv/Conv2D]:598
	                     ADD	        65137.535	    1.840	    1.875	  0.002%	 71.205%	     0.000	        1	[efficientnetv2-l/block5q_add/add]:599
	                 CONV_2D	        65139.419	  419.273	  420.377	  0.460%	 71.664%	     0.000	        1	[efficientnetv2-l/block5r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_expand_conv/Conv2D]:600
	                LOGISTIC	        65559.807	  380.782	  380.457	  0.416%	 72.080%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/Sigmoid]:601
	                     MUL	        65940.277	   11.328	   11.293	  0.012%	 72.093%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/mul_1]:602
	       DEPTHWISE_CONV_2D	        65951.582	    9.197	    8.815	  0.010%	 72.102%	     0.000	        1	[efficientnetv2-l/block5r_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:603
	                LOGISTIC	        65960.409	  190.812	  190.226	  0.208%	 72.310%	     0.000	        1	[efficientnetv2-l/block5r_activation/Sigmoid]:604
	                     MUL	        66150.648	   11.264	   11.273	  0.012%	 72.322%	     0.000	        1	[efficientnetv2-l/block5r_activation/mul_1]:605
	                    MEAN	        66161.932	  196.475	  196.436	  0.215%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_squeeze/Mean]:606
	                   SHAPE	        66358.380	    0.010	    0.009	  0.000%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Shape]:607
	           STRIDED_SLICE	        66358.395	    0.021	    0.021	  0.000%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/strided_slice]:608
	                    PACK	        66358.424	    0.028	    0.027	  0.000%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape/shape]:609
	                 RESHAPE	        66358.457	    0.015	    0.015	  0.000%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape]:610
	                 CONV_2D	        66358.478	    0.112	    0.129	  0.000%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5r_se_reduce/Conv2D]:611
	                LOGISTIC	        66358.615	    0.030	    0.030	  0.000%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/Sigmoid]:612
	                     MUL	        66358.652	    0.012	    0.013	  0.000%	 72.537%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/mul_1]:613
	                 CONV_2D	        66358.670	    0.491	    0.495	  0.001%	 72.538%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_se_expand/Conv2D]:614
	                LOGISTIC	        66359.172	    0.220	    0.222	  0.000%	 72.538%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/Sigmoid]:615
	                     MUL	        66359.400	   11.635	   11.627	  0.013%	 72.551%	     0.000	        1	[efficientnetv2-l/block5r_se_excite/mul]:616
	                 CONV_2D	        66371.039	   85.456	   85.540	  0.094%	 72.644%	     0.000	        1	[efficientnetv2-l/block5r_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_project_conv/Conv2D]:617
	                     ADD	        66456.592	    2.020	    2.008	  0.002%	 72.647%	     0.000	        1	[efficientnetv2-l/block5r_add/add]:618
	                 CONV_2D	        66458.610	  422.513	  422.469	  0.462%	 73.108%	     0.000	        1	[efficientnetv2-l/block5s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_expand_conv/Conv2D]:619
	                LOGISTIC	        66881.091	  389.593	  389.586	  0.426%	 73.534%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/Sigmoid]:620
	                     MUL	        67270.687	   11.269	   11.306	  0.012%	 73.547%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/mul_1]:621
	       DEPTHWISE_CONV_2D	        67282.004	    9.982	   10.002	  0.011%	 73.558%	     0.000	        1	[efficientnetv2-l/block5s_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:622
	                LOGISTIC	        67292.020	  340.840	  341.067	  0.373%	 73.931%	     0.000	        1	[efficientnetv2-l/block5s_activation/Sigmoid]:623
	                     MUL	        67633.098	   11.383	   11.373	  0.012%	 73.943%	     0.000	        1	[efficientnetv2-l/block5s_activation/mul_1]:624
	                    MEAN	        67644.484	  196.393	  196.693	  0.215%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_squeeze/Mean]:625
	                   SHAPE	        67841.189	    0.008	    0.009	  0.000%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Shape]:626
	           STRIDED_SLICE	        67841.204	    0.021	    0.021	  0.000%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/strided_slice]:627
	                    PACK	        67841.232	    0.029	    0.027	  0.000%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape/shape]:628
	                 RESHAPE	        67841.266	    0.015	    0.015	  0.000%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape]:629
	                 CONV_2D	        67841.287	    0.114	    0.116	  0.000%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5s_se_reduce/Conv2D]:630
	                LOGISTIC	        67841.410	    0.030	    0.030	  0.000%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/Sigmoid]:631
	                     MUL	        67841.447	    0.013	    0.013	  0.000%	 74.158%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/mul_1]:632
	                 CONV_2D	        67841.467	    0.495	    0.511	  0.001%	 74.159%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_se_expand/Conv2D]:633
	                LOGISTIC	        67841.985	    0.222	    0.224	  0.000%	 74.159%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/Sigmoid]:634
	                     MUL	        67842.216	   11.767	   11.812	  0.013%	 74.172%	     0.000	        1	[efficientnetv2-l/block5s_se_excite/mul]:635
	                 CONV_2D	        67854.040	   85.349	   85.246	  0.093%	 74.265%	     0.000	        1	[efficientnetv2-l/block5s_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_project_conv/Conv2D]:636
	                     ADD	        67939.297	    2.041	    2.000	  0.002%	 74.267%	     0.000	        1	[efficientnetv2-l/block5s_add/add]:637
	                 CONV_2D	        67941.307	  425.944	  425.082	  0.465%	 74.732%	     0.000	        1	[efficientnetv2-l/block6a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_expand_conv/Conv2D]:638
	                LOGISTIC	        68366.402	  377.358	  377.248	  0.412%	 75.144%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/Sigmoid]:639
	                     MUL	        68743.663	   11.199	   11.223	  0.012%	 75.157%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/mul_1]:640
	       DEPTHWISE_CONV_2D	        68754.897	  109.228	  109.225	  0.119%	 75.276%	     0.000	        1	[efficientnetv2-l/block6a_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_dwconv2/depthwise]:641
	                LOGISTIC	        68864.134	   47.378	   47.021	  0.051%	 75.328%	     0.000	        1	[efficientnetv2-l/block6a_activation/Sigmoid]:642
	                     MUL	        68911.166	    2.864	    2.862	  0.003%	 75.331%	     0.000	        1	[efficientnetv2-l/block6a_activation/mul_1]:643
	                    MEAN	        68914.039	   49.209	   49.169	  0.054%	 75.384%	     0.000	        1	[efficientnetv2-l/block6a_se_squeeze/Mean]:644
	                   SHAPE	        68963.220	    0.009	    0.009	  0.000%	 75.384%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Shape]:645
	           STRIDED_SLICE	        68963.235	    0.021	    0.021	  0.000%	 75.384%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/strided_slice]:646
	                    PACK	        68963.262	    0.030	    0.028	  0.000%	 75.384%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape/shape]:647
	                 RESHAPE	        68963.295	    0.015	    0.015	  0.000%	 75.384%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape]:648
	                 CONV_2D	        68963.317	    0.113	    0.124	  0.000%	 75.385%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block6a_se_reduce/Conv2D]:649
	                LOGISTIC	        68963.449	    0.030	    0.030	  0.000%	 75.385%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/Sigmoid]:650
	                     MUL	        68963.485	    0.013	    0.013	  0.000%	 75.385%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/mul_1]:651
	                 CONV_2D	        68963.504	    0.581	    0.541	  0.001%	 75.385%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_se_expand/Conv2D]:652
	                LOGISTIC	        68964.053	    0.226	    0.225	  0.000%	 75.386%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/Sigmoid]:653
	                     MUL	        68964.284	    2.905	    2.904	  0.003%	 75.389%	     0.000	        1	[efficientnetv2-l/block6a_se_excite/mul]:654
	                 CONV_2D	        68967.197	   34.462	   34.481	  0.038%	 75.426%	     0.000	        1	[efficientnetv2-l/block6a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_project_conv/Conv2D]:655
	                 CONV_2D	        69001.690	  182.599	  182.502	  0.200%	 75.626%	     0.000	        1	[efficientnetv2-l/block6b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_expand_conv/Conv2D]:656
	                LOGISTIC	        69184.205	  155.069	  154.917	  0.169%	 75.795%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/Sigmoid]:657
	                     MUL	        69339.134	    4.869	    4.877	  0.005%	 75.801%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/mul_1]:658
	       DEPTHWISE_CONV_2D	        69344.022	    4.359	    4.394	  0.005%	 75.805%	     0.000	        1	[efficientnetv2-l/block6b_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:659
	                LOGISTIC	        69348.448	  160.522	  160.592	  0.176%	 75.981%	     0.000	        1	[efficientnetv2-l/block6b_activation/Sigmoid]:660
	                     MUL	        69509.053	    4.882	    4.881	  0.005%	 75.986%	     0.000	        1	[efficientnetv2-l/block6b_activation/mul_1]:661
	                    MEAN	        69513.946	   84.468	   84.472	  0.092%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_squeeze/Mean]:662
	                   SHAPE	        69598.428	    0.008	    0.008	  0.000%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Shape]:663
	           STRIDED_SLICE	        69598.443	    0.022	    0.021	  0.000%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/strided_slice]:664
	                    PACK	        69598.470	    0.030	    0.028	  0.000%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape/shape]:665
	                 RESHAPE	        69598.504	    0.016	    0.016	  0.000%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape]:666
	                 CONV_2D	        69598.527	    0.135	    0.135	  0.000%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_reduce/Conv2D]:667
	                LOGISTIC	        69598.668	    0.053	    0.053	  0.000%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/Sigmoid]:668
	                     MUL	        69598.728	    0.013	    0.013	  0.000%	 76.079%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/mul_1]:669
	                 CONV_2D	        69598.748	    0.843	    0.841	  0.001%	 76.080%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_expand/Conv2D]:670
	                LOGISTIC	        69599.596	    0.756	    0.755	  0.001%	 76.081%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/Sigmoid]:671
	                     MUL	        69600.358	    5.075	    5.074	  0.006%	 76.086%	     0.000	        1	[efficientnetv2-l/block6b_se_excite/mul]:672
	                 CONV_2D	        69605.443	   37.401	   37.391	  0.041%	 76.127%	     0.000	        1	[efficientnetv2-l/block6b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_project_conv/Conv2D]:673
	                     ADD	        69642.844	    0.871	    0.871	  0.001%	 76.128%	     0.000	        1	[efficientnetv2-l/block6b_add/add]:674
	                 CONV_2D	        69643.724	  182.057	  182.056	  0.199%	 76.327%	     0.000	        1	[efficientnetv2-l/block6c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_expand_conv/Conv2D]:675
	                LOGISTIC	        69825.794	  161.290	  161.490	  0.177%	 76.504%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/Sigmoid]:676
	                     MUL	        69987.297	    4.883	    4.913	  0.005%	 76.509%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/mul_1]:677
	       DEPTHWISE_CONV_2D	        69992.221	    4.324	    4.475	  0.005%	 76.514%	     0.000	        1	[efficientnetv2-l/block6c_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:678
	                LOGISTIC	        69996.710	  165.601	  165.892	  0.181%	 76.695%	     0.000	        1	[efficientnetv2-l/block6c_activation/Sigmoid]:679
	                     MUL	        70162.614	    4.876	    4.881	  0.005%	 76.701%	     0.000	        1	[efficientnetv2-l/block6c_activation/mul_1]:680
	                    MEAN	        70167.507	   84.421	   84.466	  0.092%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_squeeze/Mean]:681
	                   SHAPE	        70251.984	    0.008	    0.009	  0.000%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Shape]:682
	           STRIDED_SLICE	        70251.999	    0.022	    0.021	  0.000%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/strided_slice]:683
	                    PACK	        70252.027	    0.029	    0.027	  0.000%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape/shape]:684
	                 RESHAPE	        70252.061	    0.015	    0.015	  0.000%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape]:685
	                 CONV_2D	        70252.083	    0.172	    0.157	  0.000%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_reduce/Conv2D]:686
	                LOGISTIC	        70252.247	    0.055	    0.054	  0.000%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/Sigmoid]:687
	                     MUL	        70252.309	    0.012	    0.013	  0.000%	 76.793%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/mul_1]:688
	                 CONV_2D	        70252.328	    0.830	    0.828	  0.001%	 76.794%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_expand/Conv2D]:689
	                LOGISTIC	        70253.163	    0.752	    0.752	  0.001%	 76.795%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/Sigmoid]:690
	                     MUL	        70253.921	    5.085	    5.091	  0.006%	 76.801%	     0.000	        1	[efficientnetv2-l/block6c_se_excite/mul]:691
	                 CONV_2D	        70259.024	   37.903	   37.821	  0.041%	 76.842%	     0.000	        1	[efficientnetv2-l/block6c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_project_conv/Conv2D]:692
	                     ADD	        70296.856	    0.852	    0.854	  0.001%	 76.843%	     0.000	        1	[efficientnetv2-l/block6c_add/add]:693
	                 CONV_2D	        70297.719	  182.439	  182.261	  0.199%	 77.042%	     0.000	        1	[efficientnetv2-l/block6d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_expand_conv/Conv2D]:694
	                LOGISTIC	        70479.990	  161.399	  161.236	  0.176%	 77.218%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/Sigmoid]:695
	                     MUL	        70641.239	    4.818	    4.851	  0.005%	 77.224%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/mul_1]:696
	       DEPTHWISE_CONV_2D	        70646.101	    5.337	    4.846	  0.005%	 77.229%	     0.000	        1	[efficientnetv2-l/block6d_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:697
	                LOGISTIC	        70650.961	  165.475	  165.166	  0.181%	 77.409%	     0.000	        1	[efficientnetv2-l/block6d_activation/Sigmoid]:698
	                     MUL	        70816.139	    4.853	    4.833	  0.005%	 77.415%	     0.000	        1	[efficientnetv2-l/block6d_activation/mul_1]:699
	                    MEAN	        70820.984	   84.598	   84.523	  0.092%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_squeeze/Mean]:700
	                   SHAPE	        70905.519	    0.009	    0.009	  0.000%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Shape]:701
	           STRIDED_SLICE	        70905.534	    0.021	    0.021	  0.000%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/strided_slice]:702
	                    PACK	        70905.561	    0.030	    0.028	  0.000%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape/shape]:703
	                 RESHAPE	        70905.595	    0.016	    0.016	  0.000%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape]:704
	                 CONV_2D	        70905.617	    0.136	    0.138	  0.000%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_reduce/Conv2D]:705
	                LOGISTIC	        70905.763	    0.054	    0.054	  0.000%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/Sigmoid]:706
	                     MUL	        70905.823	    0.013	    0.013	  0.000%	 77.507%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/mul_1]:707
	                 CONV_2D	        70905.842	    0.819	    0.820	  0.001%	 77.508%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_expand/Conv2D]:708
	                LOGISTIC	        70906.669	    0.773	    0.759	  0.001%	 77.509%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/Sigmoid]:709
	                     MUL	        70907.436	    5.049	    5.068	  0.006%	 77.515%	     0.000	        1	[efficientnetv2-l/block6d_se_excite/mul]:710
	                 CONV_2D	        70912.515	   37.666	   37.629	  0.041%	 77.556%	     0.000	        1	[efficientnetv2-l/block6d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_project_conv/Conv2D]:711
	                     ADD	        70950.155	    0.857	    0.829	  0.001%	 77.557%	     0.000	        1	[efficientnetv2-l/block6d_add/add]:712
	                 CONV_2D	        70950.993	  182.466	  182.432	  0.199%	 77.756%	     0.000	        1	[efficientnetv2-l/block6e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_expand_conv/Conv2D]:713
	                LOGISTIC	        71133.438	  161.279	  161.252	  0.176%	 77.933%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/Sigmoid]:714
	                     MUL	        71294.701	    4.823	    4.857	  0.005%	 77.938%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/mul_1]:715
	       DEPTHWISE_CONV_2D	        71299.569	    4.365	    4.337	  0.005%	 77.943%	     0.000	        1	[efficientnetv2-l/block6e_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:716
	                LOGISTIC	        71303.920	  164.963	  164.982	  0.180%	 78.123%	     0.000	        1	[efficientnetv2-l/block6e_activation/Sigmoid]:717
	                     MUL	        71468.914	    4.870	    4.862	  0.005%	 78.128%	     0.000	        1	[efficientnetv2-l/block6e_activation/mul_1]:718
	                    MEAN	        71473.787	   84.388	   84.391	  0.092%	 78.220%	     0.000	        1	[efficientnetv2-l/block6e_se_squeeze/Mean]:719
	                   SHAPE	        71558.189	    0.009	    0.009	  0.000%	 78.220%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Shape]:720
	           STRIDED_SLICE	        71558.204	    0.020	    0.021	  0.000%	 78.221%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/strided_slice]:721
	                    PACK	        71558.231	    0.029	    0.027	  0.000%	 78.221%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape/shape]:722
	                 RESHAPE	        71558.265	    0.016	    0.017	  0.000%	 78.221%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape]:723
	                 CONV_2D	        71558.288	    0.134	    0.137	  0.000%	 78.221%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_reduce/Conv2D]:724
	                LOGISTIC	        71558.432	    0.055	    0.054	  0.000%	 78.221%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/Sigmoid]:725
	                     MUL	        71558.493	    0.013	    0.013	  0.000%	 78.221%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/mul_1]:726
	                 CONV_2D	        71558.512	    0.858	    0.839	  0.001%	 78.222%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_expand/Conv2D]:727
	                LOGISTIC	        71559.359	    0.747	    0.744	  0.001%	 78.223%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/Sigmoid]:728
	                     MUL	        71560.110	    5.075	    5.091	  0.006%	 78.228%	     0.000	        1	[efficientnetv2-l/block6e_se_excite/mul]:729
	                 CONV_2D	        71565.213	   37.640	   37.617	  0.041%	 78.269%	     0.000	        1	[efficientnetv2-l/block6e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_project_conv/Conv2D]:730
	                     ADD	        71602.840	    0.892	    0.873	  0.001%	 78.270%	     0.000	        1	[efficientnetv2-l/block6e_add/add]:731
	                 CONV_2D	        71603.720	  182.869	  182.850	  0.200%	 78.470%	     0.000	        1	[efficientnetv2-l/block6f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_expand_conv/Conv2D]:732
	                LOGISTIC	        71786.583	  160.328	  160.333	  0.175%	 78.645%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/Sigmoid]:733
	                     MUL	        71946.928	    4.834	    4.864	  0.005%	 78.651%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/mul_1]:734
	       DEPTHWISE_CONV_2D	        71951.803	    4.423	    4.412	  0.005%	 78.655%	     0.000	        1	[efficientnetv2-l/block6f_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:735
	                LOGISTIC	        71956.230	  165.079	  165.117	  0.181%	 78.836%	     0.000	        1	[efficientnetv2-l/block6f_activation/Sigmoid]:736
	                     MUL	        72121.359	    4.897	    4.889	  0.005%	 78.841%	     0.000	        1	[efficientnetv2-l/block6f_activation/mul_1]:737
	                    MEAN	        72126.258	   84.435	   84.433	  0.092%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_squeeze/Mean]:738
	                   SHAPE	        72210.702	    0.008	    0.008	  0.000%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Shape]:739
	           STRIDED_SLICE	        72210.717	    0.031	    0.026	  0.000%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/strided_slice]:740
	                    PACK	        72210.750	    0.029	    0.028	  0.000%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape/shape]:741
	                 RESHAPE	        72210.784	    0.015	    0.015	  0.000%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape]:742
	                 CONV_2D	        72210.806	    0.132	    0.136	  0.000%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_reduce/Conv2D]:743
	                LOGISTIC	        72210.950	    0.053	    0.052	  0.000%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/Sigmoid]:744
	                     MUL	        72211.008	    0.013	    0.013	  0.000%	 78.934%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/mul_1]:745
	                 CONV_2D	        72211.027	    0.829	    0.826	  0.001%	 78.935%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_expand/Conv2D]:746
	                LOGISTIC	        72211.860	    0.744	    0.754	  0.001%	 78.936%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/Sigmoid]:747
	                     MUL	        72212.621	    5.059	    5.061	  0.006%	 78.941%	     0.000	        1	[efficientnetv2-l/block6f_se_excite/mul]:748
	                 CONV_2D	        72217.693	   37.694	   37.852	  0.041%	 78.983%	     0.000	        1	[efficientnetv2-l/block6f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_project_conv/Conv2D]:749
	                     ADD	        72255.557	    0.803	    0.816	  0.001%	 78.983%	     0.000	        1	[efficientnetv2-l/block6f_add/add]:750
	                 CONV_2D	        72256.381	  182.662	  182.748	  0.200%	 79.183%	     0.000	        1	[efficientnetv2-l/block6g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_expand_conv/Conv2D]:751
	                LOGISTIC	        72439.141	  161.228	  161.438	  0.176%	 79.360%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/Sigmoid]:752
	                     MUL	        72600.590	    4.903	    4.895	  0.005%	 79.365%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/mul_1]:753
	       DEPTHWISE_CONV_2D	        72605.496	    4.408	    4.847	  0.005%	 79.370%	     0.000	        1	[efficientnetv2-l/block6g_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:754
	                LOGISTIC	        72610.357	  164.746	  164.797	  0.180%	 79.551%	     0.000	        1	[efficientnetv2-l/block6g_activation/Sigmoid]:755
	                     MUL	        72775.166	    4.895	    4.899	  0.005%	 79.556%	     0.000	        1	[efficientnetv2-l/block6g_activation/mul_1]:756
	                    MEAN	        72780.076	   84.418	   84.354	  0.092%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_squeeze/Mean]:757
	                   SHAPE	        72864.442	    0.009	    0.009	  0.000%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Shape]:758
	           STRIDED_SLICE	        72864.457	    0.023	    0.022	  0.000%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/strided_slice]:759
	                    PACK	        72864.486	    0.030	    0.028	  0.000%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape/shape]:760
	                 RESHAPE	        72864.520	    0.017	    0.017	  0.000%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape]:761
	                 CONV_2D	        72864.543	    0.141	    0.139	  0.000%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_reduce/Conv2D]:762
	                LOGISTIC	        72864.689	    0.058	    0.056	  0.000%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/Sigmoid]:763
	                     MUL	        72864.751	    0.016	    0.015	  0.000%	 79.648%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/mul_1]:764
	                 CONV_2D	        72864.772	    0.840	    0.833	  0.001%	 79.649%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_expand/Conv2D]:765
	                LOGISTIC	        72865.614	    0.755	    0.747	  0.001%	 79.650%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/Sigmoid]:766
	                     MUL	        72866.368	    5.154	    5.131	  0.006%	 79.656%	     0.000	        1	[efficientnetv2-l/block6g_se_excite/mul]:767
	                 CONV_2D	        72871.511	   37.875	   37.751	  0.041%	 79.697%	     0.000	        1	[efficientnetv2-l/block6g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_project_conv/Conv2D]:768
	                     ADD	        72909.273	    0.853	    0.853	  0.001%	 79.698%	     0.000	        1	[efficientnetv2-l/block6g_add/add]:769
	                 CONV_2D	        72910.133	  182.945	  182.787	  0.200%	 79.898%	     0.000	        1	[efficientnetv2-l/block6h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_expand_conv/Conv2D]:770
	                LOGISTIC	        73092.932	  162.173	  161.981	  0.177%	 80.075%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/Sigmoid]:771
	                     MUL	        73254.925	    4.879	    4.875	  0.005%	 80.080%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/mul_1]:772
	       DEPTHWISE_CONV_2D	        73259.812	    4.407	    4.457	  0.005%	 80.085%	     0.000	        1	[efficientnetv2-l/block6h_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:773
	                LOGISTIC	        73264.284	  164.818	  164.793	  0.180%	 80.265%	     0.000	        1	[efficientnetv2-l/block6h_activation/Sigmoid]:774
	                     MUL	        73429.088	    4.878	    4.830	  0.005%	 80.271%	     0.000	        1	[efficientnetv2-l/block6h_activation/mul_1]:775
	                    MEAN	        73433.928	   84.439	   84.418	  0.092%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_squeeze/Mean]:776
	                   SHAPE	        73518.357	    0.008	    0.008	  0.000%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Shape]:777
	           STRIDED_SLICE	        73518.371	    0.021	    0.021	  0.000%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/strided_slice]:778
	                    PACK	        73518.398	    0.029	    0.027	  0.000%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape/shape]:779
	                 RESHAPE	        73518.432	    0.016	    0.016	  0.000%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape]:780
	                 CONV_2D	        73518.455	    0.133	    0.135	  0.000%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_reduce/Conv2D]:781
	                LOGISTIC	        73518.596	    0.055	    0.054	  0.000%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/Sigmoid]:782
	                     MUL	        73518.658	    0.013	    0.013	  0.000%	 80.363%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/mul_1]:783
	                 CONV_2D	        73518.678	    0.838	    0.829	  0.001%	 80.364%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_expand/Conv2D]:784
	                LOGISTIC	        73519.513	    0.747	    0.755	  0.001%	 80.365%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/Sigmoid]:785
	                     MUL	        73520.275	    5.065	    5.056	  0.006%	 80.370%	     0.000	        1	[efficientnetv2-l/block6h_se_excite/mul]:786
	                 CONV_2D	        73525.342	   37.509	   37.508	  0.041%	 80.411%	     0.000	        1	[efficientnetv2-l/block6h_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_project_conv/Conv2D]:787
	                     ADD	        73562.861	    0.830	    0.843	  0.001%	 80.412%	     0.000	        1	[efficientnetv2-l/block6h_add/add]:788
	                 CONV_2D	        73563.712	  182.686	  182.768	  0.200%	 80.612%	     0.000	        1	[efficientnetv2-l/block6i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_expand_conv/Conv2D]:789
	                LOGISTIC	        73746.492	  161.216	  161.215	  0.176%	 80.788%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/Sigmoid]:790
	                     MUL	        73907.719	    4.881	    4.859	  0.005%	 80.794%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/mul_1]:791
	       DEPTHWISE_CONV_2D	        73912.588	    4.354	    4.359	  0.005%	 80.798%	     0.000	        1	[efficientnetv2-l/block6i_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:792
	                LOGISTIC	        73916.960	  165.056	  165.027	  0.180%	 80.979%	     0.000	        1	[efficientnetv2-l/block6i_activation/Sigmoid]:793
	                     MUL	        74081.999	    4.874	    4.845	  0.005%	 80.984%	     0.000	        1	[efficientnetv2-l/block6i_activation/mul_1]:794
	                    MEAN	        74086.855	   84.401	   84.407	  0.092%	 81.076%	     0.000	        1	[efficientnetv2-l/block6i_se_squeeze/Mean]:795
	                   SHAPE	        74171.274	    0.009	    0.009	  0.000%	 81.076%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Shape]:796
	           STRIDED_SLICE	        74171.289	    0.021	    0.021	  0.000%	 81.076%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/strided_slice]:797
	                    PACK	        74171.317	    0.029	    0.027	  0.000%	 81.076%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape/shape]:798
	                 RESHAPE	        74171.350	    0.016	    0.017	  0.000%	 81.076%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape]:799
	                 CONV_2D	        74171.373	    0.136	    0.137	  0.000%	 81.077%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_reduce/Conv2D]:800
	                LOGISTIC	        74171.518	    0.053	    0.053	  0.000%	 81.077%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/Sigmoid]:801
	                     MUL	        74171.577	    0.013	    0.013	  0.000%	 81.077%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/mul_1]:802
	                 CONV_2D	        74171.596	    0.822	    0.832	  0.001%	 81.078%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_expand/Conv2D]:803
	                LOGISTIC	        74172.436	    0.743	    0.746	  0.001%	 81.078%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/Sigmoid]:804
	                     MUL	        74173.189	    5.115	    5.114	  0.006%	 81.084%	     0.000	        1	[efficientnetv2-l/block6i_se_excite/mul]:805
	                 CONV_2D	        74178.314	   37.867	   37.897	  0.041%	 81.125%	     0.000	        1	[efficientnetv2-l/block6i_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_project_conv/Conv2D]:806
	                     ADD	        74216.223	    0.802	    0.801	  0.001%	 81.126%	     0.000	        1	[efficientnetv2-l/block6i_add/add]:807
	                 CONV_2D	        74217.031	  182.793	  182.756	  0.200%	 81.326%	     0.000	        1	[efficientnetv2-l/block6j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_expand_conv/Conv2D]:808
	                LOGISTIC	        74399.799	  161.256	  161.257	  0.176%	 81.502%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/Sigmoid]:809
	                     MUL	        74561.068	    4.813	    4.832	  0.005%	 81.508%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/mul_1]:810
	       DEPTHWISE_CONV_2D	        74565.909	    4.396	    4.401	  0.005%	 81.512%	     0.000	        1	[efficientnetv2-l/block6j_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:811
	                LOGISTIC	        74570.323	  165.195	  165.189	  0.181%	 81.693%	     0.000	        1	[efficientnetv2-l/block6j_activation/Sigmoid]:812
	                     MUL	        74735.524	    4.776	    4.899	  0.005%	 81.698%	     0.000	        1	[efficientnetv2-l/block6j_activation/mul_1]:813
	                    MEAN	        74740.436	   84.471	   84.552	  0.092%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_squeeze/Mean]:814
	                   SHAPE	        74824.997	    0.008	    0.009	  0.000%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Shape]:815
	           STRIDED_SLICE	        74825.012	    0.021	    0.022	  0.000%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/strided_slice]:816
	                    PACK	        74825.042	    0.030	    0.028	  0.000%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape/shape]:817
	                 RESHAPE	        74825.076	    0.016	    0.017	  0.000%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape]:818
	                 CONV_2D	        74825.098	    0.136	    0.141	  0.000%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_reduce/Conv2D]:819
	                LOGISTIC	        74825.247	    0.054	    0.056	  0.000%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/Sigmoid]:820
	                     MUL	        74825.310	    0.013	    0.013	  0.000%	 81.791%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/mul_1]:821
	                 CONV_2D	        74825.330	    0.825	    0.833	  0.001%	 81.792%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_expand/Conv2D]:822
	                LOGISTIC	        74826.170	    0.740	    0.744	  0.001%	 81.793%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/Sigmoid]:823
	                     MUL	        74826.920	    5.072	    5.074	  0.006%	 81.798%	     0.000	        1	[efficientnetv2-l/block6j_se_excite/mul]:824
	                 CONV_2D	        74832.008	   37.480	   37.721	  0.041%	 81.840%	     0.000	        1	[efficientnetv2-l/block6j_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_project_conv/Conv2D]:825
	                     ADD	        74869.740	    0.803	    0.830	  0.001%	 81.841%	     0.000	        1	[efficientnetv2-l/block6j_add/add]:826
	                 CONV_2D	        74870.577	  182.338	  182.642	  0.200%	 82.040%	     0.000	        1	[efficientnetv2-l/block6k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_expand_conv/Conv2D]:827
	                LOGISTIC	        75053.231	  161.403	  161.367	  0.176%	 82.217%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/Sigmoid]:828
	                     MUL	        75214.610	    4.805	    4.844	  0.005%	 82.222%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/mul_1]:829
	       DEPTHWISE_CONV_2D	        75219.465	    4.568	    4.463	  0.005%	 82.227%	     0.000	        1	[efficientnetv2-l/block6k_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:830
	                LOGISTIC	        75223.940	  165.516	  165.412	  0.181%	 82.408%	     0.000	        1	[efficientnetv2-l/block6k_activation/Sigmoid]:831
	                     MUL	        75389.364	    4.871	    4.877	  0.005%	 82.413%	     0.000	        1	[efficientnetv2-l/block6k_activation/mul_1]:832
	                    MEAN	        75394.253	   84.550	   84.501	  0.092%	 82.505%	     0.000	        1	[efficientnetv2-l/block6k_se_squeeze/Mean]:833
	                   SHAPE	        75478.766	    0.010	    0.009	  0.000%	 82.505%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Shape]:834
	           STRIDED_SLICE	        75478.781	    0.023	    0.022	  0.000%	 82.505%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/strided_slice]:835
	                    PACK	        75478.811	    0.032	    0.029	  0.000%	 82.505%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape/shape]:836
	                 RESHAPE	        75478.846	    0.017	    0.017	  0.000%	 82.505%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape]:837
	                 CONV_2D	        75478.868	    0.148	    0.142	  0.000%	 82.506%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_reduce/Conv2D]:838
	                LOGISTIC	        75479.019	    0.055	    0.054	  0.000%	 82.506%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/Sigmoid]:839
	                     MUL	        75479.080	    0.013	    0.013	  0.000%	 82.506%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/mul_1]:840
	                 CONV_2D	        75479.099	    0.862	    0.873	  0.001%	 82.507%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_expand/Conv2D]:841
	                LOGISTIC	        75479.981	    0.759	    0.752	  0.001%	 82.507%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/Sigmoid]:842
	                     MUL	        75480.739	    5.090	    5.093	  0.006%	 82.513%	     0.000	        1	[efficientnetv2-l/block6k_se_excite/mul]:843
	                 CONV_2D	        75485.845	   38.300	   38.062	  0.042%	 82.555%	     0.000	        1	[efficientnetv2-l/block6k_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_project_conv/Conv2D]:844
	                     ADD	        75523.918	    0.804	    0.803	  0.001%	 82.556%	     0.000	        1	[efficientnetv2-l/block6k_add/add]:845
	                 CONV_2D	        75524.730	  182.629	  182.464	  0.199%	 82.755%	     0.000	        1	[efficientnetv2-l/block6l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_expand_conv/Conv2D]:846
	                LOGISTIC	        75707.206	  160.893	  160.940	  0.176%	 82.931%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/Sigmoid]:847
	                     MUL	        75868.158	    4.845	    4.837	  0.005%	 82.936%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/mul_1]:848
	       DEPTHWISE_CONV_2D	        75873.006	    4.402	    4.396	  0.005%	 82.941%	     0.000	        1	[efficientnetv2-l/block6l_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:849
	                LOGISTIC	        75877.415	  164.336	  164.334	  0.180%	 83.121%	     0.000	        1	[efficientnetv2-l/block6l_activation/Sigmoid]:850
	                     MUL	        76041.761	    4.812	    4.818	  0.005%	 83.126%	     0.000	        1	[efficientnetv2-l/block6l_activation/mul_1]:851
	                    MEAN	        76046.590	   84.492	   84.422	  0.092%	 83.218%	     0.000	        1	[efficientnetv2-l/block6l_se_squeeze/Mean]:852
	                   SHAPE	        76131.024	    0.009	    0.009	  0.000%	 83.218%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Shape]:853
	           STRIDED_SLICE	        76131.039	    0.021	    0.021	  0.000%	 83.218%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/strided_slice]:854
	                    PACK	        76131.066	    0.030	    0.028	  0.000%	 83.218%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape/shape]:855
	                 RESHAPE	        76131.101	    0.016	    0.017	  0.000%	 83.218%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape]:856
	                 CONV_2D	        76131.124	    0.153	    0.145	  0.000%	 83.218%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_reduce/Conv2D]:857
	                LOGISTIC	        76131.277	    0.055	    0.054	  0.000%	 83.219%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/Sigmoid]:858
	                     MUL	        76131.337	    0.013	    0.013	  0.000%	 83.219%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/mul_1]:859
	                 CONV_2D	        76131.356	    0.819	    0.835	  0.001%	 83.219%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_expand/Conv2D]:860
	                LOGISTIC	        76132.198	    0.743	    0.745	  0.001%	 83.220%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/Sigmoid]:861
	                     MUL	        76132.950	    5.067	    5.062	  0.006%	 83.226%	     0.000	        1	[efficientnetv2-l/block6l_se_excite/mul]:862
	                 CONV_2D	        76138.022	   37.424	   37.429	  0.041%	 83.267%	     0.000	        1	[efficientnetv2-l/block6l_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_project_conv/Conv2D]:863
	                     ADD	        76175.463	    0.798	    0.809	  0.001%	 83.268%	     0.000	        1	[efficientnetv2-l/block6l_add/add]:864
	                 CONV_2D	        76176.281	  182.520	  182.524	  0.200%	 83.467%	     0.000	        1	[efficientnetv2-l/block6m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_expand_conv/Conv2D]:865
	                LOGISTIC	        76358.818	  160.921	  160.891	  0.176%	 83.643%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/Sigmoid]:866
	                     MUL	        76519.720	    4.882	    4.899	  0.005%	 83.648%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/mul_1]:867
	       DEPTHWISE_CONV_2D	        76524.630	    4.346	    4.354	  0.005%	 83.653%	     0.000	        1	[efficientnetv2-l/block6m_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:868
	                LOGISTIC	        76528.997	  164.566	  164.596	  0.180%	 83.833%	     0.000	        1	[efficientnetv2-l/block6m_activation/Sigmoid]:869
	                     MUL	        76693.606	    4.813	    4.894	  0.005%	 83.838%	     0.000	        1	[efficientnetv2-l/block6m_activation/mul_1]:870
	                    MEAN	        76698.511	   84.371	   84.339	  0.092%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_squeeze/Mean]:871
	                   SHAPE	        76782.862	    0.009	    0.009	  0.000%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Shape]:872
	           STRIDED_SLICE	        76782.877	    0.021	    0.021	  0.000%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/strided_slice]:873
	                    PACK	        76782.905	    0.029	    0.027	  0.000%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape/shape]:874
	                 RESHAPE	        76782.939	    0.015	    0.015	  0.000%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape]:875
	                 CONV_2D	        76782.961	    0.136	    0.138	  0.000%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_reduce/Conv2D]:876
	                LOGISTIC	        76783.107	    0.053	    0.054	  0.000%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/Sigmoid]:877
	                     MUL	        76783.167	    0.012	    0.013	  0.000%	 83.931%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/mul_1]:878
	                 CONV_2D	        76783.186	    0.841	    0.848	  0.001%	 83.932%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_expand/Conv2D]:879
	                LOGISTIC	        76784.042	    0.738	    0.740	  0.001%	 83.933%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/Sigmoid]:880
	                     MUL	        76784.788	    5.080	    5.079	  0.006%	 83.938%	     0.000	        1	[efficientnetv2-l/block6m_se_excite/mul]:881
	                 CONV_2D	        76789.878	   37.824	   37.816	  0.041%	 83.980%	     0.000	        1	[efficientnetv2-l/block6m_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_project_conv/Conv2D]:882
	                     ADD	        76827.706	    0.852	    0.827	  0.001%	 83.980%	     0.000	        1	[efficientnetv2-l/block6m_add/add]:883
	                 CONV_2D	        76828.541	  183.085	  183.147	  0.200%	 84.181%	     0.000	        1	[efficientnetv2-l/block6n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_expand_conv/Conv2D]:884
	                LOGISTIC	        77011.700	  161.276	  161.345	  0.176%	 84.357%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/Sigmoid]:885
	                     MUL	        77173.056	    4.879	    4.870	  0.005%	 84.362%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/mul_1]:886
	       DEPTHWISE_CONV_2D	        77177.936	    4.354	    4.570	  0.005%	 84.367%	     0.000	        1	[efficientnetv2-l/block6n_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:887
	                LOGISTIC	        77182.518	  164.752	  165.026	  0.180%	 84.548%	     0.000	        1	[efficientnetv2-l/block6n_activation/Sigmoid]:888
	                     MUL	        77347.556	    4.823	    4.852	  0.005%	 84.553%	     0.000	        1	[efficientnetv2-l/block6n_activation/mul_1]:889
	                    MEAN	        77352.418	   84.444	   84.475	  0.092%	 84.645%	     0.000	        1	[efficientnetv2-l/block6n_se_squeeze/Mean]:890
	                   SHAPE	        77436.905	    0.008	    0.008	  0.000%	 84.645%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Shape]:891
	           STRIDED_SLICE	        77436.918	    0.021	    0.021	  0.000%	 84.645%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/strided_slice]:892
	                    PACK	        77436.947	    0.029	    0.027	  0.000%	 84.646%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape/shape]:893
	                 RESHAPE	        77436.981	    0.016	    0.017	  0.000%	 84.646%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape]:894
	                 CONV_2D	        77437.004	    0.134	    0.137	  0.000%	 84.646%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_reduce/Conv2D]:895
	                LOGISTIC	        77437.148	    0.036	    0.036	  0.000%	 84.646%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/Sigmoid]:896
	                     MUL	        77437.191	    0.013	    0.013	  0.000%	 84.646%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/mul_1]:897
	                 CONV_2D	        77437.211	    0.822	    0.827	  0.001%	 84.647%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_expand/Conv2D]:898
	                LOGISTIC	        77438.045	    0.368	    0.364	  0.000%	 84.647%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/Sigmoid]:899
	                     MUL	        77438.415	    5.067	    5.077	  0.006%	 84.653%	     0.000	        1	[efficientnetv2-l/block6n_se_excite/mul]:900
	                 CONV_2D	        77443.504	   37.980	   37.938	  0.041%	 84.694%	     0.000	        1	[efficientnetv2-l/block6n_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_project_conv/Conv2D]:901
	                     ADD	        77481.455	    0.841	    0.848	  0.001%	 84.695%	     0.000	        1	[efficientnetv2-l/block6n_add/add]:902
	                 CONV_2D	        77482.309	  186.267	  186.332	  0.204%	 84.899%	     0.000	        1	[efficientnetv2-l/block6o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_expand_conv/Conv2D]:903
	                LOGISTIC	        77668.652	  162.640	  162.547	  0.178%	 85.076%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/Sigmoid]:904
	                     MUL	        77831.210	    4.898	    4.918	  0.005%	 85.082%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/mul_1]:905
	       DEPTHWISE_CONV_2D	        77836.140	    4.821	    4.596	  0.005%	 85.087%	     0.000	        1	[efficientnetv2-l/block6o_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:906
	                LOGISTIC	        77840.751	  165.079	  164.921	  0.180%	 85.267%	     0.000	        1	[efficientnetv2-l/block6o_activation/Sigmoid]:907
	                     MUL	        78005.682	    4.898	    4.863	  0.005%	 85.272%	     0.000	        1	[efficientnetv2-l/block6o_activation/mul_1]:908
	                    MEAN	        78010.557	   84.451	   84.409	  0.092%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_squeeze/Mean]:909
	                   SHAPE	        78094.977	    0.008	    0.008	  0.000%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Shape]:910
	           STRIDED_SLICE	        78094.992	    0.020	    0.021	  0.000%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/strided_slice]:911
	                    PACK	        78095.020	    0.030	    0.028	  0.000%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape/shape]:912
	                 RESHAPE	        78095.054	    0.016	    0.016	  0.000%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape]:913
	                 CONV_2D	        78095.076	    0.135	    0.136	  0.000%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_reduce/Conv2D]:914
	                LOGISTIC	        78095.221	    0.036	    0.036	  0.000%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/Sigmoid]:915
	                     MUL	        78095.264	    0.013	    0.013	  0.000%	 85.365%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/mul_1]:916
	                 CONV_2D	        78095.283	    0.855	    0.852	  0.001%	 85.366%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_expand/Conv2D]:917
	                LOGISTIC	        78096.141	    0.364	    0.363	  0.000%	 85.366%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/Sigmoid]:918
	                     MUL	        78096.511	    5.104	    5.090	  0.006%	 85.372%	     0.000	        1	[efficientnetv2-l/block6o_se_excite/mul]:919
	                 CONV_2D	        78101.614	   37.400	   37.416	  0.041%	 85.413%	     0.000	        1	[efficientnetv2-l/block6o_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_project_conv/Conv2D]:920
	                     ADD	        78139.042	    0.833	    0.832	  0.001%	 85.414%	     0.000	        1	[efficientnetv2-l/block6o_add/add]:921
	                 CONV_2D	        78139.883	  185.962	  185.946	  0.203%	 85.617%	     0.000	        1	[efficientnetv2-l/block6p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_expand_conv/Conv2D]:922
	                LOGISTIC	        78325.841	  161.106	  160.999	  0.176%	 85.793%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/Sigmoid]:923
	                     MUL	        78486.852	    4.886	    4.893	  0.005%	 85.798%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/mul_1]:924
	       DEPTHWISE_CONV_2D	        78491.754	    3.753	    3.732	  0.004%	 85.802%	     0.000	        1	[efficientnetv2-l/block6p_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:925
	                LOGISTIC	        78495.497	   82.085	   81.947	  0.090%	 85.892%	     0.000	        1	[efficientnetv2-l/block6p_activation/Sigmoid]:926
	                     MUL	        78577.457	    4.876	    4.835	  0.005%	 85.897%	     0.000	        1	[efficientnetv2-l/block6p_activation/mul_1]:927
	                    MEAN	        78582.302	   84.463	   84.486	  0.092%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_squeeze/Mean]:928
	                   SHAPE	        78666.799	    0.007	    0.007	  0.000%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Shape]:929
	           STRIDED_SLICE	        78666.813	    0.021	    0.021	  0.000%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/strided_slice]:930
	                    PACK	        78666.841	    0.031	    0.028	  0.000%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape/shape]:931
	                 RESHAPE	        78666.875	    0.017	    0.017	  0.000%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape]:932
	                 CONV_2D	        78666.898	    0.132	    0.134	  0.000%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_reduce/Conv2D]:933
	                LOGISTIC	        78667.040	    0.036	    0.036	  0.000%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/Sigmoid]:934
	                     MUL	        78667.083	    0.012	    0.013	  0.000%	 85.990%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/mul_1]:935
	                 CONV_2D	        78667.102	    0.862	    0.862	  0.001%	 85.991%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_expand/Conv2D]:936
	                LOGISTIC	        78667.970	    0.375	    0.373	  0.000%	 85.991%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/Sigmoid]:937
	                     MUL	        78668.350	    5.071	    5.055	  0.006%	 85.997%	     0.000	        1	[efficientnetv2-l/block6p_se_excite/mul]:938
	                 CONV_2D	        78673.416	   36.746	   36.767	  0.040%	 86.037%	     0.000	        1	[efficientnetv2-l/block6p_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_project_conv/Conv2D]:939
	                     ADD	        78710.195	    0.822	    0.811	  0.001%	 86.038%	     0.000	        1	[efficientnetv2-l/block6p_add/add]:940
	                 CONV_2D	        78711.013	  186.063	  186.071	  0.203%	 86.241%	     0.000	        1	[efficientnetv2-l/block6q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_expand_conv/Conv2D]:941
	                LOGISTIC	        78897.096	  162.884	  162.840	  0.178%	 86.419%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/Sigmoid]:942
	                     MUL	        79059.950	    4.912	    4.895	  0.005%	 86.425%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/mul_1]:943
	       DEPTHWISE_CONV_2D	        79064.856	    3.740	    3.748	  0.004%	 86.429%	     0.000	        1	[efficientnetv2-l/block6q_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:944
	                LOGISTIC	        79068.615	   82.025	   81.763	  0.089%	 86.518%	     0.000	        1	[efficientnetv2-l/block6q_activation/Sigmoid]:945
	                     MUL	        79150.391	    4.880	    4.854	  0.005%	 86.523%	     0.000	        1	[efficientnetv2-l/block6q_activation/mul_1]:946
	                    MEAN	        79155.257	   84.434	   84.416	  0.092%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_squeeze/Mean]:947
	                   SHAPE	        79239.686	    0.009	    0.009	  0.000%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Shape]:948
	           STRIDED_SLICE	        79239.700	    0.021	    0.021	  0.000%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/strided_slice]:949
	                    PACK	        79239.727	    0.029	    0.028	  0.000%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape/shape]:950
	                 RESHAPE	        79239.762	    0.016	    0.016	  0.000%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape]:951
	                 CONV_2D	        79239.784	    0.130	    0.133	  0.000%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_reduce/Conv2D]:952
	                LOGISTIC	        79239.925	    0.036	    0.036	  0.000%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/Sigmoid]:953
	                     MUL	        79239.968	    0.012	    0.013	  0.000%	 86.616%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/mul_1]:954
	                 CONV_2D	        79239.986	    0.819	    0.832	  0.001%	 86.617%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_expand/Conv2D]:955
	                LOGISTIC	        79240.826	    0.367	    0.366	  0.000%	 86.617%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/Sigmoid]:956
	                     MUL	        79241.198	    5.083	    5.080	  0.006%	 86.623%	     0.000	        1	[efficientnetv2-l/block6q_se_excite/mul]:957
	                 CONV_2D	        79246.288	   36.807	   36.819	  0.040%	 86.663%	     0.000	        1	[efficientnetv2-l/block6q_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_project_conv/Conv2D]:958
	                     ADD	        79283.119	    0.852	    0.853	  0.001%	 86.664%	     0.000	        1	[efficientnetv2-l/block6q_add/add]:959
	                 CONV_2D	        79283.978	  186.560	  186.618	  0.204%	 86.868%	     0.000	        1	[efficientnetv2-l/block6r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_expand_conv/Conv2D]:960
	                LOGISTIC	        79470.609	  166.719	  166.934	  0.182%	 87.051%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/Sigmoid]:961
	                     MUL	        79637.554	    4.876	    4.877	  0.005%	 87.056%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/mul_1]:962
	       DEPTHWISE_CONV_2D	        79642.442	    3.752	    3.961	  0.004%	 87.060%	     0.000	        1	[efficientnetv2-l/block6r_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:963
	                LOGISTIC	        79646.417	   81.998	   82.297	  0.090%	 87.150%	     0.000	        1	[efficientnetv2-l/block6r_activation/Sigmoid]:964
	                     MUL	        79728.727	    4.886	    4.875	  0.005%	 87.155%	     0.000	        1	[efficientnetv2-l/block6r_activation/mul_1]:965
	                    MEAN	        79733.613	   84.459	   84.511	  0.092%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_squeeze/Mean]:966
	                   SHAPE	        79818.135	    0.008	    0.009	  0.000%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Shape]:967
	           STRIDED_SLICE	        79818.149	    0.021	    0.021	  0.000%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/strided_slice]:968
	                    PACK	        79818.178	    0.029	    0.027	  0.000%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape/shape]:969
	                 RESHAPE	        79818.212	    0.016	    0.015	  0.000%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape]:970
	                 CONV_2D	        79818.234	    0.131	    0.133	  0.000%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_reduce/Conv2D]:971
	                LOGISTIC	        79818.374	    0.036	    0.036	  0.000%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/Sigmoid]:972
	                     MUL	        79818.417	    0.013	    0.013	  0.000%	 87.248%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/mul_1]:973
	                 CONV_2D	        79818.436	    0.825	    0.822	  0.001%	 87.249%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_expand/Conv2D]:974
	                LOGISTIC	        79819.265	    0.405	    0.415	  0.000%	 87.250%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/Sigmoid]:975
	                     MUL	        79819.688	    5.064	    5.070	  0.006%	 87.255%	     0.000	        1	[efficientnetv2-l/block6r_se_excite/mul]:976
	                 CONV_2D	        79824.770	   37.169	   37.221	  0.041%	 87.296%	     0.000	        1	[efficientnetv2-l/block6r_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_project_conv/Conv2D]:977
	                     ADD	        79862.003	    0.798	    0.800	  0.001%	 87.297%	     0.000	        1	[efficientnetv2-l/block6r_add/add]:978
	                 CONV_2D	        79862.811	  186.041	  185.916	  0.203%	 87.500%	     0.000	        1	[efficientnetv2-l/block6s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_expand_conv/Conv2D]:979
	                LOGISTIC	        80048.737	  165.614	  165.350	  0.181%	 87.681%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/Sigmoid]:980
	                     MUL	        80214.098	    4.863	    4.866	  0.005%	 87.686%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/mul_1]:981
	       DEPTHWISE_CONV_2D	        80218.976	    4.092	    3.888	  0.004%	 87.690%	     0.000	        1	[efficientnetv2-l/block6s_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:982
	                LOGISTIC	        80222.875	   82.590	   82.021	  0.090%	 87.780%	     0.000	        1	[efficientnetv2-l/block6s_activation/Sigmoid]:983
	                     MUL	        80304.909	    4.874	    4.880	  0.005%	 87.785%	     0.000	        1	[efficientnetv2-l/block6s_activation/mul_1]:984
	                    MEAN	        80309.798	   84.522	   84.460	  0.092%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_squeeze/Mean]:985
	                   SHAPE	        80394.269	    0.008	    0.008	  0.000%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Shape]:986
	           STRIDED_SLICE	        80394.283	    0.022	    0.021	  0.000%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/strided_slice]:987
	                    PACK	        80394.311	    0.029	    0.027	  0.000%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape/shape]:988
	                 RESHAPE	        80394.345	    0.016	    0.016	  0.000%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape]:989
	                 CONV_2D	        80394.367	    0.154	    0.145	  0.000%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_reduce/Conv2D]:990
	                LOGISTIC	        80394.520	    0.037	    0.037	  0.000%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/Sigmoid]:991
	                     MUL	        80394.564	    0.013	    0.013	  0.000%	 87.878%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/mul_1]:992
	                 CONV_2D	        80394.583	    0.834	    0.832	  0.001%	 87.879%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_expand/Conv2D]:993
	                LOGISTIC	        80395.421	    0.363	    0.370	  0.000%	 87.879%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/Sigmoid]:994
	                     MUL	        80395.798	    5.087	    5.085	  0.006%	 87.885%	     0.000	        1	[efficientnetv2-l/block6s_se_excite/mul]:995
	                 CONV_2D	        80400.894	   36.949	   36.920	  0.040%	 87.925%	     0.000	        1	[efficientnetv2-l/block6s_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_project_conv/Conv2D]:996
	                     ADD	        80437.826	    0.841	    0.822	  0.001%	 87.926%	     0.000	        1	[efficientnetv2-l/block6s_add/add]:997
	                 CONV_2D	        80438.655	  186.339	  186.351	  0.204%	 88.130%	     0.000	        1	[efficientnetv2-l/block6t_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_expand_conv/Conv2D]:998
	                LOGISTIC	        80625.018	  163.991	  164.095	  0.179%	 88.309%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/Sigmoid]:999
	                     MUL	        80789.125	    4.829	    4.843	  0.005%	 88.314%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/mul_1]:1000
	       DEPTHWISE_CONV_2D	        80793.979	    4.365	    4.365	  0.005%	 88.319%	     0.000	        1	[efficientnetv2-l/block6t_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1001
	                LOGISTIC	        80798.357	  144.508	  144.474	  0.158%	 88.477%	     0.000	        1	[efficientnetv2-l/block6t_activation/Sigmoid]:1002
	                     MUL	        80942.844	    4.879	    4.865	  0.005%	 88.482%	     0.000	        1	[efficientnetv2-l/block6t_activation/mul_1]:1003
	                    MEAN	        80947.720	   84.427	   84.453	  0.092%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_squeeze/Mean]:1004
	                   SHAPE	        81032.183	    0.008	    0.008	  0.000%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Shape]:1005
	           STRIDED_SLICE	        81032.197	    0.022	    0.021	  0.000%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/strided_slice]:1006
	                    PACK	        81032.226	    0.030	    0.027	  0.000%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape/shape]:1007
	                 RESHAPE	        81032.258	    0.016	    0.016	  0.000%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape]:1008
	                 CONV_2D	        81032.281	    0.133	    0.135	  0.000%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_reduce/Conv2D]:1009
	                LOGISTIC	        81032.424	    0.037	    0.046	  0.000%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/Sigmoid]:1010
	                     MUL	        81032.477	    0.013	    0.014	  0.000%	 88.575%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/mul_1]:1011
	                 CONV_2D	        81032.497	    0.817	    0.819	  0.001%	 88.576%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_expand/Conv2D]:1012
	                LOGISTIC	        81033.324	    0.370	    0.371	  0.000%	 88.576%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/Sigmoid]:1013
	                     MUL	        81033.701	    5.080	    5.070	  0.006%	 88.582%	     0.000	        1	[efficientnetv2-l/block6t_se_excite/mul]:1014
	                 CONV_2D	        81038.783	   37.760	   37.781	  0.041%	 88.623%	     0.000	        1	[efficientnetv2-l/block6t_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_project_conv/Conv2D]:1015
	                     ADD	        81076.576	    0.838	    0.819	  0.001%	 88.624%	     0.000	        1	[efficientnetv2-l/block6t_add/add]:1016
	                 CONV_2D	        81077.401	  185.441	  185.432	  0.203%	 88.827%	     0.000	        1	[efficientnetv2-l/block6u_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_expand_conv/Conv2D]:1017
	                LOGISTIC	        81262.845	  160.866	  160.831	  0.176%	 89.003%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/Sigmoid]:1018
	                     MUL	        81423.687	    4.877	    4.892	  0.005%	 89.008%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/mul_1]:1019
	       DEPTHWISE_CONV_2D	        81428.590	    3.720	    3.689	  0.004%	 89.012%	     0.000	        1	[efficientnetv2-l/block6u_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1020
	                LOGISTIC	        81432.292	   82.088	   82.082	  0.090%	 89.102%	     0.000	        1	[efficientnetv2-l/block6u_activation/Sigmoid]:1021
	                     MUL	        81514.386	    4.882	    4.886	  0.005%	 89.107%	     0.000	        1	[efficientnetv2-l/block6u_activation/mul_1]:1022
	                    MEAN	        81519.284	   84.396	   84.421	  0.092%	 89.199%	     0.000	        1	[efficientnetv2-l/block6u_se_squeeze/Mean]:1023
	                   SHAPE	        81603.716	    0.008	    0.008	  0.000%	 89.199%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Shape]:1024
	           STRIDED_SLICE	        81603.730	    0.021	    0.021	  0.000%	 89.199%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/strided_slice]:1025
	                    PACK	        81603.758	    0.030	    0.028	  0.000%	 89.199%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape/shape]:1026
	                 RESHAPE	        81603.792	    0.016	    0.016	  0.000%	 89.199%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape]:1027
	                 CONV_2D	        81603.815	    0.130	    0.132	  0.000%	 89.200%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_reduce/Conv2D]:1028
	                LOGISTIC	        81603.955	    0.036	    0.036	  0.000%	 89.200%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/Sigmoid]:1029
	                     MUL	        81603.997	    0.013	    0.013	  0.000%	 89.200%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/mul_1]:1030
	                 CONV_2D	        81604.016	    0.823	    0.839	  0.001%	 89.201%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_expand/Conv2D]:1031
	                LOGISTIC	        81604.863	    0.364	    0.369	  0.000%	 89.201%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/Sigmoid]:1032
	                     MUL	        81605.239	    5.138	    5.120	  0.006%	 89.207%	     0.000	        1	[efficientnetv2-l/block6u_se_excite/mul]:1033
	                 CONV_2D	        81610.371	   37.180	   37.151	  0.041%	 89.247%	     0.000	        1	[efficientnetv2-l/block6u_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_project_conv/Conv2D]:1034
	                     ADD	        81647.533	    0.853	    0.826	  0.001%	 89.248%	     0.000	        1	[efficientnetv2-l/block6u_add/add]:1035
	                 CONV_2D	        81648.365	  186.570	  186.689	  0.204%	 89.452%	     0.000	        1	[efficientnetv2-l/block6v_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_expand_conv/Conv2D]:1036
	                LOGISTIC	        81835.067	  164.789	  164.850	  0.180%	 89.632%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/Sigmoid]:1037
	                     MUL	        81999.929	    4.890	    4.896	  0.005%	 89.638%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/mul_1]:1038
	       DEPTHWISE_CONV_2D	        82004.837	    3.772	    3.958	  0.004%	 89.642%	     0.000	        1	[efficientnetv2-l/block6v_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1039
	                LOGISTIC	        82008.807	   81.803	   82.337	  0.090%	 89.732%	     0.000	        1	[efficientnetv2-l/block6v_activation/Sigmoid]:1040
	                     MUL	        82091.156	    4.815	    4.854	  0.005%	 89.737%	     0.000	        1	[efficientnetv2-l/block6v_activation/mul_1]:1041
	                    MEAN	        82096.020	   84.503	   84.561	  0.092%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_squeeze/Mean]:1042
	                   SHAPE	        82180.594	    0.009	    0.009	  0.000%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Shape]:1043
	           STRIDED_SLICE	        82180.609	    0.022	    0.022	  0.000%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/strided_slice]:1044
	                    PACK	        82180.637	    0.030	    0.028	  0.000%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape/shape]:1045
	                 RESHAPE	        82180.672	    0.015	    0.015	  0.000%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape]:1046
	                 CONV_2D	        82180.694	    0.132	    0.139	  0.000%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_reduce/Conv2D]:1047
	                LOGISTIC	        82180.841	    0.036	    0.037	  0.000%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/Sigmoid]:1048
	                     MUL	        82180.885	    0.013	    0.013	  0.000%	 89.830%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/mul_1]:1049
	                 CONV_2D	        82180.904	    0.840	    0.850	  0.001%	 89.831%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_expand/Conv2D]:1050
	                LOGISTIC	        82181.762	    0.364	    0.377	  0.000%	 89.831%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/Sigmoid]:1051
	                     MUL	        82182.146	    5.066	    5.056	  0.006%	 89.837%	     0.000	        1	[efficientnetv2-l/block6v_se_excite/mul]:1052
	                 CONV_2D	        82187.214	   36.854	   37.011	  0.040%	 89.877%	     0.000	        1	[efficientnetv2-l/block6v_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_project_conv/Conv2D]:1053
	                     ADD	        82224.237	    0.801	    0.800	  0.001%	 89.878%	     0.000	        1	[efficientnetv2-l/block6v_add/add]:1054
	                 CONV_2D	        82225.045	  186.272	  186.095	  0.203%	 90.082%	     0.000	        1	[efficientnetv2-l/block6w_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_expand_conv/Conv2D]:1055
	                LOGISTIC	        82411.152	  165.464	  165.433	  0.181%	 90.263%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/Sigmoid]:1056
	                     MUL	        82576.596	    4.838	    4.838	  0.005%	 90.268%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/mul_1]:1057
	       DEPTHWISE_CONV_2D	        82581.445	    4.815	    4.593	  0.005%	 90.273%	     0.000	        1	[efficientnetv2-l/block6w_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1058
	                LOGISTIC	        82586.052	  146.003	  145.722	  0.159%	 90.432%	     0.000	        1	[efficientnetv2-l/block6w_activation/Sigmoid]:1059
	                     MUL	        82731.786	    4.885	    4.888	  0.005%	 90.438%	     0.000	        1	[efficientnetv2-l/block6w_activation/mul_1]:1060
	                    MEAN	        82736.685	   84.589	   84.496	  0.092%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_squeeze/Mean]:1061
	                   SHAPE	        82821.191	    0.009	    0.009	  0.000%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Shape]:1062
	           STRIDED_SLICE	        82821.205	    0.021	    0.021	  0.000%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/strided_slice]:1063
	                    PACK	        82821.234	    0.029	    0.028	  0.000%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape/shape]:1064
	                 RESHAPE	        82821.268	    0.016	    0.016	  0.000%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape]:1065
	                 CONV_2D	        82821.289	    0.136	    0.138	  0.000%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_reduce/Conv2D]:1066
	                LOGISTIC	        82821.436	    0.036	    0.036	  0.000%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/Sigmoid]:1067
	                     MUL	        82821.478	    0.013	    0.013	  0.000%	 90.530%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/mul_1]:1068
	                 CONV_2D	        82821.497	    0.831	    0.833	  0.001%	 90.531%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_expand/Conv2D]:1069
	                LOGISTIC	        82822.337	    0.364	    0.370	  0.000%	 90.532%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/Sigmoid]:1070
	                     MUL	        82822.713	    5.099	    5.104	  0.006%	 90.537%	     0.000	        1	[efficientnetv2-l/block6w_se_excite/mul]:1071
	                 CONV_2D	        82827.830	   38.022	   37.993	  0.042%	 90.579%	     0.000	        1	[efficientnetv2-l/block6w_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_project_conv/Conv2D]:1072
	                     ADD	        82865.834	    0.821	    0.812	  0.001%	 90.579%	     0.000	        1	[efficientnetv2-l/block6w_add/add]:1073
	                 CONV_2D	        82866.655	  186.085	  186.151	  0.204%	 90.783%	     0.000	        1	[efficientnetv2-l/block6x_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_expand_conv/Conv2D]:1074
	                LOGISTIC	        83052.818	  161.280	  161.255	  0.176%	 90.959%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/Sigmoid]:1075
	                     MUL	        83214.085	    4.816	    4.819	  0.005%	 90.965%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/mul_1]:1076
	       DEPTHWISE_CONV_2D	        83218.914	    3.722	    3.732	  0.004%	 90.969%	     0.000	        1	[efficientnetv2-l/block6x_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1077
	                LOGISTIC	        83222.659	   81.640	   81.716	  0.089%	 91.058%	     0.000	        1	[efficientnetv2-l/block6x_activation/Sigmoid]:1078
	                     MUL	        83304.389	    4.876	    4.878	  0.005%	 91.063%	     0.000	        1	[efficientnetv2-l/block6x_activation/mul_1]:1079
	                    MEAN	        83309.276	   84.465	   84.427	  0.092%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_squeeze/Mean]:1080
	                   SHAPE	        83393.716	    0.008	    0.007	  0.000%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Shape]:1081
	           STRIDED_SLICE	        83393.729	    0.022	    0.022	  0.000%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/strided_slice]:1082
	                    PACK	        83393.757	    0.030	    0.028	  0.000%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape/shape]:1083
	                 RESHAPE	        83393.791	    0.016	    0.016	  0.000%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape]:1084
	                 CONV_2D	        83393.813	    0.132	    0.134	  0.000%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_reduce/Conv2D]:1085
	                LOGISTIC	        83393.955	    0.036	    0.036	  0.000%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/Sigmoid]:1086
	                     MUL	        83393.997	    0.012	    0.012	  0.000%	 91.156%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/mul_1]:1087
	                 CONV_2D	        83394.016	    0.823	    0.824	  0.001%	 91.157%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_expand/Conv2D]:1088
	                LOGISTIC	        83394.847	    0.388	    0.376	  0.000%	 91.157%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/Sigmoid]:1089
	                     MUL	        83395.230	    5.061	    5.069	  0.006%	 91.163%	     0.000	        1	[efficientnetv2-l/block6x_se_excite/mul]:1090
	                 CONV_2D	        83400.311	   37.184	   37.191	  0.041%	 91.203%	     0.000	        1	[efficientnetv2-l/block6x_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_project_conv/Conv2D]:1091
	                     ADD	        83437.512	    0.798	    0.797	  0.001%	 91.204%	     0.000	        1	[efficientnetv2-l/block6x_add/add]:1092
	                 CONV_2D	        83438.318	  186.201	  186.220	  0.204%	 91.408%	     0.000	        1	[efficientnetv2-l/block6y_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_expand_conv/Conv2D]:1093
	                LOGISTIC	        83624.549	  164.374	  164.404	  0.180%	 91.588%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/Sigmoid]:1094
	                     MUL	        83788.966	    4.864	    4.877	  0.005%	 91.593%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/mul_1]:1095
	       DEPTHWISE_CONV_2D	        83793.852	    3.626	    3.648	  0.004%	 91.597%	     0.000	        1	[efficientnetv2-l/block6y_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1096
	                LOGISTIC	        83797.514	   82.070	   81.900	  0.090%	 91.686%	     0.000	        1	[efficientnetv2-l/block6y_activation/Sigmoid]:1097
	                     MUL	        83879.428	    4.840	    4.904	  0.005%	 91.692%	     0.000	        1	[efficientnetv2-l/block6y_activation/mul_1]:1098
	                    MEAN	        83884.342	   84.361	   84.391	  0.092%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_squeeze/Mean]:1099
	                   SHAPE	        83968.745	    0.009	    0.009	  0.000%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Shape]:1100
	           STRIDED_SLICE	        83968.759	    0.021	    0.021	  0.000%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/strided_slice]:1101
	                    PACK	        83968.787	    0.029	    0.028	  0.000%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape/shape]:1102
	                 RESHAPE	        83968.821	    0.017	    0.017	  0.000%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape]:1103
	                 CONV_2D	        83968.844	    0.132	    0.133	  0.000%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_reduce/Conv2D]:1104
	                LOGISTIC	        83968.984	    0.037	    0.037	  0.000%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/Sigmoid]:1105
	                     MUL	        83969.027	    0.013	    0.013	  0.000%	 91.784%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/mul_1]:1106
	                 CONV_2D	        83969.046	    0.823	    0.834	  0.001%	 91.785%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_expand/Conv2D]:1107
	                LOGISTIC	        83969.890	    0.375	    0.374	  0.000%	 91.786%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/Sigmoid]:1108
	                     MUL	        83970.272	    5.132	    5.108	  0.006%	 91.791%	     0.000	        1	[efficientnetv2-l/block6y_se_excite/mul]:1109
	                 CONV_2D	        83975.391	   36.901	   36.907	  0.040%	 91.832%	     0.000	        1	[efficientnetv2-l/block6y_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_project_conv/Conv2D]:1110
	                     ADD	        84012.311	    0.850	    0.825	  0.001%	 91.832%	     0.000	        1	[efficientnetv2-l/block6y_add/add]:1111
	                 CONV_2D	        84013.144	  186.461	  186.449	  0.204%	 92.036%	     0.000	        1	[efficientnetv2-l/block7a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_expand_conv/Conv2D]:1112
	                LOGISTIC	        84199.605	  164.986	  165.111	  0.181%	 92.217%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/Sigmoid]:1113
	                     MUL	        84364.727	    4.878	    4.856	  0.005%	 92.222%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/mul_1]:1114
	       DEPTHWISE_CONV_2D	        84369.594	    3.780	    3.987	  0.004%	 92.226%	     0.000	        1	[efficientnetv2-l/block7a_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_dwconv2/depthwise]:1115
	                LOGISTIC	        84373.593	   82.558	   82.625	  0.090%	 92.317%	     0.000	        1	[efficientnetv2-l/block7a_activation/Sigmoid]:1116
	                     MUL	        84456.231	    4.883	    4.877	  0.005%	 92.322%	     0.000	        1	[efficientnetv2-l/block7a_activation/mul_1]:1117
	                    MEAN	        84461.120	   84.548	   84.585	  0.092%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_squeeze/Mean]:1118
	                   SHAPE	        84545.717	    0.009	    0.009	  0.000%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Shape]:1119
	           STRIDED_SLICE	        84545.732	    0.022	    0.021	  0.000%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/strided_slice]:1120
	                    PACK	        84545.761	    0.029	    0.028	  0.000%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape/shape]:1121
	                 RESHAPE	        84545.795	    0.017	    0.018	  0.000%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape]:1122
	                 CONV_2D	        84545.818	    0.130	    0.137	  0.000%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_reduce/Conv2D]:1123
	                LOGISTIC	        84545.962	    0.036	    0.036	  0.000%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/Sigmoid]:1124
	                     MUL	        84546.005	    0.013	    0.013	  0.000%	 92.415%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/mul_1]:1125
	                 CONV_2D	        84546.025	    0.823	    0.819	  0.001%	 92.416%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_expand/Conv2D]:1126
	                LOGISTIC	        84546.852	    0.375	    0.374	  0.000%	 92.416%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/Sigmoid]:1127
	                     MUL	        84547.231	    5.070	    5.079	  0.006%	 92.422%	     0.000	        1	[efficientnetv2-l/block7a_se_excite/mul]:1128
	                 CONV_2D	        84552.322	   60.602	   60.886	  0.067%	 92.488%	     0.000	        1	[efficientnetv2-l/block7a_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_project_conv/Conv2D]:1129
	                 CONV_2D	        84613.221	  312.289	  312.188	  0.341%	 92.830%	     0.000	        1	[efficientnetv2-l/block7b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_expand_conv/Conv2D]:1130
	                LOGISTIC	        84925.421	  273.773	  273.305	  0.299%	 93.128%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/Sigmoid]:1131
	                     MUL	        85198.739	    8.137	    8.146	  0.009%	 93.137%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/mul_1]:1132
	       DEPTHWISE_CONV_2D	        85206.896	    7.748	    7.700	  0.008%	 93.146%	     0.000	        1	[efficientnetv2-l/block7b_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1133
	                LOGISTIC	        85214.610	  262.210	  262.190	  0.287%	 93.432%	     0.000	        1	[efficientnetv2-l/block7b_activation/Sigmoid]:1134
	                     MUL	        85476.812	    8.058	    8.065	  0.009%	 93.441%	     0.000	        1	[efficientnetv2-l/block7b_activation/mul_1]:1135
	                    MEAN	        85484.889	  140.923	  140.918	  0.154%	 93.595%	     0.000	        1	[efficientnetv2-l/block7b_se_squeeze/Mean]:1136
	                   SHAPE	        85625.819	    0.009	    0.009	  0.000%	 93.595%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Shape]:1137
	           STRIDED_SLICE	        85625.834	    0.021	    0.021	  0.000%	 93.595%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/strided_slice]:1138
	                    PACK	        85625.861	    0.030	    0.028	  0.000%	 93.595%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape/shape]:1139
	                 RESHAPE	        85625.895	    0.017	    0.018	  0.000%	 93.595%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape]:1140
	                 CONV_2D	        85625.920	    0.179	    0.180	  0.000%	 93.595%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7b_se_reduce/Conv2D]:1141
	                LOGISTIC	        85626.109	    0.074	    0.073	  0.000%	 93.596%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/Sigmoid]:1142
	                     MUL	        85626.189	    0.013	    0.013	  0.000%	 93.596%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/mul_1]:1143
	                 CONV_2D	        85626.208	    1.389	    1.371	  0.001%	 93.597%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_se_expand/Conv2D]:1144
	                LOGISTIC	        85627.586	    1.226	    1.240	  0.001%	 93.598%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/Sigmoid]:1145
	                     MUL	        85628.833	    8.473	    8.447	  0.009%	 93.608%	     0.000	        1	[efficientnetv2-l/block7b_se_excite/mul]:1146
	                 CONV_2D	        85637.291	   69.876	   69.862	  0.076%	 93.684%	     0.000	        1	[efficientnetv2-l/block7b_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_project_conv/Conv2D]:1147
	                     ADD	        85707.164	    1.347	    1.359	  0.001%	 93.686%	     0.000	        1	[efficientnetv2-l/block7b_add/add]:1148
	                 CONV_2D	        85708.533	  312.523	  312.606	  0.342%	 94.027%	     0.000	        1	[efficientnetv2-l/block7c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_expand_conv/Conv2D]:1149
	                LOGISTIC	        86021.151	  269.067	  269.080	  0.294%	 94.321%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/Sigmoid]:1150
	                     MUL	        86290.242	    8.086	    8.081	  0.009%	 94.330%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/mul_1]:1151
	       DEPTHWISE_CONV_2D	        86298.333	    7.709	    7.679	  0.008%	 94.339%	     0.000	        1	[efficientnetv2-l/block7c_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1152
	                LOGISTIC	        86306.026	  276.154	  276.111	  0.302%	 94.641%	     0.000	        1	[efficientnetv2-l/block7c_activation/Sigmoid]:1153
	                     MUL	        86582.149	    8.046	    8.082	  0.009%	 94.649%	     0.000	        1	[efficientnetv2-l/block7c_activation/mul_1]:1154
	                    MEAN	        86590.242	  141.140	  141.177	  0.154%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_squeeze/Mean]:1155
	                   SHAPE	        86731.430	    0.008	    0.009	  0.000%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Shape]:1156
	           STRIDED_SLICE	        86731.444	    0.021	    0.022	  0.000%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/strided_slice]:1157
	                    PACK	        86731.474	    0.029	    0.028	  0.000%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape/shape]:1158
	                 RESHAPE	        86731.508	    0.018	    0.019	  0.000%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape]:1159
	                 CONV_2D	        86731.534	    0.178	    0.187	  0.000%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7c_se_reduce/Conv2D]:1160
	                LOGISTIC	        86731.728	    0.075	    0.076	  0.000%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/Sigmoid]:1161
	                     MUL	        86731.811	    0.014	    0.014	  0.000%	 94.804%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/mul_1]:1162
	                 CONV_2D	        86731.832	    1.350	    1.367	  0.001%	 94.806%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_se_expand/Conv2D]:1163
	                LOGISTIC	        86733.208	    1.241	    1.242	  0.001%	 94.807%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/Sigmoid]:1164
	                     MUL	        86734.456	    8.473	    8.434	  0.009%	 94.816%	     0.000	        1	[efficientnetv2-l/block7c_se_excite/mul]:1165
	                 CONV_2D	        86742.903	   71.684	   71.873	  0.079%	 94.895%	     0.000	        1	[efficientnetv2-l/block7c_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_project_conv/Conv2D]:1166
	                     ADD	        86814.787	    1.365	    1.370	  0.001%	 94.896%	     0.000	        1	[efficientnetv2-l/block7c_add/add]:1167
	                 CONV_2D	        86816.168	  312.066	  312.286	  0.341%	 95.238%	     0.000	        1	[efficientnetv2-l/block7d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_expand_conv/Conv2D]:1168
	                LOGISTIC	        87128.467	  271.008	  270.719	  0.296%	 95.534%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/Sigmoid]:1169
	                     MUL	        87399.197	    8.035	    8.079	  0.009%	 95.542%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/mul_1]:1170
	       DEPTHWISE_CONV_2D	        87407.288	    8.341	    7.994	  0.009%	 95.551%	     0.000	        1	[efficientnetv2-l/block7d_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1171
	                LOGISTIC	        87415.293	  275.342	  275.096	  0.301%	 95.852%	     0.000	        1	[efficientnetv2-l/block7d_activation/Sigmoid]:1172
	                     MUL	        87690.402	    8.066	    8.021	  0.009%	 95.861%	     0.000	        1	[efficientnetv2-l/block7d_activation/mul_1]:1173
	                    MEAN	        87698.435	  140.897	  140.875	  0.154%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_squeeze/Mean]:1174
	                   SHAPE	        87839.322	    0.008	    0.009	  0.000%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Shape]:1175
	           STRIDED_SLICE	        87839.337	    0.022	    0.022	  0.000%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/strided_slice]:1176
	                    PACK	        87839.364	    0.029	    0.027	  0.000%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape/shape]:1177
	                 RESHAPE	        87839.398	    0.018	    0.018	  0.000%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape]:1178
	                 CONV_2D	        87839.422	    0.225	    0.204	  0.000%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7d_se_reduce/Conv2D]:1179
	                LOGISTIC	        87839.634	    0.075	    0.074	  0.000%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/Sigmoid]:1180
	                     MUL	        87839.715	    0.014	    0.013	  0.000%	 96.015%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/mul_1]:1181
	                 CONV_2D	        87839.735	    1.355	    1.367	  0.001%	 96.017%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_se_expand/Conv2D]:1182
	                LOGISTIC	        87841.109	    1.231	    1.232	  0.001%	 96.018%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/Sigmoid]:1183
	                     MUL	        87842.347	    8.508	    8.392	  0.009%	 96.027%	     0.000	        1	[efficientnetv2-l/block7d_se_excite/mul]:1184
	                 CONV_2D	        87850.751	   71.274	   71.341	  0.078%	 96.105%	     0.000	        1	[efficientnetv2-l/block7d_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_project_conv/Conv2D]:1185
	                     ADD	        87922.105	    1.404	    1.375	  0.002%	 96.107%	     0.000	        1	[efficientnetv2-l/block7d_add/add]:1186
	                 CONV_2D	        87923.490	  312.578	  312.325	  0.341%	 96.448%	     0.000	        1	[efficientnetv2-l/block7e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_expand_conv/Conv2D]:1187
	                LOGISTIC	        88235.828	  270.193	  270.177	  0.295%	 96.743%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/Sigmoid]:1188
	                     MUL	        88506.016	    7.978	    8.055	  0.009%	 96.752%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/mul_1]:1189
	       DEPTHWISE_CONV_2D	        88514.082	    7.680	    7.707	  0.008%	 96.761%	     0.000	        1	[efficientnetv2-l/block7e_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1190
	                LOGISTIC	        88521.803	  275.141	  275.182	  0.301%	 97.061%	     0.000	        1	[efficientnetv2-l/block7e_activation/Sigmoid]:1191
	                     MUL	        88796.996	    8.130	    8.173	  0.009%	 97.070%	     0.000	        1	[efficientnetv2-l/block7e_activation/mul_1]:1192
	                    MEAN	        88805.181	  141.106	  141.129	  0.154%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_squeeze/Mean]:1193
	                   SHAPE	        88946.322	    0.008	    0.008	  0.000%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Shape]:1194
	           STRIDED_SLICE	        88946.336	    0.032	    0.027	  0.000%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/strided_slice]:1195
	                    PACK	        88946.370	    0.030	    0.028	  0.000%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape/shape]:1196
	                 RESHAPE	        88946.404	    0.017	    0.018	  0.000%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape]:1197
	                 CONV_2D	        88946.428	    0.178	    0.179	  0.000%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7e_se_reduce/Conv2D]:1198
	                LOGISTIC	        88946.615	    0.075	    0.075	  0.000%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/Sigmoid]:1199
	                     MUL	        88946.697	    0.013	    0.013	  0.000%	 97.225%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/mul_1]:1200
	                 CONV_2D	        88946.716	    1.350	    1.351	  0.001%	 97.226%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_se_expand/Conv2D]:1201
	                LOGISTIC	        88948.076	    1.240	    1.252	  0.001%	 97.228%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/Sigmoid]:1202
	                     MUL	        88949.336	    8.307	    8.376	  0.009%	 97.237%	     0.000	        1	[efficientnetv2-l/block7e_se_excite/mul]:1203
	                 CONV_2D	        88957.726	   70.268	   70.407	  0.077%	 97.314%	     0.000	        1	[efficientnetv2-l/block7e_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_project_conv/Conv2D]:1204
	                     ADD	        89028.145	    1.359	    1.357	  0.001%	 97.315%	     0.000	        1	[efficientnetv2-l/block7e_add/add]:1205
	                 CONV_2D	        89029.511	  312.259	  312.662	  0.342%	 97.657%	     0.000	        1	[efficientnetv2-l/block7f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_expand_conv/Conv2D]:1206
	                LOGISTIC	        89342.186	  269.022	  269.056	  0.294%	 97.951%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/Sigmoid]:1207
	                     MUL	        89611.253	    7.996	    8.021	  0.009%	 97.960%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/mul_1]:1208
	       DEPTHWISE_CONV_2D	        89619.285	    7.517	    7.561	  0.008%	 97.968%	     0.000	        1	[efficientnetv2-l/block7f_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1209
	                LOGISTIC	        89626.859	  275.712	  275.342	  0.301%	 98.269%	     0.000	        1	[efficientnetv2-l/block7f_activation/Sigmoid]:1210
	                     MUL	        89902.214	    8.147	    8.121	  0.009%	 98.278%	     0.000	        1	[efficientnetv2-l/block7f_activation/mul_1]:1211
	                    MEAN	        89910.346	  141.048	  140.955	  0.154%	 98.432%	     0.000	        1	[efficientnetv2-l/block7f_se_squeeze/Mean]:1212
	                   SHAPE	        90051.313	    0.008	    0.008	  0.000%	 98.432%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Shape]:1213
	           STRIDED_SLICE	        90051.327	    0.022	    0.021	  0.000%	 98.432%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/strided_slice]:1214
	                    PACK	        90051.356	    0.029	    0.027	  0.000%	 98.432%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape/shape]:1215
	                 RESHAPE	        90051.389	    0.062	    0.040	  0.000%	 98.433%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape]:1216
	                 CONV_2D	        90051.436	    0.179	    0.180	  0.000%	 98.433%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7f_se_reduce/Conv2D]:1217
	                LOGISTIC	        90051.624	    0.075	    0.075	  0.000%	 98.433%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/Sigmoid]:1218
	                     MUL	        90051.705	    0.014	    0.014	  0.000%	 98.433%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/mul_1]:1219
	                 CONV_2D	        90051.725	    1.354	    1.369	  0.001%	 98.434%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_se_expand/Conv2D]:1220
	                LOGISTIC	        90053.102	    1.218	    1.216	  0.001%	 98.436%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/Sigmoid]:1221
	                     MUL	        90054.325	    8.467	    8.492	  0.009%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_excite/mul]:1222
	                 CONV_2D	        90062.830	   71.524	   71.483	  0.078%	 98.523%	     0.000	        1	[efficientnetv2-l/block7f_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_project_conv/Conv2D]:1223
	                     ADD	        90134.324	    1.412	    1.378	  0.002%	 98.525%	     0.000	        1	[efficientnetv2-l/block7f_add/add]:1224
	                 CONV_2D	        90135.712	  312.044	  312.007	  0.341%	 98.866%	     0.000	        1	[efficientnetv2-l/block7g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_expand_conv/Conv2D]:1225
	                LOGISTIC	        90447.730	  269.290	  269.293	  0.294%	 99.160%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/Sigmoid]:1226
	                     MUL	        90717.035	    8.149	    8.066	  0.009%	 99.169%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/mul_1]:1227
	       DEPTHWISE_CONV_2D	        90725.113	    7.741	    7.659	  0.008%	 99.177%	     0.000	        1	[efficientnetv2-l/block7g_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_dwconv2/depthwise]:1228
	                LOGISTIC	        90732.784	  274.650	  274.711	  0.300%	 99.478%	     0.000	        1	[efficientnetv2-l/block7g_activation/Sigmoid]:1229
	                     MUL	        91007.507	    8.121	    8.104	  0.009%	 99.486%	     0.000	        1	[efficientnetv2-l/block7g_activation/mul_1]:1230
	                    MEAN	        91015.622	  141.278	  141.204	  0.154%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_squeeze/Mean]:1231
	                   SHAPE	        91156.837	    0.009	    0.009	  0.000%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Shape]:1232
	           STRIDED_SLICE	        91156.852	    0.022	    0.022	  0.000%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/strided_slice]:1233
	                    PACK	        91156.880	    0.030	    0.028	  0.000%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape/shape]:1234
	                 RESHAPE	        91156.914	    0.019	    0.018	  0.000%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape]:1235
	                 CONV_2D	        91156.939	    0.221	    0.202	  0.000%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7g_se_reduce/Conv2D]:1236
	                LOGISTIC	        91157.148	    0.073	    0.073	  0.000%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/Sigmoid]:1237
	                     MUL	        91157.227	    0.013	    0.013	  0.000%	 99.641%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/mul_1]:1238
	                 CONV_2D	        91157.247	    1.402	    1.387	  0.002%	 99.643%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_se_expand/Conv2D]:1239
	                LOGISTIC	        91158.641	    1.225	    1.228	  0.001%	 99.644%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/Sigmoid]:1240
	                     MUL	        91159.875	    8.253	    8.289	  0.009%	 99.653%	     0.000	        1	[efficientnetv2-l/block7g_se_excite/mul]:1241
	                 CONV_2D	        91168.177	   70.857	   70.946	  0.078%	 99.731%	     0.000	        1	[efficientnetv2-l/block7g_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_project_conv/Conv2D]:1242
	                     ADD	        91239.135	    1.364	    1.343	  0.001%	 99.732%	     0.000	        1	[efficientnetv2-l/block7g_add/add]:1243
	                 CONV_2D	        91240.487	  104.398	  104.500	  0.114%	 99.846%	     0.000	        1	[efficientnetv2-l/top_bn/FusedBatchNormV3;efficientnetv2-l/top_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/top_conv/Conv2D]:1244
	                LOGISTIC	        91345.000	   89.969	   90.067	  0.098%	 99.945%	     0.000	        1	[efficientnetv2-l/top_activation/Sigmoid]:1245
	                     MUL	        91435.077	    2.720	    2.740	  0.003%	 99.948%	     0.000	        1	[efficientnetv2-l/top_activation/mul_1]:1246
	                    MEAN	        91437.827	   46.834	   46.842	  0.051%	 99.999%	     0.000	        1	[efficientnetv2-l/avg_pool/Mean]:1247
	         FULLY_CONNECTED	        91484.679	    0.299	    0.301	  0.000%	 99.999%	     0.000	        1	[efficientnetv2-l/predictions/MatMul;efficientnetv2-l/predictions/BiasAdd]:1248
	                 SOFTMAX	        91484.988	    0.584	    0.582	  0.001%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:1249

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	        19988.864	 1396.423	 1390.891	  1.521%	  1.521%	     0.000	        1	[efficientnetv2-l/block2f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_expand_conv/Conv2D]:45
	                 CONV_2D	        14032.531	 1388.602	 1386.194	  1.515%	  3.036%	     0.000	        1	[efficientnetv2-l/block2d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_expand_conv/Conv2D]:35
	                 CONV_2D	        22969.332	 1387.105	 1382.924	  1.512%	  4.548%	     0.000	        1	[efficientnetv2-l/block2g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_expand_conv/Conv2D]:50
	                 CONV_2D	        11050.970	 1386.927	 1382.853	  1.512%	  6.060%	     0.000	        1	[efficientnetv2-l/block2c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_expand_conv/Conv2D]:30
	                 CONV_2D	        17005.065	 1385.317	 1382.239	  1.511%	  7.571%	     0.000	        1	[efficientnetv2-l/block2e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_expand_conv/Conv2D]:40
	                 CONV_2D	         8202.504	 1385.462	 1380.547	  1.509%	  9.080%	     0.000	        1	[efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_expand_conv/Conv2D]:25
	                LOGISTIC	        24352.269	 1165.021	 1163.143	  1.272%	 10.351%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/Sigmoid]:51
	                LOGISTIC	        18387.316	 1160.281	 1159.081	  1.267%	 11.619%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/Sigmoid]:41
	                LOGISTIC	        12433.835	 1160.436	 1158.084	  1.266%	 12.885%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/Sigmoid]:31
	                LOGISTIC	        21379.768	 1148.828	 1146.699	  1.254%	 14.138%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/Sigmoid]:46

Number of nodes executed: 1250
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	      278	 41899.770	    45.805%	    45.805%	     0.000	      278
	                LOGISTIC	      264	 39097.383	    42.742%	    88.547%	     0.000	      264
	                    MEAN	       62	  7832.442	     8.563%	    97.110%	     0.000	       62
	                     MUL	      265	  1801.723	     1.970%	    99.080%	     0.000	      265
	       DEPTHWISE_CONV_2D	       61	   611.142	     0.668%	    99.748%	     0.000	       61
	                     ADD	       74	   225.527	     0.247%	    99.994%	     0.000	       74
	                    PACK	       61	     1.648	     0.002%	    99.996%	     0.000	       61
	           STRIDED_SLICE	       61	     1.305	     0.001%	    99.997%	     0.000	       61
	                 RESHAPE	       61	     0.987	     0.001%	    99.998%	     0.000	       61
	                 SOFTMAX	        1	     0.581	     0.001%	    99.999%	     0.000	        1
	                   SHAPE	       61	     0.513	     0.001%	   100.000%	     0.000	       61
	         FULLY_CONNECTED	        1	     0.301	     0.000%	   100.000%	     0.000	        1

Timings (microseconds): count=2 first=91598219 curr=91349021 min=91349021 max=91598219 avg=9.14736e+07 std=124599
Memory (bytes): count=0
1250 nodes observed



