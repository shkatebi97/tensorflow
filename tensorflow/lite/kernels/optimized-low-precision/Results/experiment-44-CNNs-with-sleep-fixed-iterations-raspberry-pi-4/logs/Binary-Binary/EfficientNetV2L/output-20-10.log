STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/f32i8/EfficientNetV2L.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/f32i8/EfficientNetV2L.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (230400, 3, ), and Output shape (57600, 32, ), and the ID is 0
	Changing Input Shape
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 1
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 2
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 3
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (32, 48)
	Allocating LowPrecision Activations Tensors with Shape of (57600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (128, 48)
Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (57600, 32, ), and Output shape (57600, 32, ), and the ID is 4
Applying Conv Low-Precision for Kernel shape (128, 288, ), Input shape (57600, 32, ), and Output shape (14400, 128, ), and the ID is 5
	Allocating LowPrecision Activations Tensors with Shape of (14400, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 16)
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (14400, 128, ), and Output shape (14400, 64, ), and the ID is 6
	Allocating LowPrecision Activations Tensors with Shape of (14400, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 7
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 8
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
	Changing Input Shape
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 9
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 10
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 11
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 12
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
13
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 14
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, ), and the ID is 15
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 16
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (14400, 256, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
, and the ID is 17
	Allocating LowPrecision Activations Tensors with Shape of (14400, 80)
Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (14400, 256, ), and Output shape (14400, 64, ), and the ID is 18
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (64, 32)
	Allocating LowPrecision Activations Tensors with Shape of (14400, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
Applying Conv Low-Precision for Kernel shape (256, 576, ), Input shape (14400, 64, ), and Output shape (3600, 256, ), and the ID is 19
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (256, 80)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 80)
Applying Conv Low-Precision for Kernel shape (96, 256, ), Input shape (3600, 256, ), and Output shape (3600, 96, ), and the ID is 20
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 32)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 21
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 22
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 23
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 24
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 25
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 26
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 27
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 28
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 29
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 30
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
Applying Conv Low-Precision for Kernel shape (384, 864, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 31
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 112)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 112)
Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape (3600, 384, ), and Output shape (3600, 96, ), and the ID is 32
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 48)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 48)
Applying Conv Low-Precision for Kernel shape (384, 96, ), Input shape (3600, 96, ), and Output shape (3600, 384, ), and the ID is 33
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 16)
	Allocating LowPrecision Activations Tensors with Shape of (3600, 16)
The input model file size (MB): 122.772
Initialized session in 132.622ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
Applying Conv Low-Precision for Kernel shape (24, 384, ), Input shape (1, 384, ), and Output shape (1, 24, ), and the ID is 34
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (24, 48)
	Allocating LowPrecision Activations Tensors with Shape of (1, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 16)
Applying Conv Low-Precision for Kernel shape (384, 24, ), Input shape (1, 24, ), and Output shape (1, 384, ), and the ID is 35
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 384, ), Input shape (900, 384, ), and Output shape (900, 192, ), and the ID is 36
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 48)
	Allocating LowPrecision Activations Tensors with Shape of (900, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 37
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 38	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)

	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 39
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 40
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 41
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 42
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 43
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 44
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 45
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 46
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 47
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 48
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 49
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 50
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 51
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 52
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 53
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 54
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 55
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 56
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 57
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 58
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 59
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 60
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 61
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 62
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 63
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 64
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 65
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 66
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 67
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 68
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (768, 192, ), Input shape (900, 192, ), and Output shape (900, 768, ), and the ID is 69
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 768, ), Input shape (1, 768, ), and Output shape (1, 48, ), and the ID is 70
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 96)
	Allocating LowPrecision Activations Tensors with Shape of (1, 96)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (768, 16)
Applying Conv Low-Precision for Kernel shape (768, 48, ), Input shape (1, 48, ), and Output shape (1, 768, ), and the ID is 71
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (900, 768, ), and Output shape (900, 192, ), and the ID is 72
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (192, 96)
	Allocating LowPrecision Activations Tensors with Shape of (900, 96)
Applying Conv Low-Precision for Kernel shape (1152, 192, ), Input shape (900, 192, ), and Output shape (900, 1152, ), and the ID is 73
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1152, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (48, 1152, ), Input shape (1, 1152, ), and Output shape (1, 48, ), and the ID is 74	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (48, 144)

	Allocating LowPrecision Activations Tensors with Shape of (1, 144)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1152, 16)
Applying Conv Low-Precision for Kernel shape (1152, 48, ), Input shape (1, 48, ), and Output shape (1, 1152, ), and the ID is 75
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1152, ), Input shape (900, 1152, ), and Output shape (900, 224, ), and the ID is 76
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 144)
	Allocating LowPrecision Activations Tensors with Shape of (900, 144)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 77
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 78
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 79
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 80
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 81
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 82
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
83
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 84
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 85
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 86
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 87
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 88
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 89
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 90	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)

	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 91
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 92
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 93
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 94
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
(1, 1344, ), and the ID is 95
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 96
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 97
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 98
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 99
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 100
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 101
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 102
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 103
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 104
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 105
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 106
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 107
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 108
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 109
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 110
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 111
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 112
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 113
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 114
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
, and the ID is 115
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 116
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 117
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 118
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
119
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 120
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 121
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 122	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)

	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
123
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 124
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 125
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 126	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)

	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
, and the ID is 127
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 128
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 129
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 130
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape 	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
(1, 1344, ), and the ID is 131
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 132
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 133
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 134	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)

Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 135
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 136
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 137
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 138	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)

	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 139
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 140
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 141
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 142
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 143
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 144
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 145
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 146	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)

	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 147
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (224, 1344, ), Input shape (900, 1344, ), and Output shape (900, 224, ), and the ID is 148
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (224, 176)
	Allocating LowPrecision Activations Tensors with Shape of (900, 176)
Applying Conv Low-Precision for Kernel shape (1344, 224, ), Input shape (900, 224, ), and Output shape (900, 1344, ), and the ID is 149
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 32)
	Allocating LowPrecision Activations Tensors with Shape of (900, 32)
Applying Conv Low-Precision for Kernel shape (56, 1344, ), Input shape (1, 1344, ), and Output shape (1, 56, ), and the ID is 150
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (56, 176)
	Allocating LowPrecision Activations Tensors with Shape of (1, 176)
Applying Conv Low-Precision for Kernel shape (1344, 56, ), Input shape (1, 56, ), and Output shape (1, 1344, ), and the ID is 151
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1344, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 1344, ), Input shape (225, 1344, ), and Output shape (225, 384, ), and the ID is 152
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 176)
	Allocating LowPrecision Activations Tensors with Shape of (228, 176)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 153
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 154
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 155
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 156
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 157
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 158
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 159
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 160
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 161
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 162
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 163
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 164
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 165
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 166	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)

	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 167
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 168
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 169
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 170	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)

	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 171
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 172
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 173
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 174
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 175
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 176
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 177
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 178
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 179
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 180
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 181
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 182
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 183
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, )	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
, and the ID is 184
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 185
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 186
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 187
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 188
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 189
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 190
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 191
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 192
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 193
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 194
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 195
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 196
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 197
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 198
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 199
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 200
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 201
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 202
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 203
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 204
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 205
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 206
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 207
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 208
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 209
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 210
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 211
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 212
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 213
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 214
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 215
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 216
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 217
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 218
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 219
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 220
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 221
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 222	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)

	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 223
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 224
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 225
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 226
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 227
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 228
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 229
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 230	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)

	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 231
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 232
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 233
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 234
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 235
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 236
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 237
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 238	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)

	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 239
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 240
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 241
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 242
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 243
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 244
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 245
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 246
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 247
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (384, 2304, ), Input shape (225, 2304, ), and Output shape (225, 384, ), and the ID is 248
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (384, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 48)
Applying Conv Low-Precision for Kernel shape (2304, 384, ), Input shape (225, 384, ), and Output shape (225, 2304, ), and the ID is 249
	Allocating LowPrecision Activations Tensors with Shape of (228, 48)
Applying Conv Low-Precision for Kernel shape (96, 2304, ), Input shape (1, 2304, ), and Output shape (1, 96, ), and the ID is 250
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (96, 288)
	Allocating LowPrecision Activations Tensors with Shape of (1, 288)
Applying Conv Low-Precision for Kernel shape (2304, 96, ), Input shape (1, 96, ), and Output shape (1, 2304, ), and the ID is 251
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (2304, 16)
	Allocating LowPrecision Activations Tensors with Shape of (1, 16)
Applying Conv Low-Precision for Kernel shape (640, 2304, ), Input shape (225, 2304, ), and Output shape (225, 640, ), and the ID is 252
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 288)
	Allocating LowPrecision Activations Tensors with Shape of (228, 288)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 253
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 254
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 255
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 256
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 257
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 258
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 259
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 260
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 261
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 262
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 263
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 264
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 265
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 266	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)

	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 267
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 268
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 269
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 270
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)
	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 271
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 272
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 80)
Applying Conv Low-Precision for Kernel shape (3840, 640, ), Input shape (225, 640, ), and Output shape (225, 3840, ), and the ID is 273
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Conv Low-Precision for Kernel shape (160, 3840, ), Input shape (1, 3840, ), and Output shape (1, 160, ), and the ID is 274	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (160, 480)

	Allocating LowPrecision Activations Tensors with Shape of (1, 480)
Applying Conv Low-Precision for Kernel shape (3840, 160, ), Input shape (1, 160, ), and Output shape (1, 3840, ), and the ID is 275
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (3840, 32)
	Allocating LowPrecision Activations Tensors with Shape of (1, 32)
Applying Conv Low-Precision for Kernel shape (640, 3840, ), Input shape (225, 3840, ), and Output shape (225, 640, ), and the ID is 276
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (640, 480)
	Allocating LowPrecision Activations Tensors with Shape of (228, 480)
Applying Conv Low-Precision for Kernel shape (1280, 640, ), Input shape (225, 640, ), and Output shape (225, 1280, ), and the ID is 277
	Changing Input Shape
	Reserving LowPrecision Weight Tensors
	Reserving LowPrecision Activation Tensors
	Allocating LowPrecision Weight Tensors with Shape of (1280, 80)
	Allocating LowPrecision Activations Tensors with Shape of (228, 80)
Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 7 Number of Temporaries Tensors
	Transformed Filter Shape: (1000, 160)
	Transformed Activation Shape From: (1, 1280) To: (1, 160)
count=2 first=90871399 curr=89318573 min=89318573 max=90871399 avg=9.0095e+07 std=776413

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=89363276 curr=89358399 min=89358399 max=89363276 avg=8.93608e+07 std=2438

Inference timings in us: Init: 132622, First inference: 90871399, Warmup (avg): 9.0095e+07, Inference (avg): 8.93608e+07
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=29.457 overall=272.883
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   26.838	   26.838	100.000%	100.000%	  2916.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   26.838	   26.838	100.000%	100.000%	  2916.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    26.838	   100.000%	   100.000%	  2916.000	        1

Timings (microseconds): count=1 curr=26838
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                     MUL	            0.035	    7.132	    7.145	  0.008%	  0.008%	     0.000	        1	[efficientnetv2-l/rescaling/mul]:0
	                     ADD	            7.191	    7.139	    7.125	  0.008%	  0.016%	     0.000	        1	[efficientnetv2-l/rescaling/add]:1
	                 CONV_2D	           14.326	   35.186	   35.361	  0.040%	  0.056%	     0.000	        1	[efficientnetv2-l/stem_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/stem_conv/Conv2D]:2
	                LOGISTIC	           49.702	  290.841	  291.341	  0.326%	  0.382%	     0.000	        1	[efficientnetv2-l/stem_activation/Sigmoid]:3
	                     MUL	          341.055	   17.814	   17.726	  0.020%	  0.401%	     0.000	        1	[efficientnetv2-l/stem_activation/mul_1]:4
	                 CONV_2D	          358.793	 1095.154	 1094.018	  1.224%	  1.626%	     0.000	        1	[efficientnetv2-l/block1a_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1a_project_conv/Conv2D]:5
	                LOGISTIC	         1452.822	  398.756	  398.715	  0.446%	  2.072%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/Sigmoid]:6
	                     MUL	         1851.550	   17.509	   17.480	  0.020%	  2.092%	     0.000	        1	[efficientnetv2-l/block1a_project_activation/mul_1]:7
	                     ADD	         1869.042	   17.070	   17.159	  0.019%	  2.111%	     0.000	        1	[efficientnetv2-l/block1a_add/add]:8
	                 CONV_2D	         1886.213	 1075.194	 1075.506	  1.204%	  3.315%	     0.000	        1	[efficientnetv2-l/block1b_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1b_project_conv/Conv2D]:9
	                LOGISTIC	         2961.731	  591.694	  591.620	  0.662%	  3.977%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/Sigmoid]:10
	                     MUL	         3553.383	   17.957	   17.747	  0.020%	  3.997%	     0.000	        1	[efficientnetv2-l/block1b_project_activation/mul_1]:11
	                     ADD	         3571.142	   17.166	   17.230	  0.019%	  4.016%	     0.000	        1	[efficientnetv2-l/block1b_add/add]:12
	                 CONV_2D	         3588.387	 1076.797	 1075.306	  1.203%	  5.219%	     0.000	        1	[efficientnetv2-l/block1c_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1c_project_conv/Conv2D]:13
	                LOGISTIC	         4663.704	  584.169	  584.542	  0.654%	  5.874%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/Sigmoid]:14
	                     MUL	         5248.260	   17.498	   17.518	  0.020%	  5.893%	     0.000	        1	[efficientnetv2-l/block1c_project_activation/mul_1]:15
	                     ADD	         5265.789	   17.207	   17.218	  0.019%	  5.913%	     0.000	        1	[efficientnetv2-l/block1c_add/add]:16
	                 CONV_2D	         5283.019	 1077.380	 1075.964	  1.204%	  7.117%	     0.000	        1	[efficientnetv2-l/block1d_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1d_project_conv/Conv2D]:17
	                LOGISTIC	         6358.994	  408.030	  408.238	  0.457%	  7.574%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/Sigmoid]:18
	                     MUL	         6767.245	   17.681	   17.634	  0.020%	  7.593%	     0.000	        1	[efficientnetv2-l/block1d_project_activation/mul_1]:19
	                     ADD	         6784.891	   17.276	   17.279	  0.019%	  7.613%	     0.000	        1	[efficientnetv2-l/block1d_add/add]:20
	                 CONV_2D	         6802.181	  735.272	  736.422	  0.824%	  8.437%	     0.000	        1	[efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2a_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_expand_conv/Conv2D]:21
	                LOGISTIC	         7538.615	  398.495	  398.387	  0.446%	  8.883%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/Sigmoid]:22
	                     MUL	         7937.015	   17.628	   17.628	  0.020%	  8.903%	     0.000	        1	[efficientnetv2-l/block2a_expand_activation/mul_1]:23
	                 CONV_2D	         7954.654	  430.431	  429.727	  0.481%	  9.384%	     0.000	        1	[efficientnetv2-l/block2a_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2a_project_conv/Conv2D]:24
	                 CONV_2D	         8384.394	 1350.649	 1350.862	  1.512%	 10.895%	     0.000	        1	[efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_expand_conv/Conv2D]:25
	                LOGISTIC	         9735.269	  907.782	  907.775	  1.016%	 11.911%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/Sigmoid]:26
	                     MUL	        10643.057	   35.403	   35.322	  0.040%	 11.951%	     0.000	        1	[efficientnetv2-l/block2b_expand_activation/mul_1]:27
	                 CONV_2D	        10678.391	  432.741	  431.526	  0.483%	 12.434%	     0.000	        1	[efficientnetv2-l/block2b_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_project_conv/Conv2D]:28
	                     ADD	        11109.929	    8.703	    8.672	  0.010%	 12.444%	     0.000	        1	[efficientnetv2-l/block2b_add/add]:29
	                 CONV_2D	        11118.613	 1351.977	 1353.198	  1.515%	 13.958%	     0.000	        1	[efficientnetv2-l/block2c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_expand_conv/Conv2D]:30
	                LOGISTIC	        12471.825	  786.592	  786.231	  0.880%	 14.838%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/Sigmoid]:31
	                     MUL	        13258.068	   35.367	   35.278	  0.039%	 14.878%	     0.000	        1	[efficientnetv2-l/block2c_expand_activation/mul_1]:32
	                 CONV_2D	        13293.358	  442.373	  442.373	  0.495%	 15.373%	     0.000	        1	[efficientnetv2-l/block2c_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_project_conv/Conv2D]:33
	                     ADD	        13735.744	    8.701	    8.678	  0.010%	 15.382%	     0.000	        1	[efficientnetv2-l/block2c_add/add]:34
	                 CONV_2D	        13744.433	 1397.994	 1399.060	  1.566%	 16.948%	     0.000	        1	[efficientnetv2-l/block2d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_expand_conv/Conv2D]:35
	                LOGISTIC	        15143.504	  853.081	  852.842	  0.955%	 17.903%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/Sigmoid]:36
	                     MUL	        15996.359	   35.276	   35.271	  0.039%	 17.942%	     0.000	        1	[efficientnetv2-l/block2d_expand_activation/mul_1]:37
	                 CONV_2D	        16031.642	  437.423	  437.352	  0.489%	 18.432%	     0.000	        1	[efficientnetv2-l/block2d_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_project_conv/Conv2D]:38
	                     ADD	        16469.007	    8.493	    8.550	  0.010%	 18.441%	     0.000	        1	[efficientnetv2-l/block2d_add/add]:39
	                 CONV_2D	        16477.570	 1391.899	 1392.980	  1.559%	 20.000%	     0.000	        1	[efficientnetv2-l/block2e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_expand_conv/Conv2D]:40
	                LOGISTIC	        17870.562	  921.627	  921.106	  1.031%	 21.031%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/Sigmoid]:41
	                     MUL	        18791.682	   35.208	   35.224	  0.039%	 21.071%	     0.000	        1	[efficientnetv2-l/block2e_expand_activation/mul_1]:42
	                 CONV_2D	        18826.917	  439.752	  440.454	  0.493%	 21.564%	     0.000	        1	[efficientnetv2-l/block2e_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_project_conv/Conv2D]:43
	                     ADD	        19267.384	    8.645	    8.665	  0.010%	 21.573%	     0.000	        1	[efficientnetv2-l/block2e_add/add]:44
	                 CONV_2D	        19276.060	 1378.251	 1377.885	  1.542%	 23.115%	     0.000	        1	[efficientnetv2-l/block2f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_expand_conv/Conv2D]:45
	                LOGISTIC	        20653.958	  936.024	  936.011	  1.048%	 24.163%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/Sigmoid]:46
	                     MUL	        21589.981	   35.176	   35.403	  0.040%	 24.203%	     0.000	        1	[efficientnetv2-l/block2f_expand_activation/mul_1]:47
	                 CONV_2D	        21625.394	  437.951	  438.800	  0.491%	 24.694%	     0.000	        1	[efficientnetv2-l/block2f_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_project_conv/Conv2D]:48
	                     ADD	        22064.206	    8.631	    8.640	  0.010%	 24.703%	     0.000	        1	[efficientnetv2-l/block2f_add/add]:49
	                 CONV_2D	        22072.857	 1373.181	 1371.979	  1.536%	 26.239%	     0.000	        1	[efficientnetv2-l/block2g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_expand_conv/Conv2D]:50
	                LOGISTIC	        23444.849	  898.779	  899.070	  1.006%	 27.245%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/Sigmoid]:51
	                     MUL	        24343.930	   35.154	   35.231	  0.039%	 27.285%	     0.000	        1	[efficientnetv2-l/block2g_expand_activation/mul_1]:52
	                 CONV_2D	        24379.175	  441.381	  441.475	  0.494%	 27.779%	     0.000	        1	[efficientnetv2-l/block2g_project_bn/FusedBatchNormV3;efficientnetv2-l/block2a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_project_conv/Conv2D]:53
	                     ADD	        24820.661	    8.527	    8.574	  0.010%	 27.788%	     0.000	        1	[efficientnetv2-l/block2g_add/add]:54
	                 CONV_2D	        24829.247	  347.726	  346.656	  0.388%	 28.176%	     0.000	        1	[efficientnetv2-l/block3a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_expand_conv/Conv2D]:55
	                LOGISTIC	        25175.915	  197.198	  197.063	  0.221%	 28.397%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/Sigmoid]:56
	                     MUL	        25372.991	    8.828	    8.835	  0.010%	 28.407%	     0.000	        1	[efficientnetv2-l/block3a_expand_activation/mul_1]:57
	                 CONV_2D	        25381.837	  148.388	  148.427	  0.166%	 28.573%	     0.000	        1	[efficientnetv2-l/block3a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3a_project_conv/Conv2D]:58
	                 CONV_2D	        25530.275	  504.104	  503.997	  0.564%	 29.137%	     0.000	        1	[efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_expand_conv/Conv2D]:59
	                LOGISTIC	        26034.284	  298.024	  298.106	  0.334%	 29.471%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/Sigmoid]:60
	                     MUL	        26332.402	   13.228	   13.252	  0.015%	 29.485%	     0.000	        1	[efficientnetv2-l/block3b_expand_activation/mul_1]:61
	                 CONV_2D	        26345.665	  150.537	  151.388	  0.169%	 29.655%	     0.000	        1	[efficientnetv2-l/block3b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3b_project_conv/Conv2D]:62
	                     ADD	        26497.068	    3.251	    3.285	  0.004%	 29.659%	     0.000	        1	[efficientnetv2-l/block3b_add/add]:63
	                 CONV_2D	        26500.363	  505.279	  505.610	  0.566%	 30.224%	     0.000	        1	[efficientnetv2-l/block3c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_expand_conv/Conv2D]:64
	                LOGISTIC	        27005.986	  305.072	  305.322	  0.342%	 30.566%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/Sigmoid]:65
	                     MUL	        27311.320	   13.244	   13.221	  0.015%	 30.581%	     0.000	        1	[efficientnetv2-l/block3c_expand_activation/mul_1]:66
	                 CONV_2D	        27324.554	  149.609	  149.257	  0.167%	 30.748%	     0.000	        1	[efficientnetv2-l/block3c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3c_project_conv/Conv2D]:67
	                     ADD	        27473.823	    3.379	    3.293	  0.004%	 30.752%	     0.000	        1	[efficientnetv2-l/block3c_add/add]:68
	                 CONV_2D	        27477.127	  508.161	  506.918	  0.567%	 31.319%	     0.000	        1	[efficientnetv2-l/block3d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_expand_conv/Conv2D]:69
	                LOGISTIC	        27984.057	  328.011	  327.928	  0.367%	 31.686%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/Sigmoid]:70
	                     MUL	        28311.998	   13.218	   13.205	  0.015%	 31.701%	     0.000	        1	[efficientnetv2-l/block3d_expand_activation/mul_1]:71
	                 CONV_2D	        28325.214	  149.682	  149.690	  0.168%	 31.868%	     0.000	        1	[efficientnetv2-l/block3d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3d_project_conv/Conv2D]:72
	                     ADD	        28474.916	    3.271	    3.215	  0.004%	 31.872%	     0.000	        1	[efficientnetv2-l/block3d_add/add]:73
	                 CONV_2D	        28478.142	  509.564	  510.548	  0.571%	 32.443%	     0.000	        1	[efficientnetv2-l/block3e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_expand_conv/Conv2D]:74
	                LOGISTIC	        28988.702	  315.920	  315.982	  0.354%	 32.797%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/Sigmoid]:75
	                     MUL	        29304.696	   13.253	   13.252	  0.015%	 32.812%	     0.000	        1	[efficientnetv2-l/block3e_expand_activation/mul_1]:76
	                 CONV_2D	        29317.961	  149.715	  149.760	  0.168%	 32.979%	     0.000	        1	[efficientnetv2-l/block3e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3e_project_conv/Conv2D]:77
	                     ADD	        29467.732	    3.213	    3.232	  0.004%	 32.983%	     0.000	        1	[efficientnetv2-l/block3e_add/add]:78
	                 CONV_2D	        29470.976	  508.934	  507.745	  0.568%	 33.551%	     0.000	        1	[efficientnetv2-l/block3f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_expand_conv/Conv2D]:79
	                LOGISTIC	        29978.732	  315.355	  315.205	  0.353%	 33.904%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/Sigmoid]:80
	                     MUL	        30293.950	   13.218	   13.206	  0.015%	 33.919%	     0.000	        1	[efficientnetv2-l/block3f_expand_activation/mul_1]:81
	                 CONV_2D	        30307.167	  150.549	  150.582	  0.169%	 34.087%	     0.000	        1	[efficientnetv2-l/block3f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3f_project_conv/Conv2D]:82
	                     ADD	        30457.761	    3.262	    3.275	  0.004%	 34.091%	     0.000	        1	[efficientnetv2-l/block3f_add/add]:83
	                 CONV_2D	        30461.046	  504.832	  504.791	  0.565%	 34.656%	     0.000	        1	[efficientnetv2-l/block3g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_expand_conv/Conv2D]:84
	                LOGISTIC	        30965.850	  315.380	  315.546	  0.353%	 35.009%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/Sigmoid]:85
	                     MUL	        31281.408	   13.222	   13.335	  0.015%	 35.024%	     0.000	        1	[efficientnetv2-l/block3g_expand_activation/mul_1]:86
	                 CONV_2D	        31294.754	  152.676	  153.256	  0.172%	 35.196%	     0.000	        1	[efficientnetv2-l/block3g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block3g_project_conv/Conv2D]:87
	                     ADD	        31448.022	    3.116	    3.165	  0.004%	 35.199%	     0.000	        1	[efficientnetv2-l/block3g_add/add]:88
	                 CONV_2D	        31451.198	  511.686	  511.723	  0.573%	 35.772%	     0.000	        1	[efficientnetv2-l/block4a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_expand_conv/Conv2D]:89
	                LOGISTIC	        31962.933	  320.141	  319.909	  0.358%	 36.130%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/Sigmoid]:90
	                     MUL	        32282.855	   13.379	   13.306	  0.015%	 36.145%	     0.000	        1	[efficientnetv2-l/block4a_expand_activation/mul_1]:91
	       DEPTHWISE_CONV_2D	        32296.173	  128.218	  127.837	  0.143%	 36.288%	     0.000	        1	[efficientnetv2-l/block4a_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_dwconv2/depthwise;efficientnetv2-l/block6y_project_bn/FusedBatchNormV3]:92
	                LOGISTIC	        32424.021	  111.119	  111.066	  0.124%	 36.412%	     0.000	        1	[efficientnetv2-l/block4a_activation/Sigmoid]:93
	                     MUL	        32535.100	    3.270	    3.236	  0.004%	 36.416%	     0.000	        1	[efficientnetv2-l/block4a_activation/mul_1]:94
	                    MEAN	        32538.346	   56.207	   56.258	  0.063%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_squeeze/Mean]:95
	                   SHAPE	        32594.615	    0.008	    0.008	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Shape]:96
	           STRIDED_SLICE	        32594.629	    0.021	    0.021	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/strided_slice]:97
	                    PACK	        32594.658	    0.030	    0.028	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape/shape]:98
	                 RESHAPE	        32594.692	    0.014	    0.015	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_reshape/Reshape]:99
	                 CONV_2D	        32594.713	    0.095	    0.102	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/BiasAdd;efficientnetv2-l/block4a_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4a_se_reduce/Conv2D]:100
	                LOGISTIC	        32594.823	    0.031	    0.030	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/Sigmoid]:101
	                     MUL	        32594.861	    0.012	    0.012	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_reduce/mul_1]:102
	                 CONV_2D	        32594.879	    0.177	    0.178	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/BiasAdd;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_se_expand/Conv2D]:103
	                LOGISTIC	        32595.065	    0.068	    0.070	  0.000%	 36.479%	     0.000	        1	[efficientnetv2-l/block4a_se_expand/Sigmoid]:104
	                     MUL	        32595.142	    3.348	    3.325	  0.004%	 36.483%	     0.000	        1	[efficientnetv2-l/block4a_se_excite/mul]:105
	                 CONV_2D	        32598.478	   67.596	   67.624	  0.076%	 36.559%	     0.000	        1	[efficientnetv2-l/block4a_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4a_project_conv/Conv2D]:106
	                 CONV_2D	        32666.115	  253.712	  253.677	  0.284%	 36.843%	     0.000	        1	[efficientnetv2-l/block4b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_expand_conv/Conv2D]:107
	                LOGISTIC	        32919.804	  198.380	  198.353	  0.222%	 37.065%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/Sigmoid]:108
	                     MUL	        33118.171	    6.652	    6.623	  0.007%	 37.072%	     0.000	        1	[efficientnetv2-l/block4b_expand_activation/mul_1]:109
	       DEPTHWISE_CONV_2D	        33124.806	    5.599	    5.596	  0.006%	 37.078%	     0.000	        1	[efficientnetv2-l/block4b_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:110
	                LOGISTIC	        33130.415	  208.179	  208.143	  0.233%	 37.311%	     0.000	        1	[efficientnetv2-l/block4b_activation/Sigmoid]:111
	                     MUL	        33338.570	    6.670	    6.641	  0.007%	 37.319%	     0.000	        1	[efficientnetv2-l/block4b_activation/mul_1]:112
	                    MEAN	        33345.223	  112.176	  112.273	  0.126%	 37.444%	     0.000	        1	[efficientnetv2-l/block4b_se_squeeze/Mean]:113
	                   SHAPE	        33457.507	    0.008	    0.009	  0.000%	 37.444%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Shape]:114
	           STRIDED_SLICE	        33457.522	    0.023	    0.022	  0.000%	 37.444%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/strided_slice]:115
	                    PACK	        33457.551	    0.030	    0.028	  0.000%	 37.445%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape/shape]:116
	                 RESHAPE	        33457.586	    0.014	    0.015	  0.000%	 37.445%	     0.000	        1	[efficientnetv2-l/block4b_se_reshape/Reshape]:117
	                 CONV_2D	        33457.607	    0.105	    0.106	  0.000%	 37.445%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4b_se_reduce/Conv2D]:118
	                LOGISTIC	        33457.721	    0.036	    0.035	  0.000%	 37.445%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/Sigmoid]:119
	                     MUL	        33457.763	    0.012	    0.013	  0.000%	 37.445%	     0.000	        1	[efficientnetv2-l/block4b_se_reduce/mul_1]:120
	                 CONV_2D	        33457.781	    0.310	    0.310	  0.000%	 37.445%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_se_expand/Conv2D]:121
	                LOGISTIC	        33458.099	    0.128	    0.130	  0.000%	 37.445%	     0.000	        1	[efficientnetv2-l/block4b_se_expand/Sigmoid]:122
	                     MUL	        33458.236	    6.528	    6.548	  0.007%	 37.453%	     0.000	        1	[efficientnetv2-l/block4b_se_excite/mul]:123
	                 CONV_2D	        33464.796	   69.419	   69.427	  0.078%	 37.530%	     0.000	        1	[efficientnetv2-l/block4b_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4b_project_conv/Conv2D]:124
	                     ADD	        33534.236	    1.688	    1.651	  0.002%	 37.532%	     0.000	        1	[efficientnetv2-l/block4b_add/add]:125
	                 CONV_2D	        33535.897	  250.761	  251.324	  0.281%	 37.813%	     0.000	        1	[efficientnetv2-l/block4c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_expand_conv/Conv2D]:126
	                LOGISTIC	        33787.232	  198.750	  198.719	  0.222%	 38.036%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/Sigmoid]:127
	                     MUL	        33985.963	    6.664	    6.654	  0.007%	 38.043%	     0.000	        1	[efficientnetv2-l/block4c_expand_activation/mul_1]:128
	       DEPTHWISE_CONV_2D	        33992.627	    4.720	    4.714	  0.005%	 38.049%	     0.000	        1	[efficientnetv2-l/block4c_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:129
	                LOGISTIC	        33997.353	  110.048	  110.121	  0.123%	 38.172%	     0.000	        1	[efficientnetv2-l/block4c_activation/Sigmoid]:130
	                     MUL	        34107.487	    6.688	    6.662	  0.007%	 38.179%	     0.000	        1	[efficientnetv2-l/block4c_activation/mul_1]:131
	                    MEAN	        34114.160	  112.163	  112.159	  0.126%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_squeeze/Mean]:132
	                   SHAPE	        34226.331	    0.008	    0.013	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Shape]:133
	           STRIDED_SLICE	        34226.359	    0.022	    0.025	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/strided_slice]:134
	                    PACK	        34226.390	    0.029	    0.026	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape/shape]:135
	                 RESHAPE	        34226.423	    0.014	    0.014	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_reshape/Reshape]:136
	                 CONV_2D	        34226.444	    0.104	    0.106	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4c_se_reduce/Conv2D]:137
	                LOGISTIC	        34226.558	    0.029	    0.029	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/Sigmoid]:138
	                     MUL	        34226.593	    0.013	    0.013	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_reduce/mul_1]:139
	                 CONV_2D	        34226.612	    0.310	    0.310	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_se_expand/Conv2D]:140
	                LOGISTIC	        34226.929	    0.131	    0.131	  0.000%	 38.305%	     0.000	        1	[efficientnetv2-l/block4c_se_expand/Sigmoid]:141
	                     MUL	        34227.067	    6.403	    6.405	  0.007%	 38.313%	     0.000	        1	[efficientnetv2-l/block4c_se_excite/mul]:142
	                 CONV_2D	        34233.484	   65.408	   65.426	  0.073%	 38.386%	     0.000	        1	[efficientnetv2-l/block4c_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4c_project_conv/Conv2D]:143
	                     ADD	        34298.923	    1.644	    1.652	  0.002%	 38.388%	     0.000	        1	[efficientnetv2-l/block4c_add/add]:144
	                 CONV_2D	        34300.586	  248.705	  248.588	  0.278%	 38.666%	     0.000	        1	[efficientnetv2-l/block4d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_expand_conv/Conv2D]:145
	                LOGISTIC	        34549.186	  206.795	  206.564	  0.231%	 38.897%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/Sigmoid]:146
	                     MUL	        34755.761	    6.607	    6.598	  0.007%	 38.905%	     0.000	        1	[efficientnetv2-l/block4d_expand_activation/mul_1]:147
	       DEPTHWISE_CONV_2D	        34762.370	    5.693	    5.686	  0.006%	 38.911%	     0.000	        1	[efficientnetv2-l/block4d_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:148
	                LOGISTIC	        34768.069	  197.417	  197.333	  0.221%	 39.132%	     0.000	        1	[efficientnetv2-l/block4d_activation/Sigmoid]:149
	                     MUL	        34965.415	    6.622	    6.681	  0.007%	 39.139%	     0.000	        1	[efficientnetv2-l/block4d_activation/mul_1]:150
	                    MEAN	        34972.107	  112.070	  112.144	  0.126%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_squeeze/Mean]:151
	                   SHAPE	        35084.262	    0.008	    0.008	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Shape]:152
	           STRIDED_SLICE	        35084.276	    0.021	    0.021	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/strided_slice]:153
	                    PACK	        35084.304	    0.030	    0.028	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape/shape]:154
	                 RESHAPE	        35084.338	    0.015	    0.015	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_reshape/Reshape]:155
	                 CONV_2D	        35084.360	    0.107	    0.108	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4d_se_reduce/Conv2D]:156
	                LOGISTIC	        35084.476	    0.038	    0.039	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/Sigmoid]:157
	                     MUL	        35084.522	    0.013	    0.013	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_reduce/mul_1]:158
	                 CONV_2D	        35084.541	    0.311	    0.310	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_se_expand/Conv2D]:159
	                LOGISTIC	        35084.859	    0.128	    0.133	  0.000%	 39.265%	     0.000	        1	[efficientnetv2-l/block4d_se_expand/Sigmoid]:160
	                     MUL	        35084.999	    6.429	    6.483	  0.007%	 39.273%	     0.000	        1	[efficientnetv2-l/block4d_se_excite/mul]:161
	                 CONV_2D	        35091.493	   68.656	   68.606	  0.077%	 39.350%	     0.000	        1	[efficientnetv2-l/block4d_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4d_project_conv/Conv2D]:162
	                     ADD	        35160.111	    1.663	    1.665	  0.002%	 39.351%	     0.000	        1	[efficientnetv2-l/block4d_add/add]:163
	                 CONV_2D	        35161.787	  249.068	  249.132	  0.279%	 39.630%	     0.000	        1	[efficientnetv2-l/block4e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_expand_conv/Conv2D]:164
	                LOGISTIC	        35410.931	  212.037	  212.052	  0.237%	 39.868%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/Sigmoid]:165
	                     MUL	        35622.994	    6.616	    6.601	  0.007%	 39.875%	     0.000	        1	[efficientnetv2-l/block4e_expand_activation/mul_1]:166
	       DEPTHWISE_CONV_2D	        35629.607	    4.734	    4.724	  0.005%	 39.880%	     0.000	        1	[efficientnetv2-l/block4e_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:167
	                LOGISTIC	        35634.345	  110.232	  110.240	  0.123%	 40.004%	     0.000	        1	[efficientnetv2-l/block4e_activation/Sigmoid]:168
	                     MUL	        35744.597	    6.598	    6.604	  0.007%	 40.011%	     0.000	        1	[efficientnetv2-l/block4e_activation/mul_1]:169
	                    MEAN	        35751.214	  112.224	  112.261	  0.126%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_squeeze/Mean]:170
	                   SHAPE	        35863.486	    0.008	    0.008	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Shape]:171
	           STRIDED_SLICE	        35863.501	    0.021	    0.021	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/strided_slice]:172
	                    PACK	        35863.529	    0.029	    0.027	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape/shape]:173
	                 RESHAPE	        35863.562	    0.014	    0.015	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_reshape/Reshape]:174
	                 CONV_2D	        35863.582	    0.104	    0.107	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4e_se_reduce/Conv2D]:175
	                LOGISTIC	        35863.697	    0.029	    0.029	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/Sigmoid]:176
	                     MUL	        35863.732	    0.012	    0.013	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_reduce/mul_1]:177
	                 CONV_2D	        35863.751	    0.335	    0.321	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_se_expand/Conv2D]:178
	                LOGISTIC	        35864.079	    0.134	    0.132	  0.000%	 40.137%	     0.000	        1	[efficientnetv2-l/block4e_se_expand/Sigmoid]:179
	                     MUL	        35864.217	    6.402	    6.415	  0.007%	 40.145%	     0.000	        1	[efficientnetv2-l/block4e_se_excite/mul]:180
	                 CONV_2D	        35870.645	   65.665	   65.761	  0.074%	 40.218%	     0.000	        1	[efficientnetv2-l/block4e_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4e_project_conv/Conv2D]:181
	                     ADD	        35936.418	    1.621	    1.623	  0.002%	 40.220%	     0.000	        1	[efficientnetv2-l/block4e_add/add]:182
	                 CONV_2D	        35938.048	  248.716	  249.681	  0.279%	 40.499%	     0.000	        1	[efficientnetv2-l/block4f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_expand_conv/Conv2D]:183
	                LOGISTIC	        36187.742	  201.597	  201.600	  0.226%	 40.725%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/Sigmoid]:184
	                     MUL	        36389.353	    6.635	    6.617	  0.007%	 40.732%	     0.000	        1	[efficientnetv2-l/block4f_expand_activation/mul_1]:185
	       DEPTHWISE_CONV_2D	        36395.982	    4.705	    4.715	  0.005%	 40.738%	     0.000	        1	[efficientnetv2-l/block4f_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:186
	                LOGISTIC	        36400.711	  110.277	  110.207	  0.123%	 40.861%	     0.000	        1	[efficientnetv2-l/block4f_activation/Sigmoid]:187
	                     MUL	        36510.931	    6.646	    6.636	  0.007%	 40.869%	     0.000	        1	[efficientnetv2-l/block4f_activation/mul_1]:188
	                    MEAN	        36517.579	  112.153	  112.180	  0.126%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_squeeze/Mean]:189
	                   SHAPE	        36629.770	    0.008	    0.009	  0.000%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Shape]:190
	           STRIDED_SLICE	        36629.785	    0.021	    0.021	  0.000%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/strided_slice]:191
	                    PACK	        36629.812	    0.029	    0.028	  0.000%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape/shape]:192
	                 RESHAPE	        36629.846	    0.015	    0.015	  0.000%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_reshape/Reshape]:193
	                 CONV_2D	        36629.868	    0.105	    0.107	  0.000%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4f_se_reduce/Conv2D]:194
	                LOGISTIC	        36629.983	    0.029	    0.029	  0.000%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/Sigmoid]:195
	                     MUL	        36630.018	    0.013	    0.013	  0.000%	 40.994%	     0.000	        1	[efficientnetv2-l/block4f_se_reduce/mul_1]:196
	                 CONV_2D	        36630.037	    0.315	    0.315	  0.000%	 40.995%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_se_expand/Conv2D]:197
	                LOGISTIC	        36630.359	    0.133	    0.134	  0.000%	 40.995%	     0.000	        1	[efficientnetv2-l/block4f_se_expand/Sigmoid]:198
	                     MUL	        36630.498	    6.553	    6.511	  0.007%	 41.002%	     0.000	        1	[efficientnetv2-l/block4f_se_excite/mul]:199
	                 CONV_2D	        36637.021	   65.391	   65.431	  0.073%	 41.075%	     0.000	        1	[efficientnetv2-l/block4f_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4f_project_conv/Conv2D]:200
	                     ADD	        36702.465	    1.666	    1.649	  0.002%	 41.077%	     0.000	        1	[efficientnetv2-l/block4f_add/add]:201
	                 CONV_2D	        36704.122	  250.008	  249.792	  0.280%	 41.357%	     0.000	        1	[efficientnetv2-l/block4g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_expand_conv/Conv2D]:202
	                LOGISTIC	        36953.927	  208.486	  208.212	  0.233%	 41.590%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/Sigmoid]:203
	                     MUL	        37162.151	    6.900	    6.747	  0.008%	 41.597%	     0.000	        1	[efficientnetv2-l/block4g_expand_activation/mul_1]:204
	       DEPTHWISE_CONV_2D	        37168.910	    5.216	    4.987	  0.006%	 41.603%	     0.000	        1	[efficientnetv2-l/block4g_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:205
	                LOGISTIC	        37173.911	  110.043	  110.147	  0.123%	 41.726%	     0.000	        1	[efficientnetv2-l/block4g_activation/Sigmoid]:206
	                     MUL	        37284.071	    6.631	    6.641	  0.007%	 41.734%	     0.000	        1	[efficientnetv2-l/block4g_activation/mul_1]:207
	                    MEAN	        37290.723	  112.182	  112.173	  0.126%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_squeeze/Mean]:208
	                   SHAPE	        37402.907	    0.008	    0.009	  0.000%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Shape]:209
	           STRIDED_SLICE	        37402.922	    0.021	    0.021	  0.000%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/strided_slice]:210
	                    PACK	        37402.950	    0.029	    0.028	  0.000%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape/shape]:211
	                 RESHAPE	        37402.984	    0.014	    0.015	  0.000%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_reshape/Reshape]:212
	                 CONV_2D	        37403.005	    0.107	    0.112	  0.000%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4g_se_reduce/Conv2D]:213
	                LOGISTIC	        37403.124	    0.029	    0.029	  0.000%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/Sigmoid]:214
	                     MUL	        37403.161	    0.012	    0.013	  0.000%	 41.859%	     0.000	        1	[efficientnetv2-l/block4g_se_reduce/mul_1]:215
	                 CONV_2D	        37403.179	    0.314	    0.315	  0.000%	 41.860%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_se_expand/Conv2D]:216
	                LOGISTIC	        37403.501	    0.129	    0.130	  0.000%	 41.860%	     0.000	        1	[efficientnetv2-l/block4g_se_expand/Sigmoid]:217
	                     MUL	        37403.637	    6.399	    6.390	  0.007%	 41.867%	     0.000	        1	[efficientnetv2-l/block4g_se_excite/mul]:218
	                 CONV_2D	        37410.039	   65.331	   65.404	  0.073%	 41.940%	     0.000	        1	[efficientnetv2-l/block4g_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4g_project_conv/Conv2D]:219
	                     ADD	        37475.455	    1.624	    1.627	  0.002%	 41.942%	     0.000	        1	[efficientnetv2-l/block4g_add/add]:220
	                 CONV_2D	        37477.093	  248.869	  248.900	  0.279%	 42.221%	     0.000	        1	[efficientnetv2-l/block4h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_expand_conv/Conv2D]:221
	                LOGISTIC	        37726.005	  207.939	  207.888	  0.233%	 42.453%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/Sigmoid]:222
	                     MUL	        37933.906	    6.659	    6.662	  0.007%	 42.461%	     0.000	        1	[efficientnetv2-l/block4h_expand_activation/mul_1]:223
	       DEPTHWISE_CONV_2D	        37940.580	    4.747	    4.747	  0.005%	 42.466%	     0.000	        1	[efficientnetv2-l/block4h_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:224
	                LOGISTIC	        37945.341	  110.227	  110.283	  0.123%	 42.590%	     0.000	        1	[efficientnetv2-l/block4h_activation/Sigmoid]:225
	                     MUL	        38055.636	    6.603	    6.617	  0.007%	 42.597%	     0.000	        1	[efficientnetv2-l/block4h_activation/mul_1]:226
	                    MEAN	        38062.264	  112.159	  112.165	  0.126%	 42.722%	     0.000	        1	[efficientnetv2-l/block4h_se_squeeze/Mean]:227
	                   SHAPE	        38174.442	    0.009	    0.009	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Shape]:228
	           STRIDED_SLICE	        38174.457	    0.021	    0.021	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/strided_slice]:229
	                    PACK	        38174.484	    0.029	    0.028	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape/shape]:230
	                 RESHAPE	        38174.519	    0.014	    0.015	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_reshape/Reshape]:231
	                 CONV_2D	        38174.539	    0.104	    0.108	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4h_se_reduce/Conv2D]:232
	                LOGISTIC	        38174.656	    0.029	    0.029	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/Sigmoid]:233
	                     MUL	        38174.692	    0.012	    0.012	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_reduce/mul_1]:234
	                 CONV_2D	        38174.711	    0.306	    0.308	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_se_expand/Conv2D]:235
	                LOGISTIC	        38175.026	    0.128	    0.131	  0.000%	 42.723%	     0.000	        1	[efficientnetv2-l/block4h_se_expand/Sigmoid]:236
	                     MUL	        38175.163	    6.451	    6.438	  0.007%	 42.730%	     0.000	        1	[efficientnetv2-l/block4h_se_excite/mul]:237
	                 CONV_2D	        38181.613	   65.502	   65.573	  0.073%	 42.804%	     0.000	        1	[efficientnetv2-l/block4h_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4h_project_conv/Conv2D]:238
	                     ADD	        38247.200	    1.683	    1.674	  0.002%	 42.806%	     0.000	        1	[efficientnetv2-l/block4h_add/add]:239
	                 CONV_2D	        38248.884	  250.624	  251.392	  0.281%	 43.087%	     0.000	        1	[efficientnetv2-l/block4i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_expand_conv/Conv2D]:240
	                LOGISTIC	        38500.288	  205.941	  206.274	  0.231%	 43.318%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/Sigmoid]:241
	                     MUL	        38706.572	    6.647	    6.657	  0.007%	 43.325%	     0.000	        1	[efficientnetv2-l/block4i_expand_activation/mul_1]:242
	       DEPTHWISE_CONV_2D	        38713.241	    5.636	    5.627	  0.006%	 43.332%	     0.000	        1	[efficientnetv2-l/block4i_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_dwconv2/depthwise;efficientnetv2-l/block4j_bn/FusedBatchNormV3]:243
	                LOGISTIC	        38718.880	  199.961	  199.897	  0.224%	 43.555%	     0.000	        1	[efficientnetv2-l/block4i_activation/Sigmoid]:244
	                     MUL	        38918.790	    6.649	    6.655	  0.007%	 43.563%	     0.000	        1	[efficientnetv2-l/block4i_activation/mul_1]:245
	                    MEAN	        38925.457	  112.231	  112.237	  0.126%	 43.688%	     0.000	        1	[efficientnetv2-l/block4i_se_squeeze/Mean]:246
	                   SHAPE	        39037.707	    0.009	    0.009	  0.000%	 43.688%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Shape]:247
	           STRIDED_SLICE	        39037.721	    0.022	    0.021	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/strided_slice]:248
	                    PACK	        39037.750	    0.029	    0.027	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape/shape]:249
	                 RESHAPE	        39037.783	    0.014	    0.015	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_reshape/Reshape]:250
	                 CONV_2D	        39037.804	    0.104	    0.107	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4i_se_reduce/Conv2D]:251
	                LOGISTIC	        39037.919	    0.038	    0.038	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/Sigmoid]:252
	                     MUL	        39037.963	    0.013	    0.013	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_reduce/mul_1]:253
	                 CONV_2D	        39037.982	    0.309	    0.309	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_se_expand/Conv2D]:254
	                LOGISTIC	        39038.298	    0.134	    0.134	  0.000%	 43.689%	     0.000	        1	[efficientnetv2-l/block4i_se_expand/Sigmoid]:255
	                     MUL	        39038.438	    6.393	    6.394	  0.007%	 43.696%	     0.000	        1	[efficientnetv2-l/block4i_se_excite/mul]:256
	                 CONV_2D	        39044.845	   67.499	   67.512	  0.076%	 43.772%	     0.000	        1	[efficientnetv2-l/block4i_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4i_project_conv/Conv2D]:257
	                     ADD	        39112.370	    1.634	    1.645	  0.002%	 43.774%	     0.000	        1	[efficientnetv2-l/block4i_add/add]:258
	                 CONV_2D	        39114.024	  248.416	  248.136	  0.278%	 44.052%	     0.000	        1	[efficientnetv2-l/block4j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_expand_conv/Conv2D]:259
	                LOGISTIC	        39362.173	  211.667	  211.417	  0.237%	 44.288%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/Sigmoid]:260
	                     MUL	        39573.601	    6.748	    6.698	  0.007%	 44.296%	     0.000	        1	[efficientnetv2-l/block4j_expand_activation/mul_1]:261
	       DEPTHWISE_CONV_2D	        39580.311	    6.627	    6.143	  0.007%	 44.302%	     0.000	        1	[efficientnetv2-l/block4j_bn/FusedBatchNormV3;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_dwconv2/depthwise]:262
	                LOGISTIC	        39586.469	  208.933	  208.972	  0.234%	 44.536%	     0.000	        1	[efficientnetv2-l/block4j_activation/Sigmoid]:263
	                     MUL	        39795.454	    6.621	    6.622	  0.007%	 44.544%	     0.000	        1	[efficientnetv2-l/block4j_activation/mul_1]:264
	                    MEAN	        39802.087	  112.106	  112.134	  0.126%	 44.669%	     0.000	        1	[efficientnetv2-l/block4j_se_squeeze/Mean]:265
	                   SHAPE	        39914.233	    0.008	    0.009	  0.000%	 44.669%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Shape]:266
	           STRIDED_SLICE	        39914.248	    0.021	    0.021	  0.000%	 44.669%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/strided_slice]:267
	                    PACK	        39914.276	    0.030	    0.028	  0.000%	 44.669%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape/shape]:268
	                 RESHAPE	        39914.310	    0.015	    0.015	  0.000%	 44.669%	     0.000	        1	[efficientnetv2-l/block4j_se_reshape/Reshape]:269
	                 CONV_2D	        39914.331	    0.108	    0.108	  0.000%	 44.669%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block4j_se_reduce/Conv2D]:270
	                LOGISTIC	        39914.447	    0.037	    0.037	  0.000%	 44.670%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/Sigmoid]:271
	                     MUL	        39914.491	    0.013	    0.013	  0.000%	 44.670%	     0.000	        1	[efficientnetv2-l/block4j_se_reduce/mul_1]:272
	                 CONV_2D	        39914.510	    0.308	    0.309	  0.000%	 44.670%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/BiasAdd;efficientnetv2-l/block4b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_se_expand/Conv2D]:273
	                LOGISTIC	        39914.827	    0.126	    0.130	  0.000%	 44.670%	     0.000	        1	[efficientnetv2-l/block4j_se_expand/Sigmoid]:274
	                     MUL	        39914.963	    6.463	    6.503	  0.007%	 44.677%	     0.000	        1	[efficientnetv2-l/block4j_se_excite/mul]:275
	                 CONV_2D	        39921.480	   68.067	   68.053	  0.076%	 44.753%	     0.000	        1	[efficientnetv2-l/block4j_project_bn/FusedBatchNormV3;efficientnetv2-l/block4a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block4j_project_conv/Conv2D]:276
	                     ADD	        39989.546	    1.662	    1.651	  0.002%	 44.755%	     0.000	        1	[efficientnetv2-l/block4j_add/add]:277
	                 CONV_2D	        39991.207	  373.585	  373.680	  0.418%	 45.174%	     0.000	        1	[efficientnetv2-l/block5a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_expand_conv/Conv2D]:278
	                LOGISTIC	        40364.899	  310.316	  310.524	  0.348%	 45.521%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/Sigmoid]:279
	                     MUL	        40675.435	    9.847	    9.829	  0.011%	 45.532%	     0.000	        1	[efficientnetv2-l/block5a_expand_activation/mul_1]:280
	       DEPTHWISE_CONV_2D	        40685.276	    7.117	    7.191	  0.008%	 45.540%	     0.000	        1	[efficientnetv2-l/block5a_bn/FusedBatchNormV3;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_dwconv2/depthwise]:281
	                LOGISTIC	        40692.480	  165.968	  165.992	  0.186%	 45.726%	     0.000	        1	[efficientnetv2-l/block5a_activation/Sigmoid]:282
	                     MUL	        40858.485	    9.887	    9.859	  0.011%	 45.737%	     0.000	        1	[efficientnetv2-l/block5a_activation/mul_1]:283
	                    MEAN	        40868.356	  168.691	  168.789	  0.189%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_squeeze/Mean]:284
	                   SHAPE	        41037.157	    0.009	    0.009	  0.000%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Shape]:285
	           STRIDED_SLICE	        41037.172	    0.023	    0.022	  0.000%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/strided_slice]:286
	                    PACK	        41037.201	    0.029	    0.027	  0.000%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape/shape]:287
	                 RESHAPE	        41037.235	    0.015	    0.015	  0.000%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_reshape/Reshape]:288
	                 CONV_2D	        41037.257	    0.108	    0.110	  0.000%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/BiasAdd;efficientnetv2-l/block4b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5a_se_reduce/Conv2D]:289
	                LOGISTIC	        41037.374	    0.028	    0.028	  0.000%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/Sigmoid]:290
	                     MUL	        41037.408	    0.013	    0.021	  0.000%	 45.926%	     0.000	        1	[efficientnetv2-l/block5a_se_reduce/mul_1]:291
	                 CONV_2D	        41037.435	    0.449	    0.455	  0.001%	 45.927%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/BiasAdd;efficientnetv2-l/block5a_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_se_expand/Conv2D]:292
	                LOGISTIC	        41037.897	    0.200	    0.199	  0.000%	 45.927%	     0.000	        1	[efficientnetv2-l/block5a_se_expand/Sigmoid]:293
	                     MUL	        41038.102	    9.706	    9.679	  0.011%	 45.938%	     0.000	        1	[efficientnetv2-l/block5a_se_excite/mul]:294
	                 CONV_2D	        41047.793	   81.392	   81.367	  0.091%	 46.029%	     0.000	        1	[efficientnetv2-l/block5a_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5a_project_conv/Conv2D]:295
	                 CONV_2D	        41129.173	  424.710	  424.777	  0.475%	 46.504%	     0.000	        1	[efficientnetv2-l/block5b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_expand_conv/Conv2D]:296
	                LOGISTIC	        41553.963	  363.116	  362.663	  0.406%	 46.910%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/Sigmoid]:297
	                     MUL	        41916.637	   11.438	   11.509	  0.013%	 46.923%	     0.000	        1	[efficientnetv2-l/block5b_expand_activation/mul_1]:298
	       DEPTHWISE_CONV_2D	        41928.158	   10.992	   10.410	  0.012%	 46.935%	     0.000	        1	[efficientnetv2-l/block5b_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:299
	                LOGISTIC	        41938.582	  339.147	  338.978	  0.379%	 47.314%	     0.000	        1	[efficientnetv2-l/block5b_activation/Sigmoid]:300
	                     MUL	        42277.573	   11.432	   11.407	  0.013%	 47.327%	     0.000	        1	[efficientnetv2-l/block5b_activation/mul_1]:301
	                    MEAN	        42288.991	  196.671	  196.677	  0.220%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_squeeze/Mean]:302
	                   SHAPE	        42485.680	    0.009	    0.009	  0.000%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Shape]:303
	           STRIDED_SLICE	        42485.696	    0.066	    0.043	  0.000%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/strided_slice]:304
	                    PACK	        42485.746	    0.030	    0.028	  0.000%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape/shape]:305
	                 RESHAPE	        42485.780	    0.015	    0.015	  0.000%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_reshape/Reshape]:306
	                 CONV_2D	        42485.801	    0.115	    0.116	  0.000%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5b_se_reduce/Conv2D]:307
	                LOGISTIC	        42485.925	    0.042	    0.042	  0.000%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/Sigmoid]:308
	                     MUL	        42485.973	    0.012	    0.013	  0.000%	 47.547%	     0.000	        1	[efficientnetv2-l/block5b_se_reduce/mul_1]:309
	                 CONV_2D	        42485.992	    0.514	    0.516	  0.001%	 47.548%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_se_expand/Conv2D]:310
	                LOGISTIC	        42486.516	    0.432	    0.444	  0.000%	 47.548%	     0.000	        1	[efficientnetv2-l/block5b_se_expand/Sigmoid]:311
	                     MUL	        42486.967	   11.270	   11.252	  0.013%	 47.561%	     0.000	        1	[efficientnetv2-l/block5b_se_excite/mul]:312
	                 CONV_2D	        42498.231	   81.870	   81.945	  0.092%	 47.653%	     0.000	        1	[efficientnetv2-l/block5b_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5b_project_conv/Conv2D]:313
	                     ADD	        42580.188	    1.940	    1.942	  0.002%	 47.655%	     0.000	        1	[efficientnetv2-l/block5b_add/add]:314
	                 CONV_2D	        42582.139	  427.595	  427.671	  0.479%	 48.133%	     0.000	        1	[efficientnetv2-l/block5c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_expand_conv/Conv2D]:315
	                LOGISTIC	        43009.821	  363.589	  363.984	  0.407%	 48.541%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/Sigmoid]:316
	                     MUL	        43373.818	   11.455	   11.402	  0.013%	 48.554%	     0.000	        1	[efficientnetv2-l/block5c_expand_activation/mul_1]:317
	       DEPTHWISE_CONV_2D	        43385.232	    9.673	    9.751	  0.011%	 48.564%	     0.000	        1	[efficientnetv2-l/block5c_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:318
	                LOGISTIC	        43394.999	  260.472	  260.459	  0.292%	 48.856%	     0.000	        1	[efficientnetv2-l/block5c_activation/Sigmoid]:319
	                     MUL	        43655.470	   11.401	   11.443	  0.013%	 48.869%	     0.000	        1	[efficientnetv2-l/block5c_activation/mul_1]:320
	                    MEAN	        43666.923	  196.362	  196.333	  0.220%	 49.088%	     0.000	        1	[efficientnetv2-l/block5c_se_squeeze/Mean]:321
	                   SHAPE	        43863.268	    0.008	    0.009	  0.000%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Shape]:322
	           STRIDED_SLICE	        43863.283	    0.021	    0.021	  0.000%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/strided_slice]:323
	                    PACK	        43863.310	    0.028	    0.028	  0.000%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape/shape]:324
	                 RESHAPE	        43863.344	    0.015	    0.015	  0.000%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_reshape/Reshape]:325
	                 CONV_2D	        43863.365	    0.114	    0.117	  0.000%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5c_se_reduce/Conv2D]:326
	                LOGISTIC	        43863.490	    0.040	    0.041	  0.000%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/Sigmoid]:327
	                     MUL	        43863.537	    0.013	    0.013	  0.000%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_reduce/mul_1]:328
	                 CONV_2D	        43863.556	    0.522	    0.520	  0.001%	 49.089%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_se_expand/Conv2D]:329
	                LOGISTIC	        43864.084	    0.460	    0.448	  0.001%	 49.090%	     0.000	        1	[efficientnetv2-l/block5c_se_expand/Sigmoid]:330
	                     MUL	        43864.538	   11.276	   11.312	  0.013%	 49.103%	     0.000	        1	[efficientnetv2-l/block5c_se_excite/mul]:331
	                 CONV_2D	        43875.863	   82.672	   82.674	  0.093%	 49.195%	     0.000	        1	[efficientnetv2-l/block5c_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5c_project_conv/Conv2D]:332
	                     ADD	        43958.551	    1.899	    1.940	  0.002%	 49.197%	     0.000	        1	[efficientnetv2-l/block5c_add/add]:333
	                 CONV_2D	        43960.501	  425.879	  424.969	  0.476%	 49.673%	     0.000	        1	[efficientnetv2-l/block5d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_expand_conv/Conv2D]:334
	                LOGISTIC	        44385.482	  356.234	  356.176	  0.399%	 50.071%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/Sigmoid]:335
	                     MUL	        44741.671	   11.440	   11.430	  0.013%	 50.084%	     0.000	        1	[efficientnetv2-l/block5d_expand_activation/mul_1]:336
	       DEPTHWISE_CONV_2D	        44753.113	    9.812	    9.793	  0.011%	 50.095%	     0.000	        1	[efficientnetv2-l/block5d_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:337
	                LOGISTIC	        44762.919	  233.314	  233.455	  0.261%	 50.357%	     0.000	        1	[efficientnetv2-l/block5d_activation/Sigmoid]:338
	                     MUL	        44996.387	   11.392	   11.458	  0.013%	 50.369%	     0.000	        1	[efficientnetv2-l/block5d_activation/mul_1]:339
	                    MEAN	        45007.857	  196.695	  196.661	  0.220%	 50.589%	     0.000	        1	[efficientnetv2-l/block5d_se_squeeze/Mean]:340
	                   SHAPE	        45204.529	    0.009	    0.009	  0.000%	 50.589%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Shape]:341
	           STRIDED_SLICE	        45204.544	    0.021	    0.021	  0.000%	 50.589%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/strided_slice]:342
	                    PACK	        45204.572	    0.029	    0.027	  0.000%	 50.590%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape/shape]:343
	                 RESHAPE	        45204.606	    0.015	    0.015	  0.000%	 50.590%	     0.000	        1	[efficientnetv2-l/block5d_se_reshape/Reshape]:344
	                 CONV_2D	        45204.628	    0.114	    0.115	  0.000%	 50.590%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5d_se_reduce/Conv2D]:345
	                LOGISTIC	        45204.750	    0.040	    0.040	  0.000%	 50.590%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/Sigmoid]:346
	                     MUL	        45204.796	    0.013	    0.013	  0.000%	 50.590%	     0.000	        1	[efficientnetv2-l/block5d_se_reduce/mul_1]:347
	                 CONV_2D	        45204.815	    0.517	    0.517	  0.001%	 50.590%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_se_expand/Conv2D]:348
	                LOGISTIC	        45205.340	    0.431	    0.432	  0.000%	 50.591%	     0.000	        1	[efficientnetv2-l/block5d_se_expand/Sigmoid]:349
	                     MUL	        45205.779	   11.316	   11.313	  0.013%	 50.603%	     0.000	        1	[efficientnetv2-l/block5d_se_excite/mul]:350
	                 CONV_2D	        45217.105	   82.271	   82.366	  0.092%	 50.696%	     0.000	        1	[efficientnetv2-l/block5d_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5d_project_conv/Conv2D]:351
	                     ADD	        45299.484	    1.840	    1.914	  0.002%	 50.698%	     0.000	        1	[efficientnetv2-l/block5d_add/add]:352
	                 CONV_2D	        45301.408	  422.501	  423.622	  0.474%	 51.172%	     0.000	        1	[efficientnetv2-l/block5e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_expand_conv/Conv2D]:353
	                LOGISTIC	        45725.041	  358.292	  358.341	  0.401%	 51.573%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/Sigmoid]:354
	                     MUL	        46083.394	   11.464	   11.454	  0.013%	 51.586%	     0.000	        1	[efficientnetv2-l/block5e_expand_activation/mul_1]:355
	       DEPTHWISE_CONV_2D	        46094.858	    9.789	    9.773	  0.011%	 51.597%	     0.000	        1	[efficientnetv2-l/block5e_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:356
	                LOGISTIC	        46104.643	  221.225	  221.245	  0.248%	 51.844%	     0.000	        1	[efficientnetv2-l/block5e_activation/Sigmoid]:357
	                     MUL	        46325.901	   11.327	   11.334	  0.013%	 51.857%	     0.000	        1	[efficientnetv2-l/block5e_activation/mul_1]:358
	                    MEAN	        46337.245	  197.017	  196.844	  0.220%	 52.077%	     0.000	        1	[efficientnetv2-l/block5e_se_squeeze/Mean]:359
	                   SHAPE	        46534.101	    0.009	    0.009	  0.000%	 52.077%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Shape]:360
	           STRIDED_SLICE	        46534.116	    0.022	    0.022	  0.000%	 52.077%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/strided_slice]:361
	                    PACK	        46534.145	    0.032	    0.029	  0.000%	 52.077%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape/shape]:362
	                 RESHAPE	        46534.179	    0.016	    0.016	  0.000%	 52.077%	     0.000	        1	[efficientnetv2-l/block5e_se_reshape/Reshape]:363
	                 CONV_2D	        46534.201	    0.117	    0.117	  0.000%	 52.078%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5e_se_reduce/Conv2D]:364
	                LOGISTIC	        46534.326	    0.043	    0.042	  0.000%	 52.078%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/Sigmoid]:365
	                     MUL	        46534.374	    0.014	    0.014	  0.000%	 52.078%	     0.000	        1	[efficientnetv2-l/block5e_se_reduce/mul_1]:366
	                 CONV_2D	        46534.394	    0.537	    0.534	  0.001%	 52.078%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_se_expand/Conv2D]:367
	                LOGISTIC	        46534.937	    0.453	    0.446	  0.000%	 52.079%	     0.000	        1	[efficientnetv2-l/block5e_se_expand/Sigmoid]:368
	                     MUL	        46535.389	   11.300	   11.288	  0.013%	 52.091%	     0.000	        1	[efficientnetv2-l/block5e_se_excite/mul]:369
	                 CONV_2D	        46546.690	   83.345	   82.900	  0.093%	 52.184%	     0.000	        1	[efficientnetv2-l/block5e_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5e_project_conv/Conv2D]:370
	                     ADD	        46629.602	    2.001	    1.962	  0.002%	 52.186%	     0.000	        1	[efficientnetv2-l/block5e_add/add]:371
	                 CONV_2D	        46631.575	  428.862	  428.366	  0.479%	 52.666%	     0.000	        1	[efficientnetv2-l/block5f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_expand_conv/Conv2D]:372
	                LOGISTIC	        47059.954	  361.028	  361.036	  0.404%	 53.070%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/Sigmoid]:373
	                     MUL	        47421.002	   11.406	   11.390	  0.013%	 53.083%	     0.000	        1	[efficientnetv2-l/block5f_expand_activation/mul_1]:374
	       DEPTHWISE_CONV_2D	        47432.403	    9.744	    9.756	  0.011%	 53.093%	     0.000	        1	[efficientnetv2-l/block5f_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:375
	                LOGISTIC	        47442.174	  258.305	  258.310	  0.289%	 53.383%	     0.000	        1	[efficientnetv2-l/block5f_activation/Sigmoid]:376
	                     MUL	        47700.497	   11.392	   11.402	  0.013%	 53.395%	     0.000	        1	[efficientnetv2-l/block5f_activation/mul_1]:377
	                    MEAN	        47711.912	  196.797	  196.924	  0.220%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_squeeze/Mean]:378
	                   SHAPE	        47908.848	    0.009	    0.009	  0.000%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Shape]:379
	           STRIDED_SLICE	        47908.863	    0.022	    0.022	  0.000%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/strided_slice]:380
	                    PACK	        47908.892	    0.029	    0.027	  0.000%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape/shape]:381
	                 RESHAPE	        47908.926	    0.015	    0.015	  0.000%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_reshape/Reshape]:382
	                 CONV_2D	        47908.948	    0.115	    0.119	  0.000%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5f_se_reduce/Conv2D]:383
	                LOGISTIC	        47909.075	    0.040	    0.041	  0.000%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/Sigmoid]:384
	                     MUL	        47909.122	    0.013	    0.013	  0.000%	 53.616%	     0.000	        1	[efficientnetv2-l/block5f_se_reduce/mul_1]:385
	                 CONV_2D	        47909.141	    0.517	    0.524	  0.001%	 53.617%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_se_expand/Conv2D]:386
	                LOGISTIC	        47909.673	    0.227	    0.229	  0.000%	 53.617%	     0.000	        1	[efficientnetv2-l/block5f_se_expand/Sigmoid]:387
	                     MUL	        47909.908	   11.312	   11.267	  0.013%	 53.629%	     0.000	        1	[efficientnetv2-l/block5f_se_excite/mul]:388
	                 CONV_2D	        47921.188	   83.768	   84.428	  0.094%	 53.724%	     0.000	        1	[efficientnetv2-l/block5f_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5f_project_conv/Conv2D]:389
	                     ADD	        48005.651	    1.980	    1.925	  0.002%	 53.726%	     0.000	        1	[efficientnetv2-l/block5f_add/add]:390
	                 CONV_2D	        48007.588	  438.048	  438.459	  0.491%	 54.217%	     0.000	        1	[efficientnetv2-l/block5g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_expand_conv/Conv2D]:391
	                LOGISTIC	        48446.058	  372.535	  372.515	  0.417%	 54.634%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/Sigmoid]:392
	                     MUL	        48818.586	   11.532	   11.424	  0.013%	 54.647%	     0.000	        1	[efficientnetv2-l/block5g_expand_activation/mul_1]:393
	       DEPTHWISE_CONV_2D	        48830.022	    9.779	    9.733	  0.011%	 54.657%	     0.000	        1	[efficientnetv2-l/block5g_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:394
	                LOGISTIC	        48839.768	  354.661	  354.204	  0.396%	 55.054%	     0.000	        1	[efficientnetv2-l/block5g_activation/Sigmoid]:395
	                     MUL	        49193.986	   11.548	   11.508	  0.013%	 55.067%	     0.000	        1	[efficientnetv2-l/block5g_activation/mul_1]:396
	                    MEAN	        49205.505	  196.657	  196.727	  0.220%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_squeeze/Mean]:397
	                   SHAPE	        49402.244	    0.008	    0.009	  0.000%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Shape]:398
	           STRIDED_SLICE	        49402.260	    0.021	    0.021	  0.000%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/strided_slice]:399
	                    PACK	        49402.289	    0.029	    0.027	  0.000%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape/shape]:400
	                 RESHAPE	        49402.322	    0.015	    0.015	  0.000%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_reshape/Reshape]:401
	                 CONV_2D	        49402.344	    0.115	    0.117	  0.000%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5g_se_reduce/Conv2D]:402
	                LOGISTIC	        49402.467	    0.040	    0.041	  0.000%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/Sigmoid]:403
	                     MUL	        49402.514	    0.013	    0.013	  0.000%	 55.287%	     0.000	        1	[efficientnetv2-l/block5g_se_reduce/mul_1]:404
	                 CONV_2D	        49402.533	    0.524	    0.520	  0.001%	 55.288%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_se_expand/Conv2D]:405
	                LOGISTIC	        49403.061	    0.228	    0.221	  0.000%	 55.288%	     0.000	        1	[efficientnetv2-l/block5g_se_expand/Sigmoid]:406
	                     MUL	        49403.288	   11.316	   11.292	  0.013%	 55.301%	     0.000	        1	[efficientnetv2-l/block5g_se_excite/mul]:407
	                 CONV_2D	        49414.593	   84.171	   84.076	  0.094%	 55.395%	     0.000	        1	[efficientnetv2-l/block5g_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5g_project_conv/Conv2D]:408
	                     ADD	        49498.683	    1.938	    1.938	  0.002%	 55.397%	     0.000	        1	[efficientnetv2-l/block5g_add/add]:409
	                 CONV_2D	        49500.631	  432.013	  431.884	  0.483%	 55.880%	     0.000	        1	[efficientnetv2-l/block5h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_expand_conv/Conv2D]:410
	                LOGISTIC	        49932.527	  364.777	  364.894	  0.408%	 56.289%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/Sigmoid]:411
	                     MUL	        50297.435	   11.402	   11.408	  0.013%	 56.301%	     0.000	        1	[efficientnetv2-l/block5h_expand_activation/mul_1]:412
	       DEPTHWISE_CONV_2D	        50308.855	    8.308	    8.649	  0.010%	 56.311%	     0.000	        1	[efficientnetv2-l/block5h_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:413
	                LOGISTIC	        50317.516	  193.851	  193.786	  0.217%	 56.528%	     0.000	        1	[efficientnetv2-l/block5h_activation/Sigmoid]:414
	                     MUL	        50511.315	   11.439	   11.501	  0.013%	 56.541%	     0.000	        1	[efficientnetv2-l/block5h_activation/mul_1]:415
	                    MEAN	        50522.829	  196.822	  196.864	  0.220%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_squeeze/Mean]:416
	                   SHAPE	        50719.704	    0.010	    0.009	  0.000%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Shape]:417
	           STRIDED_SLICE	        50719.719	    0.021	    0.021	  0.000%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/strided_slice]:418
	                    PACK	        50719.747	    0.029	    0.027	  0.000%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape/shape]:419
	                 RESHAPE	        50719.781	    0.016	    0.015	  0.000%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_reshape/Reshape]:420
	                 CONV_2D	        50719.803	    0.109	    0.111	  0.000%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5h_se_reduce/Conv2D]:421
	                LOGISTIC	        50719.922	    0.029	    0.029	  0.000%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/Sigmoid]:422
	                     MUL	        50719.958	    0.013	    0.013	  0.000%	 56.761%	     0.000	        1	[efficientnetv2-l/block5h_se_reduce/mul_1]:423
	                 CONV_2D	        50719.976	    0.552	    0.539	  0.001%	 56.762%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_se_expand/Conv2D]:424
	                LOGISTIC	        50720.522	    0.217	    0.221	  0.000%	 56.762%	     0.000	        1	[efficientnetv2-l/block5h_se_expand/Sigmoid]:425
	                     MUL	        50720.749	   11.232	   11.251	  0.013%	 56.775%	     0.000	        1	[efficientnetv2-l/block5h_se_excite/mul]:426
	                 CONV_2D	        50732.012	   80.712	   80.657	  0.090%	 56.865%	     0.000	        1	[efficientnetv2-l/block5h_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5h_project_conv/Conv2D]:427
	                     ADD	        50812.681	    1.941	    1.960	  0.002%	 56.867%	     0.000	        1	[efficientnetv2-l/block5h_add/add]:428
	                 CONV_2D	        50814.650	  433.676	  433.450	  0.485%	 57.353%	     0.000	        1	[efficientnetv2-l/block5i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_expand_conv/Conv2D]:429
	                LOGISTIC	        51248.124	  360.776	  360.433	  0.403%	 57.756%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/Sigmoid]:430
	                     MUL	        51608.570	   11.315	   11.350	  0.013%	 57.769%	     0.000	        1	[efficientnetv2-l/block5i_expand_activation/mul_1]:431
	       DEPTHWISE_CONV_2D	        51619.932	    9.797	    9.784	  0.011%	 57.780%	     0.000	        1	[efficientnetv2-l/block5i_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:432
	                LOGISTIC	        51629.728	  342.806	  342.707	  0.384%	 58.163%	     0.000	        1	[efficientnetv2-l/block5i_activation/Sigmoid]:433
	                     MUL	        51972.448	   11.447	   11.420	  0.013%	 58.176%	     0.000	        1	[efficientnetv2-l/block5i_activation/mul_1]:434
	                    MEAN	        51983.880	  196.643	  196.669	  0.220%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_squeeze/Mean]:435
	                   SHAPE	        52180.562	    0.009	    0.009	  0.000%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Shape]:436
	           STRIDED_SLICE	        52180.577	    0.022	    0.021	  0.000%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/strided_slice]:437
	                    PACK	        52180.604	    0.031	    0.029	  0.000%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape/shape]:438
	                 RESHAPE	        52180.639	    0.015	    0.015	  0.000%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_reshape/Reshape]:439
	                 CONV_2D	        52180.660	    0.116	    0.119	  0.000%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5i_se_reduce/Conv2D]:440
	                LOGISTIC	        52180.787	    0.042	    0.041	  0.000%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/Sigmoid]:441
	                     MUL	        52180.834	    0.013	    0.013	  0.000%	 58.396%	     0.000	        1	[efficientnetv2-l/block5i_se_reduce/mul_1]:442
	                 CONV_2D	        52180.853	    0.518	    0.519	  0.001%	 58.397%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_se_expand/Conv2D]:443
	                LOGISTIC	        52181.380	    0.223	    0.225	  0.000%	 58.397%	     0.000	        1	[efficientnetv2-l/block5i_se_expand/Sigmoid]:444
	                     MUL	        52181.611	   11.353	   11.303	  0.013%	 58.410%	     0.000	        1	[efficientnetv2-l/block5i_se_excite/mul]:445
	                 CONV_2D	        52192.928	   84.222	   84.227	  0.094%	 58.504%	     0.000	        1	[efficientnetv2-l/block5i_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5i_project_conv/Conv2D]:446
	                     ADD	        52277.168	    1.980	    1.982	  0.002%	 58.506%	     0.000	        1	[efficientnetv2-l/block5i_add/add]:447
	                 CONV_2D	        52279.160	  436.594	  436.992	  0.489%	 58.995%	     0.000	        1	[efficientnetv2-l/block5j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_expand_conv/Conv2D]:448
	                LOGISTIC	        52716.164	  369.915	  370.159	  0.414%	 59.410%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/Sigmoid]:449
	                     MUL	        53086.336	   11.396	   11.418	  0.013%	 59.422%	     0.000	        1	[efficientnetv2-l/block5j_expand_activation/mul_1]:450
	       DEPTHWISE_CONV_2D	        53097.764	    9.846	    9.855	  0.011%	 59.433%	     0.000	        1	[efficientnetv2-l/block5j_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:451
	                LOGISTIC	        53107.633	  365.329	  365.330	  0.409%	 59.842%	     0.000	        1	[efficientnetv2-l/block5j_activation/Sigmoid]:452
	                     MUL	        53472.976	   11.484	   11.466	  0.013%	 59.855%	     0.000	        1	[efficientnetv2-l/block5j_activation/mul_1]:453
	                    MEAN	        53484.455	  196.959	  196.864	  0.220%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_squeeze/Mean]:454
	                   SHAPE	        53681.331	    0.008	    0.008	  0.000%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Shape]:455
	           STRIDED_SLICE	        53681.345	    0.022	    0.022	  0.000%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/strided_slice]:456
	                    PACK	        53681.374	    0.029	    0.027	  0.000%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape/shape]:457
	                 RESHAPE	        53681.408	    0.015	    0.015	  0.000%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_reshape/Reshape]:458
	                 CONV_2D	        53681.429	    0.117	    0.118	  0.000%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5j_se_reduce/Conv2D]:459
	                LOGISTIC	        53681.554	    0.038	    0.037	  0.000%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/Sigmoid]:460
	                     MUL	        53681.598	    0.013	    0.013	  0.000%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_reduce/mul_1]:461
	                 CONV_2D	        53681.616	    0.524	    0.541	  0.001%	 60.076%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_se_expand/Conv2D]:462
	                LOGISTIC	        53682.166	    0.445	    0.444	  0.000%	 60.077%	     0.000	        1	[efficientnetv2-l/block5j_se_expand/Sigmoid]:463
	                     MUL	        53682.616	   11.265	   11.313	  0.013%	 60.090%	     0.000	        1	[efficientnetv2-l/block5j_se_excite/mul]:464
	                 CONV_2D	        53693.941	   85.376	   84.788	  0.095%	 60.184%	     0.000	        1	[efficientnetv2-l/block5j_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5j_project_conv/Conv2D]:465
	                     ADD	        53778.743	    1.992	    1.987	  0.002%	 60.187%	     0.000	        1	[efficientnetv2-l/block5j_add/add]:466
	                 CONV_2D	        53780.740	  433.902	  433.457	  0.485%	 60.672%	     0.000	        1	[efficientnetv2-l/block5k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_expand_conv/Conv2D]:467
	                LOGISTIC	        54214.210	  377.961	  377.927	  0.423%	 61.095%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/Sigmoid]:468
	                     MUL	        54592.149	   11.308	   11.364	  0.013%	 61.107%	     0.000	        1	[efficientnetv2-l/block5k_expand_activation/mul_1]:469
	       DEPTHWISE_CONV_2D	        54603.524	    9.748	    9.741	  0.011%	 61.118%	     0.000	        1	[efficientnetv2-l/block5k_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:470
	                LOGISTIC	        54613.279	  358.573	  358.489	  0.401%	 61.520%	     0.000	        1	[efficientnetv2-l/block5k_activation/Sigmoid]:471
	                     MUL	        54971.780	   11.435	   11.417	  0.013%	 61.532%	     0.000	        1	[efficientnetv2-l/block5k_activation/mul_1]:472
	                    MEAN	        54983.207	  196.634	  196.897	  0.220%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_squeeze/Mean]:473
	                   SHAPE	        55180.116	    0.009	    0.010	  0.000%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Shape]:474
	           STRIDED_SLICE	        55180.132	    0.022	    0.023	  0.000%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/strided_slice]:475
	                    PACK	        55180.162	    0.030	    0.029	  0.000%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape/shape]:476
	                 RESHAPE	        55180.197	    0.015	    0.015	  0.000%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_reshape/Reshape]:477
	                 CONV_2D	        55180.224	    0.114	    0.133	  0.000%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5k_se_reduce/Conv2D]:478
	                LOGISTIC	        55180.365	    0.041	    0.041	  0.000%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/Sigmoid]:479
	                     MUL	        55180.412	    0.013	    0.013	  0.000%	 61.753%	     0.000	        1	[efficientnetv2-l/block5k_se_reduce/mul_1]:480
	                 CONV_2D	        55180.431	    0.519	    0.525	  0.001%	 61.754%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_se_expand/Conv2D]:481
	                LOGISTIC	        55180.964	    0.224	    0.229	  0.000%	 61.754%	     0.000	        1	[efficientnetv2-l/block5k_se_expand/Sigmoid]:482
	                     MUL	        55181.199	   11.258	   11.270	  0.013%	 61.767%	     0.000	        1	[efficientnetv2-l/block5k_se_excite/mul]:483
	                 CONV_2D	        55192.482	   85.355	   85.626	  0.096%	 61.862%	     0.000	        1	[efficientnetv2-l/block5k_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5k_project_conv/Conv2D]:484
	                     ADD	        55278.120	    1.965	    1.931	  0.002%	 61.865%	     0.000	        1	[efficientnetv2-l/block5k_add/add]:485
	                 CONV_2D	        55280.061	  430.847	  430.704	  0.482%	 62.347%	     0.000	        1	[efficientnetv2-l/block5l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_expand_conv/Conv2D]:486
	                LOGISTIC	        55710.777	  364.541	  364.332	  0.408%	 62.754%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/Sigmoid]:487
	                     MUL	        56075.121	   11.544	   11.539	  0.013%	 62.767%	     0.000	        1	[efficientnetv2-l/block5l_expand_activation/mul_1]:488
	       DEPTHWISE_CONV_2D	        56086.671	   10.662	   10.231	  0.011%	 62.779%	     0.000	        1	[efficientnetv2-l/block5l_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:489
	                LOGISTIC	        56096.916	  367.122	  366.624	  0.410%	 63.189%	     0.000	        1	[efficientnetv2-l/block5l_activation/Sigmoid]:490
	                     MUL	        56463.553	   11.476	   11.418	  0.013%	 63.202%	     0.000	        1	[efficientnetv2-l/block5l_activation/mul_1]:491
	                    MEAN	        56474.982	  196.866	  196.899	  0.220%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_squeeze/Mean]:492
	                   SHAPE	        56671.893	    0.009	    0.009	  0.000%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Shape]:493
	           STRIDED_SLICE	        56671.908	    0.021	    0.021	  0.000%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/strided_slice]:494
	                    PACK	        56671.937	    0.030	    0.028	  0.000%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape/shape]:495
	                 RESHAPE	        56671.970	    0.016	    0.016	  0.000%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_reshape/Reshape]:496
	                 CONV_2D	        56671.992	    0.115	    0.117	  0.000%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5l_se_reduce/Conv2D]:497
	                LOGISTIC	        56672.118	    0.039	    0.039	  0.000%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/Sigmoid]:498
	                     MUL	        56672.164	    0.013	    0.013	  0.000%	 63.422%	     0.000	        1	[efficientnetv2-l/block5l_se_reduce/mul_1]:499
	                 CONV_2D	        56672.183	    0.524	    0.526	  0.001%	 63.423%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_se_expand/Conv2D]:500
	                LOGISTIC	        56672.716	    0.223	    0.222	  0.000%	 63.423%	     0.000	        1	[efficientnetv2-l/block5l_se_expand/Sigmoid]:501
	                     MUL	        56672.944	   11.430	   11.379	  0.013%	 63.436%	     0.000	        1	[efficientnetv2-l/block5l_se_excite/mul]:502
	                 CONV_2D	        56684.335	   85.439	   85.305	  0.095%	 63.531%	     0.000	        1	[efficientnetv2-l/block5l_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5l_project_conv/Conv2D]:503
	                     ADD	        56769.653	    1.885	    1.911	  0.002%	 63.534%	     0.000	        1	[efficientnetv2-l/block5l_add/add]:504
	                 CONV_2D	        56771.575	  432.033	  432.063	  0.484%	 64.017%	     0.000	        1	[efficientnetv2-l/block5m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_expand_conv/Conv2D]:505
	                LOGISTIC	        57203.650	  360.573	  361.115	  0.404%	 64.421%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/Sigmoid]:506
	                     MUL	        57564.777	   11.442	   11.393	  0.013%	 64.434%	     0.000	        1	[efficientnetv2-l/block5m_expand_activation/mul_1]:507
	       DEPTHWISE_CONV_2D	        57576.181	    9.774	   10.129	  0.011%	 64.445%	     0.000	        1	[efficientnetv2-l/block5m_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:508
	                LOGISTIC	        57586.323	  374.086	  374.223	  0.419%	 64.864%	     0.000	        1	[efficientnetv2-l/block5m_activation/Sigmoid]:509
	                     MUL	        57960.559	   11.338	   11.374	  0.013%	 64.877%	     0.000	        1	[efficientnetv2-l/block5m_activation/mul_1]:510
	                    MEAN	        57971.944	  196.757	  196.720	  0.220%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_squeeze/Mean]:511
	                   SHAPE	        58168.677	    0.008	    0.008	  0.000%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Shape]:512
	           STRIDED_SLICE	        58168.692	    0.021	    0.021	  0.000%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/strided_slice]:513
	                    PACK	        58168.719	    0.031	    0.028	  0.000%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape/shape]:514
	                 RESHAPE	        58168.754	    0.014	    0.014	  0.000%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_reshape/Reshape]:515
	                 CONV_2D	        58168.775	    0.115	    0.117	  0.000%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5m_se_reduce/Conv2D]:516
	                LOGISTIC	        58168.900	    0.038	    0.038	  0.000%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/Sigmoid]:517
	                     MUL	        58168.945	    0.012	    0.013	  0.000%	 65.097%	     0.000	        1	[efficientnetv2-l/block5m_se_reduce/mul_1]:518
	                 CONV_2D	        58168.964	    0.516	    0.518	  0.001%	 65.098%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_se_expand/Conv2D]:519
	                LOGISTIC	        58169.489	    0.219	    0.224	  0.000%	 65.098%	     0.000	        1	[efficientnetv2-l/block5m_se_expand/Sigmoid]:520
	                     MUL	        58169.719	   11.316	   11.325	  0.013%	 65.111%	     0.000	        1	[efficientnetv2-l/block5m_se_excite/mul]:521
	                 CONV_2D	        58181.056	   84.850	   84.808	  0.095%	 65.206%	     0.000	        1	[efficientnetv2-l/block5m_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5m_project_conv/Conv2D]:522
	                     ADD	        58265.877	    1.983	    1.923	  0.002%	 65.208%	     0.000	        1	[efficientnetv2-l/block5m_add/add]:523
	                 CONV_2D	        58267.811	  433.575	  432.313	  0.484%	 65.692%	     0.000	        1	[efficientnetv2-l/block5n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_expand_conv/Conv2D]:524
	                LOGISTIC	        58700.137	  360.603	  360.591	  0.404%	 66.095%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/Sigmoid]:525
	                     MUL	        59060.740	   11.357	   11.391	  0.013%	 66.108%	     0.000	        1	[efficientnetv2-l/block5n_expand_activation/mul_1]:526
	       DEPTHWISE_CONV_2D	        59072.143	    9.796	    9.814	  0.011%	 66.119%	     0.000	        1	[efficientnetv2-l/block5n_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:527
	                LOGISTIC	        59081.970	  367.153	  367.164	  0.411%	 66.530%	     0.000	        1	[efficientnetv2-l/block5n_activation/Sigmoid]:528
	                     MUL	        59449.145	   11.504	   11.455	  0.013%	 66.543%	     0.000	        1	[efficientnetv2-l/block5n_activation/mul_1]:529
	                    MEAN	        59460.613	  196.752	  196.773	  0.220%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_squeeze/Mean]:530
	                   SHAPE	        59657.397	    0.008	    0.008	  0.000%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Shape]:531
	           STRIDED_SLICE	        59657.412	    0.021	    0.021	  0.000%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/strided_slice]:532
	                    PACK	        59657.440	    0.030	    0.028	  0.000%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape/shape]:533
	                 RESHAPE	        59657.474	    0.016	    0.015	  0.000%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_reshape/Reshape]:534
	                 CONV_2D	        59657.495	    0.115	    0.117	  0.000%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5n_se_reduce/Conv2D]:535
	                LOGISTIC	        59657.620	    0.034	    0.035	  0.000%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/Sigmoid]:536
	                     MUL	        59657.662	    0.013	    0.013	  0.000%	 66.763%	     0.000	        1	[efficientnetv2-l/block5n_se_reduce/mul_1]:537
	                 CONV_2D	        59657.681	    0.543	    0.530	  0.001%	 66.764%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_se_expand/Conv2D]:538
	                LOGISTIC	        59658.217	    0.437	    0.436	  0.000%	 66.765%	     0.000	        1	[efficientnetv2-l/block5n_se_expand/Sigmoid]:539
	                     MUL	        59658.660	   11.341	   11.364	  0.013%	 66.777%	     0.000	        1	[efficientnetv2-l/block5n_se_excite/mul]:540
	                 CONV_2D	        59670.036	   84.886	   85.306	  0.095%	 66.873%	     0.000	        1	[efficientnetv2-l/block5n_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5n_project_conv/Conv2D]:541
	                     ADD	        59755.355	    1.947	    1.935	  0.002%	 66.875%	     0.000	        1	[efficientnetv2-l/block5n_add/add]:542
	                 CONV_2D	        59757.300	  432.957	  433.989	  0.486%	 67.361%	     0.000	        1	[efficientnetv2-l/block5o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_expand_conv/Conv2D]:543
	                LOGISTIC	        60191.300	  374.850	  375.181	  0.420%	 67.781%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/Sigmoid]:544
	                     MUL	        60566.493	   11.506	   11.421	  0.013%	 67.793%	     0.000	        1	[efficientnetv2-l/block5o_expand_activation/mul_1]:545
	       DEPTHWISE_CONV_2D	        60577.926	    8.204	    8.219	  0.009%	 67.802%	     0.000	        1	[efficientnetv2-l/block5o_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:546
	                LOGISTIC	        60586.158	  194.073	  193.930	  0.217%	 68.020%	     0.000	        1	[efficientnetv2-l/block5o_activation/Sigmoid]:547
	                     MUL	        60780.102	   11.439	   11.385	  0.013%	 68.032%	     0.000	        1	[efficientnetv2-l/block5o_activation/mul_1]:548
	                    MEAN	        60791.499	  197.145	  196.950	  0.220%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_squeeze/Mean]:549
	                   SHAPE	        60988.461	    0.009	    0.009	  0.000%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Shape]:550
	           STRIDED_SLICE	        60988.476	    0.023	    0.022	  0.000%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/strided_slice]:551
	                    PACK	        60988.505	    0.030	    0.028	  0.000%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape/shape]:552
	                 RESHAPE	        60988.539	    0.016	    0.015	  0.000%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_reshape/Reshape]:553
	                 CONV_2D	        60988.560	    0.114	    0.115	  0.000%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5o_se_reduce/Conv2D]:554
	                LOGISTIC	        60988.683	    0.030	    0.030	  0.000%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/Sigmoid]:555
	                     MUL	        60988.720	    0.013	    0.013	  0.000%	 68.253%	     0.000	        1	[efficientnetv2-l/block5o_se_reduce/mul_1]:556
	                 CONV_2D	        60988.740	    0.513	    0.533	  0.001%	 68.254%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_se_expand/Conv2D]:557
	                LOGISTIC	        60989.279	    0.219	    0.219	  0.000%	 68.254%	     0.000	        1	[efficientnetv2-l/block5o_se_expand/Sigmoid]:558
	                     MUL	        60989.505	   11.333	   11.339	  0.013%	 68.267%	     0.000	        1	[efficientnetv2-l/block5o_se_excite/mul]:559
	                 CONV_2D	        61000.858	   81.215	   80.995	  0.091%	 68.357%	     0.000	        1	[efficientnetv2-l/block5o_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5o_project_conv/Conv2D]:560
	                     ADD	        61081.865	    1.944	    1.960	  0.002%	 68.359%	     0.000	        1	[efficientnetv2-l/block5o_add/add]:561
	                 CONV_2D	        61083.836	  432.458	  432.476	  0.484%	 68.843%	     0.000	        1	[efficientnetv2-l/block5p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_expand_conv/Conv2D]:562
	                LOGISTIC	        61516.325	  362.107	  361.989	  0.405%	 69.249%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/Sigmoid]:563
	                     MUL	        61878.325	   11.344	   11.381	  0.013%	 69.261%	     0.000	        1	[efficientnetv2-l/block5p_expand_activation/mul_1]:564
	       DEPTHWISE_CONV_2D	        61889.717	    9.745	    9.761	  0.011%	 69.272%	     0.000	        1	[efficientnetv2-l/block5p_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:565
	                LOGISTIC	        61899.492	  341.308	  341.453	  0.382%	 69.654%	     0.000	        1	[efficientnetv2-l/block5p_activation/Sigmoid]:566
	                     MUL	        62240.957	   11.427	   11.499	  0.013%	 69.667%	     0.000	        1	[efficientnetv2-l/block5p_activation/mul_1]:567
	                    MEAN	        62252.467	  196.791	  197.008	  0.220%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_squeeze/Mean]:568
	                   SHAPE	        62449.486	    0.009	    0.009	  0.000%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Shape]:569
	           STRIDED_SLICE	        62449.501	    0.022	    0.023	  0.000%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/strided_slice]:570
	                    PACK	        62449.531	    0.029	    0.028	  0.000%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape/shape]:571
	                 RESHAPE	        62449.566	    0.015	    0.015	  0.000%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_reshape/Reshape]:572
	                 CONV_2D	        62449.588	    0.113	    0.118	  0.000%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5p_se_reduce/Conv2D]:573
	                LOGISTIC	        62449.715	    0.040	    0.041	  0.000%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/Sigmoid]:574
	                     MUL	        62449.762	    0.013	    0.013	  0.000%	 69.888%	     0.000	        1	[efficientnetv2-l/block5p_se_reduce/mul_1]:575
	                 CONV_2D	        62449.781	    0.521	    0.526	  0.001%	 69.889%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_se_expand/Conv2D]:576
	                LOGISTIC	        62450.315	    0.227	    0.230	  0.000%	 69.889%	     0.000	        1	[efficientnetv2-l/block5p_se_expand/Sigmoid]:577
	                     MUL	        62450.552	   11.255	   11.290	  0.013%	 69.901%	     0.000	        1	[efficientnetv2-l/block5p_se_excite/mul]:578
	                 CONV_2D	        62461.855	   83.817	   83.864	  0.094%	 69.995%	     0.000	        1	[efficientnetv2-l/block5p_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5p_project_conv/Conv2D]:579
	                     ADD	        62545.731	    1.971	    1.948	  0.002%	 69.998%	     0.000	        1	[efficientnetv2-l/block5p_add/add]:580
	                 CONV_2D	        62547.690	  435.053	  434.903	  0.487%	 70.484%	     0.000	        1	[efficientnetv2-l/block5q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_expand_conv/Conv2D]:581
	                LOGISTIC	        62982.605	  369.819	  369.402	  0.413%	 70.898%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/Sigmoid]:582
	                     MUL	        63352.020	   11.367	   11.370	  0.013%	 70.910%	     0.000	        1	[efficientnetv2-l/block5q_expand_activation/mul_1]:583
	       DEPTHWISE_CONV_2D	        63363.402	   10.066	    9.896	  0.011%	 70.922%	     0.000	        1	[efficientnetv2-l/block5q_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:584
	                LOGISTIC	        63373.312	  361.409	  361.398	  0.404%	 71.326%	     0.000	        1	[efficientnetv2-l/block5q_activation/Sigmoid]:585
	                     MUL	        63734.723	   11.374	   11.370	  0.013%	 71.339%	     0.000	        1	[efficientnetv2-l/block5q_activation/mul_1]:586
	                    MEAN	        63746.105	  196.789	  196.714	  0.220%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_squeeze/Mean]:587
	                   SHAPE	        63942.830	    0.009	    0.009	  0.000%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Shape]:588
	           STRIDED_SLICE	        63942.845	    0.022	    0.021	  0.000%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/strided_slice]:589
	                    PACK	        63942.873	    0.030	    0.028	  0.000%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape/shape]:590
	                 RESHAPE	        63942.908	    0.015	    0.016	  0.000%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_reshape/Reshape]:591
	                 CONV_2D	        63942.930	    0.112	    0.116	  0.000%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5q_se_reduce/Conv2D]:592
	                LOGISTIC	        63943.054	    0.040	    0.040	  0.000%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/Sigmoid]:593
	                     MUL	        63943.099	    0.013	    0.013	  0.000%	 71.559%	     0.000	        1	[efficientnetv2-l/block5q_se_reduce/mul_1]:594
	                 CONV_2D	        63943.118	    0.522	    0.532	  0.001%	 71.560%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_se_expand/Conv2D]:595
	                LOGISTIC	        63943.658	    0.220	    0.225	  0.000%	 71.560%	     0.000	        1	[efficientnetv2-l/block5q_se_expand/Sigmoid]:596
	                     MUL	        63943.889	   11.283	   11.312	  0.013%	 71.573%	     0.000	        1	[efficientnetv2-l/block5q_se_excite/mul]:597
	                 CONV_2D	        63955.214	   83.832	   83.846	  0.094%	 71.666%	     0.000	        1	[efficientnetv2-l/block5q_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5q_project_conv/Conv2D]:598
	                     ADD	        64039.073	    1.989	    1.927	  0.002%	 71.669%	     0.000	        1	[efficientnetv2-l/block5q_add/add]:599
	                 CONV_2D	        64041.011	  434.582	  434.455	  0.486%	 72.155%	     0.000	        1	[efficientnetv2-l/block5r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_expand_conv/Conv2D]:600
	                LOGISTIC	        64475.480	  363.719	  364.173	  0.408%	 72.562%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/Sigmoid]:601
	                     MUL	        64839.664	   11.280	   11.363	  0.013%	 72.575%	     0.000	        1	[efficientnetv2-l/block5r_expand_activation/mul_1]:602
	       DEPTHWISE_CONV_2D	        64851.037	    8.276	    8.287	  0.009%	 72.584%	     0.000	        1	[efficientnetv2-l/block5r_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:603
	                LOGISTIC	        64859.338	  193.506	  193.365	  0.216%	 72.801%	     0.000	        1	[efficientnetv2-l/block5r_activation/Sigmoid]:604
	                     MUL	        65052.715	   11.508	   11.499	  0.013%	 72.814%	     0.000	        1	[efficientnetv2-l/block5r_activation/mul_1]:605
	                    MEAN	        65064.227	  196.793	  196.805	  0.220%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_squeeze/Mean]:606
	                   SHAPE	        65261.043	    0.009	    0.009	  0.000%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Shape]:607
	           STRIDED_SLICE	        65261.058	    0.022	    0.022	  0.000%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/strided_slice]:608
	                    PACK	        65261.086	    0.029	    0.027	  0.000%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape/shape]:609
	                 RESHAPE	        65261.120	    0.015	    0.015	  0.000%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_reshape/Reshape]:610
	                 CONV_2D	        65261.141	    0.111	    0.113	  0.000%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5r_se_reduce/Conv2D]:611
	                LOGISTIC	        65261.262	    0.029	    0.029	  0.000%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/Sigmoid]:612
	                     MUL	        65261.298	    0.012	    0.013	  0.000%	 73.034%	     0.000	        1	[efficientnetv2-l/block5r_se_reduce/mul_1]:613
	                 CONV_2D	        65261.317	    0.516	    0.517	  0.001%	 73.035%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_se_expand/Conv2D]:614
	                LOGISTIC	        65261.841	    0.217	    0.222	  0.000%	 73.035%	     0.000	        1	[efficientnetv2-l/block5r_se_expand/Sigmoid]:615
	                     MUL	        65262.069	   11.383	   11.374	  0.013%	 73.048%	     0.000	        1	[efficientnetv2-l/block5r_se_excite/mul]:616
	                 CONV_2D	        65273.458	   81.843	   81.920	  0.092%	 73.140%	     0.000	        1	[efficientnetv2-l/block5r_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5r_project_conv/Conv2D]:617
	                     ADD	        65355.391	    1.989	    1.964	  0.002%	 73.142%	     0.000	        1	[efficientnetv2-l/block5r_add/add]:618
	                 CONV_2D	        65357.363	  433.643	  432.791	  0.484%	 73.626%	     0.000	        1	[efficientnetv2-l/block5s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_expand_conv/Conv2D]:619
	                LOGISTIC	        65790.174	  365.504	  365.380	  0.409%	 74.035%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/Sigmoid]:620
	                     MUL	        66155.566	   11.407	   11.386	  0.013%	 74.048%	     0.000	        1	[efficientnetv2-l/block5s_expand_activation/mul_1]:621
	       DEPTHWISE_CONV_2D	        66166.963	    9.716	    9.741	  0.011%	 74.059%	     0.000	        1	[efficientnetv2-l/block5s_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_dwconv2/depthwise;efficientnetv2-l/block6a_bn/FusedBatchNormV3]:622
	                LOGISTIC	        66176.716	  351.100	  351.293	  0.393%	 74.452%	     0.000	        1	[efficientnetv2-l/block5s_activation/Sigmoid]:623
	                     MUL	        66528.020	   11.408	   11.392	  0.013%	 74.465%	     0.000	        1	[efficientnetv2-l/block5s_activation/mul_1]:624
	                    MEAN	        66539.423	  196.689	  196.751	  0.220%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_squeeze/Mean]:625
	                   SHAPE	        66736.186	    0.009	    0.009	  0.000%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Shape]:626
	           STRIDED_SLICE	        66736.201	    0.022	    0.022	  0.000%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/strided_slice]:627
	                    PACK	        66736.230	    0.029	    0.027	  0.000%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape/shape]:628
	                 RESHAPE	        66736.263	    0.016	    0.016	  0.000%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_reshape/Reshape]:629
	                 CONV_2D	        66736.285	    0.113	    0.115	  0.000%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block5s_se_reduce/Conv2D]:630
	                LOGISTIC	        66736.408	    0.035	    0.035	  0.000%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/Sigmoid]:631
	                     MUL	        66736.450	    0.012	    0.013	  0.000%	 74.685%	     0.000	        1	[efficientnetv2-l/block5s_se_reduce/mul_1]:632
	                 CONV_2D	        66736.469	    0.519	    0.519	  0.001%	 74.686%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_se_expand/Conv2D]:633
	                LOGISTIC	        66736.995	    0.435	    0.435	  0.000%	 74.686%	     0.000	        1	[efficientnetv2-l/block5s_se_expand/Sigmoid]:634
	                     MUL	        66737.437	   11.347	   11.335	  0.013%	 74.699%	     0.000	        1	[efficientnetv2-l/block5s_se_excite/mul]:635
	                 CONV_2D	        66748.784	   83.740	   83.704	  0.094%	 74.793%	     0.000	        1	[efficientnetv2-l/block5s_project_bn/FusedBatchNormV3;efficientnetv2-l/block5a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block5s_project_conv/Conv2D]:636
	                     ADD	        66832.513	    2.016	    1.980	  0.002%	 74.795%	     0.000	        1	[efficientnetv2-l/block5s_add/add]:637
	                 CONV_2D	        66834.503	  436.383	  437.437	  0.490%	 75.284%	     0.000	        1	[efficientnetv2-l/block6a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_expand_conv/Conv2D]:638
	                LOGISTIC	        67271.952	  373.063	  373.134	  0.418%	 75.702%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/Sigmoid]:639
	                     MUL	        67645.098	   11.385	   11.377	  0.013%	 75.715%	     0.000	        1	[efficientnetv2-l/block6a_expand_activation/mul_1]:640
	       DEPTHWISE_CONV_2D	        67656.486	  108.655	  108.657	  0.122%	 75.836%	     0.000	        1	[efficientnetv2-l/block6a_bn/FusedBatchNormV3;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_dwconv2/depthwise]:641
	                LOGISTIC	        67765.156	   48.353	   48.358	  0.054%	 75.890%	     0.000	        1	[efficientnetv2-l/block6a_activation/Sigmoid]:642
	                     MUL	        67813.526	    2.847	    2.868	  0.003%	 75.894%	     0.000	        1	[efficientnetv2-l/block6a_activation/mul_1]:643
	                    MEAN	        67816.404	   49.394	   49.319	  0.055%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_squeeze/Mean]:644
	                   SHAPE	        67865.734	    0.009	    0.009	  0.000%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Shape]:645
	           STRIDED_SLICE	        67865.749	    0.021	    0.021	  0.000%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/strided_slice]:646
	                    PACK	        67865.777	    0.030	    0.028	  0.000%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape/shape]:647
	                 RESHAPE	        67865.811	    0.015	    0.015	  0.000%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_reshape/Reshape]:648
	                 CONV_2D	        67865.832	    0.113	    0.116	  0.000%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/BiasAdd;efficientnetv2-l/block5b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block6a_se_reduce/Conv2D]:649
	                LOGISTIC	        67865.955	    0.030	    0.030	  0.000%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/Sigmoid]:650
	                     MUL	        67865.992	    0.013	    0.013	  0.000%	 75.949%	     0.000	        1	[efficientnetv2-l/block6a_se_reduce/mul_1]:651
	                 CONV_2D	        67866.011	    0.516	    0.515	  0.001%	 75.950%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/BiasAdd;efficientnetv2-l/block5b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_se_expand/Conv2D]:652
	                LOGISTIC	        67866.534	    0.224	    0.225	  0.000%	 75.950%	     0.000	        1	[efficientnetv2-l/block6a_se_expand/Sigmoid]:653
	                     MUL	        67866.765	    2.907	    2.906	  0.003%	 75.953%	     0.000	        1	[efficientnetv2-l/block6a_se_excite/mul]:654
	                 CONV_2D	        67869.682	   33.546	   33.544	  0.038%	 75.991%	     0.000	        1	[efficientnetv2-l/block6a_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6a_project_conv/Conv2D]:655
	                 CONV_2D	        67903.238	  184.736	  184.576	  0.207%	 76.197%	     0.000	        1	[efficientnetv2-l/block6b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_expand_conv/Conv2D]:656
	                LOGISTIC	        68087.826	  161.168	  161.008	  0.180%	 76.377%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/Sigmoid]:657
	                     MUL	        68248.845	    4.873	    4.876	  0.005%	 76.383%	     0.000	        1	[efficientnetv2-l/block6b_expand_activation/mul_1]:658
	       DEPTHWISE_CONV_2D	        68253.732	    4.383	    4.406	  0.005%	 76.388%	     0.000	        1	[efficientnetv2-l/block6b_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:659
	                LOGISTIC	        68258.151	  108.150	  108.172	  0.121%	 76.509%	     0.000	        1	[efficientnetv2-l/block6b_activation/Sigmoid]:660
	                     MUL	        68366.336	    4.900	    4.909	  0.005%	 76.514%	     0.000	        1	[efficientnetv2-l/block6b_activation/mul_1]:661
	                    MEAN	        68371.255	   84.369	   84.365	  0.094%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_squeeze/Mean]:662
	                   SHAPE	        68455.633	    0.008	    0.008	  0.000%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Shape]:663
	           STRIDED_SLICE	        68455.647	    0.021	    0.021	  0.000%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/strided_slice]:664
	                    PACK	        68455.674	    0.029	    0.027	  0.000%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape/shape]:665
	                 RESHAPE	        68455.708	    0.016	    0.017	  0.000%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_reshape/Reshape]:666
	                 CONV_2D	        68455.731	    0.140	    0.141	  0.000%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_reduce/Conv2D]:667
	                LOGISTIC	        68455.879	    0.053	    0.053	  0.000%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/Sigmoid]:668
	                     MUL	        68455.939	    0.012	    0.013	  0.000%	 76.609%	     0.000	        1	[efficientnetv2-l/block6b_se_reduce/mul_1]:669
	                 CONV_2D	        68455.958	    0.862	    0.864	  0.001%	 76.610%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_se_expand/Conv2D]:670
	                LOGISTIC	        68456.829	    0.755	    0.754	  0.001%	 76.611%	     0.000	        1	[efficientnetv2-l/block6b_se_expand/Sigmoid]:671
	                     MUL	        68457.588	    4.835	    4.845	  0.005%	 76.616%	     0.000	        1	[efficientnetv2-l/block6b_se_excite/mul]:672
	                 CONV_2D	        68462.444	   36.378	   36.340	  0.041%	 76.657%	     0.000	        1	[efficientnetv2-l/block6b_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6b_project_conv/Conv2D]:673
	                     ADD	        68498.798	    0.823	    0.822	  0.001%	 76.658%	     0.000	        1	[efficientnetv2-l/block6b_add/add]:674
	                 CONV_2D	        68499.629	  184.502	  184.764	  0.207%	 76.865%	     0.000	        1	[efficientnetv2-l/block6c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_expand_conv/Conv2D]:675
	                LOGISTIC	        68684.406	  156.418	  156.435	  0.175%	 77.040%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/Sigmoid]:676
	                     MUL	        68840.853	    5.038	    4.955	  0.006%	 77.045%	     0.000	        1	[efficientnetv2-l/block6c_expand_activation/mul_1]:677
	       DEPTHWISE_CONV_2D	        68845.818	    4.301	    4.325	  0.005%	 77.050%	     0.000	        1	[efficientnetv2-l/block6c_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:678
	                LOGISTIC	        68850.156	  103.440	  103.516	  0.116%	 77.166%	     0.000	        1	[efficientnetv2-l/block6c_activation/Sigmoid]:679
	                     MUL	        68953.686	    4.911	    4.891	  0.005%	 77.172%	     0.000	        1	[efficientnetv2-l/block6c_activation/mul_1]:680
	                    MEAN	        68958.588	   84.380	   84.391	  0.094%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_squeeze/Mean]:681
	                   SHAPE	        69042.991	    0.009	    0.009	  0.000%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Shape]:682
	           STRIDED_SLICE	        69043.005	    0.021	    0.021	  0.000%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/strided_slice]:683
	                    PACK	        69043.033	    0.029	    0.028	  0.000%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape/shape]:684
	                 RESHAPE	        69043.067	    0.016	    0.016	  0.000%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_reshape/Reshape]:685
	                 CONV_2D	        69043.090	    0.137	    0.139	  0.000%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_reduce/Conv2D]:686
	                LOGISTIC	        69043.241	    0.074	    0.077	  0.000%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/Sigmoid]:687
	                     MUL	        69043.326	    0.013	    0.013	  0.000%	 77.266%	     0.000	        1	[efficientnetv2-l/block6c_se_reduce/mul_1]:688
	                 CONV_2D	        69043.345	    0.866	    0.866	  0.001%	 77.267%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_se_expand/Conv2D]:689
	                LOGISTIC	        69044.217	    0.750	    0.750	  0.001%	 77.268%	     0.000	        1	[efficientnetv2-l/block6c_se_expand/Sigmoid]:690
	                     MUL	        69044.973	    4.860	    4.843	  0.005%	 77.274%	     0.000	        1	[efficientnetv2-l/block6c_se_excite/mul]:691
	                 CONV_2D	        69049.829	   36.238	   36.255	  0.041%	 77.314%	     0.000	        1	[efficientnetv2-l/block6c_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6c_project_conv/Conv2D]:692
	                     ADD	        69086.095	    0.794	    0.837	  0.001%	 77.315%	     0.000	        1	[efficientnetv2-l/block6c_add/add]:693
	                 CONV_2D	        69086.943	  183.568	  183.642	  0.206%	 77.521%	     0.000	        1	[efficientnetv2-l/block6d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_expand_conv/Conv2D]:694
	                LOGISTIC	        69270.596	  153.435	  153.587	  0.172%	 77.693%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/Sigmoid]:695
	                     MUL	        69424.196	    4.888	    4.885	  0.005%	 77.698%	     0.000	        1	[efficientnetv2-l/block6d_expand_activation/mul_1]:696
	       DEPTHWISE_CONV_2D	        69429.092	    4.357	    4.556	  0.005%	 77.703%	     0.000	        1	[efficientnetv2-l/block6d_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:697
	                LOGISTIC	        69433.662	  105.828	  106.009	  0.119%	 77.822%	     0.000	        1	[efficientnetv2-l/block6d_activation/Sigmoid]:698
	                     MUL	        69539.683	    4.885	    4.884	  0.005%	 77.827%	     0.000	        1	[efficientnetv2-l/block6d_activation/mul_1]:699
	                    MEAN	        69544.577	   84.459	   84.548	  0.095%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_squeeze/Mean]:700
	                   SHAPE	        69629.137	    0.008	    0.009	  0.000%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Shape]:701
	           STRIDED_SLICE	        69629.152	    0.022	    0.022	  0.000%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/strided_slice]:702
	                    PACK	        69629.180	    0.031	    0.028	  0.000%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape/shape]:703
	                 RESHAPE	        69629.215	    0.016	    0.016	  0.000%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_reshape/Reshape]:704
	                 CONV_2D	        69629.238	    0.138	    0.140	  0.000%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_reduce/Conv2D]:705
	                LOGISTIC	        69629.386	    0.055	    0.054	  0.000%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/Sigmoid]:706
	                     MUL	        69629.447	    0.013	    0.013	  0.000%	 77.922%	     0.000	        1	[efficientnetv2-l/block6d_se_reduce/mul_1]:707
	                 CONV_2D	        69629.466	    0.898	    0.892	  0.001%	 77.923%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_se_expand/Conv2D]:708
	                LOGISTIC	        69630.365	    0.750	    0.750	  0.001%	 77.924%	     0.000	        1	[efficientnetv2-l/block6d_se_expand/Sigmoid]:709
	                     MUL	        69631.122	    4.853	    4.848	  0.005%	 77.929%	     0.000	        1	[efficientnetv2-l/block6d_se_excite/mul]:710
	                 CONV_2D	        69635.982	   36.805	   36.821	  0.041%	 77.971%	     0.000	        1	[efficientnetv2-l/block6d_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6d_project_conv/Conv2D]:711
	                     ADD	        69672.814	    0.836	    0.818	  0.001%	 77.972%	     0.000	        1	[efficientnetv2-l/block6d_add/add]:712
	                 CONV_2D	        69673.640	  183.522	  183.753	  0.206%	 78.177%	     0.000	        1	[efficientnetv2-l/block6e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_expand_conv/Conv2D]:713
	                LOGISTIC	        69857.405	  152.879	  152.905	  0.171%	 78.348%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/Sigmoid]:714
	                     MUL	        70010.322	    4.873	    4.875	  0.005%	 78.354%	     0.000	        1	[efficientnetv2-l/block6e_expand_activation/mul_1]:715
	       DEPTHWISE_CONV_2D	        70015.208	    4.345	    4.348	  0.005%	 78.359%	     0.000	        1	[efficientnetv2-l/block6e_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:716
	                LOGISTIC	        70019.568	  105.183	  105.268	  0.118%	 78.476%	     0.000	        1	[efficientnetv2-l/block6e_activation/Sigmoid]:717
	                     MUL	        70124.849	    4.881	    4.880	  0.005%	 78.482%	     0.000	        1	[efficientnetv2-l/block6e_activation/mul_1]:718
	                    MEAN	        70129.741	   84.381	   84.400	  0.094%	 78.576%	     0.000	        1	[efficientnetv2-l/block6e_se_squeeze/Mean]:719
	                   SHAPE	        70214.152	    0.008	    0.008	  0.000%	 78.576%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Shape]:720
	           STRIDED_SLICE	        70214.167	    0.024	    0.022	  0.000%	 78.576%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/strided_slice]:721
	                    PACK	        70214.196	    0.034	    0.030	  0.000%	 78.576%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape/shape]:722
	                 RESHAPE	        70214.232	    0.017	    0.017	  0.000%	 78.576%	     0.000	        1	[efficientnetv2-l/block6e_se_reshape/Reshape]:723
	                 CONV_2D	        70214.256	    0.143	    0.141	  0.000%	 78.577%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_reduce/Conv2D]:724
	                LOGISTIC	        70214.405	    0.057	    0.056	  0.000%	 78.577%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/Sigmoid]:725
	                     MUL	        70214.467	    0.014	    0.013	  0.000%	 78.577%	     0.000	        1	[efficientnetv2-l/block6e_se_reduce/mul_1]:726
	                 CONV_2D	        70214.486	    0.871	    0.865	  0.001%	 78.578%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_se_expand/Conv2D]:727
	                LOGISTIC	        70215.359	    0.750	    0.745	  0.001%	 78.579%	     0.000	        1	[efficientnetv2-l/block6e_se_expand/Sigmoid]:728
	                     MUL	        70216.111	    4.894	    4.882	  0.005%	 78.584%	     0.000	        1	[efficientnetv2-l/block6e_se_excite/mul]:729
	                 CONV_2D	        70221.004	   36.978	   36.956	  0.041%	 78.625%	     0.000	        1	[efficientnetv2-l/block6e_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6e_project_conv/Conv2D]:730
	                     ADD	        70257.971	    0.846	    0.845	  0.001%	 78.626%	     0.000	        1	[efficientnetv2-l/block6e_add/add]:731
	                 CONV_2D	        70258.825	  184.288	  184.133	  0.206%	 78.832%	     0.000	        1	[efficientnetv2-l/block6f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_expand_conv/Conv2D]:732
	                LOGISTIC	        70442.970	  153.991	  153.776	  0.172%	 79.004%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/Sigmoid]:733
	                     MUL	        70596.757	    4.907	    4.892	  0.005%	 79.010%	     0.000	        1	[efficientnetv2-l/block6f_expand_activation/mul_1]:734
	       DEPTHWISE_CONV_2D	        70601.659	    5.289	    4.874	  0.005%	 79.015%	     0.000	        1	[efficientnetv2-l/block6f_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:735
	                LOGISTIC	        70606.546	  103.444	  103.473	  0.116%	 79.131%	     0.000	        1	[efficientnetv2-l/block6f_activation/Sigmoid]:736
	                     MUL	        70710.031	    4.921	    4.913	  0.005%	 79.137%	     0.000	        1	[efficientnetv2-l/block6f_activation/mul_1]:737
	                    MEAN	        70714.955	   84.476	   84.476	  0.095%	 79.231%	     0.000	        1	[efficientnetv2-l/block6f_se_squeeze/Mean]:738
	                   SHAPE	        70799.442	    0.008	    0.008	  0.000%	 79.231%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Shape]:739
	           STRIDED_SLICE	        70799.457	    0.022	    0.021	  0.000%	 79.231%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/strided_slice]:740
	                    PACK	        70799.484	    0.043	    0.035	  0.000%	 79.231%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape/shape]:741
	                 RESHAPE	        70799.526	    0.017	    0.017	  0.000%	 79.231%	     0.000	        1	[efficientnetv2-l/block6f_se_reshape/Reshape]:742
	                 CONV_2D	        70799.549	    0.140	    0.140	  0.000%	 79.232%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_reduce/Conv2D]:743
	                LOGISTIC	        70799.697	    0.042	    0.062	  0.000%	 79.232%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/Sigmoid]:744
	                     MUL	        70799.766	    0.013	    0.013	  0.000%	 79.232%	     0.000	        1	[efficientnetv2-l/block6f_se_reduce/mul_1]:745
	                 CONV_2D	        70799.785	    0.867	    0.865	  0.001%	 79.233%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_se_expand/Conv2D]:746
	                LOGISTIC	        70800.658	    0.363	    0.372	  0.000%	 79.233%	     0.000	        1	[efficientnetv2-l/block6f_se_expand/Sigmoid]:747
	                     MUL	        70801.037	    4.831	    4.841	  0.005%	 79.238%	     0.000	        1	[efficientnetv2-l/block6f_se_excite/mul]:748
	                 CONV_2D	        70805.889	   36.181	   36.158	  0.040%	 79.279%	     0.000	        1	[efficientnetv2-l/block6f_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6f_project_conv/Conv2D]:749
	                     ADD	        70842.060	    0.887	    0.875	  0.001%	 79.280%	     0.000	        1	[efficientnetv2-l/block6f_add/add]:750
	                 CONV_2D	        70842.943	  187.361	  187.337	  0.210%	 79.490%	     0.000	        1	[efficientnetv2-l/block6g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_expand_conv/Conv2D]:751
	                LOGISTIC	        71030.293	  153.274	  153.213	  0.171%	 79.661%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/Sigmoid]:752
	                     MUL	        71183.518	    4.887	    4.878	  0.005%	 79.666%	     0.000	        1	[efficientnetv2-l/block6g_expand_activation/mul_1]:753
	       DEPTHWISE_CONV_2D	        71188.406	    4.449	    4.423	  0.005%	 79.671%	     0.000	        1	[efficientnetv2-l/block6g_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:754
	                LOGISTIC	        71192.842	  152.243	  152.214	  0.170%	 79.842%	     0.000	        1	[efficientnetv2-l/block6g_activation/Sigmoid]:755
	                     MUL	        71345.070	    4.879	    4.876	  0.005%	 79.847%	     0.000	        1	[efficientnetv2-l/block6g_activation/mul_1]:756
	                    MEAN	        71349.957	   84.406	   84.397	  0.094%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_squeeze/Mean]:757
	                   SHAPE	        71434.365	    0.008	    0.008	  0.000%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Shape]:758
	           STRIDED_SLICE	        71434.379	    0.022	    0.021	  0.000%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/strided_slice]:759
	                    PACK	        71434.407	    0.030	    0.028	  0.000%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape/shape]:760
	                 RESHAPE	        71434.441	    0.016	    0.016	  0.000%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_reshape/Reshape]:761
	                 CONV_2D	        71434.463	    0.182	    0.163	  0.000%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_reduce/Conv2D]:762
	                LOGISTIC	        71434.634	    0.048	    0.048	  0.000%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/Sigmoid]:763
	                     MUL	        71434.688	    0.013	    0.013	  0.000%	 79.942%	     0.000	        1	[efficientnetv2-l/block6g_se_reduce/mul_1]:764
	                 CONV_2D	        71434.708	    0.896	    0.896	  0.001%	 79.943%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_se_expand/Conv2D]:765
	                LOGISTIC	        71435.611	    0.751	    0.750	  0.001%	 79.944%	     0.000	        1	[efficientnetv2-l/block6g_se_expand/Sigmoid]:766
	                     MUL	        71436.367	    4.858	    4.845	  0.005%	 79.949%	     0.000	        1	[efficientnetv2-l/block6g_se_excite/mul]:767
	                 CONV_2D	        71441.223	   37.011	   37.015	  0.041%	 79.991%	     0.000	        1	[efficientnetv2-l/block6g_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6g_project_conv/Conv2D]:768
	                     ADD	        71478.249	    0.891	    0.861	  0.001%	 79.992%	     0.000	        1	[efficientnetv2-l/block6g_add/add]:769
	                 CONV_2D	        71479.118	  187.242	  187.335	  0.210%	 80.201%	     0.000	        1	[efficientnetv2-l/block6h_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_expand_conv/Conv2D]:770
	                LOGISTIC	        71666.466	  159.335	  159.597	  0.179%	 80.380%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/Sigmoid]:771
	                     MUL	        71826.075	    4.874	    4.894	  0.005%	 80.385%	     0.000	        1	[efficientnetv2-l/block6h_expand_activation/mul_1]:772
	       DEPTHWISE_CONV_2D	        71830.982	    4.431	    4.671	  0.005%	 80.391%	     0.000	        1	[efficientnetv2-l/block6h_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:773
	                LOGISTIC	        71835.667	  156.704	  156.808	  0.176%	 80.566%	     0.000	        1	[efficientnetv2-l/block6h_activation/Sigmoid]:774
	                     MUL	        71992.486	    4.948	    4.912	  0.005%	 80.572%	     0.000	        1	[efficientnetv2-l/block6h_activation/mul_1]:775
	                    MEAN	        71997.409	   84.486	   84.500	  0.095%	 80.666%	     0.000	        1	[efficientnetv2-l/block6h_se_squeeze/Mean]:776
	                   SHAPE	        72081.921	    0.008	    0.009	  0.000%	 80.666%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Shape]:777
	           STRIDED_SLICE	        72081.936	    0.021	    0.021	  0.000%	 80.666%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/strided_slice]:778
	                    PACK	        72081.963	    0.031	    0.028	  0.000%	 80.666%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape/shape]:779
	                 RESHAPE	        72081.998	    0.016	    0.017	  0.000%	 80.666%	     0.000	        1	[efficientnetv2-l/block6h_se_reshape/Reshape]:780
	                 CONV_2D	        72082.021	    0.137	    0.140	  0.000%	 80.666%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_reduce/Conv2D]:781
	                LOGISTIC	        72082.168	    0.043	    0.052	  0.000%	 80.667%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/Sigmoid]:782
	                     MUL	        72082.227	    0.014	    0.013	  0.000%	 80.667%	     0.000	        1	[efficientnetv2-l/block6h_se_reduce/mul_1]:783
	                 CONV_2D	        72082.246	    0.866	    0.869	  0.001%	 80.668%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_se_expand/Conv2D]:784
	                LOGISTIC	        72083.122	    0.369	    0.372	  0.000%	 80.668%	     0.000	        1	[efficientnetv2-l/block6h_se_expand/Sigmoid]:785
	                     MUL	        72083.501	    4.849	    4.854	  0.005%	 80.673%	     0.000	        1	[efficientnetv2-l/block6h_se_excite/mul]:786
	                 CONV_2D	        72088.367	   37.001	   36.997	  0.041%	 80.715%	     0.000	        1	[efficientnetv2-l/block6h_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6h_project_conv/Conv2D]:787
	                     ADD	        72125.376	    0.793	    0.811	  0.001%	 80.716%	     0.000	        1	[efficientnetv2-l/block6h_add/add]:788
	                 CONV_2D	        72126.197	  186.478	  186.564	  0.209%	 80.924%	     0.000	        1	[efficientnetv2-l/block6i_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_expand_conv/Conv2D]:789
	                LOGISTIC	        72312.773	  153.728	  153.684	  0.172%	 81.096%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/Sigmoid]:790
	                     MUL	        72466.468	    4.972	    4.927	  0.006%	 81.102%	     0.000	        1	[efficientnetv2-l/block6i_expand_activation/mul_1]:791
	       DEPTHWISE_CONV_2D	        72471.406	    4.357	    4.418	  0.005%	 81.107%	     0.000	        1	[efficientnetv2-l/block6i_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:792
	                LOGISTIC	        72475.838	  159.128	  159.089	  0.178%	 81.285%	     0.000	        1	[efficientnetv2-l/block6i_activation/Sigmoid]:793
	                     MUL	        72634.939	    4.879	    4.878	  0.005%	 81.290%	     0.000	        1	[efficientnetv2-l/block6i_activation/mul_1]:794
	                    MEAN	        72639.828	   84.487	   84.450	  0.095%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_squeeze/Mean]:795
	                   SHAPE	        72724.289	    0.009	    0.009	  0.000%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Shape]:796
	           STRIDED_SLICE	        72724.304	    0.022	    0.021	  0.000%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/strided_slice]:797
	                    PACK	        72724.333	    0.031	    0.028	  0.000%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape/shape]:798
	                 RESHAPE	        72724.367	    0.017	    0.017	  0.000%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_reshape/Reshape]:799
	                 CONV_2D	        72724.390	    0.142	    0.141	  0.000%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_reduce/Conv2D]:800
	                LOGISTIC	        72724.539	    0.049	    0.049	  0.000%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/Sigmoid]:801
	                     MUL	        72724.595	    0.014	    0.013	  0.000%	 81.385%	     0.000	        1	[efficientnetv2-l/block6i_se_reduce/mul_1]:802
	                 CONV_2D	        72724.614	    0.882	    0.873	  0.001%	 81.386%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_se_expand/Conv2D]:803
	                LOGISTIC	        72725.494	    0.382	    0.380	  0.000%	 81.387%	     0.000	        1	[efficientnetv2-l/block6i_se_expand/Sigmoid]:804
	                     MUL	        72725.880	    4.839	    4.847	  0.005%	 81.392%	     0.000	        1	[efficientnetv2-l/block6i_se_excite/mul]:805
	                 CONV_2D	        72730.739	   37.010	   36.877	  0.041%	 81.433%	     0.000	        1	[efficientnetv2-l/block6i_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6i_project_conv/Conv2D]:806
	                     ADD	        72767.628	    0.836	    0.815	  0.001%	 81.434%	     0.000	        1	[efficientnetv2-l/block6i_add/add]:807
	                 CONV_2D	        72768.451	  187.596	  187.160	  0.209%	 81.644%	     0.000	        1	[efficientnetv2-l/block6j_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_expand_conv/Conv2D]:808
	                LOGISTIC	        72955.623	  153.270	  153.185	  0.171%	 81.815%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/Sigmoid]:809
	                     MUL	        73108.821	    4.871	    4.925	  0.006%	 81.821%	     0.000	        1	[efficientnetv2-l/block6j_expand_activation/mul_1]:810
	       DEPTHWISE_CONV_2D	        73113.757	    3.748	    3.768	  0.004%	 81.825%	     0.000	        1	[efficientnetv2-l/block6j_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:811
	                LOGISTIC	        73117.539	   83.084	   82.945	  0.093%	 81.918%	     0.000	        1	[efficientnetv2-l/block6j_activation/Sigmoid]:812
	                     MUL	        73200.496	    4.885	    4.881	  0.005%	 81.923%	     0.000	        1	[efficientnetv2-l/block6j_activation/mul_1]:813
	                    MEAN	        73205.390	   84.572	   84.519	  0.095%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_squeeze/Mean]:814
	                   SHAPE	        73289.920	    0.009	    0.009	  0.000%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Shape]:815
	           STRIDED_SLICE	        73289.935	    0.021	    0.021	  0.000%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/strided_slice]:816
	                    PACK	        73289.963	    0.029	    0.028	  0.000%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape/shape]:817
	                 RESHAPE	        73289.997	    0.017	    0.017	  0.000%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_reshape/Reshape]:818
	                 CONV_2D	        73290.020	    0.135	    0.138	  0.000%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_reduce/Conv2D]:819
	                LOGISTIC	        73290.166	    0.036	    0.036	  0.000%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/Sigmoid]:820
	                     MUL	        73290.208	    0.014	    0.013	  0.000%	 82.018%	     0.000	        1	[efficientnetv2-l/block6j_se_reduce/mul_1]:821
	                 CONV_2D	        73290.227	    0.866	    0.875	  0.001%	 82.019%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_se_expand/Conv2D]:822
	                LOGISTIC	        73291.110	    0.410	    0.395	  0.000%	 82.020%	     0.000	        1	[efficientnetv2-l/block6j_se_expand/Sigmoid]:823
	                     MUL	        73291.511	    4.815	    4.830	  0.005%	 82.025%	     0.000	        1	[efficientnetv2-l/block6j_se_excite/mul]:824
	                 CONV_2D	        73296.352	   36.847	   36.882	  0.041%	 82.066%	     0.000	        1	[efficientnetv2-l/block6j_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6j_project_conv/Conv2D]:825
	                     ADD	        73333.245	    0.800	    0.826	  0.001%	 82.067%	     0.000	        1	[efficientnetv2-l/block6j_add/add]:826
	                 CONV_2D	        73334.079	  187.170	  187.196	  0.210%	 82.277%	     0.000	        1	[efficientnetv2-l/block6k_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_expand_conv/Conv2D]:827
	                LOGISTIC	        73521.288	  152.835	  152.948	  0.171%	 82.448%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/Sigmoid]:828
	                     MUL	        73674.249	    4.866	    4.876	  0.005%	 82.453%	     0.000	        1	[efficientnetv2-l/block6k_expand_activation/mul_1]:829
	       DEPTHWISE_CONV_2D	        73679.136	    4.474	    4.428	  0.005%	 82.458%	     0.000	        1	[efficientnetv2-l/block6k_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:830
	                LOGISTIC	        73683.577	  149.448	  149.476	  0.167%	 82.626%	     0.000	        1	[efficientnetv2-l/block6k_activation/Sigmoid]:831
	                     MUL	        73833.066	    4.884	    4.917	  0.006%	 82.631%	     0.000	        1	[efficientnetv2-l/block6k_activation/mul_1]:832
	                    MEAN	        73837.993	   84.468	   84.422	  0.094%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_squeeze/Mean]:833
	                   SHAPE	        73922.428	    0.008	    0.007	  0.000%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Shape]:834
	           STRIDED_SLICE	        73922.442	    0.021	    0.021	  0.000%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/strided_slice]:835
	                    PACK	        73922.469	    0.031	    0.029	  0.000%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape/shape]:836
	                 RESHAPE	        73922.504	    0.016	    0.017	  0.000%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_reshape/Reshape]:837
	                 CONV_2D	        73922.527	    0.137	    0.138	  0.000%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_reduce/Conv2D]:838
	                LOGISTIC	        73922.673	    0.048	    0.049	  0.000%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/Sigmoid]:839
	                     MUL	        73922.727	    0.013	    0.013	  0.000%	 82.726%	     0.000	        1	[efficientnetv2-l/block6k_se_reduce/mul_1]:840
	                 CONV_2D	        73922.746	    0.895	    0.898	  0.001%	 82.727%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_se_expand/Conv2D]:841
	                LOGISTIC	        73923.652	    0.382	    0.376	  0.000%	 82.727%	     0.000	        1	[efficientnetv2-l/block6k_se_expand/Sigmoid]:842
	                     MUL	        73924.034	    4.825	    4.825	  0.005%	 82.733%	     0.000	        1	[efficientnetv2-l/block6k_se_excite/mul]:843
	                 CONV_2D	        73928.870	   36.825	   36.815	  0.041%	 82.774%	     0.000	        1	[efficientnetv2-l/block6k_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6k_project_conv/Conv2D]:844
	                     ADD	        73965.697	    0.849	    0.867	  0.001%	 82.775%	     0.000	        1	[efficientnetv2-l/block6k_add/add]:845
	                 CONV_2D	        73966.572	  186.569	  186.867	  0.209%	 82.984%	     0.000	        1	[efficientnetv2-l/block6l_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_expand_conv/Conv2D]:846
	                LOGISTIC	        74153.451	  157.030	  157.241	  0.176%	 83.160%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/Sigmoid]:847
	                     MUL	        74310.703	    4.868	    4.875	  0.005%	 83.165%	     0.000	        1	[efficientnetv2-l/block6l_expand_activation/mul_1]:848
	       DEPTHWISE_CONV_2D	        74315.588	    3.807	    3.803	  0.004%	 83.170%	     0.000	        1	[efficientnetv2-l/block6l_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:849
	                LOGISTIC	        74319.404	   82.933	   82.984	  0.093%	 83.263%	     0.000	        1	[efficientnetv2-l/block6l_activation/Sigmoid]:850
	                     MUL	        74402.401	    4.876	    4.880	  0.005%	 83.268%	     0.000	        1	[efficientnetv2-l/block6l_activation/mul_1]:851
	                    MEAN	        74407.291	   84.465	   84.483	  0.095%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_squeeze/Mean]:852
	                   SHAPE	        74491.785	    0.008	    0.008	  0.000%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Shape]:853
	           STRIDED_SLICE	        74491.799	    0.021	    0.021	  0.000%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/strided_slice]:854
	                    PACK	        74491.826	    0.029	    0.028	  0.000%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape/shape]:855
	                 RESHAPE	        74491.860	    0.017	    0.017	  0.000%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_reshape/Reshape]:856
	                 CONV_2D	        74491.883	    0.167	    0.151	  0.000%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_reduce/Conv2D]:857
	                LOGISTIC	        74492.042	    0.039	    0.038	  0.000%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/Sigmoid]:858
	                     MUL	        74492.087	    0.014	    0.014	  0.000%	 83.363%	     0.000	        1	[efficientnetv2-l/block6l_se_reduce/mul_1]:859
	                 CONV_2D	        74492.106	    0.869	    0.867	  0.001%	 83.364%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_se_expand/Conv2D]:860
	                LOGISTIC	        74492.981	    0.370	    0.375	  0.000%	 83.364%	     0.000	        1	[efficientnetv2-l/block6l_se_expand/Sigmoid]:861
	                     MUL	        74493.362	    4.823	    4.850	  0.005%	 83.370%	     0.000	        1	[efficientnetv2-l/block6l_se_excite/mul]:862
	                 CONV_2D	        74498.224	   35.359	   35.386	  0.040%	 83.409%	     0.000	        1	[efficientnetv2-l/block6l_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6l_project_conv/Conv2D]:863
	                     ADD	        74533.622	    0.847	    0.851	  0.001%	 83.410%	     0.000	        1	[efficientnetv2-l/block6l_add/add]:864
	                 CONV_2D	        74534.482	  187.009	  187.102	  0.209%	 83.620%	     0.000	        1	[efficientnetv2-l/block6m_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_expand_conv/Conv2D]:865
	                LOGISTIC	        74721.597	  154.754	  154.769	  0.173%	 83.793%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/Sigmoid]:866
	                     MUL	        74876.379	    4.876	    4.873	  0.005%	 83.798%	     0.000	        1	[efficientnetv2-l/block6m_expand_activation/mul_1]:867
	       DEPTHWISE_CONV_2D	        74881.262	    4.398	    4.380	  0.005%	 83.803%	     0.000	        1	[efficientnetv2-l/block6m_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:868
	                LOGISTIC	        74885.656	  146.788	  146.768	  0.164%	 83.968%	     0.000	        1	[efficientnetv2-l/block6m_activation/Sigmoid]:869
	                     MUL	        75032.438	    4.879	    4.875	  0.005%	 83.973%	     0.000	        1	[efficientnetv2-l/block6m_activation/mul_1]:870
	                    MEAN	        75037.324	   84.382	   84.412	  0.094%	 84.067%	     0.000	        1	[efficientnetv2-l/block6m_se_squeeze/Mean]:871
	                   SHAPE	        75121.747	    0.009	    0.009	  0.000%	 84.067%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Shape]:872
	           STRIDED_SLICE	        75121.763	    0.022	    0.021	  0.000%	 84.067%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/strided_slice]:873
	                    PACK	        75121.791	    0.031	    0.029	  0.000%	 84.068%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape/shape]:874
	                 RESHAPE	        75121.826	    0.017	    0.017	  0.000%	 84.068%	     0.000	        1	[efficientnetv2-l/block6m_se_reshape/Reshape]:875
	                 CONV_2D	        75121.849	    0.139	    0.141	  0.000%	 84.068%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_reduce/Conv2D]:876
	                LOGISTIC	        75121.997	    0.049	    0.049	  0.000%	 84.068%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/Sigmoid]:877
	                     MUL	        75122.052	    0.013	    0.022	  0.000%	 84.068%	     0.000	        1	[efficientnetv2-l/block6m_se_reduce/mul_1]:878
	                 CONV_2D	        75122.081	    0.862	    0.864	  0.001%	 84.069%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_se_expand/Conv2D]:879
	                LOGISTIC	        75122.951	    0.379	    0.378	  0.000%	 84.069%	     0.000	        1	[efficientnetv2-l/block6m_se_expand/Sigmoid]:880
	                     MUL	        75123.336	    4.851	    4.838	  0.005%	 84.075%	     0.000	        1	[efficientnetv2-l/block6m_se_excite/mul]:881
	                 CONV_2D	        75128.186	   37.094	   37.015	  0.041%	 84.116%	     0.000	        1	[efficientnetv2-l/block6m_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6m_project_conv/Conv2D]:882
	                     ADD	        75165.213	    0.861	    0.854	  0.001%	 84.117%	     0.000	        1	[efficientnetv2-l/block6m_add/add]:883
	                 CONV_2D	        75166.076	  188.148	  187.602	  0.210%	 84.327%	     0.000	        1	[efficientnetv2-l/block6n_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_expand_conv/Conv2D]:884
	                LOGISTIC	        75353.691	  154.699	  154.497	  0.173%	 84.500%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/Sigmoid]:885
	                     MUL	        75508.200	    4.874	    4.875	  0.005%	 84.505%	     0.000	        1	[efficientnetv2-l/block6n_expand_activation/mul_1]:886
	       DEPTHWISE_CONV_2D	        75513.086	    4.367	    4.383	  0.005%	 84.510%	     0.000	        1	[efficientnetv2-l/block6n_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:887
	                LOGISTIC	        75517.482	  157.635	  157.812	  0.177%	 84.687%	     0.000	        1	[efficientnetv2-l/block6n_activation/Sigmoid]:888
	                     MUL	        75675.307	    4.886	    4.884	  0.005%	 84.692%	     0.000	        1	[efficientnetv2-l/block6n_activation/mul_1]:889
	                    MEAN	        75680.201	   84.499	   84.493	  0.095%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_squeeze/Mean]:890
	                   SHAPE	        75764.705	    0.008	    0.009	  0.000%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Shape]:891
	           STRIDED_SLICE	        75764.720	    0.021	    0.021	  0.000%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/strided_slice]:892
	                    PACK	        75764.747	    0.031	    0.029	  0.000%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape/shape]:893
	                 RESHAPE	        75764.783	    0.016	    0.017	  0.000%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_reshape/Reshape]:894
	                 CONV_2D	        75764.806	    0.136	    0.138	  0.000%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_reduce/Conv2D]:895
	                LOGISTIC	        75764.951	    0.049	    0.049	  0.000%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/Sigmoid]:896
	                     MUL	        75765.006	    0.013	    0.013	  0.000%	 84.787%	     0.000	        1	[efficientnetv2-l/block6n_se_reduce/mul_1]:897
	                 CONV_2D	        75765.025	    0.859	    0.865	  0.001%	 84.788%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_se_expand/Conv2D]:898
	                LOGISTIC	        75765.897	    0.740	    0.741	  0.001%	 84.789%	     0.000	        1	[efficientnetv2-l/block6n_se_expand/Sigmoid]:899
	                     MUL	        75766.644	    4.852	    4.851	  0.005%	 84.794%	     0.000	        1	[efficientnetv2-l/block6n_se_excite/mul]:900
	                 CONV_2D	        75771.506	   36.881	   36.881	  0.041%	 84.836%	     0.000	        1	[efficientnetv2-l/block6n_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6n_project_conv/Conv2D]:901
	                     ADD	        75808.399	    0.850	    0.851	  0.001%	 84.837%	     0.000	        1	[efficientnetv2-l/block6n_add/add]:902
	                 CONV_2D	        75809.258	  187.408	  187.328	  0.210%	 85.046%	     0.000	        1	[efficientnetv2-l/block6o_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_expand_conv/Conv2D]:903
	                LOGISTIC	        75996.614	  160.160	  160.100	  0.179%	 85.225%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/Sigmoid]:904
	                     MUL	        76156.724	    4.872	    4.873	  0.005%	 85.231%	     0.000	        1	[efficientnetv2-l/block6o_expand_activation/mul_1]:905
	       DEPTHWISE_CONV_2D	        76161.609	    4.317	    4.341	  0.005%	 85.236%	     0.000	        1	[efficientnetv2-l/block6o_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:906
	                LOGISTIC	        76165.963	  156.686	  156.642	  0.175%	 85.411%	     0.000	        1	[efficientnetv2-l/block6o_activation/Sigmoid]:907
	                     MUL	        76322.617	    4.891	    4.886	  0.005%	 85.417%	     0.000	        1	[efficientnetv2-l/block6o_activation/mul_1]:908
	                    MEAN	        76327.513	   84.370	   84.430	  0.094%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_squeeze/Mean]:909
	                   SHAPE	        76411.955	    0.008	    0.008	  0.000%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Shape]:910
	           STRIDED_SLICE	        76411.969	    0.021	    0.021	  0.000%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/strided_slice]:911
	                    PACK	        76411.996	    0.030	    0.028	  0.000%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape/shape]:912
	                 RESHAPE	        76412.031	    0.016	    0.016	  0.000%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_reshape/Reshape]:913
	                 CONV_2D	        76412.053	    0.138	    0.140	  0.000%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_reduce/Conv2D]:914
	                LOGISTIC	        76412.201	    0.043	    0.043	  0.000%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/Sigmoid]:915
	                     MUL	        76412.250	    0.013	    0.013	  0.000%	 85.511%	     0.000	        1	[efficientnetv2-l/block6o_se_reduce/mul_1]:916
	                 CONV_2D	        76412.269	    0.865	    0.869	  0.001%	 85.512%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_se_expand/Conv2D]:917
	                LOGISTIC	        76413.144	    0.747	    0.748	  0.001%	 85.513%	     0.000	        1	[efficientnetv2-l/block6o_se_expand/Sigmoid]:918
	                     MUL	        76413.898	    4.842	    4.835	  0.005%	 85.519%	     0.000	        1	[efficientnetv2-l/block6o_se_excite/mul]:919
	                 CONV_2D	        76418.745	   37.191	   37.194	  0.042%	 85.560%	     0.000	        1	[efficientnetv2-l/block6o_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6o_project_conv/Conv2D]:920
	                     ADD	        76455.950	    0.848	    0.868	  0.001%	 85.561%	     0.000	        1	[efficientnetv2-l/block6o_add/add]:921
	                 CONV_2D	        76456.826	  187.490	  187.850	  0.210%	 85.771%	     0.000	        1	[efficientnetv2-l/block6p_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_expand_conv/Conv2D]:922
	                LOGISTIC	        76644.689	  160.957	  161.183	  0.180%	 85.952%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/Sigmoid]:923
	                     MUL	        76805.883	    4.957	    4.928	  0.006%	 85.957%	     0.000	        1	[efficientnetv2-l/block6p_expand_activation/mul_1]:924
	       DEPTHWISE_CONV_2D	        76810.822	    3.825	    3.835	  0.004%	 85.962%	     0.000	        1	[efficientnetv2-l/block6p_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:925
	                LOGISTIC	        76814.670	   82.659	   82.826	  0.093%	 86.054%	     0.000	        1	[efficientnetv2-l/block6p_activation/Sigmoid]:926
	                     MUL	        76897.507	    4.884	    4.893	  0.005%	 86.060%	     0.000	        1	[efficientnetv2-l/block6p_activation/mul_1]:927
	                    MEAN	        76902.412	   84.401	   84.358	  0.094%	 86.154%	     0.000	        1	[efficientnetv2-l/block6p_se_squeeze/Mean]:928
	                   SHAPE	        76986.780	    0.009	    0.009	  0.000%	 86.154%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Shape]:929
	           STRIDED_SLICE	        76986.795	    0.020	    0.019	  0.000%	 86.154%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/strided_slice]:930
	                    PACK	        76986.822	    0.028	    0.027	  0.000%	 86.154%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape/shape]:931
	                 RESHAPE	        76986.856	    0.016	    0.017	  0.000%	 86.154%	     0.000	        1	[efficientnetv2-l/block6p_se_reshape/Reshape]:932
	                 CONV_2D	        76986.879	    0.136	    0.138	  0.000%	 86.154%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_reduce/Conv2D]:933
	                LOGISTIC	        76987.023	    0.035	    0.036	  0.000%	 86.154%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/Sigmoid]:934
	                     MUL	        76987.066	    0.014	    0.013	  0.000%	 86.155%	     0.000	        1	[efficientnetv2-l/block6p_se_reduce/mul_1]:935
	                 CONV_2D	        76987.086	    0.866	    0.864	  0.001%	 86.155%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_se_expand/Conv2D]:936
	                LOGISTIC	        76987.957	    0.405	    0.393	  0.000%	 86.156%	     0.000	        1	[efficientnetv2-l/block6p_se_expand/Sigmoid]:937
	                     MUL	        76988.356	    4.821	    4.834	  0.005%	 86.161%	     0.000	        1	[efficientnetv2-l/block6p_se_excite/mul]:938
	                 CONV_2D	        76993.202	   35.322	   35.333	  0.040%	 86.201%	     0.000	        1	[efficientnetv2-l/block6p_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6p_project_conv/Conv2D]:939
	                     ADD	        77028.548	    0.851	    0.850	  0.001%	 86.202%	     0.000	        1	[efficientnetv2-l/block6p_add/add]:940
	                 CONV_2D	        77029.405	  187.204	  187.240	  0.210%	 86.411%	     0.000	        1	[efficientnetv2-l/block6q_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_expand_conv/Conv2D]:941
	                LOGISTIC	        77216.658	  152.191	  152.289	  0.170%	 86.582%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/Sigmoid]:942
	                     MUL	        77368.959	    4.967	    4.949	  0.006%	 86.587%	     0.000	        1	[efficientnetv2-l/block6q_expand_activation/mul_1]:943
	       DEPTHWISE_CONV_2D	        77373.917	    4.176	    3.965	  0.004%	 86.592%	     0.000	        1	[efficientnetv2-l/block6q_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:944
	                LOGISTIC	        77377.897	   83.063	   83.001	  0.093%	 86.685%	     0.000	        1	[efficientnetv2-l/block6q_activation/Sigmoid]:945
	                     MUL	        77460.909	    4.866	    4.869	  0.005%	 86.690%	     0.000	        1	[efficientnetv2-l/block6q_activation/mul_1]:946
	                    MEAN	        77465.788	   84.529	   84.470	  0.095%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_squeeze/Mean]:947
	                   SHAPE	        77550.269	    0.009	    0.013	  0.000%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Shape]:948
	           STRIDED_SLICE	        77550.288	    0.023	    0.022	  0.000%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/strided_slice]:949
	                    PACK	        77550.318	    0.033	    0.029	  0.000%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape/shape]:950
	                 RESHAPE	        77550.353	    0.017	    0.017	  0.000%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_reshape/Reshape]:951
	                 CONV_2D	        77550.376	    0.147	    0.141	  0.000%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_reduce/Conv2D]:952
	                LOGISTIC	        77550.527	    0.041	    0.038	  0.000%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/Sigmoid]:953
	                     MUL	        77550.572	    0.013	    0.013	  0.000%	 86.785%	     0.000	        1	[efficientnetv2-l/block6q_se_reduce/mul_1]:954
	                 CONV_2D	        77550.591	    0.907	    0.884	  0.001%	 86.786%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_se_expand/Conv2D]:955
	                LOGISTIC	        77551.485	    0.418	    0.401	  0.000%	 86.786%	     0.000	        1	[efficientnetv2-l/block6q_se_expand/Sigmoid]:956
	                     MUL	        77551.893	    4.856	    4.841	  0.005%	 86.792%	     0.000	        1	[efficientnetv2-l/block6q_se_excite/mul]:957
	                 CONV_2D	        77556.746	   35.945	   35.752	  0.040%	 86.832%	     0.000	        1	[efficientnetv2-l/block6q_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6q_project_conv/Conv2D]:958
	                     ADD	        77592.509	    0.856	    0.854	  0.001%	 86.833%	     0.000	        1	[efficientnetv2-l/block6q_add/add]:959
	                 CONV_2D	        77593.370	  187.426	  186.874	  0.209%	 87.042%	     0.000	        1	[efficientnetv2-l/block6r_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_expand_conv/Conv2D]:960
	                LOGISTIC	        77780.257	  156.388	  156.321	  0.175%	 87.217%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/Sigmoid]:961
	                     MUL	        77936.590	    4.921	    4.895	  0.005%	 87.222%	     0.000	        1	[efficientnetv2-l/block6r_expand_activation/mul_1]:962
	       DEPTHWISE_CONV_2D	        77941.496	    3.789	    3.784	  0.004%	 87.227%	     0.000	        1	[efficientnetv2-l/block6r_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:963
	                LOGISTIC	        77945.292	   82.667	   82.759	  0.093%	 87.319%	     0.000	        1	[efficientnetv2-l/block6r_activation/Sigmoid]:964
	                     MUL	        78028.064	    4.876	    4.883	  0.005%	 87.325%	     0.000	        1	[efficientnetv2-l/block6r_activation/mul_1]:965
	                    MEAN	        78032.958	   84.558	   84.548	  0.095%	 87.419%	     0.000	        1	[efficientnetv2-l/block6r_se_squeeze/Mean]:966
	                   SHAPE	        78117.516	    0.009	    0.009	  0.000%	 87.419%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Shape]:967
	           STRIDED_SLICE	        78117.531	    0.022	    0.021	  0.000%	 87.419%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/strided_slice]:968
	                    PACK	        78117.559	    0.030	    0.028	  0.000%	 87.419%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape/shape]:969
	                 RESHAPE	        78117.593	    0.017	    0.017	  0.000%	 87.419%	     0.000	        1	[efficientnetv2-l/block6r_se_reshape/Reshape]:970
	                 CONV_2D	        78117.616	    0.133	    0.135	  0.000%	 87.420%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_reduce/Conv2D]:971
	                LOGISTIC	        78117.759	    0.035	    0.036	  0.000%	 87.420%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/Sigmoid]:972
	                     MUL	        78117.802	    0.013	    0.013	  0.000%	 87.420%	     0.000	        1	[efficientnetv2-l/block6r_se_reduce/mul_1]:973
	                 CONV_2D	        78117.821	    0.862	    0.864	  0.001%	 87.421%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_se_expand/Conv2D]:974
	                LOGISTIC	        78118.692	    0.384	    0.373	  0.000%	 87.421%	     0.000	        1	[efficientnetv2-l/block6r_se_expand/Sigmoid]:975
	                     MUL	        78119.072	    4.823	    4.832	  0.005%	 87.426%	     0.000	        1	[efficientnetv2-l/block6r_se_excite/mul]:976
	                 CONV_2D	        78123.916	   35.630	   35.510	  0.040%	 87.466%	     0.000	        1	[efficientnetv2-l/block6r_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6r_project_conv/Conv2D]:977
	                     ADD	        78159.436	    0.846	    0.867	  0.001%	 87.467%	     0.000	        1	[efficientnetv2-l/block6r_add/add]:978
	                 CONV_2D	        78160.311	  187.593	  187.533	  0.210%	 87.677%	     0.000	        1	[efficientnetv2-l/block6s_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_expand_conv/Conv2D]:979
	                LOGISTIC	        78347.857	  154.464	  154.466	  0.173%	 87.850%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/Sigmoid]:980
	                     MUL	        78502.336	    4.889	    4.886	  0.005%	 87.855%	     0.000	        1	[efficientnetv2-l/block6s_expand_activation/mul_1]:981
	       DEPTHWISE_CONV_2D	        78507.232	    3.761	    3.793	  0.004%	 87.860%	     0.000	        1	[efficientnetv2-l/block6s_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:982
	                LOGISTIC	        78511.038	   82.867	   82.850	  0.093%	 87.952%	     0.000	        1	[efficientnetv2-l/block6s_activation/Sigmoid]:983
	                     MUL	        78593.899	    4.877	    4.876	  0.005%	 87.958%	     0.000	        1	[efficientnetv2-l/block6s_activation/mul_1]:984
	                    MEAN	        78598.788	   84.380	   84.409	  0.094%	 88.052%	     0.000	        1	[efficientnetv2-l/block6s_se_squeeze/Mean]:985
	                   SHAPE	        78683.208	    0.008	    0.009	  0.000%	 88.052%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Shape]:986
	           STRIDED_SLICE	        78683.227	    0.020	    0.021	  0.000%	 88.052%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/strided_slice]:987
	                    PACK	        78683.254	    0.030	    0.028	  0.000%	 88.052%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape/shape]:988
	                 RESHAPE	        78683.288	    0.016	    0.016	  0.000%	 88.052%	     0.000	        1	[efficientnetv2-l/block6s_se_reshape/Reshape]:989
	                 CONV_2D	        78683.311	    0.131	    0.133	  0.000%	 88.053%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_reduce/Conv2D]:990
	                LOGISTIC	        78683.452	    0.037	    0.057	  0.000%	 88.053%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/Sigmoid]:991
	                     MUL	        78683.515	    0.014	    0.013	  0.000%	 88.053%	     0.000	        1	[efficientnetv2-l/block6s_se_reduce/mul_1]:992
	                 CONV_2D	        78683.534	    0.860	    0.863	  0.001%	 88.054%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_se_expand/Conv2D]:993
	                LOGISTIC	        78684.405	    0.378	    0.378	  0.000%	 88.054%	     0.000	        1	[efficientnetv2-l/block6s_se_expand/Sigmoid]:994
	                     MUL	        78684.788	    4.822	    4.827	  0.005%	 88.059%	     0.000	        1	[efficientnetv2-l/block6s_se_excite/mul]:995
	                 CONV_2D	        78689.626	   36.677	   36.758	  0.041%	 88.101%	     0.000	        1	[efficientnetv2-l/block6s_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6s_project_conv/Conv2D]:996
	                     ADD	        78726.398	    0.868	    0.872	  0.001%	 88.102%	     0.000	        1	[efficientnetv2-l/block6s_add/add]:997
	                 CONV_2D	        78727.279	  186.549	  186.812	  0.209%	 88.311%	     0.000	        1	[efficientnetv2-l/block6t_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_expand_conv/Conv2D]:998
	                LOGISTIC	        78914.103	  153.572	  153.865	  0.172%	 88.483%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/Sigmoid]:999
	                     MUL	        79067.981	    4.873	    4.875	  0.005%	 88.488%	     0.000	        1	[efficientnetv2-l/block6t_expand_activation/mul_1]:1000
	       DEPTHWISE_CONV_2D	        79072.867	    4.416	    4.408	  0.005%	 88.493%	     0.000	        1	[efficientnetv2-l/block6t_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1001
	                LOGISTIC	        79077.288	  148.803	  148.965	  0.167%	 88.660%	     0.000	        1	[efficientnetv2-l/block6t_activation/Sigmoid]:1002
	                     MUL	        79226.265	    4.876	    4.934	  0.006%	 88.665%	     0.000	        1	[efficientnetv2-l/block6t_activation/mul_1]:1003
	                    MEAN	        79231.209	   84.451	   84.436	  0.095%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_squeeze/Mean]:1004
	                   SHAPE	        79315.656	    0.009	    0.009	  0.000%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Shape]:1005
	           STRIDED_SLICE	        79315.670	    0.022	    0.021	  0.000%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/strided_slice]:1006
	                    PACK	        79315.698	    0.030	    0.028	  0.000%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape/shape]:1007
	                 RESHAPE	        79315.733	    0.016	    0.017	  0.000%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_reshape/Reshape]:1008
	                 CONV_2D	        79315.756	    0.159	    0.150	  0.000%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_reduce/Conv2D]:1009
	                LOGISTIC	        79315.914	    0.055	    0.056	  0.000%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/Sigmoid]:1010
	                     MUL	        79315.976	    0.013	    0.013	  0.000%	 88.760%	     0.000	        1	[efficientnetv2-l/block6t_se_reduce/mul_1]:1011
	                 CONV_2D	        79315.995	    0.868	    0.867	  0.001%	 88.761%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_se_expand/Conv2D]:1012
	                LOGISTIC	        79316.868	    0.745	    0.744	  0.001%	 88.762%	     0.000	        1	[efficientnetv2-l/block6t_se_expand/Sigmoid]:1013
	                     MUL	        79317.618	    4.834	    4.852	  0.005%	 88.768%	     0.000	        1	[efficientnetv2-l/block6t_se_excite/mul]:1014
	                 CONV_2D	        79322.481	   36.934	   37.000	  0.041%	 88.809%	     0.000	        1	[efficientnetv2-l/block6t_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6t_project_conv/Conv2D]:1015
	                     ADD	        79359.493	    0.824	    0.810	  0.001%	 88.810%	     0.000	        1	[efficientnetv2-l/block6t_add/add]:1016
	                 CONV_2D	        79360.312	  187.604	  187.735	  0.210%	 89.020%	     0.000	        1	[efficientnetv2-l/block6u_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_expand_conv/Conv2D]:1017
	                LOGISTIC	        79548.060	  160.281	  160.238	  0.179%	 89.199%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/Sigmoid]:1018
	                     MUL	        79708.310	    4.873	    4.898	  0.005%	 89.205%	     0.000	        1	[efficientnetv2-l/block6u_expand_activation/mul_1]:1019
	       DEPTHWISE_CONV_2D	        79713.218	    4.385	    4.374	  0.005%	 89.210%	     0.000	        1	[efficientnetv2-l/block6u_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1020
	                LOGISTIC	        79717.606	  156.635	  156.498	  0.175%	 89.385%	     0.000	        1	[efficientnetv2-l/block6u_activation/Sigmoid]:1021
	                     MUL	        79874.116	    4.883	    4.884	  0.005%	 89.390%	     0.000	        1	[efficientnetv2-l/block6u_activation/mul_1]:1022
	                    MEAN	        79879.011	   84.624	   84.538	  0.095%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_squeeze/Mean]:1023
	                   SHAPE	        79963.560	    0.012	    0.011	  0.000%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Shape]:1024
	           STRIDED_SLICE	        79963.576	    0.025	    0.023	  0.000%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/strided_slice]:1025
	                    PACK	        79963.606	    0.033	    0.029	  0.000%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape/shape]:1026
	                 RESHAPE	        79963.642	    0.016	    0.016	  0.000%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_reshape/Reshape]:1027
	                 CONV_2D	        79963.664	    0.183	    0.161	  0.000%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_reduce/Conv2D]:1028
	                LOGISTIC	        79963.834	    0.068	    0.061	  0.000%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/Sigmoid]:1029
	                     MUL	        79963.902	    0.018	    0.015	  0.000%	 89.485%	     0.000	        1	[efficientnetv2-l/block6u_se_reduce/mul_1]:1030
	                 CONV_2D	        79963.924	    0.944	    0.904	  0.001%	 89.486%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_se_expand/Conv2D]:1031
	                LOGISTIC	        79964.837	    0.381	    0.377	  0.000%	 89.487%	     0.000	        1	[efficientnetv2-l/block6u_se_expand/Sigmoid]:1032
	                     MUL	        79965.219	    4.843	    4.846	  0.005%	 89.492%	     0.000	        1	[efficientnetv2-l/block6u_se_excite/mul]:1033
	                 CONV_2D	        79970.076	   37.540	   37.234	  0.042%	 89.534%	     0.000	        1	[efficientnetv2-l/block6u_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6u_project_conv/Conv2D]:1034
	                     ADD	        80007.324	    0.873	    0.860	  0.001%	 89.535%	     0.000	        1	[efficientnetv2-l/block6u_add/add]:1035
	                 CONV_2D	        80008.194	  188.218	  187.875	  0.210%	 89.745%	     0.000	        1	[efficientnetv2-l/block6v_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_expand_conv/Conv2D]:1036
	                LOGISTIC	        80196.082	  156.418	  156.260	  0.175%	 89.920%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/Sigmoid]:1037
	                     MUL	        80352.353	    4.873	    4.875	  0.005%	 89.925%	     0.000	        1	[efficientnetv2-l/block6v_expand_activation/mul_1]:1038
	       DEPTHWISE_CONV_2D	        80357.239	    3.806	    3.782	  0.004%	 89.930%	     0.000	        1	[efficientnetv2-l/block6v_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1039
	                LOGISTIC	        80361.034	   82.612	   82.793	  0.093%	 90.022%	     0.000	        1	[efficientnetv2-l/block6v_activation/Sigmoid]:1040
	                     MUL	        80443.840	    4.916	    4.894	  0.005%	 90.028%	     0.000	        1	[efficientnetv2-l/block6v_activation/mul_1]:1041
	                    MEAN	        80448.745	   84.480	   84.490	  0.095%	 90.122%	     0.000	        1	[efficientnetv2-l/block6v_se_squeeze/Mean]:1042
	                   SHAPE	        80533.246	    0.009	    0.009	  0.000%	 90.122%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Shape]:1043
	           STRIDED_SLICE	        80533.261	    0.020	    0.020	  0.000%	 90.122%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/strided_slice]:1044
	                    PACK	        80533.288	    0.028	    0.026	  0.000%	 90.122%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape/shape]:1045
	                 RESHAPE	        80533.321	    0.016	    0.016	  0.000%	 90.122%	     0.000	        1	[efficientnetv2-l/block6v_se_reshape/Reshape]:1046
	                 CONV_2D	        80533.343	    0.135	    0.136	  0.000%	 90.123%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_reduce/Conv2D]:1047
	                LOGISTIC	        80533.487	    0.037	    0.036	  0.000%	 90.123%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/Sigmoid]:1048
	                     MUL	        80533.530	    0.013	    0.013	  0.000%	 90.123%	     0.000	        1	[efficientnetv2-l/block6v_se_reduce/mul_1]:1049
	                 CONV_2D	        80533.549	    0.871	    0.870	  0.001%	 90.124%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_se_expand/Conv2D]:1050
	                LOGISTIC	        80534.425	    0.386	    0.385	  0.000%	 90.124%	     0.000	        1	[efficientnetv2-l/block6v_se_expand/Sigmoid]:1051
	                     MUL	        80534.816	    4.833	    4.855	  0.005%	 90.129%	     0.000	        1	[efficientnetv2-l/block6v_se_excite/mul]:1052
	                 CONV_2D	        80539.682	   35.511	   35.516	  0.040%	 90.169%	     0.000	        1	[efficientnetv2-l/block6v_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6v_project_conv/Conv2D]:1053
	                     ADD	        80575.210	    0.795	    0.820	  0.001%	 90.170%	     0.000	        1	[efficientnetv2-l/block6v_add/add]:1054
	                 CONV_2D	        80576.038	  186.516	  186.444	  0.209%	 90.379%	     0.000	        1	[efficientnetv2-l/block6w_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_expand_conv/Conv2D]:1055
	                LOGISTIC	        80762.495	  155.192	  155.207	  0.174%	 90.552%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/Sigmoid]:1056
	                     MUL	        80917.714	    4.870	    4.907	  0.005%	 90.558%	     0.000	        1	[efficientnetv2-l/block6w_expand_activation/mul_1]:1057
	       DEPTHWISE_CONV_2D	        80922.632	    4.352	    4.367	  0.005%	 90.563%	     0.000	        1	[efficientnetv2-l/block6w_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1058
	                LOGISTIC	        80927.011	  149.894	  149.923	  0.168%	 90.731%	     0.000	        1	[efficientnetv2-l/block6w_activation/Sigmoid]:1059
	                     MUL	        81076.946	    4.878	    4.880	  0.005%	 90.736%	     0.000	        1	[efficientnetv2-l/block6w_activation/mul_1]:1060
	                    MEAN	        81081.837	   84.369	   84.385	  0.094%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_squeeze/Mean]:1061
	                   SHAPE	        81166.233	    0.009	    0.009	  0.000%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Shape]:1062
	           STRIDED_SLICE	        81166.249	    0.019	    0.021	  0.000%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/strided_slice]:1063
	                    PACK	        81166.276	    0.031	    0.028	  0.000%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape/shape]:1064
	                 RESHAPE	        81166.311	    0.016	    0.016	  0.000%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_reshape/Reshape]:1065
	                 CONV_2D	        81166.333	    0.138	    0.141	  0.000%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_reduce/Conv2D]:1066
	                LOGISTIC	        81166.482	    0.043	    0.043	  0.000%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/Sigmoid]:1067
	                     MUL	        81166.533	    0.013	    0.013	  0.000%	 90.831%	     0.000	        1	[efficientnetv2-l/block6w_se_reduce/mul_1]:1068
	                 CONV_2D	        81166.552	    0.913	    0.906	  0.001%	 90.832%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_se_expand/Conv2D]:1069
	                LOGISTIC	        81167.465	    0.749	    0.750	  0.001%	 90.833%	     0.000	        1	[efficientnetv2-l/block6w_se_expand/Sigmoid]:1070
	                     MUL	        81168.221	    4.842	    4.848	  0.005%	 90.838%	     0.000	        1	[efficientnetv2-l/block6w_se_excite/mul]:1071
	                 CONV_2D	        81173.080	   38.180	   38.355	  0.043%	 90.881%	     0.000	        1	[efficientnetv2-l/block6w_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6w_project_conv/Conv2D]:1072
	                     ADD	        81211.447	    0.844	    0.846	  0.001%	 90.882%	     0.000	        1	[efficientnetv2-l/block6w_add/add]:1073
	                 CONV_2D	        81212.302	  187.166	  187.431	  0.210%	 91.092%	     0.000	        1	[efficientnetv2-l/block6x_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_expand_conv/Conv2D]:1074
	                LOGISTIC	        81399.745	  161.012	  161.190	  0.180%	 91.272%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/Sigmoid]:1075
	                     MUL	        81560.946	    4.876	    4.915	  0.006%	 91.278%	     0.000	        1	[efficientnetv2-l/block6x_expand_activation/mul_1]:1076
	       DEPTHWISE_CONV_2D	        81565.872	    4.405	    4.399	  0.005%	 91.283%	     0.000	        1	[efficientnetv2-l/block6x_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1077
	                LOGISTIC	        81570.284	  155.722	  155.712	  0.174%	 91.457%	     0.000	        1	[efficientnetv2-l/block6x_activation/Sigmoid]:1078
	                     MUL	        81726.008	    4.877	    4.882	  0.005%	 91.462%	     0.000	        1	[efficientnetv2-l/block6x_activation/mul_1]:1079
	                    MEAN	        81730.901	   84.413	   84.404	  0.094%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_squeeze/Mean]:1080
	                   SHAPE	        81815.317	    0.009	    0.009	  0.000%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Shape]:1081
	           STRIDED_SLICE	        81815.333	    0.021	    0.021	  0.000%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/strided_slice]:1082
	                    PACK	        81815.360	    0.029	    0.027	  0.000%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape/shape]:1083
	                 RESHAPE	        81815.394	    0.016	    0.016	  0.000%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_reshape/Reshape]:1084
	                 CONV_2D	        81815.416	    0.137	    0.140	  0.000%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_reduce/Conv2D]:1085
	                LOGISTIC	        81815.563	    0.047	    0.048	  0.000%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/Sigmoid]:1086
	                     MUL	        81815.617	    0.013	    0.013	  0.000%	 91.557%	     0.000	        1	[efficientnetv2-l/block6x_se_reduce/mul_1]:1087
	                 CONV_2D	        81815.636	    0.885	    0.875	  0.001%	 91.558%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_se_expand/Conv2D]:1088
	                LOGISTIC	        81816.519	    0.740	    0.740	  0.001%	 91.559%	     0.000	        1	[efficientnetv2-l/block6x_se_expand/Sigmoid]:1089
	                     MUL	        81817.265	    4.852	    4.853	  0.005%	 91.564%	     0.000	        1	[efficientnetv2-l/block6x_se_excite/mul]:1090
	                 CONV_2D	        81822.130	   37.471	   37.371	  0.042%	 91.606%	     0.000	        1	[efficientnetv2-l/block6x_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6x_project_conv/Conv2D]:1091
	                     ADD	        81859.514	    0.815	    0.831	  0.001%	 91.607%	     0.000	        1	[efficientnetv2-l/block6x_add/add]:1092
	                 CONV_2D	        81860.354	  187.806	  187.786	  0.210%	 91.817%	     0.000	        1	[efficientnetv2-l/block6y_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_expand_conv/Conv2D]:1093
	                LOGISTIC	        82048.152	  161.129	  161.017	  0.180%	 91.997%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/Sigmoid]:1094
	                     MUL	        82209.180	    4.875	    4.873	  0.005%	 92.003%	     0.000	        1	[efficientnetv2-l/block6y_expand_activation/mul_1]:1095
	       DEPTHWISE_CONV_2D	        82214.064	    3.757	    3.736	  0.004%	 92.007%	     0.000	        1	[efficientnetv2-l/block6y_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_dwconv2/depthwise;efficientnetv2-l/block7a_bn/FusedBatchNormV3]:1096
	                LOGISTIC	        82217.812	   83.071	   82.895	  0.093%	 92.100%	     0.000	        1	[efficientnetv2-l/block6y_activation/Sigmoid]:1097
	                     MUL	        82300.719	    4.896	    4.888	  0.005%	 92.105%	     0.000	        1	[efficientnetv2-l/block6y_activation/mul_1]:1098
	                    MEAN	        82305.617	   84.530	   84.472	  0.095%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_squeeze/Mean]:1099
	                   SHAPE	        82390.102	    0.008	    0.009	  0.000%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Shape]:1100
	           STRIDED_SLICE	        82390.116	    0.024	    0.022	  0.000%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/strided_slice]:1101
	                    PACK	        82390.145	    0.034	    0.030	  0.000%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape/shape]:1102
	                 RESHAPE	        82390.182	    0.019	    0.018	  0.000%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_reshape/Reshape]:1103
	                 CONV_2D	        82390.205	    0.141	    0.140	  0.000%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_reduce/Conv2D]:1104
	                LOGISTIC	        82390.352	    0.040	    0.038	  0.000%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/Sigmoid]:1105
	                     MUL	        82390.397	    0.014	    0.013	  0.000%	 92.200%	     0.000	        1	[efficientnetv2-l/block6y_se_reduce/mul_1]:1106
	                 CONV_2D	        82390.416	    0.900	    0.887	  0.001%	 92.201%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_se_expand/Conv2D]:1107
	                LOGISTIC	        82391.311	    0.389	    0.383	  0.000%	 92.202%	     0.000	        1	[efficientnetv2-l/block6y_se_expand/Sigmoid]:1108
	                     MUL	        82391.701	    4.866	    4.856	  0.005%	 92.207%	     0.000	        1	[efficientnetv2-l/block6y_se_excite/mul]:1109
	                 CONV_2D	        82396.568	   35.699	   35.572	  0.040%	 92.247%	     0.000	        1	[efficientnetv2-l/block6y_project_bn/FusedBatchNormV3;efficientnetv2-l/block3b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block6y_project_conv/Conv2D]:1110
	                     ADD	        82432.152	    0.857	    0.852	  0.001%	 92.248%	     0.000	        1	[efficientnetv2-l/block6y_add/add]:1111
	                 CONV_2D	        82433.011	  186.985	  186.810	  0.209%	 92.457%	     0.000	        1	[efficientnetv2-l/block7a_expand_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_expand_conv/Conv2D]:1112
	                LOGISTIC	        82619.833	  154.061	  153.921	  0.172%	 92.629%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/Sigmoid]:1113
	                     MUL	        82773.765	    4.874	    4.874	  0.005%	 92.635%	     0.000	        1	[efficientnetv2-l/block7a_expand_activation/mul_1]:1114
	       DEPTHWISE_CONV_2D	        82778.649	    3.818	    3.804	  0.004%	 92.639%	     0.000	        1	[efficientnetv2-l/block7a_bn/FusedBatchNormV3;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_dwconv2/depthwise]:1115
	                LOGISTIC	        82782.466	   82.841	   82.931	  0.093%	 92.732%	     0.000	        1	[efficientnetv2-l/block7a_activation/Sigmoid]:1116
	                     MUL	        82865.410	    4.876	    4.913	  0.005%	 92.737%	     0.000	        1	[efficientnetv2-l/block7a_activation/mul_1]:1117
	                    MEAN	        82870.334	   84.538	   84.528	  0.095%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_squeeze/Mean]:1118
	                   SHAPE	        82954.874	    0.009	    0.009	  0.000%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Shape]:1119
	           STRIDED_SLICE	        82954.889	    0.021	    0.021	  0.000%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/strided_slice]:1120
	                    PACK	        82954.916	    0.031	    0.028	  0.000%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape/shape]:1121
	                 RESHAPE	        82954.950	    0.017	    0.017	  0.000%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_reshape/Reshape]:1122
	                 CONV_2D	        82954.973	    0.137	    0.138	  0.000%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/BiasAdd;efficientnetv2-l/block3a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_reduce/Conv2D]:1123
	                LOGISTIC	        82955.120	    0.036	    0.036	  0.000%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/Sigmoid]:1124
	                     MUL	        82955.163	    0.013	    0.013	  0.000%	 92.832%	     0.000	        1	[efficientnetv2-l/block7a_se_reduce/mul_1]:1125
	                 CONV_2D	        82955.182	    0.863	    0.878	  0.001%	 92.833%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/BiasAdd;efficientnetv2-l/block6b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_se_expand/Conv2D]:1126
	                LOGISTIC	        82956.068	    0.366	    0.374	  0.000%	 92.834%	     0.000	        1	[efficientnetv2-l/block7a_se_expand/Sigmoid]:1127
	                     MUL	        82956.449	    4.826	    4.842	  0.005%	 92.839%	     0.000	        1	[efficientnetv2-l/block7a_se_excite/mul]:1128
	                 CONV_2D	        82961.303	   57.520	   57.541	  0.064%	 92.903%	     0.000	        1	[efficientnetv2-l/block7a_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7a_project_conv/Conv2D]:1129
	                 CONV_2D	        83018.856	  307.699	  307.646	  0.344%	 93.248%	     0.000	        1	[efficientnetv2-l/block7b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_expand_conv/Conv2D]:1130
	                LOGISTIC	        83326.514	  228.006	  228.068	  0.255%	 93.503%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/Sigmoid]:1131
	                     MUL	        83554.595	    8.166	    8.181	  0.009%	 93.512%	     0.000	        1	[efficientnetv2-l/block7b_expand_activation/mul_1]:1132
	       DEPTHWISE_CONV_2D	        83562.788	    7.600	    7.693	  0.009%	 93.521%	     0.000	        1	[efficientnetv2-l/block7b_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1133
	                LOGISTIC	        83570.494	  211.432	  211.450	  0.237%	 93.757%	     0.000	        1	[efficientnetv2-l/block7b_activation/Sigmoid]:1134
	                     MUL	        83781.955	    8.192	    8.242	  0.009%	 93.767%	     0.000	        1	[efficientnetv2-l/block7b_activation/mul_1]:1135
	                    MEAN	        83790.209	  140.687	  140.865	  0.158%	 93.924%	     0.000	        1	[efficientnetv2-l/block7b_se_squeeze/Mean]:1136
	                   SHAPE	        83931.086	    0.008	    0.009	  0.000%	 93.924%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Shape]:1137
	           STRIDED_SLICE	        83931.101	    0.022	    0.022	  0.000%	 93.924%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/strided_slice]:1138
	                    PACK	        83931.129	    0.029	    0.028	  0.000%	 93.924%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape/shape]:1139
	                 RESHAPE	        83931.163	    0.018	    0.018	  0.000%	 93.924%	     0.000	        1	[efficientnetv2-l/block7b_se_reshape/Reshape]:1140
	                 CONV_2D	        83931.188	    0.185	    0.185	  0.000%	 93.924%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7b_se_reduce/Conv2D]:1141
	                LOGISTIC	        83931.381	    0.073	    0.074	  0.000%	 93.925%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/Sigmoid]:1142
	                     MUL	        83931.462	    0.013	    0.014	  0.000%	 93.925%	     0.000	        1	[efficientnetv2-l/block7b_se_reduce/mul_1]:1143
	                 CONV_2D	        83931.482	    1.420	    1.429	  0.002%	 93.926%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_se_expand/Conv2D]:1144
	                LOGISTIC	        83932.920	    1.216	    1.228	  0.001%	 93.928%	     0.000	        1	[efficientnetv2-l/block7b_se_expand/Sigmoid]:1145
	                     MUL	        83934.154	    8.022	    8.042	  0.009%	 93.937%	     0.000	        1	[efficientnetv2-l/block7b_se_excite/mul]:1146
	                 CONV_2D	        83942.208	   63.284	   63.473	  0.071%	 94.008%	     0.000	        1	[efficientnetv2-l/block7b_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7b_project_conv/Conv2D]:1147
	                     ADD	        84005.694	    1.444	    1.447	  0.002%	 94.009%	     0.000	        1	[efficientnetv2-l/block7b_add/add]:1148
	                 CONV_2D	        84007.150	  307.481	  307.548	  0.344%	 94.353%	     0.000	        1	[efficientnetv2-l/block7c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_expand_conv/Conv2D]:1149
	                LOGISTIC	        84314.711	  253.597	  253.550	  0.284%	 94.637%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/Sigmoid]:1150
	                     MUL	        84568.273	    8.207	    8.231	  0.009%	 94.646%	     0.000	        1	[efficientnetv2-l/block7c_expand_activation/mul_1]:1151
	       DEPTHWISE_CONV_2D	        84576.516	    7.526	    7.509	  0.008%	 94.655%	     0.000	        1	[efficientnetv2-l/block7c_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1152
	                LOGISTIC	        84584.038	  204.767	  204.524	  0.229%	 94.884%	     0.000	        1	[efficientnetv2-l/block7c_activation/Sigmoid]:1153
	                     MUL	        84788.573	    8.261	    8.216	  0.009%	 94.893%	     0.000	        1	[efficientnetv2-l/block7c_activation/mul_1]:1154
	                    MEAN	        84796.801	  141.046	  140.882	  0.158%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_squeeze/Mean]:1155
	                   SHAPE	        84937.695	    0.009	    0.009	  0.000%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Shape]:1156
	           STRIDED_SLICE	        84937.710	    0.022	    0.021	  0.000%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/strided_slice]:1157
	                    PACK	        84937.738	    0.030	    0.028	  0.000%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape/shape]:1158
	                 RESHAPE	        84937.773	    0.019	    0.018	  0.000%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_reshape/Reshape]:1159
	                 CONV_2D	        84937.797	    0.175	    0.174	  0.000%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7c_se_reduce/Conv2D]:1160
	                LOGISTIC	        84937.979	    0.074	    0.073	  0.000%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/Sigmoid]:1161
	                     MUL	        84938.060	    0.014	    0.013	  0.000%	 95.051%	     0.000	        1	[efficientnetv2-l/block7c_se_reduce/mul_1]:1162
	                 CONV_2D	        84938.079	    1.450	    1.446	  0.002%	 95.053%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_se_expand/Conv2D]:1163
	                LOGISTIC	        84939.533	    1.240	    1.238	  0.001%	 95.054%	     0.000	        1	[efficientnetv2-l/block7c_se_expand/Sigmoid]:1164
	                     MUL	        84940.777	    8.069	    8.100	  0.009%	 95.063%	     0.000	        1	[efficientnetv2-l/block7c_se_excite/mul]:1165
	                 CONV_2D	        84948.888	   62.092	   62.091	  0.069%	 95.133%	     0.000	        1	[efficientnetv2-l/block7c_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7c_project_conv/Conv2D]:1166
	                     ADD	        85010.992	    1.336	    1.333	  0.001%	 95.134%	     0.000	        1	[efficientnetv2-l/block7c_add/add]:1167
	                 CONV_2D	        85012.335	  307.330	  307.409	  0.344%	 95.478%	     0.000	        1	[efficientnetv2-l/block7d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_expand_conv/Conv2D]:1168
	                LOGISTIC	        85319.757	  253.184	  253.196	  0.283%	 95.761%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/Sigmoid]:1169
	                     MUL	        85572.965	    8.137	    8.130	  0.009%	 95.771%	     0.000	        1	[efficientnetv2-l/block7d_expand_activation/mul_1]:1170
	       DEPTHWISE_CONV_2D	        85581.106	    7.524	    7.561	  0.008%	 95.779%	     0.000	        1	[efficientnetv2-l/block7d_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1171
	                LOGISTIC	        85588.679	  195.661	  195.577	  0.219%	 95.998%	     0.000	        1	[efficientnetv2-l/block7d_activation/Sigmoid]:1172
	                     MUL	        85784.269	    8.206	    8.177	  0.009%	 96.007%	     0.000	        1	[efficientnetv2-l/block7d_activation/mul_1]:1173
	                    MEAN	        85792.457	  140.893	  140.882	  0.158%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_squeeze/Mean]:1174
	                   SHAPE	        85933.352	    0.009	    0.009	  0.000%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Shape]:1175
	           STRIDED_SLICE	        85933.366	    0.022	    0.022	  0.000%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/strided_slice]:1176
	                    PACK	        85933.394	    0.030	    0.028	  0.000%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape/shape]:1177
	                 RESHAPE	        85933.428	    0.018	    0.018	  0.000%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_reshape/Reshape]:1178
	                 CONV_2D	        85933.453	    0.170	    0.177	  0.000%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7d_se_reduce/Conv2D]:1179
	                LOGISTIC	        85933.639	    0.076	    0.076	  0.000%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/Sigmoid]:1180
	                     MUL	        85933.721	    0.014	    0.014	  0.000%	 96.165%	     0.000	        1	[efficientnetv2-l/block7d_se_reduce/mul_1]:1181
	                 CONV_2D	        85933.742	    1.430	    1.451	  0.002%	 96.167%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_se_expand/Conv2D]:1182
	                LOGISTIC	        85935.201	    1.233	    1.239	  0.001%	 96.168%	     0.000	        1	[efficientnetv2-l/block7d_se_expand/Sigmoid]:1183
	                     MUL	        85936.447	    8.039	    8.021	  0.009%	 96.177%	     0.000	        1	[efficientnetv2-l/block7d_se_excite/mul]:1184
	                 CONV_2D	        85944.481	   61.717	   61.950	  0.069%	 96.246%	     0.000	        1	[efficientnetv2-l/block7d_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7d_project_conv/Conv2D]:1185
	                     ADD	        86006.443	    1.439	    1.395	  0.002%	 96.248%	     0.000	        1	[efficientnetv2-l/block7d_add/add]:1186
	                 CONV_2D	        86007.848	  307.134	  307.471	  0.344%	 96.592%	     0.000	        1	[efficientnetv2-l/block7e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_expand_conv/Conv2D]:1187
	                LOGISTIC	        86315.330	  255.339	  255.402	  0.286%	 96.878%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/Sigmoid]:1188
	                     MUL	        86570.744	    8.221	    8.194	  0.009%	 96.887%	     0.000	        1	[efficientnetv2-l/block7e_expand_activation/mul_1]:1189
	       DEPTHWISE_CONV_2D	        86578.950	    8.943	    8.267	  0.009%	 96.896%	     0.000	        1	[efficientnetv2-l/block7e_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1190
	                LOGISTIC	        86587.234	  184.789	  184.889	  0.207%	 97.103%	     0.000	        1	[efficientnetv2-l/block7e_activation/Sigmoid]:1191
	                     MUL	        86772.135	    8.140	    8.119	  0.009%	 97.112%	     0.000	        1	[efficientnetv2-l/block7e_activation/mul_1]:1192
	                    MEAN	        86780.265	  140.796	  140.821	  0.158%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_squeeze/Mean]:1193
	                   SHAPE	        86921.098	    0.009	    0.009	  0.000%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Shape]:1194
	           STRIDED_SLICE	        86921.113	    0.023	    0.022	  0.000%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/strided_slice]:1195
	                    PACK	        86921.142	    0.032	    0.029	  0.000%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape/shape]:1196
	                 RESHAPE	        86921.177	    0.020	    0.019	  0.000%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_reshape/Reshape]:1197
	                 CONV_2D	        86921.202	    0.180	    0.177	  0.000%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7e_se_reduce/Conv2D]:1198
	                LOGISTIC	        86921.387	    0.074	    0.074	  0.000%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/Sigmoid]:1199
	                     MUL	        86921.467	    0.014	    0.014	  0.000%	 97.270%	     0.000	        1	[efficientnetv2-l/block7e_se_reduce/mul_1]:1200
	                 CONV_2D	        86921.488	    1.420	    1.424	  0.002%	 97.272%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_se_expand/Conv2D]:1201
	                LOGISTIC	        86922.920	    1.289	    1.274	  0.001%	 97.273%	     0.000	        1	[efficientnetv2-l/block7e_se_expand/Sigmoid]:1202
	                     MUL	        86924.201	    8.080	    8.060	  0.009%	 97.282%	     0.000	        1	[efficientnetv2-l/block7e_se_excite/mul]:1203
	                 CONV_2D	        86932.276	   61.957	   61.716	  0.069%	 97.352%	     0.000	        1	[efficientnetv2-l/block7e_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7e_project_conv/Conv2D]:1204
	                     ADD	        86994.003	    1.438	    1.375	  0.002%	 97.353%	     0.000	        1	[efficientnetv2-l/block7e_add/add]:1205
	                 CONV_2D	        86995.386	  311.041	  310.670	  0.348%	 97.701%	     0.000	        1	[efficientnetv2-l/block7f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_expand_conv/Conv2D]:1206
	                LOGISTIC	        87306.072	  256.461	  256.476	  0.287%	 97.988%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/Sigmoid]:1207
	                     MUL	        87562.560	    8.190	    8.187	  0.009%	 97.997%	     0.000	        1	[efficientnetv2-l/block7f_expand_activation/mul_1]:1208
	       DEPTHWISE_CONV_2D	        87570.758	    7.536	    7.614	  0.009%	 98.006%	     0.000	        1	[efficientnetv2-l/block7f_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_dwconv2/depthwise;efficientnetv2-l/block7g_bn/FusedBatchNormV3]:1209
	                LOGISTIC	        87578.384	  243.710	  243.720	  0.273%	 98.278%	     0.000	        1	[efficientnetv2-l/block7f_activation/Sigmoid]:1210
	                     MUL	        87822.116	    8.117	    8.182	  0.009%	 98.287%	     0.000	        1	[efficientnetv2-l/block7f_activation/mul_1]:1211
	                    MEAN	        87830.310	  140.858	  140.833	  0.158%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_squeeze/Mean]:1212
	                   SHAPE	        87971.154	    0.009	    0.009	  0.000%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Shape]:1213
	           STRIDED_SLICE	        87971.169	    0.022	    0.021	  0.000%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/strided_slice]:1214
	                    PACK	        87971.197	    0.029	    0.027	  0.000%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape/shape]:1215
	                 RESHAPE	        87971.231	    0.018	    0.018	  0.000%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_reshape/Reshape]:1216
	                 CONV_2D	        87971.255	    0.173	    0.175	  0.000%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7f_se_reduce/Conv2D]:1217
	                LOGISTIC	        87971.439	    0.053	    0.063	  0.000%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/Sigmoid]:1218
	                     MUL	        87971.508	    0.013	    0.013	  0.000%	 98.445%	     0.000	        1	[efficientnetv2-l/block7f_se_reduce/mul_1]:1219
	                 CONV_2D	        87971.527	    1.410	    1.453	  0.002%	 98.447%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_se_expand/Conv2D]:1220
	                LOGISTIC	        87972.988	    0.625	    0.613	  0.001%	 98.448%	     0.000	        1	[efficientnetv2-l/block7f_se_expand/Sigmoid]:1221
	                     MUL	        87973.606	    7.990	    8.037	  0.009%	 98.457%	     0.000	        1	[efficientnetv2-l/block7f_se_excite/mul]:1222
	                 CONV_2D	        87981.656	   62.915	   62.870	  0.070%	 98.527%	     0.000	        1	[efficientnetv2-l/block7f_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7f_project_conv/Conv2D]:1223
	                     ADD	        88044.538	    1.399	    1.416	  0.002%	 98.529%	     0.000	        1	[efficientnetv2-l/block7f_add/add]:1224
	                 CONV_2D	        88045.963	  311.799	  311.937	  0.349%	 98.878%	     0.000	        1	[efficientnetv2-l/block7g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_expand_conv/Conv2D]:1225
	                LOGISTIC	        88357.913	  260.012	  260.306	  0.291%	 99.169%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/Sigmoid]:1226
	                     MUL	        88618.232	    8.253	    8.202	  0.009%	 99.178%	     0.000	        1	[efficientnetv2-l/block7g_expand_activation/mul_1]:1227
	       DEPTHWISE_CONV_2D	        88626.446	    7.570	    7.612	  0.009%	 99.187%	     0.000	        1	[efficientnetv2-l/block7g_bn/FusedBatchNormV3;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_dwconv2/depthwise]:1228
	                LOGISTIC	        88634.072	  261.822	  261.942	  0.293%	 99.480%	     0.000	        1	[efficientnetv2-l/block7g_activation/Sigmoid]:1229
	                     MUL	        88896.027	    8.179	    8.153	  0.009%	 99.489%	     0.000	        1	[efficientnetv2-l/block7g_activation/mul_1]:1230
	                    MEAN	        88904.191	  140.865	  140.811	  0.158%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_squeeze/Mean]:1231
	                   SHAPE	        89045.014	    0.009	    0.009	  0.000%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Shape]:1232
	           STRIDED_SLICE	        89045.029	    0.021	    0.021	  0.000%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/strided_slice]:1233
	                    PACK	        89045.057	    0.029	    0.028	  0.000%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape/shape]:1234
	                 RESHAPE	        89045.091	    0.018	    0.018	  0.000%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_reshape/Reshape]:1235
	                 CONV_2D	        89045.115	    0.169	    0.171	  0.000%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/BiasAdd;efficientnetv2-l/block7b_se_reduce/BiasAdd/ReadVariableOp;efficientnetv2-l/block7g_se_reduce/Conv2D]:1236
	                LOGISTIC	        89045.295	    0.074	    0.074	  0.000%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/Sigmoid]:1237
	                     MUL	        89045.376	    0.014	    0.013	  0.000%	 99.647%	     0.000	        1	[efficientnetv2-l/block7g_se_reduce/mul_1]:1238
	                 CONV_2D	        89045.397	    1.451	    1.435	  0.002%	 99.649%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/BiasAdd;efficientnetv2-l/block7b_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_se_expand/Conv2D]:1239
	                LOGISTIC	        89046.839	    1.246	    1.248	  0.001%	 99.650%	     0.000	        1	[efficientnetv2-l/block7g_se_expand/Sigmoid]:1240
	                     MUL	        89048.094	    8.018	    8.026	  0.009%	 99.659%	     0.000	        1	[efficientnetv2-l/block7g_se_excite/mul]:1241
	                 CONV_2D	        89056.133	   62.838	   62.978	  0.070%	 99.730%	     0.000	        1	[efficientnetv2-l/block7g_project_bn/FusedBatchNormV3;efficientnetv2-l/block7a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block7g_project_conv/Conv2D]:1242
	                     ADD	        89119.124	    1.325	    1.363	  0.002%	 99.731%	     0.000	        1	[efficientnetv2-l/block7g_add/add]:1243
	                 CONV_2D	        89120.497	  103.273	  103.365	  0.116%	 99.847%	     0.000	        1	[efficientnetv2-l/top_bn/FusedBatchNormV3;efficientnetv2-l/top_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/top_conv/Conv2D]:1244
	                LOGISTIC	        89223.874	   86.299	   86.257	  0.097%	 99.943%	     0.000	        1	[efficientnetv2-l/top_activation/Sigmoid]:1245
	                     MUL	        89310.143	    2.716	    2.736	  0.003%	 99.946%	     0.000	        1	[efficientnetv2-l/top_activation/mul_1]:1246
	                    MEAN	        89312.890	   46.984	   46.931	  0.053%	 99.999%	     0.000	        1	[efficientnetv2-l/avg_pool/Mean]:1247
	         FULLY_CONNECTED	        89359.833	    0.362	    0.363	  0.000%	 99.999%	     0.000	        1	[efficientnetv2-l/predictions/MatMul;efficientnetv2-l/predictions/BiasAdd]:1248
	                 SOFTMAX	        89360.203	    0.578	    0.578	  0.001%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:1249

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	        13744.433	 1397.994	 1399.060	  1.566%	  1.566%	     0.000	        1	[efficientnetv2-l/block2d_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2d_expand_conv/Conv2D]:35
	                 CONV_2D	        16477.570	 1391.899	 1392.980	  1.559%	  3.125%	     0.000	        1	[efficientnetv2-l/block2e_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2e_expand_conv/Conv2D]:40
	                 CONV_2D	        19276.060	 1378.251	 1377.885	  1.542%	  4.667%	     0.000	        1	[efficientnetv2-l/block2f_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2f_expand_conv/Conv2D]:45
	                 CONV_2D	        22072.857	 1373.181	 1371.979	  1.536%	  6.203%	     0.000	        1	[efficientnetv2-l/block2g_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2g_expand_conv/Conv2D]:50
	                 CONV_2D	        11118.613	 1351.977	 1353.198	  1.515%	  7.717%	     0.000	        1	[efficientnetv2-l/block2c_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2c_expand_conv/Conv2D]:30
	                 CONV_2D	         8384.394	 1350.649	 1350.862	  1.512%	  9.229%	     0.000	        1	[efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3;efficientnetv2-l/block2b_expand_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block2b_expand_conv/Conv2D]:25
	                 CONV_2D	          358.793	 1095.154	 1094.018	  1.224%	 10.453%	     0.000	        1	[efficientnetv2-l/block1a_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1a_project_conv/Conv2D]:5
	                 CONV_2D	         5283.019	 1077.380	 1075.964	  1.204%	 11.658%	     0.000	        1	[efficientnetv2-l/block1d_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1d_project_conv/Conv2D]:17
	                 CONV_2D	         1886.213	 1075.194	 1075.506	  1.204%	 12.861%	     0.000	        1	[efficientnetv2-l/block1b_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1b_project_conv/Conv2D]:9
	                 CONV_2D	         3588.387	 1076.797	 1075.306	  1.203%	 14.065%	     0.000	        1	[efficientnetv2-l/block1c_project_bn/FusedBatchNormV3;efficientnetv2-l/block1a_project_bn/FusedBatchNormV3/ReadVariableOp;efficientnetv2-l/block1c_project_conv/Conv2D]:13

Number of nodes executed: 1250
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	      278	 42451.121	    47.512%	    47.512%	     0.000	      278
	                LOGISTIC	      264	 36433.609	    40.777%	    88.289%	     0.000	      264
	                    MEAN	       62	  7829.507	     8.763%	    97.052%	     0.000	       62
	                     MUL	      265	  1787.447	     2.001%	    99.052%	     0.000	      265
	       DEPTHWISE_CONV_2D	       61	   615.559	     0.689%	    99.741%	     0.000	       61
	                     ADD	       74	   225.683	     0.253%	    99.994%	     0.000	       74
	                    PACK	       61	     1.687	     0.002%	    99.996%	     0.000	       61
	           STRIDED_SLICE	       61	     1.322	     0.001%	    99.997%	     0.000	       61
	                 RESHAPE	       61	     0.959	     0.001%	    99.998%	     0.000	       61
	                 SOFTMAX	        1	     0.577	     0.001%	    99.999%	     0.000	        1
	                   SHAPE	       61	     0.519	     0.001%	   100.000%	     0.000	       61
	         FULLY_CONNECTED	        1	     0.363	     0.000%	   100.000%	     0.000	        1

Timings (microseconds): count=2 first=89351166 curr=89346160 min=89346160 max=89351166 avg=8.93487e+07 std=2503
Memory (bytes): count=0
1250 nodes observed



