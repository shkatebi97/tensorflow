STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/f32i8/InceptionV3.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/f32i8/InceptionV3.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (89401, 3, ), and Output shape (22201, 32, ), and the ID is 0	Changing Input Shape
	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (32, 288, ), Input shape (22201, 32, ), and Output shape (21609, 32, ), and the ID is 1
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 288, ), Input shape (21609, 32, ), and Output shape (21609, 64, ), and the ID is 2
NOT Applying Conv Low-Precision for Kernel shape (80, 64, ), Input shape 	Changing Input Shape
(5329, 64, ), and Output shape (5329, 80, ), and the ID is 3
NOT Applying Conv Low-Precision for Kernel shape (192, 720, ), Input shape (5329, 80, ), and Output shape 	Changing Input Shape
	Changing Input Shape
(5041, 192, ), and the ID is 4
NOT Applying Conv Low-Precision for Kernel shape (32, 192, ), Input shape (1225, 192, ), and Output shape (1225, 32, ), and the ID is 5
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(64, 192, ), Input shape (1225, 192, ), and Output shape (1225, 64, ), and the ID is 6
NOT Applying Conv Low-Precision for Kernel shape (48, 192, ), Input shape 	Changing Input Shape
(1225, 192, ), and Output shape (1225, 48, ), and the ID is 7
NOT Applying Conv Low-Precision for Kernel shape (64, 1200, ), Input shape (1225, 48, )	Changing Input Shape
, and Output shape (1225, 64, ), and the ID is 8
NOT Applying Conv Low-Precision for Kernel shape (64, 192, ), Input shape 	Changing Input Shape
(1225, 192, ), and Output shape (1225, 64, ), and the ID is 9
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (1225, 64, )	Changing Input Shape
, and Output shape (1225, 96, ), and the ID is 10
NOT Applying Conv Low-Precision for Kernel shape (96, 864, ), Input shape (1225, 96, ), and Output shape 	Changing Input Shape
(1225, 96, ), and the ID is 11
NOT Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (1225, 256, ), and Output shape 	Changing Input Shape
(1225, 64, ), and the ID is 12
NOT Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (1225, 256, ), and Output shape 	Changing Input Shape
(1225, 64, ), and the ID is 13
NOT Applying Conv Low-Precision for Kernel shape (48, 256, ), Input shape (1225, 256, ), and Output shape (1225, 48, )	Changing Input Shape
, and the ID is 14
NOT Applying Conv Low-Precision for Kernel shape (64, 1200, ), Input shape (1225, 48, ), and Output shape (1225, 64, ), and the ID is 	Changing Input Shape
15
NOT Applying Conv Low-Precision for Kernel shape (64, 256, ), Input shape (1225, 256, ), and Output shape (1225, 64, )	Changing Input Shape
, and the ID is 16
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (1225, 64, ), and Output shape (1225, 96, ), and the ID is 	Changing Input Shape
17
NOT Applying Conv Low-Precision for Kernel shape (96, 864, ), Input shape (1225, 96, ), and Output shape (1225, 96, ), and the ID is 18
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 288, ), Input shape (1225, 288, ), and Output shape (1225, 64, ), and the ID is 19
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 288, ), Input shape (1225, 288, ), and Output shape (1225, 64, ), and the ID is 20
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (48, 288, ), Input shape (1225, 288, ), and Output shape (1225, 48, ), and the ID is 21
NOT Applying Conv Low-Precision for Kernel shape (64, 1200, ), Input shape (1225, 48, ), and Output shape (1225, 64, ), and the ID is 22
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 288, ), Input shape (1225, 288, ), and Output shape (1225, 64, ), and the ID is 23
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (1225, 64, ), and Output shape (1225, 96, ), and the ID is 24
NOT Applying Conv Low-Precision for Kernel shape (96, 864, ), Input shape (1225, 96, ), and Output shape (1225, 96, ), and the ID is 25
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 2592, ), Input shape (1225, 288, ), and Output shape (289, 384, ), and the ID is 26
NOT Applying Conv Low-Precision for Kernel shape (64, 288, ), Input shape (1225, 288, ), and Output shape (1225, 64, ), and the ID is 27
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (1225, 64, ), and Output shape (1225, 96, ), and the ID is 28
NOT Applying Conv Low-Precision for Kernel shape (96, 864, ), Input shape (1225, 96, ), and Output shape (289, 96, ), and the ID is 29
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 30
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 31
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
	Changing Input Shape
(128, 768, ), Input shape (289, 768, ), and Output shape (289, 128, ), and the ID is 32
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(128, 896, ), Input shape (289, 128, ), and Output shape (289, 128, ), and the ID is 33
NOT Applying Conv Low-Precision for Kernel shape (192, 896, )	Changing Input Shape
, Input shape (289, 128, ), and Output shape (289, 192, ), and the ID is 34
NOT Applying Conv Low-Precision for Kernel shape (128, 768, ), Input shape 	Changing Input Shape
(289, 768, ), and Output shape (289, 128, ), and the ID is 35
NOT Applying Conv Low-Precision for Kernel shape (128, 896, ), Input shape (289, 128, )	Changing Input Shape
, and Output shape (289, 128, ), and the ID is 36
NOT Applying Conv Low-Precision for Kernel shape (128, 896, ), Input shape (289, 128, ), and Output shape 	Changing Input Shape
(289, 128, ), and the ID is 37
NOT Applying Conv Low-Precision for Kernel shape (128, 896, ), Input shape (289, 128, ), and Output shape (289, 128, )	Changing Input Shape
, and the ID is 38
NOT Applying Conv Low-Precision for Kernel shape (192, 896, ), Input shape (289, 128, )	Changing Input Shape
, and Output shape (289, 192, ), and the ID is 39
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 40
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 41
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (160, 768, ), Input shape (289, 768, ), and Output shape (289, 160, ), and the ID is 42
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, ), Input shape (289, 160, ), and Output shape (289, 160, ), and the ID is 43
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 1120, ), Input shape (289, 160, ), and Output shape (289, 192, ), and the ID is 44
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (160, 768, ), Input shape (289, 768, ), and Output shape (289, 160, ), and the ID is 45
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, ), Input shape (289, 160, ), and Output shape (289, 160, ), and the ID is 46
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, ), Input shape (289, 160, ), and Output shape (289, 160, ), and the ID is 47
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, ), Input shape (289, 160, ), and Output shape (289, 160, ), and the ID is 48
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 1120, ), Input shape (289, 160, ), and Output shape (289, 192, ), and the ID is 49
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 50
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 51
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(160, 768, ), Input shape (289, 768, ), and Output shape (289, 160, ), and the ID is 52
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, )	Changing Input Shape
, Input shape (289, 160, ), and Output shape (289, 160, ), and the ID is 53
NOT Applying Conv Low-Precision for Kernel shape (192, 1120, ), Input shape 	Changing Input Shape
(289, 160, ), and Output shape (289, 192, ), and the ID is 54
NOT Applying Conv Low-Precision for Kernel shape (160, 768, ), Input shape (289, 768, )	Changing Input Shape
, and Output shape (289, 160, ), and the ID is 55
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, ), Input shape (289, 160, ), and Output shape (289, 160, )	Changing Input Shape
, and the ID is 56
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, ), Input shape (289, 160, ), and Output shape (289, 160, )	Changing Input Shape
, and the ID is 57
NOT Applying Conv Low-Precision for Kernel shape (160, 1120, ), Input shape (289, 160, ), and Output shape (289, 160, ), and the ID is 	Changing Input Shape
58
NOT Applying Conv Low-Precision for Kernel shape (192, 1120, ), Input shape (289, 160, ), and Output shape (289, 192, ), and the ID is 59
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 60
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 61
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 62
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 1344, ), Input shape (289, 192, ), and Output shape (289, 192, ), and the ID is 63
NOT Applying Conv Low-Precision for Kernel shape (192, 1344, ), Input shape (289, 192, ), and Output shape (289, 192, ), and the ID is 64
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 65
NOT Applying Conv Low-Precision for Kernel shape (192, 1344, ), Input shape (289, 192, ), and Output shape (289, 192, ), and the ID is 66
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 1344, ), Input shape (289, 192, ), and Output shape (289, 192, ), and the ID is 67
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(192, 1344, ), Input shape (289, 192, ), and Output shape (289, 192, ), and the ID is 68
NOT Applying Conv Low-Precision for Kernel shape (192, 1344, ), Input shape 	Changing Input Shape
(289, 192, ), and Output shape (289, 192, ), and the ID is 69
NOT Applying Conv Low-Precision for Kernel shape (192, 768, )	Changing Input Shape
, Input shape (289, 768, ), and Output shape (289, 192, ), and the ID is 70
NOT Applying Conv Low-Precision for Kernel shape (320, 1728, ), Input shape 	Changing Input Shape
(289, 192, ), and Output shape (64, 320, ), and the ID is 71
NOT Applying Conv Low-Precision for Kernel shape (192, 768, ), Input shape (289, 768, )	Changing Input Shape
, and Output shape (289, 192, ), and the ID is 72
NOT Applying Conv Low-Precision for Kernel shape (192, 1344, ), Input shape (289, 192, ), and Output shape 	Changing Input Shape
(289, 192, ), and the ID is 73
NOT Applying Conv Low-Precision for Kernel shape (192, 1344, ), Input shape (289, 192, ), and Output shape (289, 192, )	Changing Input Shape
, and the ID is 74
NOT Applying Conv Low-Precision for Kernel shape (192, 1728, ), Input shape (289, 192, ), and Output shape (64, 192, ), and the ID is 	Changing Input Shape
75
NOT Applying Conv Low-Precision for Kernel shape (192, 1280, ), Input shape (64, 1280, ), and Output shape (64, 192, ), and the ID is 	Changing Input Shape
76
NOT Applying Conv Low-Precision for Kernel shape (320, 1280, ), Input shape (64, 1280, ), and Output shape (64, 320, )	Changing Input Shape
, and the ID is 77
NOT Applying Conv Low-Precision for Kernel shape (384, 1280, ), Input shape (64, 1280, ), and Output shape (64, 384, ), and the ID is 	Changing Input Shape
78
NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 79	Changing Input Shape

NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 80
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (448, 1280, ), Input shape (64, 1280, ), and Output shape (64, 448, ), and the ID is 81
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 4032, ), Input shape (64, 448, ), and Output shape (64, 384, ), and the ID is 82
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 83
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 84
NOT Applying Conv Low-Precision for Kernel shape (192, 2048, ), Input shape (64, 2048, ), and Output shape (64, 192, ), and the ID is 85
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (320, 2048, ), Input shape (64, 2048, ), and Output shape (64, 320, ), and the ID is 86
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 2048, ), Input shape (64, 2048, ), and Output shape (64, 384, ), and the ID is 87
NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 88
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 89
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (448, 2048, ), Input shape (64, 2048, ), and Output shape (64, 448, ), and the ID is 90
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 4032, ), Input shape (64, 448, ), and Output shape (64, 384, ), and the ID is 91
NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 92
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 1152, ), Input shape (64, 384, ), and Output shape (64, 384, ), and the ID is 93
NOT Applying Low-Precision for shape (1000, 2048, ) and Input shape (1, 2048, ) With 5 Number of Temp Tensors
The input model file size (MB): 24.0673
Initialized session in 25.189ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=10 first=5193803 curr=5105599 min=5105007 max=5193803 avg=5.11518e+06 std=26238

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=5106600 curr=5106264 min=5106247 max=5111424 avg=5.10851e+06 std=1675

Inference timings in us: Init: 25189, First inference: 5193803, Warmup (avg): 5.11518e+06, Inference (avg): 5.10851e+06
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=6.86328 overall=54.8555
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   16.663	   16.663	100.000%	100.000%	   504.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   16.663	   16.663	100.000%	100.000%	   504.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    16.663	   100.000%	   100.000%	   504.000	        1

Timings (microseconds): count=1 curr=16663
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.029	   13.976	   13.976	  0.274%	  0.274%	     0.000	        1	[inception_v3/activation/Relu;inception_v3/batch_normalization/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d/Conv2D]:0
	                 CONV_2D	           14.019	  392.720	  393.108	  7.697%	  7.971%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	                 CONV_2D	          407.139	  640.583	  640.152	 12.535%	 20.506%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	             MAX_POOL_2D	         1047.303	  185.954	  185.746	  3.637%	 24.143%	     0.000	        1	[inception_v3/max_pooling2d/MaxPool]:3
	                 CONV_2D	         1233.061	  175.126	  175.245	  3.431%	 27.574%	     0.000	        1	[inception_v3/activation_3/Relu;inception_v3/batch_normalization_3/FusedBatchNormV3;inception_v3/batch_normalization_3/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_3/Conv2D]:4
	                 CONV_2D	         1408.319	  434.398	  434.984	  8.517%	 36.092%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	             MAX_POOL_2D	         1843.315	   85.992	   86.378	  1.691%	 37.783%	     0.000	        1	[inception_v3/max_pooling2d_1/MaxPool]:6
	         AVERAGE_POOL_2D	         1929.706	   87.678	   87.679	  1.717%	 39.500%	     0.000	        1	[inception_v3/average_pooling2d/AvgPool]:7
	                 CONV_2D	         2017.397	   21.907	   21.895	  0.429%	 39.929%	     0.000	        1	[inception_v3/activation_11/Relu;inception_v3/batch_normalization_11/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_11/Conv2D]:8
	                 CONV_2D	         2039.304	   35.560	   35.535	  0.696%	 40.624%	     0.000	        1	[inception_v3/activation_5/Relu;inception_v3/batch_normalization_5/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_5/Conv2D]:9
	                 CONV_2D	         2074.850	   28.760	   28.754	  0.563%	 41.187%	     0.000	        1	[inception_v3/activation_6/Relu;inception_v3/batch_normalization_6/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_6/Conv2D]:10
	                 CONV_2D	         2103.616	   46.299	   46.423	  0.909%	 42.096%	     0.000	        1	[inception_v3/activation_7/Relu;inception_v3/batch_normalization_7/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_7/Conv2D]:11
	                 CONV_2D	         2150.051	   35.425	   35.429	  0.694%	 42.790%	     0.000	        1	[inception_v3/activation_8/Relu;inception_v3/batch_normalization_8/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_8/Conv2D]:12
	                 CONV_2D	         2185.493	   54.839	   54.906	  1.075%	 43.865%	     0.000	        1	[inception_v3/activation_9/Relu;inception_v3/batch_normalization_9/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_9/Conv2D]:13
	                 CONV_2D	         2240.410	   59.265	   59.304	  1.161%	 45.027%	     0.000	        1	[inception_v3/activation_10/Relu;inception_v3/batch_normalization_10/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_10/Conv2D]:14
	           CONCATENATION	         2299.727	    1.144	    1.172	  0.023%	 45.050%	     0.000	        1	[inception_v3/mixed0/concat]:15
	         AVERAGE_POOL_2D	         2300.909	  112.076	  112.511	  2.203%	 47.253%	     0.000	        1	[inception_v3/average_pooling2d_1/AvgPool]:16
	                 CONV_2D	         2413.432	   36.496	   36.269	  0.710%	 47.963%	     0.000	        1	[inception_v3/activation_18/Relu;inception_v3/batch_normalization_18/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_18/Conv2D]:17
	                 CONV_2D	         2449.714	   36.170	   36.352	  0.712%	 48.675%	     0.000	        1	[inception_v3/activation_12/Relu;inception_v3/batch_normalization_12/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_12/Conv2D]:18
	                 CONV_2D	         2486.078	   29.336	   29.390	  0.575%	 49.250%	     0.000	        1	[inception_v3/activation_13/Relu;inception_v3/batch_normalization_13/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_13/Conv2D]:19
	                 CONV_2D	         2515.479	   46.163	   46.194	  0.905%	 50.155%	     0.000	        1	[inception_v3/activation_14/Relu;inception_v3/batch_normalization_14/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_14/Conv2D]:20
	                 CONV_2D	         2561.685	   36.255	   36.288	  0.711%	 50.865%	     0.000	        1	[inception_v3/activation_15/Relu;inception_v3/batch_normalization_15/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_15/Conv2D]:21
	                 CONV_2D	         2597.985	   54.759	   54.868	  1.074%	 51.939%	     0.000	        1	[inception_v3/activation_16/Relu;inception_v3/batch_normalization_16/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_16/Conv2D]:22
	                 CONV_2D	         2652.865	   59.093	   59.293	  1.161%	 53.100%	     0.000	        1	[inception_v3/activation_17/Relu;inception_v3/batch_normalization_17/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_17/Conv2D]:23
	           CONCATENATION	         2712.169	    1.324	    1.373	  0.027%	 53.127%	     0.000	        1	[inception_v3/mixed1/concat]:24
	         AVERAGE_POOL_2D	         2713.552	  124.726	  124.937	  2.446%	 55.574%	     0.000	        1	[inception_v3/average_pooling2d_2/AvgPool]:25
	                 CONV_2D	         2838.502	   36.804	   36.830	  0.721%	 56.295%	     0.000	        1	[inception_v3/activation_25/Relu;inception_v3/batch_normalization_25/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_25/Conv2D]:26
	                 CONV_2D	         2875.344	   36.908	   36.858	  0.722%	 57.017%	     0.000	        1	[inception_v3/activation_19/Relu;inception_v3/batch_normalization_19/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_19/Conv2D]:27
	                 CONV_2D	         2912.213	   29.551	   29.736	  0.582%	 57.599%	     0.000	        1	[inception_v3/activation_20/Relu;inception_v3/batch_normalization_20/FusedBatchNormV3;inception_v3/batch_normalization_13/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_20/Conv2D]:28
	                 CONV_2D	         2941.961	   46.228	   46.248	  0.906%	 58.504%	     0.000	        1	[inception_v3/activation_21/Relu;inception_v3/batch_normalization_21/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_21/Conv2D]:29
	                 CONV_2D	         2988.221	   36.555	   36.638	  0.717%	 59.222%	     0.000	        1	[inception_v3/activation_22/Relu;inception_v3/batch_normalization_22/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_22/Conv2D]:30
	                 CONV_2D	         3024.871	   54.773	   54.822	  1.073%	 60.295%	     0.000	        1	[inception_v3/activation_23/Relu;inception_v3/batch_normalization_23/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_23/Conv2D]:31
	                 CONV_2D	         3079.705	   59.684	   59.291	  1.161%	 61.456%	     0.000	        1	[inception_v3/activation_24/Relu;inception_v3/batch_normalization_24/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_24/Conv2D]:32
	           CONCATENATION	         3139.009	    1.436	    1.384	  0.027%	 61.483%	     0.000	        1	[inception_v3/mixed2/concat]:33
	                 CONV_2D	         3140.403	   75.316	   75.241	  1.473%	 62.957%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34
	                 CONV_2D	         3215.656	   37.012	   36.749	  0.720%	 63.676%	     0.000	        1	[inception_v3/activation_27/Relu;inception_v3/batch_normalization_27/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_27/Conv2D]:35
	                 CONV_2D	         3252.416	   55.391	   54.944	  1.076%	 64.752%	     0.000	        1	[inception_v3/activation_28/Relu;inception_v3/batch_normalization_28/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_28/Conv2D]:36
	                 CONV_2D	         3307.373	   14.451	   14.298	  0.280%	 65.032%	     0.000	        1	[inception_v3/activation_29/Relu;inception_v3/batch_normalization_29/FusedBatchNormV3;inception_v3/batch_normalization_10/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_29/Conv2D]:37
	             MAX_POOL_2D	         3321.682	   27.896	   27.868	  0.546%	 65.578%	     0.000	        1	[inception_v3/max_pooling2d_2/MaxPool]:38
	           CONCATENATION	         3349.561	    1.021	    0.841	  0.016%	 65.594%	     0.000	        1	[inception_v3/mixed3/concat]:39
	         AVERAGE_POOL_2D	         3350.411	   72.008	   71.688	  1.404%	 66.998%	     0.000	        1	[inception_v3/average_pooling2d_3/AvgPool]:40
	                 CONV_2D	         3422.111	   26.252	   26.193	  0.513%	 67.511%	     0.000	        1	[inception_v3/activation_39/Relu;inception_v3/batch_normalization_39/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_39/Conv2D]:41
	                 CONV_2D	         3448.316	   26.475	   26.016	  0.509%	 68.020%	     0.000	        1	[inception_v3/activation_30/Relu;inception_v3/batch_normalization_30/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_30/Conv2D]:42
	                 CONV_2D	         3474.344	   18.309	   18.241	  0.357%	 68.377%	     0.000	        1	[inception_v3/activation_31/Relu;inception_v3/batch_normalization_31/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_31/Conv2D]:43
	                 CONV_2D	         3492.596	   18.853	   18.843	  0.369%	 68.746%	     0.000	        1	[inception_v3/activation_32/Relu;inception_v3/batch_normalization_32/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_32/Conv2D]:44
	                 CONV_2D	         3511.451	   26.190	   26.190	  0.513%	 69.259%	     0.000	        1	[inception_v3/activation_33/Relu;inception_v3/batch_normalization_33/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_33/Conv2D]:45
	                 CONV_2D	         3537.653	   18.274	   18.312	  0.359%	 69.618%	     0.000	        1	[inception_v3/activation_34/Relu;inception_v3/batch_normalization_34/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_34/Conv2D]:46
	                 CONV_2D	         3555.976	   18.364	   18.330	  0.359%	 69.977%	     0.000	        1	[inception_v3/activation_35/Relu;inception_v3/batch_normalization_35/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_35/Conv2D]:47
	                 CONV_2D	         3574.317	   18.322	   18.397	  0.360%	 70.337%	     0.000	        1	[inception_v3/activation_36/Relu;inception_v3/batch_normalization_36/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_36/Conv2D]:48
	                 CONV_2D	         3592.725	   18.295	   18.377	  0.360%	 70.697%	     0.000	        1	[inception_v3/activation_37/Relu;inception_v3/batch_normalization_37/FusedBatchNormV3;inception_v3/batch_normalization_31/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_37/Conv2D]:49
	                 CONV_2D	         3611.114	   26.208	   26.288	  0.515%	 71.212%	     0.000	        1	[inception_v3/activation_38/Relu;inception_v3/batch_normalization_38/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_38/Conv2D]:50
	           CONCATENATION	         3637.414	    1.012	    0.929	  0.018%	 71.230%	     0.000	        1	[inception_v3/mixed4/concat]:51
	         AVERAGE_POOL_2D	         3638.353	   71.425	   71.606	  1.402%	 72.632%	     0.000	        1	[inception_v3/average_pooling2d_4/AvgPool]:52
	                 CONV_2D	         3709.971	   25.770	   25.795	  0.505%	 73.137%	     0.000	        1	[inception_v3/activation_49/Relu;inception_v3/batch_normalization_49/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_49/Conv2D]:53
	                 CONV_2D	         3735.778	   26.242	   26.247	  0.514%	 73.651%	     0.000	        1	[inception_v3/activation_40/Relu;inception_v3/batch_normalization_40/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_40/Conv2D]:54
	                 CONV_2D	         3762.037	   22.035	   22.060	  0.432%	 74.083%	     0.000	        1	[inception_v3/activation_41/Relu;inception_v3/batch_normalization_41/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_41/Conv2D]:55
	                 CONV_2D	         3784.108	   23.654	   23.568	  0.461%	 74.544%	     0.000	        1	[inception_v3/activation_42/Relu;inception_v3/batch_normalization_42/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_42/Conv2D]:56
	                 CONV_2D	         3807.688	   27.721	   27.809	  0.545%	 75.089%	     0.000	        1	[inception_v3/activation_43/Relu;inception_v3/batch_normalization_43/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_43/Conv2D]:57
	                 CONV_2D	         3835.510	   22.059	   22.045	  0.432%	 75.520%	     0.000	        1	[inception_v3/activation_44/Relu;inception_v3/batch_normalization_44/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_44/Conv2D]:58
	                 CONV_2D	         3857.566	   23.675	   23.711	  0.464%	 75.985%	     0.000	        1	[inception_v3/activation_45/Relu;inception_v3/batch_normalization_45/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_45/Conv2D]:59
	                 CONV_2D	         3881.289	   23.824	   23.822	  0.466%	 76.451%	     0.000	        1	[inception_v3/activation_46/Relu;inception_v3/batch_normalization_46/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_46/Conv2D]:60
	                 CONV_2D	         3905.123	   24.321	   24.333	  0.476%	 76.928%	     0.000	        1	[inception_v3/activation_47/Relu;inception_v3/batch_normalization_47/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_47/Conv2D]:61
	                 CONV_2D	         3929.467	   28.018	   28.035	  0.549%	 77.477%	     0.000	        1	[inception_v3/activation_48/Relu;inception_v3/batch_normalization_48/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_48/Conv2D]:62
	           CONCATENATION	         3957.514	    0.938	    0.931	  0.018%	 77.495%	     0.000	        1	[inception_v3/mixed5/concat]:63
	         AVERAGE_POOL_2D	         3958.455	   71.743	   71.604	  1.402%	 78.897%	     0.000	        1	[inception_v3/average_pooling2d_5/AvgPool]:64
	                 CONV_2D	         4030.071	   25.849	   25.803	  0.505%	 79.402%	     0.000	        1	[inception_v3/activation_59/Relu;inception_v3/batch_normalization_59/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_59/Conv2D]:65
	                 CONV_2D	         4055.886	   25.745	   25.805	  0.505%	 79.907%	     0.000	        1	[inception_v3/activation_50/Relu;inception_v3/batch_normalization_50/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_50/Conv2D]:66
	                 CONV_2D	         4081.703	   22.028	   22.032	  0.431%	 80.339%	     0.000	        1	[inception_v3/activation_51/Relu;inception_v3/batch_normalization_51/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_51/Conv2D]:67
	                 CONV_2D	         4103.747	   23.443	   23.512	  0.460%	 80.799%	     0.000	        1	[inception_v3/activation_52/Relu;inception_v3/batch_normalization_52/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_52/Conv2D]:68
	                 CONV_2D	         4127.271	   27.740	   27.745	  0.543%	 81.343%	     0.000	        1	[inception_v3/activation_53/Relu;inception_v3/batch_normalization_53/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_53/Conv2D]:69
	                 CONV_2D	         4155.028	   22.043	   22.093	  0.433%	 81.775%	     0.000	        1	[inception_v3/activation_54/Relu;inception_v3/batch_normalization_54/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_54/Conv2D]:70
	                 CONV_2D	         4177.132	   23.598	   23.646	  0.463%	 82.238%	     0.000	        1	[inception_v3/activation_55/Relu;inception_v3/batch_normalization_55/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_55/Conv2D]:71
	                 CONV_2D	         4200.791	   23.588	   23.624	  0.463%	 82.701%	     0.000	        1	[inception_v3/activation_56/Relu;inception_v3/batch_normalization_56/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_56/Conv2D]:72
	                 CONV_2D	         4224.426	   23.568	   23.654	  0.463%	 83.164%	     0.000	        1	[inception_v3/activation_57/Relu;inception_v3/batch_normalization_57/FusedBatchNormV3;inception_v3/batch_normalization_41/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_57/Conv2D]:73
	                 CONV_2D	         4248.092	   27.641	   27.780	  0.544%	 83.708%	     0.000	        1	[inception_v3/activation_58/Relu;inception_v3/batch_normalization_58/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_58/Conv2D]:74
	           CONCATENATION	         4275.883	    0.956	    0.919	  0.018%	 83.726%	     0.000	        1	[inception_v3/mixed6/concat]:75
	         AVERAGE_POOL_2D	         4276.813	   71.725	   71.651	  1.403%	 85.129%	     0.000	        1	[inception_v3/average_pooling2d_6/AvgPool]:76
	                 CONV_2D	         4348.476	   25.859	   25.925	  0.508%	 85.636%	     0.000	        1	[inception_v3/activation_69/Relu;inception_v3/batch_normalization_69/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_69/Conv2D]:77
	                 CONV_2D	         4374.412	   25.838	   25.859	  0.506%	 86.143%	     0.000	        1	[inception_v3/activation_60/Relu;inception_v3/batch_normalization_60/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_60/Conv2D]:78
	                 CONV_2D	         4400.283	   25.881	   25.902	  0.507%	 86.650%	     0.000	        1	[inception_v3/activation_61/Relu;inception_v3/batch_normalization_61/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_61/Conv2D]:79
	                 CONV_2D	         4426.196	   29.466	   29.430	  0.576%	 87.226%	     0.000	        1	[inception_v3/activation_62/Relu;inception_v3/batch_normalization_62/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_62/Conv2D]:80
	                 CONV_2D	         4455.638	   29.497	   29.518	  0.578%	 87.804%	     0.000	        1	[inception_v3/activation_63/Relu;inception_v3/batch_normalization_63/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_63/Conv2D]:81
	                 CONV_2D	         4485.168	   26.164	   26.171	  0.512%	 88.317%	     0.000	        1	[inception_v3/activation_64/Relu;inception_v3/batch_normalization_64/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_64/Conv2D]:82
	                 CONV_2D	         4511.350	   29.265	   29.367	  0.575%	 88.892%	     0.000	        1	[inception_v3/activation_65/Relu;inception_v3/batch_normalization_65/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_65/Conv2D]:83
	                 CONV_2D	         4540.729	   29.216	   29.295	  0.574%	 89.465%	     0.000	        1	[inception_v3/activation_66/Relu;inception_v3/batch_normalization_66/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_66/Conv2D]:84
	                 CONV_2D	         4570.036	   29.926	   29.992	  0.587%	 90.053%	     0.000	        1	[inception_v3/activation_67/Relu;inception_v3/batch_normalization_67/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_67/Conv2D]:85
	                 CONV_2D	         4600.039	   29.421	   29.508	  0.578%	 90.630%	     0.000	        1	[inception_v3/activation_68/Relu;inception_v3/batch_normalization_68/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_68/Conv2D]:86
	           CONCATENATION	         4629.559	    0.883	    0.902	  0.018%	 90.648%	     0.000	        1	[inception_v3/mixed7/concat]:87
	                 CONV_2D	         4630.472	   26.141	   26.203	  0.513%	 91.161%	     0.000	        1	[inception_v3/activation_70/Relu;inception_v3/batch_normalization_70/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_70/Conv2D]:88
	                 CONV_2D	         4656.686	   12.050	   12.013	  0.235%	 91.396%	     0.000	        1	[inception_v3/activation_71/Relu;inception_v3/batch_normalization_71/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_71/Conv2D]:89
	                 CONV_2D	         4668.712	   25.770	   25.887	  0.507%	 91.903%	     0.000	        1	[inception_v3/activation_72/Relu;inception_v3/batch_normalization_72/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_72/Conv2D]:90
	                 CONV_2D	         4694.612	   29.412	   29.459	  0.577%	 92.480%	     0.000	        1	[inception_v3/activation_73/Relu;inception_v3/batch_normalization_73/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_73/Conv2D]:91
	                 CONV_2D	         4724.082	   29.468	   29.529	  0.578%	 93.058%	     0.000	        1	[inception_v3/activation_74/Relu;inception_v3/batch_normalization_74/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_74/Conv2D]:92
	                 CONV_2D	         4753.623	    7.464	    7.482	  0.147%	 93.205%	     0.000	        1	[inception_v3/activation_75/Relu;inception_v3/batch_normalization_75/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_75/Conv2D]:93
	             MAX_POOL_2D	         4761.117	   14.950	   14.701	  0.288%	 93.493%	     0.000	        1	[inception_v3/max_pooling2d_3/MaxPool]:94
	           CONCATENATION	         4775.828	    0.151	    0.169	  0.003%	 93.496%	     0.000	        1	[inception_v3/mixed8/concat]:95
	         AVERAGE_POOL_2D	         4776.004	   24.721	   24.802	  0.486%	 93.982%	     0.000	        1	[inception_v3/average_pooling2d_7/AvgPool]:96
	                 CONV_2D	         4800.816	    6.900	    6.921	  0.136%	 94.117%	     0.000	        1	[inception_v3/activation_84/Relu;inception_v3/batch_normalization_84/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_84/Conv2D]:97
	                 CONV_2D	         4807.749	   11.134	   11.158	  0.218%	 94.336%	     0.000	        1	[inception_v3/activation_76/Relu;inception_v3/batch_normalization_76/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_76/Conv2D]:98
	                 CONV_2D	         4818.919	   13.291	   13.335	  0.261%	 94.597%	     0.000	        1	[inception_v3/activation_77/Relu;inception_v3/batch_normalization_77/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_77/Conv2D]:99
	                 CONV_2D	         4832.266	   12.481	   12.492	  0.245%	 94.841%	     0.000	        1	[inception_v3/activation_78/Relu;inception_v3/batch_normalization_78/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_78/Conv2D]:100
	                 CONV_2D	         4844.769	   12.430	   12.507	  0.245%	 95.086%	     0.000	        1	[inception_v3/activation_79/Relu;inception_v3/batch_normalization_79/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_79/Conv2D]:101
	           CONCATENATION	         4857.288	    0.111	    0.123	  0.002%	 95.089%	     0.000	        1	[inception_v3/mixed9_0/concat]:102
	                 CONV_2D	         4857.418	   15.008	   15.017	  0.294%	 95.383%	     0.000	        1	[inception_v3/activation_80/Relu;inception_v3/batch_normalization_80/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_80/Conv2D]:103
	                 CONV_2D	         4872.446	   21.607	   21.566	  0.422%	 95.805%	     0.000	        1	[inception_v3/activation_81/Relu;inception_v3/batch_normalization_81/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_81/Conv2D]:104
	                 CONV_2D	         4894.024	   12.454	   12.404	  0.243%	 96.048%	     0.000	        1	[inception_v3/activation_82/Relu;inception_v3/batch_normalization_82/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_82/Conv2D]:105
	                 CONV_2D	         4906.439	   12.458	   12.495	  0.245%	 96.293%	     0.000	        1	[inception_v3/activation_83/Relu;inception_v3/batch_normalization_83/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_83/Conv2D]:106
	           CONCATENATION	         4918.945	    0.134	    0.145	  0.003%	 96.295%	     0.000	        1	[inception_v3/concatenate/concat]:107
	           CONCATENATION	         4919.097	    0.332	    0.325	  0.006%	 96.302%	     0.000	        1	[inception_v3/mixed9/concat]:108
	         AVERAGE_POOL_2D	         4919.431	   39.226	   39.338	  0.770%	 97.072%	     0.000	        1	[inception_v3/average_pooling2d_8/AvgPool]:109
	                 CONV_2D	         4958.780	    8.302	    8.289	  0.162%	 97.234%	     0.000	        1	[inception_v3/activation_93/Relu;inception_v3/batch_normalization_93/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_93/Conv2D]:110
	                 CONV_2D	         4967.080	   12.928	   13.013	  0.255%	 97.489%	     0.000	        1	[inception_v3/activation_85/Relu;inception_v3/batch_normalization_85/FusedBatchNormV3;inception_v3/batch_normalization_71/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_85/Conv2D]:111
	                 CONV_2D	         4980.105	   15.333	   15.363	  0.301%	 97.790%	     0.000	        1	[inception_v3/activation_86/Relu;inception_v3/batch_normalization_86/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_86/Conv2D]:112
	                 CONV_2D	         4995.479	   12.376	   12.444	  0.244%	 98.034%	     0.000	        1	[inception_v3/activation_87/Relu;inception_v3/batch_normalization_87/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_87/Conv2D]:113
	                 CONV_2D	         5007.935	   12.498	   12.543	  0.246%	 98.279%	     0.000	        1	[inception_v3/activation_88/Relu;inception_v3/batch_normalization_88/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_88/Conv2D]:114
	           CONCATENATION	         5020.489	    0.110	    0.123	  0.002%	 98.282%	     0.000	        1	[inception_v3/mixed9_1/concat]:115
	                 CONV_2D	         5020.620	   17.712	   17.828	  0.349%	 98.631%	     0.000	        1	[inception_v3/activation_89/Relu;inception_v3/batch_normalization_89/FusedBatchNormV3;inception_v3/batch_normalization_80/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_89/Conv2D]:116
	                 CONV_2D	         5038.459	   21.515	   21.580	  0.423%	 99.053%	     0.000	        1	[inception_v3/activation_90/Relu;inception_v3/batch_normalization_90/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_90/Conv2D]:117
	                 CONV_2D	         5060.052	   12.311	   12.357	  0.242%	 99.295%	     0.000	        1	[inception_v3/activation_91/Relu;inception_v3/batch_normalization_91/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_91/Conv2D]:118
	                 CONV_2D	         5072.421	   12.717	   12.743	  0.250%	 99.545%	     0.000	        1	[inception_v3/activation_92/Relu;inception_v3/batch_normalization_92/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_92/Conv2D]:119
	           CONCATENATION	         5085.176	    0.143	    0.146	  0.003%	 99.548%	     0.000	        1	[inception_v3/concatenate_1/concat]:120
	           CONCATENATION	         5085.328	    0.326	    0.326	  0.006%	 99.554%	     0.000	        1	[inception_v3/mixed10/concat]:121
	                    MEAN	         5085.663	   21.350	   21.372	  0.418%	 99.972%	     0.000	        1	[inception_v3/avg_pool/Mean]:122
	         FULLY_CONNECTED	         5107.044	    0.815	    0.819	  0.016%	 99.989%	     0.000	        1	[inception_v3/predictions/MatMul;inception_v3/predictions/BiasAdd]:123
	                 SOFTMAX	         5107.874	    0.606	    0.586	  0.011%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:124

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          407.139	  640.583	  640.152	 12.535%	 12.535%	     0.000	        1	[inception_v3/activation_2/Relu;inception_v3/batch_normalization_2/FusedBatchNormV3;inception_v3/batch_normalization_12/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_2/Conv2D]:2
	                 CONV_2D	         1408.319	  434.398	  434.984	  8.517%	 21.052%	     0.000	        1	[inception_v3/activation_4/Relu;inception_v3/batch_normalization_4/FusedBatchNormV3;inception_v3/batch_normalization_30/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_4/Conv2D]:5
	                 CONV_2D	           14.019	  392.720	  393.108	  7.697%	 28.750%	     0.000	        1	[inception_v3/activation_1/Relu;inception_v3/batch_normalization_1/FusedBatchNormV3;inception_v3/batch_normalization_11/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_1/Conv2D]:1
	             MAX_POOL_2D	         1047.303	  185.954	  185.746	  3.637%	 32.387%	     0.000	        1	[inception_v3/max_pooling2d/MaxPool]:3
	                 CONV_2D	         1233.061	  175.126	  175.245	  3.431%	 35.818%	     0.000	        1	[inception_v3/activation_3/Relu;inception_v3/batch_normalization_3/FusedBatchNormV3;inception_v3/batch_normalization_3/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_3/Conv2D]:4
	         AVERAGE_POOL_2D	         2713.552	  124.726	  124.937	  2.446%	 38.264%	     0.000	        1	[inception_v3/average_pooling2d_2/AvgPool]:25
	         AVERAGE_POOL_2D	         2300.909	  112.076	  112.511	  2.203%	 40.468%	     0.000	        1	[inception_v3/average_pooling2d_1/AvgPool]:16
	         AVERAGE_POOL_2D	         1929.706	   87.678	   87.679	  1.717%	 42.184%	     0.000	        1	[inception_v3/average_pooling2d/AvgPool]:7
	             MAX_POOL_2D	         1843.315	   85.992	   86.378	  1.691%	 43.876%	     0.000	        1	[inception_v3/max_pooling2d_1/MaxPool]:6
	                 CONV_2D	         3140.403	   75.316	   75.241	  1.473%	 45.349%	     0.000	        1	[inception_v3/activation_26/Relu;inception_v3/batch_normalization_26/FusedBatchNormV3;inception_v3/batch_normalization_26/FusedBatchNormV3/ReadVariableOp;inception_v3/conv2d_26/Conv2D]:34

Number of nodes executed: 125
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       94	  4083.886	    79.967%	    79.967%	     0.000	       94
	         AVERAGE_POOL_2D	        9	   675.811	    13.233%	    93.200%	     0.000	        9
	             MAX_POOL_2D	        4	   314.690	     6.162%	    99.362%	     0.000	        4
	                    MEAN	        1	    21.372	     0.418%	    99.781%	     0.000	        1
	           CONCATENATION	       15	     9.800	     0.192%	    99.973%	     0.000	       15
	         FULLY_CONNECTED	        1	     0.818	     0.016%	    99.989%	     0.000	        1
	                 SOFTMAX	        1	     0.586	     0.011%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=5105112 curr=5104785 min=5104757 max=5109916 avg=5.10702e+06 std=1667
Memory (bytes): count=0
125 nodes observed



