STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [10]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/f32i8/MobileNetV2.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/f32i8/MobileNetV2.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (32, 27, ), Input shape (50176, 3, ), and Output shape (12544, 32, ), and the ID is 0
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (16, 32, ), Input shape (12544, 32, ), and Output shape (12544, 16, ), and the ID is 1
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(96, 16, ), Input shape (12544, 16, ), and Output shape (12544, 96, ), and the ID is 2
NOT Applying Conv Low-Precision for Kernel shape (24, 96, ), Input shape 	Changing Input Shape
(3136, 96, ), and Output shape (3136, 24, ), and the ID is 3
NOT Applying Conv Low-Precision for Kernel shape (144, 24, ), Input shape (3136, 24, ), and Output shape (3136, 144, ), and the ID is 	Changing Input Shape
4
NOT Applying Conv Low-Precision for Kernel shape (24, 144, ), Input shape (3136, 144, ), and Output shape (3136, 24, ), and the ID is 5
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (144, 24, ), Input shape (3136, 24, ), and Output shape (3136, 144, ), and the ID is 6
NOT Applying Conv Low-Precision for Kernel shape (32, 144, ), Input shape (784, 144, ), and Output shape (784, 32, )	Changing Input Shape
	Changing Input Shape
, and the ID is 7
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, ), and the ID is 8
NOT Applying Conv Low-Precision for Kernel shape (32, 192, ), Input shape (784, 192, ), and Output shape (784, 32, ), and the ID is 9
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, ), and the ID is 10
NOT Applying Conv Low-Precision for Kernel shape (32, 192, ), Input shape (784, 192, ), and Output shape (784, 32, ), and the ID is 	Changing Input Shape
	Changing Input Shape
11
NOT Applying Conv Low-Precision for Kernel shape (192, 32, ), Input shape (784, 32, ), and Output shape (784, 192, ), and the ID is 12
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 192, ), Input shape (196, 192, ), and Output shape (196, 64, ), and the ID is 13
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, )	Changing Input Shape
, and Output shape (196, 384, ), and the ID is 14
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape (196, 384, )	Changing Input Shape
, and Output shape (196, 64, ), and the ID is 15
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 16
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape (196, 384, ), and Output shape (196, 64, ), and the ID is 17
NOT Applying Conv Low-Precision for Kernel shape 	Changing Input Shape
(384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 18
NOT Applying Conv Low-Precision for Kernel shape (64, 384, ), Input shape 	Changing Input Shape
(196, 384, ), and Output shape (196, 64, ), and the ID is 19
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (384, 64, ), Input shape (196, 64, ), and Output shape (196, 384, ), and the ID is 20
NOT Applying Conv Low-Precision for Kernel shape (96, 384, ), Input shape 	Changing Input Shape
(196, 384, ), and Output shape (196, 96, ), and the ID is 21
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, )	Changing Input Shape
, and the ID is 22
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (196, 576, ), and Output shape (196, 96, ), and the ID is 23
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, ), and the ID is 24
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (96, 576, ), Input shape (196, 576, ), and Output shape (196, 96, ), and the ID is 25
NOT Applying Conv Low-Precision for Kernel shape (576, 96, ), Input shape (196, 96, ), and Output shape (196, 576, )	Changing Input Shape
, and the ID is 26
NOT Applying Conv Low-Precision for Kernel shape (160, 576, ), Input shape (49, 576, ), and Output shape (49, 160, ), and the ID is 27
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape (49, 160, ), and Output shape (49, 960, ), and the ID is 28
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (160, 960, ), Input shape (49, 960, ), and Output shape (49, 160, ), and the ID is 29
NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape 	Changing Input Shape
(49, 160, ), and Output shape (49, 960, ), and the ID is 30
NOT Applying Conv Low-Precision for Kernel shape (160, 960, ), Input shape (49, 960, ), and Output shape (49, 160, ), and the ID is 31
	Changing Input Shape
	Changing Input Shape
NOT Applying Conv Low-Precision for Kernel shape (960, 160, ), Input shape (49, 160, ), and Output shape (49, 960, ), and the ID is 32
NOT Applying Conv Low-Precision for Kernel shape (320, 960, ), Input shape (49, 960, ), and Output shape (49, 320, ), and the ID is 33
NOT Applying Conv Low-Precision for Kernel shape (1280, 320, )	Changing Input Shape
	Changing Input Shape
, Input shape (49, 320, ), and Output shape (49, 1280, ), and the ID is 34
NOT Applying Low-Precision for shape (1000, 1280, ) and Input shape (1, 1280, ) With 5 Number of Temp Tensors
The input model file size (MB): 3.73314
Initialized session in 12.463ms.
Running benchmark for at least 10 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=10 first=1635209 curr=1590131 min=1588474 max=1635209 avg=1.59496e+06 std=13495

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=1592377 curr=1590766 min=1590764 max=1593165 avg=1.59192e+06 std=793

Inference timings in us: Init: 12463, First inference: 1635209, Warmup (avg): 1.59496e+06, Inference (avg): 1.59192e+06
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=2.49609 overall=19.7383
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	    5.499	    5.499	100.000%	100.000%	     0.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	    5.499	    5.499	100.000%	100.000%	     0.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	     5.499	   100.000%	   100.000%	     0.000	        1

Timings (microseconds): count=1 curr=5499
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.024	    7.960	    7.979	  0.501%	  0.501%	     0.000	        1	[mobilenetv2_1.00_224/Conv1_relu/Relu6;mobilenetv2_1.00_224/bn_Conv1/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv1/Conv2D]:0
	       DEPTHWISE_CONV_2D	            8.015	   34.365	   34.607	  2.175%	  2.676%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_depthwise_relu/Relu6;mobilenetv2_1.00_224/expanded_conv_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_depthwise/depthwise;mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3]:1
	                 CONV_2D	           42.634	    4.459	    4.439	  0.279%	  2.955%	     0.000	        1	[mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/expanded_conv_project/Conv2D]:2
	                 CONV_2D	           47.085	  471.741	  472.451	 29.692%	 32.647%	     0.000	        1	[mobilenetv2_1.00_224/block_1_expand_relu/Relu6;mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_expand/Conv2D]:3
	                     PAD	          519.549	    2.316	    2.325	  0.146%	 32.794%	     0.000	        1	[mobilenetv2_1.00_224/block_1_pad/Pad]:4
	       DEPTHWISE_CONV_2D	          521.884	   26.856	   26.887	  1.690%	 34.483%	     0.000	        1	[mobilenetv2_1.00_224/block_1_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_1_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_depthwise/depthwise;mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3]:5
	                 CONV_2D	          548.784	   44.710	   44.807	  2.816%	 37.299%	     0.000	        1	[mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_project/Conv2D]:6
	                 CONV_2D	          593.604	  170.078	  169.751	 10.668%	 47.968%	     0.000	        1	[mobilenetv2_1.00_224/block_2_expand_relu/Relu6;mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_expand/Conv2D]:7
	       DEPTHWISE_CONV_2D	          763.368	    3.825	    3.916	  0.246%	 48.214%	     0.000	        1	[mobilenetv2_1.00_224/block_2_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_depthwise/depthwise;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3]:8
	                 CONV_2D	          767.296	   46.181	   46.057	  2.895%	 51.108%	     0.000	        1	[mobilenetv2_1.00_224/block_2_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_project/Conv2D]:9
	                     ADD	          813.365	    0.730	    0.741	  0.047%	 51.155%	     0.000	        1	[mobilenetv2_1.00_224/block_2_add/add]:10
	                 CONV_2D	          814.114	  171.087	  170.295	 10.702%	 61.857%	     0.000	        1	[mobilenetv2_1.00_224/block_3_expand_relu/Relu6;mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_expand/Conv2D]:11
	                     PAD	          984.421	    0.982	    1.047	  0.066%	 61.923%	     0.000	        1	[mobilenetv2_1.00_224/block_3_pad/Pad]:12
	       DEPTHWISE_CONV_2D	          985.478	    2.324	    2.223	  0.140%	 62.063%	     0.000	        1	[mobilenetv2_1.00_224/block_3_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_depthwise/depthwise]:13
	                 CONV_2D	          987.713	   13.669	   13.650	  0.858%	 62.921%	     0.000	        1	[mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_project/Conv2D]:14
	                 CONV_2D	         1001.377	   55.107	   54.838	  3.446%	 66.367%	     0.000	        1	[mobilenetv2_1.00_224/block_4_expand_relu/Relu6;mobilenetv2_1.00_224/block_4_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_expand/Conv2D]:15
	       DEPTHWISE_CONV_2D	         1056.227	    1.444	    1.325	  0.083%	 66.450%	     0.000	        1	[mobilenetv2_1.00_224/block_4_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3]:16
	                 CONV_2D	         1057.562	   14.151	   13.959	  0.877%	 67.328%	     0.000	        1	[mobilenetv2_1.00_224/block_4_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_project/Conv2D]:17
	                     ADD	         1071.533	    0.259	    0.262	  0.016%	 67.344%	     0.000	        1	[mobilenetv2_1.00_224/block_4_add/add]:18
	                 CONV_2D	         1071.801	   54.799	   54.868	  3.448%	 70.792%	     0.000	        1	[mobilenetv2_1.00_224/block_5_expand_relu/Relu6;mobilenetv2_1.00_224/block_5_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_expand/Conv2D]:19
	       DEPTHWISE_CONV_2D	         1126.681	    1.284	    1.292	  0.081%	 70.874%	     0.000	        1	[mobilenetv2_1.00_224/block_5_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_5_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3]:20
	                 CONV_2D	         1127.983	   13.914	   13.905	  0.874%	 71.748%	     0.000	        1	[mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_project/Conv2D]:21
	                     ADD	         1141.900	    0.256	    0.256	  0.016%	 71.764%	     0.000	        1	[mobilenetv2_1.00_224/block_5_add/add]:22
	                 CONV_2D	         1142.161	   54.977	   55.018	  3.458%	 75.221%	     0.000	        1	[mobilenetv2_1.00_224/block_6_expand_relu/Relu6;mobilenetv2_1.00_224/block_6_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_expand/Conv2D]:23
	                     PAD	         1197.194	    0.338	    0.360	  0.023%	 75.244%	     0.000	        1	[mobilenetv2_1.00_224/block_6_pad/Pad]:24
	       DEPTHWISE_CONV_2D	         1197.561	    0.758	    0.760	  0.048%	 75.292%	     0.000	        1	[mobilenetv2_1.00_224/block_6_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_depthwise/depthwise]:25
	                 CONV_2D	         1198.330	    5.690	    5.680	  0.357%	 75.649%	     0.000	        1	[mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_project/Conv2D]:26
	                 CONV_2D	         1204.021	   26.908	   26.861	  1.688%	 77.337%	     0.000	        1	[mobilenetv2_1.00_224/block_7_expand_relu/Relu6;mobilenetv2_1.00_224/block_7_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_expand/Conv2D]:27
	       DEPTHWISE_CONV_2D	         1230.892	    0.605	    0.570	  0.036%	 77.373%	     0.000	        1	[mobilenetv2_1.00_224/block_7_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_7_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:28
	                 CONV_2D	         1231.472	    6.046	    6.076	  0.382%	 77.754%	     0.000	        1	[mobilenetv2_1.00_224/block_7_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_7_project/Conv2D]:29
	                     ADD	         1237.558	    0.137	    0.137	  0.009%	 77.763%	     0.000	        1	[mobilenetv2_1.00_224/block_7_add/add]:30
	                 CONV_2D	         1237.701	   26.795	   26.796	  1.684%	 79.447%	     0.000	        1	[mobilenetv2_1.00_224/block_8_expand_relu/Relu6;mobilenetv2_1.00_224/block_8_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_expand/Conv2D]:31
	       DEPTHWISE_CONV_2D	         1264.507	    0.539	    0.564	  0.035%	 79.483%	     0.000	        1	[mobilenetv2_1.00_224/block_8_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_8_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:32
	                 CONV_2D	         1265.079	    6.057	    6.047	  0.380%	 79.863%	     0.000	        1	[mobilenetv2_1.00_224/block_8_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_8_project/Conv2D]:33
	                     ADD	         1271.136	    0.135	    0.139	  0.009%	 79.871%	     0.000	        1	[mobilenetv2_1.00_224/block_8_add/add]:34
	                 CONV_2D	         1271.281	   26.777	   26.742	  1.681%	 81.552%	     0.000	        1	[mobilenetv2_1.00_224/block_9_expand_relu/Relu6;mobilenetv2_1.00_224/block_9_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_expand/Conv2D]:35
	       DEPTHWISE_CONV_2D	         1298.034	    0.551	    0.550	  0.035%	 81.587%	     0.000	        1	[mobilenetv2_1.00_224/block_9_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_9_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3]:36
	                 CONV_2D	         1298.591	    6.100	    6.050	  0.380%	 81.967%	     0.000	        1	[mobilenetv2_1.00_224/block_9_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_9_project/Conv2D]:37
	                     ADD	         1304.651	    0.137	    0.136	  0.009%	 81.975%	     0.000	        1	[mobilenetv2_1.00_224/block_9_add/add]:38
	                 CONV_2D	         1304.793	   26.625	   26.649	  1.675%	 83.650%	     0.000	        1	[mobilenetv2_1.00_224/block_10_expand_relu/Relu6;mobilenetv2_1.00_224/block_10_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_expand/Conv2D]:39
	       DEPTHWISE_CONV_2D	         1331.453	    0.541	    0.548	  0.034%	 83.685%	     0.000	        1	[mobilenetv2_1.00_224/block_10_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_depthwise/depthwise]:40
	                 CONV_2D	         1332.008	    8.368	    8.334	  0.524%	 84.208%	     0.000	        1	[mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_10_project/Conv2D]:41
	                 CONV_2D	         1340.352	   40.308	   40.334	  2.535%	 86.743%	     0.000	        1	[mobilenetv2_1.00_224/block_11_expand_relu/Relu6;mobilenetv2_1.00_224/block_11_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_expand/Conv2D]:42
	       DEPTHWISE_CONV_2D	         1380.699	    0.877	    0.887	  0.056%	 86.799%	     0.000	        1	[mobilenetv2_1.00_224/block_11_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3]:43
	                 CONV_2D	         1381.596	    8.985	    8.964	  0.563%	 87.362%	     0.000	        1	[mobilenetv2_1.00_224/block_11_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_project/Conv2D]:44
	                     ADD	         1390.571	    0.196	    0.198	  0.012%	 87.375%	     0.000	        1	[mobilenetv2_1.00_224/block_11_add/add]:45
	                 CONV_2D	         1390.775	   39.782	   39.902	  2.508%	 89.883%	     0.000	        1	[mobilenetv2_1.00_224/block_12_expand_relu/Relu6;mobilenetv2_1.00_224/block_12_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_expand/Conv2D]:46
	       DEPTHWISE_CONV_2D	         1430.690	    0.917	    0.885	  0.056%	 89.938%	     0.000	        1	[mobilenetv2_1.00_224/block_12_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_12_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3]:47
	                 CONV_2D	         1431.584	    9.021	    8.986	  0.565%	 90.503%	     0.000	        1	[mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_12_project/Conv2D]:48
	                     ADD	         1440.581	    0.202	    0.204	  0.013%	 90.516%	     0.000	        1	[mobilenetv2_1.00_224/block_12_add/add]:49
	                 CONV_2D	         1440.791	   40.159	   40.140	  2.523%	 93.038%	     0.000	        1	[mobilenetv2_1.00_224/block_13_expand_relu/Relu6;mobilenetv2_1.00_224/block_13_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_expand/Conv2D]:50
	                     PAD	         1480.944	    0.207	    0.266	  0.017%	 93.055%	     0.000	        1	[mobilenetv2_1.00_224/block_13_pad/Pad]:51
	       DEPTHWISE_CONV_2D	         1481.217	    0.559	    0.586	  0.037%	 93.092%	     0.000	        1	[mobilenetv2_1.00_224/block_13_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_depthwise/depthwise]:52
	                 CONV_2D	         1481.811	    3.698	    3.687	  0.232%	 93.324%	     0.000	        1	[mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_project/Conv2D]:53
	                 CONV_2D	         1485.509	   17.161	   17.251	  1.084%	 94.408%	     0.000	        1	[mobilenetv2_1.00_224/block_14_expand_relu/Relu6;mobilenetv2_1.00_224/block_14_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_expand/Conv2D]:54
	       DEPTHWISE_CONV_2D	         1502.770	    0.400	    0.412	  0.026%	 94.434%	     0.000	        1	[mobilenetv2_1.00_224/block_14_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3]:55
	                 CONV_2D	         1503.189	    4.095	    4.131	  0.260%	 94.693%	     0.000	        1	[mobilenetv2_1.00_224/block_14_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_14_project/Conv2D]:56
	                     ADD	         1507.331	    0.090	    0.095	  0.006%	 94.699%	     0.000	        1	[mobilenetv2_1.00_224/block_14_add/add]:57
	                 CONV_2D	         1507.433	   17.795	   17.804	  1.119%	 95.818%	     0.000	        1	[mobilenetv2_1.00_224/block_15_expand_relu/Relu6;mobilenetv2_1.00_224/block_15_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_expand/Conv2D]:58
	       DEPTHWISE_CONV_2D	         1525.248	    0.380	    0.394	  0.025%	 95.843%	     0.000	        1	[mobilenetv2_1.00_224/block_15_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_15_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3]:59
	                 CONV_2D	         1525.649	    4.117	    4.129	  0.259%	 96.102%	     0.000	        1	[mobilenetv2_1.00_224/block_15_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_15_project/Conv2D]:60
	                     ADD	         1529.788	    0.095	    0.095	  0.006%	 96.108%	     0.000	        1	[mobilenetv2_1.00_224/block_15_add/add]:61
	                 CONV_2D	         1529.889	   17.385	   17.361	  1.091%	 97.199%	     0.000	        1	[mobilenetv2_1.00_224/block_16_expand_relu/Relu6;mobilenetv2_1.00_224/block_16_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_expand/Conv2D]:62
	       DEPTHWISE_CONV_2D	         1547.261	    0.373	    0.378	  0.024%	 97.223%	     0.000	        1	[mobilenetv2_1.00_224/block_16_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_depthwise/depthwise]:63
	                 CONV_2D	         1547.646	    7.737	    7.723	  0.485%	 97.709%	     0.000	        1	[mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_16_project/Conv2D]:64
	                 CONV_2D	         1555.380	   24.877	   24.955	  1.568%	 99.277%	     0.000	        1	[mobilenetv2_1.00_224/out_relu/Relu6;mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3;mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/Conv_1/Conv2D]:65
	                    MEAN	         1580.347	   10.330	   10.261	  0.645%	 99.922%	     0.000	        1	[mobilenetv2_1.00_224/global_average_pooling2d/Mean]:66
	         FULLY_CONNECTED	         1590.616	    0.721	    0.654	  0.041%	 99.963%	     0.000	        1	[mobilenetv2_1.00_224/predictions/MatMul;mobilenetv2_1.00_224/predictions/BiasAdd]:67
	                 SOFTMAX	         1591.280	    0.580	    0.591	  0.037%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:68

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	           47.085	  471.741	  472.451	 29.692%	 29.692%	     0.000	        1	[mobilenetv2_1.00_224/block_1_expand_relu/Relu6;mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_expand/Conv2D]:3
	                 CONV_2D	          814.114	  171.087	  170.295	 10.702%	 40.395%	     0.000	        1	[mobilenetv2_1.00_224/block_3_expand_relu/Relu6;mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_3_expand/Conv2D]:11
	                 CONV_2D	          593.604	  170.078	  169.751	 10.668%	 51.063%	     0.000	        1	[mobilenetv2_1.00_224/block_2_expand_relu/Relu6;mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_expand/Conv2D]:7
	                 CONV_2D	         1142.161	   54.977	   55.018	  3.458%	 54.521%	     0.000	        1	[mobilenetv2_1.00_224/block_6_expand_relu/Relu6;mobilenetv2_1.00_224/block_6_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_6_expand/Conv2D]:23
	                 CONV_2D	         1071.801	   54.799	   54.868	  3.448%	 57.969%	     0.000	        1	[mobilenetv2_1.00_224/block_5_expand_relu/Relu6;mobilenetv2_1.00_224/block_5_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_5_expand/Conv2D]:19
	                 CONV_2D	         1001.377	   55.107	   54.838	  3.446%	 61.415%	     0.000	        1	[mobilenetv2_1.00_224/block_4_expand_relu/Relu6;mobilenetv2_1.00_224/block_4_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_4_expand/Conv2D]:15
	                 CONV_2D	          767.296	   46.181	   46.057	  2.895%	 64.310%	     0.000	        1	[mobilenetv2_1.00_224/block_2_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_2_project/Conv2D]:9
	                 CONV_2D	          548.784	   44.710	   44.807	  2.816%	 67.126%	     0.000	        1	[mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_1_project/Conv2D]:6
	                 CONV_2D	         1340.352	   40.308	   40.334	  2.535%	 69.661%	     0.000	        1	[mobilenetv2_1.00_224/block_11_expand_relu/Relu6;mobilenetv2_1.00_224/block_11_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_11_expand/Conv2D]:42
	                 CONV_2D	         1440.791	   40.159	   40.140	  2.523%	 72.183%	     0.000	        1	[mobilenetv2_1.00_224/block_13_expand_relu/Relu6;mobilenetv2_1.00_224/block_13_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3/ReadVariableOp;mobilenetv2_1.00_224/block_13_expand/Conv2D]:50

Number of nodes executed: 69
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       35	  1496.603	    94.059%	    94.059%	     0.000	       35
	       DEPTHWISE_CONV_2D	       17	    76.775	     4.825%	    98.884%	     0.000	       17
	                    MEAN	        1	    10.261	     0.645%	    99.529%	     0.000	        1
	                     PAD	        4	     3.997	     0.251%	    99.780%	     0.000	        4
	                     ADD	       10	     2.255	     0.142%	    99.922%	     0.000	       10
	         FULLY_CONNECTED	        1	     0.654	     0.041%	    99.963%	     0.000	        1
	                 SOFTMAX	        1	     0.591	     0.037%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=1591628 curr=1590022 min=1590018 max=1592429 avg=1.59117e+06 std=795
Memory (bytes): count=0
69 nodes observed



