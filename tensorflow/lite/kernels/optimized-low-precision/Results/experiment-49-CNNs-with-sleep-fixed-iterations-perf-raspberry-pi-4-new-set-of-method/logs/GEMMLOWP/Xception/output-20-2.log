STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [0]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ), and Output shape (22201, 32, ), and the ID is 0
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (22201, 32, ), and Output shape (21609, 64, ), and the ID is 1
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (21609, 128, ), and the ID is 2
	Changing Input Shape
	New Input Shape: (21609, 64, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (21609, 128, ), and Output shape (21609, 128, ), and the ID is 3
	Changing Input Shape
	New Input Shape: (21609, 128, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (5476, 128, ), and the ID is 4
	Changing Input Shape
	New Input Shape: (5476, 64, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (5476, 256, ), and the ID is 5
	Changing Input Shape
	New Input Shape: (5476, 128, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 256, ), Input shape (5476, 256, ), and Output shape (5476, 256, ), and the ID is 6
	Changing Input Shape
	New Input Shape: (5476, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (1369, 256, ), and the ID is 7
	Changing Input Shape
	New Input Shape: (1369, 128, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (1369, 728, ), and the ID is 8
	Changing Input Shape
	New Input Shape: (1369, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (1369, 728, ), and Output shape (1369, 728, ), and the ID is 9
	Changing Input Shape
	New Input Shape: (1369, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (361, 728, ), and the ID is 10
	Changing Input Shape
	New Input Shape: (361, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 11
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 12
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 13
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 14
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 15
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 16
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 17
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 18
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 19
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 20
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 21
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 22
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 23
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 24
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 25
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 26
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 27
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 28
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 29
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 30
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 31
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 32
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 33
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 34
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 35
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (361, 1024, ), and the ID is 36
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (100, 1024, ), and the ID is 37
	Changing Input Shape
	New Input Shape: (100, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1024, 1536, ), Input shape (100, 1024, ), and Output shape (100, 1536, ), and the ID is 38
	Changing Input Shape
	New Input Shape: (100, 1024, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1536, 2048, ), Input shape (100, 1536, ), and Output shape (100, 2048, ), and the ID is 39
	Changing Input Shape
	New Input Shape: (100, 1536, )
	No Changes To Appliability.
The input model file size (MB): 24.0822
Initialized session in 42.59ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=7048900 curr=7017851 min=7017851 max=7048900 avg=7.03338e+06 std=15524

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=7025879 curr=7029586 min=7025879 max=7036617 avg=7.03007e+06 std=2908

Inference timings in us: Init: 42590, First inference: 7048900, Warmup (avg): 7.03338e+06, Inference (avg): 7.03007e+06
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=7.98047 overall=34.6172
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   14.185	   14.185	100.000%	100.000%	   768.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   14.185	   14.185	100.000%	100.000%	   768.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    14.185	   100.000%	   100.000%	   768.000	        1

Timings (microseconds): count=1 curr=14185
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.018	  180.774	  180.776	  2.572%	  2.572%	     0.000	        1	[xception/block1_conv1_act/Relu;xception/block1_conv1_bn/FusedBatchNormV3;xception/block1_conv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv1/Conv2D]:0
	                 CONV_2D	          180.799	  451.742	  452.211	  6.433%	  9.005%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	       DEPTHWISE_CONV_2D	          633.015	    5.474	    5.394	  0.077%	  9.081%	     0.000	        1	[xception/block2_sepconv1/separable_conv2d/depthwise1]:2
	                 CONV_2D	          638.414	  672.403	  673.504	  9.581%	 18.662%	     0.000	        1	[xception/block2_sepconv2_act/Relu;xception/block2_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv1/separable_conv2d]:3
	       DEPTHWISE_CONV_2D	         1311.924	   13.331	   13.358	  0.190%	 18.852%	     0.000	        1	[xception/block2_sepconv2/separable_conv2d/depthwise1]:4
	                 CONV_2D	         1325.286	  712.690	  713.947	 10.156%	 29.009%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	             MAX_POOL_2D	         2039.239	   15.794	   15.833	  0.225%	 29.234%	     0.000	        1	[xception/block2_pool/MaxPool]:6
	                 CONV_2D	         2055.077	  172.251	  172.200	  2.450%	 31.683%	     0.000	        1	[xception/batch_normalization_297/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/conv2d_297/Conv2D]:7
	                     ADD	         2227.282	   66.068	   66.171	  0.941%	 32.625%	     0.000	        1	[xception/add_4/add]:8
	                    RELU	         2293.458	   87.232	   87.325	  1.242%	 33.867%	     0.000	        1	[xception/block3_sepconv1_act/Relu]:9
	       DEPTHWISE_CONV_2D	         2380.788	    3.466	    3.428	  0.049%	 33.916%	     0.000	        1	[xception/block3_sepconv1/separable_conv2d/depthwise1]:10
	                 CONV_2D	         2384.220	  353.160	  353.093	  5.023%	 38.939%	     0.000	        1	[xception/block3_sepconv2_act/Relu;xception/block3_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv1/separable_conv2d]:11
	       DEPTHWISE_CONV_2D	         2737.319	    7.041	    6.913	  0.098%	 39.037%	     0.000	        1	[xception/block3_sepconv2/separable_conv2d/depthwise1]:12
	                 CONV_2D	         2744.237	  385.163	  385.285	  5.481%	 44.518%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	             MAX_POOL_2D	         3129.527	    7.777	    7.687	  0.109%	 44.627%	     0.000	        1	[xception/block3_pool/MaxPool]:14
	                 CONV_2D	         3137.219	   89.163	   89.246	  1.270%	 45.897%	     0.000	        1	[xception/batch_normalization_298/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/conv2d_298/Conv2D]:15
	                     ADD	         3226.470	   33.032	   33.087	  0.471%	 46.368%	     0.000	        1	[xception/add_5/add]:16
	                    RELU	         3259.562	   43.947	   43.979	  0.626%	 46.993%	     0.000	        1	[xception/block4_sepconv1_act/Relu]:17
	       DEPTHWISE_CONV_2D	         3303.545	    1.634	    1.651	  0.023%	 47.017%	     0.000	        1	[xception/block4_sepconv1/separable_conv2d/depthwise1]:18
	                 CONV_2D	         3305.198	  267.453	  267.716	  3.808%	 50.825%	     0.000	        1	[xception/block4_sepconv2_act/Relu;xception/block4_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv1/separable_conv2d]:19
	       DEPTHWISE_CONV_2D	         3572.919	    5.131	    5.155	  0.073%	 50.898%	     0.000	        1	[xception/block4_sepconv2/separable_conv2d/depthwise1]:20
	                 CONV_2D	         3578.079	  506.259	  506.563	  7.206%	 58.105%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	             MAX_POOL_2D	         4084.647	    6.277	    6.290	  0.089%	 58.194%	     0.000	        1	[xception/block4_pool/MaxPool]:22
	                 CONV_2D	         4090.941	   54.711	   54.670	  0.778%	 58.972%	     0.000	        1	[xception/batch_normalization_299/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/conv2d_299/Conv2D]:23
	                     ADD	         4145.616	   24.801	   24.838	  0.353%	 59.325%	     0.000	        1	[xception/add_6/add]:24
	                    RELU	         4170.458	   32.960	   32.968	  0.469%	 59.794%	     0.000	        1	[xception/block5_sepconv1_act/Relu]:25
	       DEPTHWISE_CONV_2D	         4203.430	    1.341	    1.306	  0.019%	 59.813%	     0.000	        1	[xception/block5_sepconv1/separable_conv2d/depthwise1]:26
	                 CONV_2D	         4204.737	   75.579	   75.670	  1.076%	 60.889%	     0.000	        1	[xception/block5_sepconv2_act/Relu;xception/block5_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv1/separable_conv2d]:27
	       DEPTHWISE_CONV_2D	         4280.413	    1.345	    1.347	  0.019%	 60.908%	     0.000	        1	[xception/block5_sepconv2/separable_conv2d/depthwise1]:28
	                 CONV_2D	         4281.762	   75.676	   75.495	  1.074%	 61.982%	     0.000	        1	[xception/block5_sepconv3_act/Relu;xception/block5_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv2/separable_conv2d]:29
	       DEPTHWISE_CONV_2D	         4357.262	    1.321	    1.344	  0.019%	 62.001%	     0.000	        1	[xception/block5_sepconv3/separable_conv2d/depthwise1]:30
	                 CONV_2D	         4358.609	   75.598	   75.686	  1.077%	 63.078%	     0.000	        1	[xception/block5_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv3/separable_conv2d]:31
	                     ADD	         4434.300	   24.773	   24.838	  0.353%	 63.431%	     0.000	        1	[xception/add_7/add]:32
	                    RELU	         4459.143	   32.954	   32.941	  0.469%	 63.900%	     0.000	        1	[xception/block6_sepconv1_act/Relu]:33
	       DEPTHWISE_CONV_2D	         4492.088	    1.250	    1.286	  0.018%	 63.918%	     0.000	        1	[xception/block6_sepconv1/separable_conv2d/depthwise1]:34
	                 CONV_2D	         4493.375	   75.583	   75.698	  1.077%	 64.995%	     0.000	        1	[xception/block6_sepconv2_act/Relu;xception/block6_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv1/separable_conv2d]:35
	       DEPTHWISE_CONV_2D	         4569.078	    1.373	    1.350	  0.019%	 65.014%	     0.000	        1	[xception/block6_sepconv2/separable_conv2d/depthwise1]:36
	                 CONV_2D	         4570.431	   75.853	   75.560	  1.075%	 66.089%	     0.000	        1	[xception/block6_sepconv3_act/Relu;xception/block6_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv2/separable_conv2d]:37
	       DEPTHWISE_CONV_2D	         4645.997	    1.314	    1.360	  0.019%	 66.109%	     0.000	        1	[xception/block6_sepconv3/separable_conv2d/depthwise1]:38
	                 CONV_2D	         4647.358	   75.557	   75.595	  1.075%	 67.184%	     0.000	        1	[xception/block6_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv3/separable_conv2d]:39
	                     ADD	         4722.958	   24.845	   24.841	  0.353%	 67.537%	     0.000	        1	[xception/add_8/add]:40
	                    RELU	         4747.803	   32.960	   32.942	  0.469%	 68.006%	     0.000	        1	[xception/block7_sepconv1_act/Relu]:41
	       DEPTHWISE_CONV_2D	         4780.748	    1.241	    1.283	  0.018%	 68.024%	     0.000	        1	[xception/block7_sepconv1/separable_conv2d/depthwise1]:42
	                 CONV_2D	         4782.033	   75.589	   75.559	  1.075%	 69.099%	     0.000	        1	[xception/block7_sepconv2_act/Relu;xception/block7_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv1/separable_conv2d]:43
	       DEPTHWISE_CONV_2D	         4857.596	    1.384	    1.355	  0.019%	 69.118%	     0.000	        1	[xception/block7_sepconv2/separable_conv2d/depthwise1]:44
	                 CONV_2D	         4858.954	   75.671	   75.567	  1.075%	 70.193%	     0.000	        1	[xception/block7_sepconv3_act/Relu;xception/block7_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv2/separable_conv2d]:45
	       DEPTHWISE_CONV_2D	         4934.526	    1.366	    1.343	  0.019%	 70.212%	     0.000	        1	[xception/block7_sepconv3/separable_conv2d/depthwise1]:46
	                 CONV_2D	         4935.871	   75.542	   75.688	  1.077%	 71.289%	     0.000	        1	[xception/block7_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv3/separable_conv2d]:47
	                     ADD	         5011.566	   24.842	   24.852	  0.354%	 71.643%	     0.000	        1	[xception/add_9/add]:48
	                    RELU	         5036.423	   32.942	   32.956	  0.469%	 72.111%	     0.000	        1	[xception/block8_sepconv1_act/Relu]:49
	       DEPTHWISE_CONV_2D	         5069.383	    1.297	    1.290	  0.018%	 72.130%	     0.000	        1	[xception/block8_sepconv1/separable_conv2d/depthwise1]:50
	                 CONV_2D	         5070.675	   75.621	   75.541	  1.075%	 73.204%	     0.000	        1	[xception/block8_sepconv2_act/Relu;xception/block8_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv1/separable_conv2d]:51
	       DEPTHWISE_CONV_2D	         5146.220	    1.374	    1.369	  0.019%	 73.224%	     0.000	        1	[xception/block8_sepconv2/separable_conv2d/depthwise1]:52
	                 CONV_2D	         5147.591	   75.485	   75.648	  1.076%	 74.300%	     0.000	        1	[xception/block8_sepconv3_act/Relu;xception/block8_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv2/separable_conv2d]:53
	       DEPTHWISE_CONV_2D	         5223.245	    1.382	    1.357	  0.019%	 74.319%	     0.000	        1	[xception/block8_sepconv3/separable_conv2d/depthwise1]:54
	                 CONV_2D	         5224.604	   75.720	   75.601	  1.075%	 75.395%	     0.000	        1	[xception/block8_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv3/separable_conv2d]:55
	                     ADD	         5300.211	   24.799	   24.849	  0.353%	 75.748%	     0.000	        1	[xception/add_10/add]:56
	                    RELU	         5325.064	   32.924	   32.969	  0.469%	 76.217%	     0.000	        1	[xception/block9_sepconv1_act/Relu]:57
	       DEPTHWISE_CONV_2D	         5358.037	    1.266	    1.281	  0.018%	 76.235%	     0.000	        1	[xception/block9_sepconv1/separable_conv2d/depthwise1]:58
	                 CONV_2D	         5359.320	   75.679	   75.644	  1.076%	 77.312%	     0.000	        1	[xception/block9_sepconv2_act/Relu;xception/block9_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv1/separable_conv2d]:59
	       DEPTHWISE_CONV_2D	         5434.970	    1.377	    1.338	  0.019%	 77.331%	     0.000	        1	[xception/block9_sepconv2/separable_conv2d/depthwise1]:60
	                 CONV_2D	         5436.310	   75.540	   75.538	  1.075%	 78.405%	     0.000	        1	[xception/block9_sepconv3_act/Relu;xception/block9_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv2/separable_conv2d]:61
	       DEPTHWISE_CONV_2D	         5511.856	    1.317	    1.346	  0.019%	 78.424%	     0.000	        1	[xception/block9_sepconv3/separable_conv2d/depthwise1]:62
	                 CONV_2D	         5513.204	   75.633	   75.538	  1.075%	 79.499%	     0.000	        1	[xception/block9_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv3/separable_conv2d]:63
	                     ADD	         5588.748	   24.796	   24.828	  0.353%	 79.852%	     0.000	        1	[xception/add_11/add]:64
	                    RELU	         5613.580	   33.033	   32.963	  0.469%	 80.321%	     0.000	        1	[xception/block10_sepconv1_act/Relu]:65
	       DEPTHWISE_CONV_2D	         5646.547	    1.357	    1.294	  0.018%	 80.339%	     0.000	        1	[xception/block10_sepconv1/separable_conv2d/depthwise1]:66
	                 CONV_2D	         5647.843	   75.499	   75.588	  1.075%	 81.415%	     0.000	        1	[xception/block10_sepconv2_act/Relu;xception/block10_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv1/separable_conv2d]:67
	       DEPTHWISE_CONV_2D	         5723.436	    1.415	    1.347	  0.019%	 81.434%	     0.000	        1	[xception/block10_sepconv2/separable_conv2d/depthwise1]:68
	                 CONV_2D	         5724.784	   75.512	   75.540	  1.075%	 82.508%	     0.000	        1	[xception/block10_sepconv3_act/Relu;xception/block10_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv2/separable_conv2d]:69
	       DEPTHWISE_CONV_2D	         5800.330	    1.325	    1.348	  0.019%	 82.528%	     0.000	        1	[xception/block10_sepconv3/separable_conv2d/depthwise1]:70
	                 CONV_2D	         5801.681	   75.461	   75.508	  1.074%	 83.602%	     0.000	        1	[xception/block10_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv3/separable_conv2d]:71
	                     ADD	         5877.193	   24.820	   24.839	  0.353%	 83.955%	     0.000	        1	[xception/add_12/add]:72
	                    RELU	         5902.037	   32.956	   32.936	  0.469%	 84.424%	     0.000	        1	[xception/block11_sepconv1_act/Relu]:73
	       DEPTHWISE_CONV_2D	         5934.977	    1.351	    1.286	  0.018%	 84.442%	     0.000	        1	[xception/block11_sepconv1/separable_conv2d/depthwise1]:74
	                 CONV_2D	         5936.265	   75.401	   75.643	  1.076%	 85.518%	     0.000	        1	[xception/block11_sepconv2_act/Relu;xception/block11_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv1/separable_conv2d]:75
	       DEPTHWISE_CONV_2D	         6011.914	    1.361	    1.343	  0.019%	 85.537%	     0.000	        1	[xception/block11_sepconv2/separable_conv2d/depthwise1]:76
	                 CONV_2D	         6013.259	   75.562	   75.545	  1.075%	 86.612%	     0.000	        1	[xception/block11_sepconv3_act/Relu;xception/block11_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv2/separable_conv2d]:77
	       DEPTHWISE_CONV_2D	         6088.809	    1.326	    1.357	  0.019%	 86.631%	     0.000	        1	[xception/block11_sepconv3/separable_conv2d/depthwise1]:78
	                 CONV_2D	         6090.169	   75.669	   75.598	  1.075%	 87.706%	     0.000	        1	[xception/block11_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv3/separable_conv2d]:79
	                     ADD	         6165.772	   24.848	   24.840	  0.353%	 88.060%	     0.000	        1	[xception/add_13/add]:80
	                    RELU	         6190.617	   32.918	   32.965	  0.469%	 88.529%	     0.000	        1	[xception/block12_sepconv1_act/Relu]:81
	       DEPTHWISE_CONV_2D	         6223.585	    1.374	    1.314	  0.019%	 88.547%	     0.000	        1	[xception/block12_sepconv1/separable_conv2d/depthwise1]:82
	                 CONV_2D	         6224.901	   75.455	   75.606	  1.076%	 89.623%	     0.000	        1	[xception/block12_sepconv2_act/Relu;xception/block12_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv1/separable_conv2d]:83
	       DEPTHWISE_CONV_2D	         6300.512	    1.361	    1.331	  0.019%	 89.642%	     0.000	        1	[xception/block12_sepconv2/separable_conv2d/depthwise1]:84
	                 CONV_2D	         6301.845	   75.315	   75.542	  1.075%	 90.717%	     0.000	        1	[xception/block12_sepconv3_act/Relu;xception/block12_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv2/separable_conv2d]:85
	       DEPTHWISE_CONV_2D	         6377.392	    1.339	    1.368	  0.019%	 90.736%	     0.000	        1	[xception/block12_sepconv3/separable_conv2d/depthwise1]:86
	                 CONV_2D	         6378.762	   75.684	   75.652	  1.076%	 91.812%	     0.000	        1	[xception/block12_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv3/separable_conv2d]:87
	                     ADD	         6454.420	   24.844	   24.843	  0.353%	 92.166%	     0.000	        1	[xception/add_14/add]:88
	                    RELU	         6479.267	   32.968	   32.962	  0.469%	 92.635%	     0.000	        1	[xception/block13_sepconv1_act/Relu]:89
	       DEPTHWISE_CONV_2D	         6512.232	    1.321	    1.278	  0.018%	 92.653%	     0.000	        1	[xception/block13_sepconv1/separable_conv2d/depthwise1]:90
	                 CONV_2D	         6513.511	   75.457	   75.541	  1.075%	 93.727%	     0.000	        1	[xception/block13_sepconv2_act/Relu;xception/block13_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv1/separable_conv2d]:91
	       DEPTHWISE_CONV_2D	         6589.058	    1.331	    1.351	  0.019%	 93.747%	     0.000	        1	[xception/block13_sepconv2/separable_conv2d/depthwise1]:92
	                 CONV_2D	         6590.411	  110.118	  110.048	  1.565%	 95.312%	     0.000	        1	[xception/block13_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv2/separable_conv2d]:93
	             MAX_POOL_2D	         6700.464	    2.199	    2.254	  0.032%	 95.344%	     0.000	        1	[xception/block13_pool/MaxPool]:94
	                 CONV_2D	         6702.720	   35.600	   35.722	  0.508%	 95.852%	     0.000	        1	[xception/batch_normalization_300/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/conv2d_300/Conv2D]:95
	                     ADD	         6738.447	    9.696	    9.695	  0.138%	 95.990%	     0.000	        1	[xception/add_15/add]:96
	       DEPTHWISE_CONV_2D	         6748.145	    0.523	    0.516	  0.007%	 95.998%	     0.000	        1	[xception/block14_sepconv1/separable_conv2d/depthwise1]:97
	                 CONV_2D	         6748.662	   63.867	   63.903	  0.909%	 96.907%	     0.000	        1	[xception/block14_sepconv1_act/Relu;xception/block14_sepconv1_bn/FusedBatchNormV3;xception/block14_sepconv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv1/separable_conv2d]:98
	       DEPTHWISE_CONV_2D	         6812.570	    0.815	    0.799	  0.011%	 96.918%	     0.000	        1	[xception/block14_sepconv2/separable_conv2d/depthwise1]:99
	                 CONV_2D	         6813.370	  112.919	  113.092	  1.609%	 98.527%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100
	                    MEAN	         6926.468	   35.085	   35.073	  0.499%	 99.026%	     0.000	        1	[xception/avg_pool/Mean]:101
	         FULLY_CONNECTED	         6961.544	   68.362	   68.412	  0.973%	 99.999%	     0.000	        1	[xception/predictions/MatMul;xception/predictions/BiasAdd]:102
	                 SOFTMAX	         7029.960	    0.077	    0.080	  0.001%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:103

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	         1325.286	  712.690	  713.947	 10.156%	 10.156%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	                 CONV_2D	          638.414	  672.403	  673.504	  9.581%	 19.737%	     0.000	        1	[xception/block2_sepconv2_act/Relu;xception/block2_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv1/separable_conv2d]:3
	                 CONV_2D	         3578.079	  506.259	  506.563	  7.206%	 26.943%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	                 CONV_2D	          180.799	  451.742	  452.211	  6.433%	 33.376%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	                 CONV_2D	         2744.237	  385.163	  385.285	  5.481%	 38.857%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	                 CONV_2D	         2384.220	  353.160	  353.093	  5.023%	 43.880%	     0.000	        1	[xception/block3_sepconv2_act/Relu;xception/block3_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv1/separable_conv2d]:11
	                 CONV_2D	         3305.198	  267.453	  267.716	  3.808%	 47.689%	     0.000	        1	[xception/block4_sepconv2_act/Relu;xception/block4_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv1/separable_conv2d]:19
	                 CONV_2D	            0.018	  180.774	  180.776	  2.572%	 50.260%	     0.000	        1	[xception/block1_conv1_act/Relu;xception/block1_conv1_bn/FusedBatchNormV3;xception/block1_conv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv1/Conv2D]:0
	                 CONV_2D	         2055.077	  172.251	  172.200	  2.450%	 52.710%	     0.000	        1	[xception/batch_normalization_297/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/conv2d_297/Conv2D]:7
	                 CONV_2D	         6813.370	  112.919	  113.092	  1.609%	 54.319%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100

Number of nodes executed: 104
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       40	  6061.741	    86.232%	    86.232%	     0.000	       40
	                    RELU	       11	   427.899	     6.087%	    92.319%	     0.000	       11
	                     ADD	       12	   332.515	     4.730%	    97.050%	     0.000	       12
	       DEPTHWISE_CONV_2D	       34	    71.768	     1.021%	    98.071%	     0.000	       34
	         FULLY_CONNECTED	        1	    68.411	     0.973%	    99.044%	     0.000	        1
	                    MEAN	        1	    35.072	     0.499%	    99.543%	     0.000	        1
	             MAX_POOL_2D	        4	    32.062	     0.456%	    99.999%	     0.000	        4
	                 SOFTMAX	        1	     0.079	     0.001%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=7025367 curr=7029106 min=7025367 max=7036107 avg=7.0296e+06 std=2903
Memory (bytes): count=0
104 nodes observed



[ perf record: Woken up 633 times to write data ]
Warning:
Processed 619418 events and lost 1 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 158.077 MB /tmp/data.record (618019 samples) ]

156.757

