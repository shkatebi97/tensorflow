STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ), and Output shape (22201, 32, ), and the ID is 0
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 32, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (32, 32, ) DONE
	Preparing Filter With Shape: (27, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22208, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22208, 32, ) DONE
	Allocating An Output Temporary Tensor With Shape: (22208, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (22201, 32, ), and Output shape (21609, 64, ), and the ID is 1
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21616, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (21609, 128, ), and the ID is 2
	Changing Input Shape
	New Input Shape: (21609, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21616, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (21609, 128, ), and Output shape (21609, 128, ), and the ID is 3
	Changing Input Shape
	New Input Shape: (21609, 128, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 128, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21616, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (5476, 128, ), and the ID is 4
	Changing Input Shape
	New Input Shape: (5476, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5480, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (5476, 256, ), and the ID is 5
	Changing Input Shape
	New Input Shape: (5476, 128, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 256, ) DONE
	Preparing Filter With Shape: (128, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 128, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5480, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 256, ), Input shape (5476, 256, ), and Output shape (5476, 256, ), and the ID is 6
	Changing Input Shape
	New Input Shape: (5476, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 256, ) DONE
	Preparing Filter With Shape: (256, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5480, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (1369, 256, ), and the ID is 7
	Changing Input Shape
	New Input Shape: (1369, 128, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 256, ) DONE
	Preparing Filter With Shape: (128, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 128, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1376, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (1369, 728, ), and the ID is 8
	Changing Input Shape
	New Input Shape: (1369, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 728, ) DONE
	Preparing Filter With Shape: (256, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1376, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (1369, 728, ), and Output shape (1369, 728, ), and the ID is 9
	Changing Input Shape
	New Input Shape: (1369, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1376, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (361, 728, ), and the ID is 10
	Changing Input Shape
	New Input Shape: (361, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 728, ) DONE
	Preparing Filter With Shape: (256, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 11
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 12
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 13
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 14
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 15
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 16
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 17
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 18
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 19
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 20
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 21
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 22
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 23
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 24
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 25
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 26
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 27
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 28
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 29
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 30
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 31
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 32
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 33
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 34
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 35
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (361, 1024, ), and the ID is 36
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 1024, ) DONE
	Preparing Filter With Shape: (728, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (100, 1024, ), and the ID is 37
	Changing Input Shape
	New Input Shape: (100, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (736, 1024, ) DONE
	Preparing Filter With Shape: (728, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (104, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 1536, ), Input shape (100, 1024, ), and Output shape (100, 1536, ), and the ID is 38
	Changing Input Shape
	New Input Shape: (100, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 1536, ) DONE
	Preparing Filter With Shape: (1024, 1536, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (104, 1536, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 2048, ), Input shape (100, 1536, ), and Output shape (100, 2048, ), and the ID is 39
	Changing Input Shape
	New Input Shape: (100, 1536, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1536, 2048, ) DONE
	Preparing Filter With Shape: (1536, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1536, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1536, ) DONE
	Allocating An Output Temporary Tensor With Shape: (104, 2048, ) DONE
Applying Low-Precision for shape (2048, 1000, ) and Input shape (1, 2048, ) With 9 Number of Temporaries Tensors, and the ID is 0
	Allocating Filter Shape: (2048, 1000, ) DONE
	Preparing Filter With Shape: (2048, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (8, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (8, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (8, 1000, ) DONE
The input model file size (MB): 24.0822
Initialized session in 208.864ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=1962559 curr=1906752 min=1906752 max=1962559 avg=1.93466e+06 std=27903

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=1908598 curr=1908889 min=1907190 max=1912872 avg=1.90946e+06 std=1378

Inference timings in us: Init: 208864, First inference: 1962559, Warmup (avg): 1.93466e+06, Inference (avg): 1.90946e+06
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=48.793 overall=76.3516
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  179.349	  179.349	100.000%	100.000%	 42864.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  179.349	  179.349	100.000%	100.000%	 42864.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   179.349	   100.000%	   100.000%	 42864.000	        1

Timings (microseconds): count=1 curr=179349
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.020	   10.092	   10.086	  0.528%	  0.528%	     0.000	        1	[xception/block1_conv1_act/Relu;xception/block1_conv1_bn/FusedBatchNormV3;xception/block1_conv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv1/Conv2D]:0
	                 CONV_2D	           10.110	   60.890	   61.132	  3.202%	  3.731%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	       DEPTHWISE_CONV_2D	           71.254	    5.338	    5.311	  0.278%	  4.009%	     0.000	        1	[xception/block2_sepconv1/separable_conv2d/depthwise1]:2
	                 CONV_2D	           76.569	   27.841	   27.742	  1.453%	  5.462%	     0.000	        1	[xception/block2_sepconv2_act/Relu;xception/block2_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv1/separable_conv2d]:3
	       DEPTHWISE_CONV_2D	          104.317	   13.461	   13.431	  0.704%	  6.166%	     0.000	        1	[xception/block2_sepconv2/separable_conv2d/depthwise1]:4
	                 CONV_2D	          117.754	   47.490	   47.678	  2.498%	  8.663%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	             MAX_POOL_2D	          165.437	   16.771	   16.705	  0.875%	  9.538%	     0.000	        1	[xception/block2_pool/MaxPool]:6
	                 CONV_2D	          182.148	    7.660	    7.757	  0.406%	  9.945%	     0.000	        1	[xception/batch_normalization_297/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/conv2d_297/Conv2D]:7
	                     ADD	          189.912	   65.800	   65.788	  3.446%	 13.391%	     0.000	        1	[xception/add_4/add]:8
	                    RELU	          255.705	   83.861	   84.034	  4.402%	 17.793%	     0.000	        1	[xception/block3_sepconv1_act/Relu]:9
	       DEPTHWISE_CONV_2D	          339.745	    3.453	    3.453	  0.181%	 17.974%	     0.000	        1	[xception/block3_sepconv1/separable_conv2d/depthwise1]:10
	                 CONV_2D	          343.203	   24.786	   24.831	  1.301%	 19.275%	     0.000	        1	[xception/block3_sepconv2_act/Relu;xception/block3_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv1/separable_conv2d]:11
	       DEPTHWISE_CONV_2D	          368.040	    7.031	    7.019	  0.368%	 19.642%	     0.000	        1	[xception/block3_sepconv2/separable_conv2d/depthwise1]:12
	                 CONV_2D	          375.066	   44.517	   44.506	  2.331%	 21.974%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	             MAX_POOL_2D	          419.578	    8.436	    8.178	  0.428%	 22.402%	     0.000	        1	[xception/block3_pool/MaxPool]:14
	                 CONV_2D	          427.760	    6.264	    6.227	  0.326%	 22.728%	     0.000	        1	[xception/batch_normalization_298/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/conv2d_298/Conv2D]:15
	                     ADD	          433.992	   33.006	   32.930	  1.725%	 24.453%	     0.000	        1	[xception/add_5/add]:16
	                    RELU	          466.926	   40.479	   40.538	  2.124%	 26.577%	     0.000	        1	[xception/block4_sepconv1_act/Relu]:17
	       DEPTHWISE_CONV_2D	          507.469	    1.672	    1.661	  0.087%	 26.664%	     0.000	        1	[xception/block4_sepconv1/separable_conv2d/depthwise1]:18
	                 CONV_2D	          509.132	   29.676	   29.568	  1.549%	 28.213%	     0.000	        1	[xception/block4_sepconv2_act/Relu;xception/block4_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv1/separable_conv2d]:19
	       DEPTHWISE_CONV_2D	          538.704	    5.245	    5.200	  0.272%	 28.485%	     0.000	        1	[xception/block4_sepconv2/separable_conv2d/depthwise1]:20
	                 CONV_2D	          543.908	   91.479	   91.422	  4.789%	 33.274%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	             MAX_POOL_2D	          635.334	    6.557	    6.482	  0.340%	 33.614%	     0.000	        1	[xception/block4_pool/MaxPool]:22
	                 CONV_2D	          641.821	    8.197	    8.195	  0.429%	 34.043%	     0.000	        1	[xception/batch_normalization_299/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/conv2d_299/Conv2D]:23
	                     ADD	          650.021	   24.733	   24.704	  1.294%	 35.337%	     0.000	        1	[xception/add_6/add]:24
	                    RELU	          674.730	   30.452	   30.504	  1.598%	 36.935%	     0.000	        1	[xception/block5_sepconv1_act/Relu]:25
	       DEPTHWISE_CONV_2D	          705.238	    1.303	    1.285	  0.067%	 37.002%	     0.000	        1	[xception/block5_sepconv1/separable_conv2d/depthwise1]:26
	                 CONV_2D	          706.525	   22.742	   22.741	  1.191%	 38.194%	     0.000	        1	[xception/block5_sepconv2_act/Relu;xception/block5_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv1/separable_conv2d]:27
	       DEPTHWISE_CONV_2D	          729.272	    1.345	    1.401	  0.073%	 38.267%	     0.000	        1	[xception/block5_sepconv2/separable_conv2d/depthwise1]:28
	                 CONV_2D	          730.675	   22.954	   22.821	  1.195%	 39.463%	     0.000	        1	[xception/block5_sepconv3_act/Relu;xception/block5_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv2/separable_conv2d]:29
	       DEPTHWISE_CONV_2D	          753.502	    1.348	    1.383	  0.072%	 39.535%	     0.000	        1	[xception/block5_sepconv3/separable_conv2d/depthwise1]:30
	                 CONV_2D	          754.888	   22.795	   22.546	  1.181%	 40.716%	     0.000	        1	[xception/block5_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv3/separable_conv2d]:31
	                     ADD	          777.439	   24.748	   24.717	  1.295%	 42.011%	     0.000	        1	[xception/add_7/add]:32
	                    RELU	          802.161	   30.466	   30.514	  1.598%	 43.609%	     0.000	        1	[xception/block6_sepconv1_act/Relu]:33
	       DEPTHWISE_CONV_2D	          832.678	    1.280	    1.283	  0.067%	 43.676%	     0.000	        1	[xception/block6_sepconv1/separable_conv2d/depthwise1]:34
	                 CONV_2D	          833.963	   22.564	   22.615	  1.185%	 44.861%	     0.000	        1	[xception/block6_sepconv2_act/Relu;xception/block6_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv1/separable_conv2d]:35
	       DEPTHWISE_CONV_2D	          856.583	    1.402	    1.397	  0.073%	 44.934%	     0.000	        1	[xception/block6_sepconv2/separable_conv2d/depthwise1]:36
	                 CONV_2D	          857.981	   22.589	   22.503	  1.179%	 46.113%	     0.000	        1	[xception/block6_sepconv3_act/Relu;xception/block6_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv2/separable_conv2d]:37
	       DEPTHWISE_CONV_2D	          880.489	    1.405	    1.391	  0.073%	 46.186%	     0.000	        1	[xception/block6_sepconv3/separable_conv2d/depthwise1]:38
	                 CONV_2D	          881.883	   22.568	   22.493	  1.178%	 47.364%	     0.000	        1	[xception/block6_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv3/separable_conv2d]:39
	                     ADD	          904.381	   24.736	   24.714	  1.295%	 48.659%	     0.000	        1	[xception/add_8/add]:40
	                    RELU	          929.100	   30.493	   30.494	  1.597%	 50.256%	     0.000	        1	[xception/block7_sepconv1_act/Relu]:41
	       DEPTHWISE_CONV_2D	          959.599	    1.321	    1.268	  0.066%	 50.323%	     0.000	        1	[xception/block7_sepconv1/separable_conv2d/depthwise1]:42
	                 CONV_2D	          960.868	   22.731	   22.866	  1.198%	 51.521%	     0.000	        1	[xception/block7_sepconv2_act/Relu;xception/block7_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv1/separable_conv2d]:43
	       DEPTHWISE_CONV_2D	          983.739	    1.475	    1.371	  0.072%	 51.592%	     0.000	        1	[xception/block7_sepconv2/separable_conv2d/depthwise1]:44
	                 CONV_2D	          985.111	   22.631	   22.802	  1.194%	 52.787%	     0.000	        1	[xception/block7_sepconv3_act/Relu;xception/block7_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv2/separable_conv2d]:45
	       DEPTHWISE_CONV_2D	         1007.918	    1.452	    1.374	  0.072%	 52.859%	     0.000	        1	[xception/block7_sepconv3/separable_conv2d/depthwise1]:46
	                 CONV_2D	         1009.295	   22.566	   22.499	  1.179%	 54.037%	     0.000	        1	[xception/block7_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv3/separable_conv2d]:47
	                     ADD	         1031.799	   24.625	   24.734	  1.296%	 55.333%	     0.000	        1	[xception/add_9/add]:48
	                    RELU	         1056.539	   30.498	   30.507	  1.598%	 56.931%	     0.000	        1	[xception/block8_sepconv1_act/Relu]:49
	       DEPTHWISE_CONV_2D	         1087.049	    1.295	    1.275	  0.067%	 56.998%	     0.000	        1	[xception/block8_sepconv1/separable_conv2d/depthwise1]:50
	                 CONV_2D	         1088.325	   22.400	   22.545	  1.181%	 58.179%	     0.000	        1	[xception/block8_sepconv2_act/Relu;xception/block8_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv1/separable_conv2d]:51
	       DEPTHWISE_CONV_2D	         1110.875	    1.355	    1.392	  0.073%	 58.252%	     0.000	        1	[xception/block8_sepconv2/separable_conv2d/depthwise1]:52
	                 CONV_2D	         1112.269	   22.469	   22.528	  1.180%	 59.432%	     0.000	        1	[xception/block8_sepconv3_act/Relu;xception/block8_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv2/separable_conv2d]:53
	       DEPTHWISE_CONV_2D	         1134.802	    1.377	    1.395	  0.073%	 59.505%	     0.000	        1	[xception/block8_sepconv3/separable_conv2d/depthwise1]:54
	                 CONV_2D	         1136.199	   22.875	   22.777	  1.193%	 60.698%	     0.000	        1	[xception/block8_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv3/separable_conv2d]:55
	                     ADD	         1158.982	   24.762	   24.774	  1.298%	 61.996%	     0.000	        1	[xception/add_10/add]:56
	                    RELU	         1183.761	   30.496	   30.462	  1.596%	 63.592%	     0.000	        1	[xception/block9_sepconv1_act/Relu]:57
	       DEPTHWISE_CONV_2D	         1214.226	    1.249	    1.301	  0.068%	 63.660%	     0.000	        1	[xception/block9_sepconv1/separable_conv2d/depthwise1]:58
	                 CONV_2D	         1215.530	   22.715	   22.807	  1.195%	 64.854%	     0.000	        1	[xception/block9_sepconv2_act/Relu;xception/block9_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv1/separable_conv2d]:59
	       DEPTHWISE_CONV_2D	         1238.342	    1.356	    1.405	  0.074%	 64.928%	     0.000	        1	[xception/block9_sepconv2/separable_conv2d/depthwise1]:60
	                 CONV_2D	         1239.748	   22.576	   22.437	  1.175%	 66.103%	     0.000	        1	[xception/block9_sepconv3_act/Relu;xception/block9_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv2/separable_conv2d]:61
	       DEPTHWISE_CONV_2D	         1262.190	    1.333	    1.402	  0.073%	 66.177%	     0.000	        1	[xception/block9_sepconv3/separable_conv2d/depthwise1]:62
	                 CONV_2D	         1263.595	   22.507	   22.434	  1.175%	 67.352%	     0.000	        1	[xception/block9_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv3/separable_conv2d]:63
	                     ADD	         1286.034	   24.669	   24.724	  1.295%	 68.647%	     0.000	        1	[xception/add_11/add]:64
	                    RELU	         1310.764	   30.403	   30.513	  1.598%	 70.246%	     0.000	        1	[xception/block10_sepconv1_act/Relu]:65
	       DEPTHWISE_CONV_2D	         1341.281	    1.253	    1.271	  0.067%	 70.312%	     0.000	        1	[xception/block10_sepconv1/separable_conv2d/depthwise1]:66
	                 CONV_2D	         1342.553	   22.730	   22.809	  1.195%	 71.507%	     0.000	        1	[xception/block10_sepconv2_act/Relu;xception/block10_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv1/separable_conv2d]:67
	       DEPTHWISE_CONV_2D	         1365.372	    1.355	    1.386	  0.073%	 71.580%	     0.000	        1	[xception/block10_sepconv2/separable_conv2d/depthwise1]:68
	                 CONV_2D	         1366.761	   22.819	   22.845	  1.197%	 72.776%	     0.000	        1	[xception/block10_sepconv3_act/Relu;xception/block10_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv2/separable_conv2d]:69
	       DEPTHWISE_CONV_2D	         1389.611	    1.326	    1.362	  0.071%	 72.848%	     0.000	        1	[xception/block10_sepconv3/separable_conv2d/depthwise1]:70
	                 CONV_2D	         1390.976	   22.789	   22.820	  1.195%	 74.043%	     0.000	        1	[xception/block10_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv3/separable_conv2d]:71
	                     ADD	         1413.801	   24.805	   24.722	  1.295%	 75.338%	     0.000	        1	[xception/add_12/add]:72
	                    RELU	         1438.528	   30.563	   30.530	  1.599%	 76.937%	     0.000	        1	[xception/block11_sepconv1_act/Relu]:73
	       DEPTHWISE_CONV_2D	         1469.062	    1.270	    1.296	  0.068%	 77.005%	     0.000	        1	[xception/block11_sepconv1/separable_conv2d/depthwise1]:74
	                 CONV_2D	         1470.360	   23.168	   22.865	  1.198%	 78.203%	     0.000	        1	[xception/block11_sepconv2_act/Relu;xception/block11_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv1/separable_conv2d]:75
	       DEPTHWISE_CONV_2D	         1493.230	    1.357	    1.379	  0.072%	 78.275%	     0.000	        1	[xception/block11_sepconv2/separable_conv2d/depthwise1]:76
	                 CONV_2D	         1494.611	   22.497	   22.470	  1.177%	 79.452%	     0.000	        1	[xception/block11_sepconv3_act/Relu;xception/block11_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv2/separable_conv2d]:77
	       DEPTHWISE_CONV_2D	         1517.087	    1.333	    1.381	  0.072%	 79.525%	     0.000	        1	[xception/block11_sepconv3/separable_conv2d/depthwise1]:78
	                 CONV_2D	         1518.470	   22.289	   22.548	  1.181%	 80.706%	     0.000	        1	[xception/block11_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv3/separable_conv2d]:79
	                     ADD	         1541.024	   24.721	   24.706	  1.294%	 82.000%	     0.000	        1	[xception/add_13/add]:80
	                    RELU	         1565.734	   30.564	   30.500	  1.598%	 83.598%	     0.000	        1	[xception/block12_sepconv1_act/Relu]:81
	       DEPTHWISE_CONV_2D	         1596.237	    1.315	    1.291	  0.068%	 83.665%	     0.000	        1	[xception/block12_sepconv1/separable_conv2d/depthwise1]:82
	                 CONV_2D	         1597.530	   22.811	   22.847	  1.197%	 84.862%	     0.000	        1	[xception/block12_sepconv2_act/Relu;xception/block12_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv1/separable_conv2d]:83
	       DEPTHWISE_CONV_2D	         1620.382	    1.385	    1.372	  0.072%	 84.934%	     0.000	        1	[xception/block12_sepconv2/separable_conv2d/depthwise1]:84
	                 CONV_2D	         1621.756	   22.457	   22.487	  1.178%	 86.112%	     0.000	        1	[xception/block12_sepconv3_act/Relu;xception/block12_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv2/separable_conv2d]:85
	       DEPTHWISE_CONV_2D	         1644.248	    1.384	    1.377	  0.072%	 86.184%	     0.000	        1	[xception/block12_sepconv3/separable_conv2d/depthwise1]:86
	                 CONV_2D	         1645.627	   22.231	   22.480	  1.178%	 87.362%	     0.000	        1	[xception/block12_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv3/separable_conv2d]:87
	                     ADD	         1668.112	   24.742	   24.714	  1.295%	 88.656%	     0.000	        1	[xception/add_14/add]:88
	                    RELU	         1692.830	   30.495	   30.504	  1.598%	 90.254%	     0.000	        1	[xception/block13_sepconv1_act/Relu]:89
	       DEPTHWISE_CONV_2D	         1723.337	    1.307	    1.284	  0.067%	 90.322%	     0.000	        1	[xception/block13_sepconv1/separable_conv2d/depthwise1]:90
	                 CONV_2D	         1724.624	   23.011	   22.898	  1.199%	 91.521%	     0.000	        1	[xception/block13_sepconv2_act/Relu;xception/block13_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv1/separable_conv2d]:91
	       DEPTHWISE_CONV_2D	         1747.526	    1.336	    1.373	  0.072%	 91.593%	     0.000	        1	[xception/block13_sepconv2/separable_conv2d/depthwise1]:92
	                 CONV_2D	         1748.902	   31.370	   31.574	  1.654%	 93.247%	     0.000	        1	[xception/block13_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv2/separable_conv2d]:93
	             MAX_POOL_2D	         1780.481	    2.421	    2.417	  0.127%	 93.374%	     0.000	        1	[xception/block13_pool/MaxPool]:94
	                 CONV_2D	         1782.900	    9.483	    9.517	  0.499%	 93.872%	     0.000	        1	[xception/batch_normalization_300/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/conv2d_300/Conv2D]:95
	                     ADD	         1792.422	    9.612	    9.668	  0.506%	 94.379%	     0.000	        1	[xception/add_15/add]:96
	       DEPTHWISE_CONV_2D	         1802.092	    0.516	    0.512	  0.027%	 94.405%	     0.000	        1	[xception/block14_sepconv1/separable_conv2d/depthwise1]:97
	                 CONV_2D	         1802.605	   23.022	   23.154	  1.213%	 95.618%	     0.000	        1	[xception/block14_sepconv1_act/Relu;xception/block14_sepconv1_bn/FusedBatchNormV3;xception/block14_sepconv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv1/separable_conv2d]:98
	       DEPTHWISE_CONV_2D	         1825.763	    0.827	    0.846	  0.044%	 95.663%	     0.000	        1	[xception/block14_sepconv2/separable_conv2d/depthwise1]:99
	                 CONV_2D	         1826.610	   44.660	   44.918	  2.353%	 98.016%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100
	                    MEAN	         1871.533	   35.147	   35.211	  1.844%	 99.860%	     0.000	        1	[xception/avg_pool/Mean]:101
	         FULLY_CONNECTED	         1906.747	    2.609	    2.588	  0.136%	 99.996%	     0.000	        1	[xception/predictions/MatMul;xception/predictions/BiasAdd]:102
	                 SOFTMAX	         1909.340	    0.076	    0.083	  0.004%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:103

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          543.908	   91.479	   91.422	  4.789%	  4.789%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	                    RELU	          255.705	   83.861	   84.034	  4.402%	  9.191%	     0.000	        1	[xception/block3_sepconv1_act/Relu]:9
	                     ADD	          189.912	   65.800	   65.788	  3.446%	 12.637%	     0.000	        1	[xception/add_4/add]:8
	                 CONV_2D	           10.110	   60.890	   61.132	  3.202%	 15.840%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	                 CONV_2D	          117.754	   47.490	   47.678	  2.498%	 18.337%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	                 CONV_2D	         1826.610	   44.660	   44.918	  2.353%	 20.690%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100
	                 CONV_2D	          375.066	   44.517	   44.506	  2.331%	 23.022%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	                    RELU	          466.926	   40.479	   40.538	  2.124%	 25.145%	     0.000	        1	[xception/block4_sepconv1_act/Relu]:17
	                    MEAN	         1871.533	   35.147	   35.211	  1.844%	 26.990%	     0.000	        1	[xception/avg_pool/Mean]:101
	                     ADD	          433.992	   33.006	   32.930	  1.725%	 28.715%	     0.000	        1	[xception/add_5/add]:16

Number of nodes executed: 104
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       40	  1034.773	    54.207%	    54.207%	     0.000	       40
	                    RELU	       11	   399.096	    20.907%	    75.114%	     0.000	       11
	                     ADD	       12	   330.889	    17.334%	    92.448%	     0.000	       12
	       DEPTHWISE_CONV_2D	       34	    72.509	     3.798%	    96.246%	     0.000	       34
	                    MEAN	        1	    35.210	     1.844%	    98.091%	     0.000	        1
	             MAX_POOL_2D	        4	    33.780	     1.770%	    99.860%	     0.000	        4
	         FULLY_CONNECTED	        1	     2.587	     0.136%	    99.996%	     0.000	        1
	                 SOFTMAX	        1	     0.083	     0.004%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=1908117 curr=1908402 min=1906693 max=1912399 avg=1.90898e+06 std=1377
Memory (bytes): count=0
104 nodes observed



[ perf record: Woken up 131 times to write data ]
Warning:
Processed 168852 events and lost 1 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 32.725 MB /tmp/data.record (168540 samples) ]

43.638

