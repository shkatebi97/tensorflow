STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite
INFO: Initialized TensorFlow Lite runtime.
NOT Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ), and Output shape (22201, 32, ), and the ID is 0
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (22201, 32, ), and Output shape (21609, 64, ), and the ID is 1
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (21609, 128, ), and the ID is 2
	Changing Input Shape
	New Input Shape: (21609, 64, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (21609, 128, ), and Output shape (21609, 128, ), and the ID is 3
	Changing Input Shape
	New Input Shape: (21609, 128, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (5476, 128, ), and the ID is 4
	Changing Input Shape
	New Input Shape: (5476, 64, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (5476, 256, ), and the ID is 5
	Changing Input Shape
	New Input Shape: (5476, 128, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 256, ), Input shape (5476, 256, ), and Output shape (5476, 256, ), and the ID is 6
	Changing Input Shape
	New Input Shape: (5476, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (1369, 256, ), and the ID is 7
	Changing Input Shape
	New Input Shape: (1369, 128, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (1369, 728, ), and the ID is 8
	Changing Input Shape
	New Input Shape: (1369, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (1369, 728, ), and Output shape (1369, 728, ), and the ID is 9
	Changing Input Shape
	New Input Shape: (1369, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (361, 728, ), and the ID is 10
	Changing Input Shape
	New Input Shape: (361, 256, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 11
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 12
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 13
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 14
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 15
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 16
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 17
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 18
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 19
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 20
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 21
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 22
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 23
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 24
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 25
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 26
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 27
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 28
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 29
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 30
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 31
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 32
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 33
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 34
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 35
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (361, 1024, ), and the ID is 36
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (100, 1024, ), and the ID is 37
	Changing Input Shape
	New Input Shape: (100, 728, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1024, 1536, ), Input shape (100, 1024, ), and Output shape (100, 1536, ), and the ID is 38
	Changing Input Shape
	New Input Shape: (100, 1024, )
	No Changes To Appliability.
NOT Applying Conv Low-Precision for Kernel shape (1536, 2048, ), Input shape (100, 1536, ), and Output shape (100, 2048, ), and the ID is 39
	Changing Input Shape
	New Input Shape: (100, 1536, )
	No Changes To Appliability.
The input model file size (MB): 24.0822
Initialized session in 42.898ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=2159439 curr=2114033 min=2114033 max=2159439 avg=2.13674e+06 std=22703

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=2108829 curr=2109662 min=2107948 max=2112116 avg=2.10942e+06 std=938

Inference timings in us: Init: 42898, First inference: 2159439, Warmup (avg): 2.13674e+06, Inference (avg): 2.10942e+06
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=7.68359 overall=43.8086
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   14.344	   14.344	100.000%	100.000%	   768.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	   14.344	   14.344	100.000%	100.000%	   768.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	    14.344	   100.000%	   100.000%	   768.000	        1

Timings (microseconds): count=1 curr=14344
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.019	   14.028	   13.970	  0.662%	  0.662%	     0.000	        1	[xception/block1_conv1_act/Relu;xception/block1_conv1_bn/FusedBatchNormV3;xception/block1_conv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv1/Conv2D]:0
	                 CONV_2D	           14.000	   70.377	   70.079	  3.323%	  3.985%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	       DEPTHWISE_CONV_2D	           84.091	    5.356	    5.443	  0.258%	  4.244%	     0.000	        1	[xception/block2_sepconv1/separable_conv2d/depthwise1]:2
	                 CONV_2D	           89.538	   39.520	   39.704	  1.883%	  6.126%	     0.000	        1	[xception/block2_sepconv2_act/Relu;xception/block2_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv1/separable_conv2d]:3
	       DEPTHWISE_CONV_2D	          129.247	   13.680	   13.591	  0.644%	  6.771%	     0.000	        1	[xception/block2_sepconv2/separable_conv2d/depthwise1]:4
	                 CONV_2D	          142.843	   61.899	   62.003	  2.940%	  9.711%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	             MAX_POOL_2D	          204.852	   16.629	   16.700	  0.792%	 10.503%	     0.000	        1	[xception/block2_pool/MaxPool]:6
	                 CONV_2D	          221.556	   11.035	   11.062	  0.525%	 11.027%	     0.000	        1	[xception/batch_normalization_297/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/conv2d_297/Conv2D]:7
	                     ADD	          232.624	   65.736	   65.708	  3.116%	 14.143%	     0.000	        1	[xception/add_4/add]:8
	                    RELU	          298.337	   89.026	   89.069	  4.223%	 18.366%	     0.000	        1	[xception/block3_sepconv1_act/Relu]:9
	       DEPTHWISE_CONV_2D	          387.411	    3.485	    3.455	  0.164%	 18.530%	     0.000	        1	[xception/block3_sepconv1/separable_conv2d/depthwise1]:10
	                 CONV_2D	          390.870	   30.753	   30.834	  1.462%	 19.992%	     0.000	        1	[xception/block3_sepconv2_act/Relu;xception/block3_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv1/separable_conv2d]:11
	       DEPTHWISE_CONV_2D	          421.709	    6.955	    7.048	  0.334%	 20.326%	     0.000	        1	[xception/block3_sepconv2/separable_conv2d/depthwise1]:12
	                 CONV_2D	          428.763	   52.846	   52.966	  2.512%	 22.838%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	             MAX_POOL_2D	          481.735	    8.073	    8.183	  0.388%	 23.226%	     0.000	        1	[xception/block3_pool/MaxPool]:14
	                 CONV_2D	          489.923	    8.046	    8.025	  0.381%	 23.607%	     0.000	        1	[xception/batch_normalization_298/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/conv2d_298/Conv2D]:15
	                     ADD	          497.953	   32.994	   32.877	  1.559%	 25.165%	     0.000	        1	[xception/add_5/add]:16
	                    RELU	          530.835	   45.040	   44.872	  2.128%	 27.293%	     0.000	        1	[xception/block4_sepconv1_act/Relu]:17
	       DEPTHWISE_CONV_2D	          575.712	    1.653	    1.655	  0.078%	 27.372%	     0.000	        1	[xception/block4_sepconv1/separable_conv2d/depthwise1]:18
	                 CONV_2D	          577.369	   37.602	   37.681	  1.787%	 29.158%	     0.000	        1	[xception/block4_sepconv2_act/Relu;xception/block4_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv1/separable_conv2d]:19
	       DEPTHWISE_CONV_2D	          615.054	    5.362	    5.316	  0.252%	 29.410%	     0.000	        1	[xception/block4_sepconv2/separable_conv2d/depthwise1]:20
	                 CONV_2D	          620.381	   96.822	   96.584	  4.580%	 33.990%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	             MAX_POOL_2D	          716.969	    6.516	    6.488	  0.308%	 34.298%	     0.000	        1	[xception/block4_pool/MaxPool]:22
	                 CONV_2D	          723.461	   10.238	   10.360	  0.491%	 34.789%	     0.000	        1	[xception/batch_normalization_299/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/conv2d_299/Conv2D]:23
	                     ADD	          733.827	   24.839	   24.686	  1.171%	 35.960%	     0.000	        1	[xception/add_6/add]:24
	                    RELU	          758.518	   33.612	   33.622	  1.594%	 37.554%	     0.000	        1	[xception/block5_sepconv1_act/Relu]:25
	       DEPTHWISE_CONV_2D	          792.144	    1.260	    1.295	  0.061%	 37.615%	     0.000	        1	[xception/block5_sepconv1/separable_conv2d/depthwise1]:26
	                 CONV_2D	          793.441	   26.216	   26.236	  1.244%	 38.859%	     0.000	        1	[xception/block5_sepconv2_act/Relu;xception/block5_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv1/separable_conv2d]:27
	       DEPTHWISE_CONV_2D	          819.683	    1.326	    1.346	  0.064%	 38.923%	     0.000	        1	[xception/block5_sepconv2/separable_conv2d/depthwise1]:28
	                 CONV_2D	          821.033	   26.174	   26.252	  1.245%	 40.168%	     0.000	        1	[xception/block5_sepconv3_act/Relu;xception/block5_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv2/separable_conv2d]:29
	       DEPTHWISE_CONV_2D	          847.290	    1.322	    1.351	  0.064%	 40.232%	     0.000	        1	[xception/block5_sepconv3/separable_conv2d/depthwise1]:30
	                 CONV_2D	          848.644	   26.146	   26.232	  1.244%	 41.476%	     0.000	        1	[xception/block5_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv3/separable_conv2d]:31
	                     ADD	          874.883	   24.647	   24.677	  1.170%	 42.646%	     0.000	        1	[xception/add_7/add]:32
	                    RELU	          899.565	   33.616	   33.637	  1.595%	 44.241%	     0.000	        1	[xception/block6_sepconv1_act/Relu]:33
	       DEPTHWISE_CONV_2D	          933.207	    1.442	    1.296	  0.061%	 44.303%	     0.000	        1	[xception/block6_sepconv1/separable_conv2d/depthwise1]:34
	                 CONV_2D	          934.504	   26.288	   26.270	  1.246%	 45.548%	     0.000	        1	[xception/block6_sepconv2_act/Relu;xception/block6_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv1/separable_conv2d]:35
	       DEPTHWISE_CONV_2D	          960.779	    1.324	    1.345	  0.064%	 45.612%	     0.000	        1	[xception/block6_sepconv2/separable_conv2d/depthwise1]:36
	                 CONV_2D	          962.127	   26.401	   26.176	  1.241%	 46.853%	     0.000	        1	[xception/block6_sepconv3_act/Relu;xception/block6_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv2/separable_conv2d]:37
	       DEPTHWISE_CONV_2D	          988.308	    1.307	    1.314	  0.062%	 46.916%	     0.000	        1	[xception/block6_sepconv3/separable_conv2d/depthwise1]:38
	                 CONV_2D	          989.625	   26.274	   26.209	  1.243%	 48.158%	     0.000	        1	[xception/block6_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv3/separable_conv2d]:39
	                     ADD	         1015.840	   24.972	   24.703	  1.171%	 49.330%	     0.000	        1	[xception/add_8/add]:40
	                    RELU	         1040.548	   33.726	   33.640	  1.595%	 50.925%	     0.000	        1	[xception/block7_sepconv1_act/Relu]:41
	       DEPTHWISE_CONV_2D	         1074.192	    1.288	    1.298	  0.062%	 50.986%	     0.000	        1	[xception/block7_sepconv1/separable_conv2d/depthwise1]:42
	                 CONV_2D	         1075.492	   26.226	   26.269	  1.246%	 52.232%	     0.000	        1	[xception/block7_sepconv2_act/Relu;xception/block7_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv1/separable_conv2d]:43
	       DEPTHWISE_CONV_2D	         1101.766	    1.319	    1.360	  0.064%	 52.297%	     0.000	        1	[xception/block7_sepconv2/separable_conv2d/depthwise1]:44
	                 CONV_2D	         1103.129	   25.971	   26.166	  1.241%	 53.537%	     0.000	        1	[xception/block7_sepconv3_act/Relu;xception/block7_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv2/separable_conv2d]:45
	       DEPTHWISE_CONV_2D	         1129.299	    1.349	    1.331	  0.063%	 53.600%	     0.000	        1	[xception/block7_sepconv3/separable_conv2d/depthwise1]:46
	                 CONV_2D	         1130.632	   25.950	   26.205	  1.243%	 54.843%	     0.000	        1	[xception/block7_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv3/separable_conv2d]:47
	                     ADD	         1156.842	   24.634	   24.665	  1.170%	 56.013%	     0.000	        1	[xception/add_9/add]:48
	                    RELU	         1181.512	   33.661	   33.658	  1.596%	 57.609%	     0.000	        1	[xception/block8_sepconv1_act/Relu]:49
	       DEPTHWISE_CONV_2D	         1215.174	    1.269	    1.281	  0.061%	 57.669%	     0.000	        1	[xception/block8_sepconv1/separable_conv2d/depthwise1]:50
	                 CONV_2D	         1216.458	   26.325	   26.239	  1.244%	 58.913%	     0.000	        1	[xception/block8_sepconv2_act/Relu;xception/block8_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv1/separable_conv2d]:51
	       DEPTHWISE_CONV_2D	         1242.702	    1.339	    1.357	  0.064%	 58.978%	     0.000	        1	[xception/block8_sepconv2/separable_conv2d/depthwise1]:52
	                 CONV_2D	         1244.061	   26.117	   26.193	  1.242%	 60.220%	     0.000	        1	[xception/block8_sepconv3_act/Relu;xception/block8_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv2/separable_conv2d]:53
	       DEPTHWISE_CONV_2D	         1270.258	    1.346	    1.338	  0.063%	 60.283%	     0.000	        1	[xception/block8_sepconv3/separable_conv2d/depthwise1]:54
	                 CONV_2D	         1271.598	   26.240	   26.257	  1.245%	 61.528%	     0.000	        1	[xception/block8_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv3/separable_conv2d]:55
	                     ADD	         1297.861	   24.668	   24.668	  1.170%	 62.698%	     0.000	        1	[xception/add_10/add]:56
	                    RELU	         1322.534	   33.756	   33.641	  1.595%	 64.293%	     0.000	        1	[xception/block9_sepconv1_act/Relu]:57
	       DEPTHWISE_CONV_2D	         1356.179	    1.274	    1.278	  0.061%	 64.354%	     0.000	        1	[xception/block9_sepconv1/separable_conv2d/depthwise1]:58
	                 CONV_2D	         1357.460	   26.127	   26.273	  1.246%	 65.600%	     0.000	        1	[xception/block9_sepconv2_act/Relu;xception/block9_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv1/separable_conv2d]:59
	       DEPTHWISE_CONV_2D	         1383.738	    1.337	    1.331	  0.063%	 65.663%	     0.000	        1	[xception/block9_sepconv2/separable_conv2d/depthwise1]:60
	                 CONV_2D	         1385.071	   26.154	   26.281	  1.246%	 66.909%	     0.000	        1	[xception/block9_sepconv3_act/Relu;xception/block9_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv2/separable_conv2d]:61
	       DEPTHWISE_CONV_2D	         1411.358	    1.321	    1.343	  0.064%	 66.973%	     0.000	        1	[xception/block9_sepconv3/separable_conv2d/depthwise1]:62
	                 CONV_2D	         1412.703	   26.177	   26.216	  1.243%	 68.216%	     0.000	        1	[xception/block9_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv3/separable_conv2d]:63
	                     ADD	         1438.925	   24.680	   24.669	  1.170%	 69.385%	     0.000	        1	[xception/add_11/add]:64
	                    RELU	         1463.599	   33.569	   33.620	  1.594%	 70.980%	     0.000	        1	[xception/block10_sepconv1_act/Relu]:65
	       DEPTHWISE_CONV_2D	         1497.224	    1.261	    1.281	  0.061%	 71.040%	     0.000	        1	[xception/block10_sepconv1/separable_conv2d/depthwise1]:66
	                 CONV_2D	         1498.508	   26.213	   26.270	  1.246%	 72.286%	     0.000	        1	[xception/block10_sepconv2_act/Relu;xception/block10_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv1/separable_conv2d]:67
	       DEPTHWISE_CONV_2D	         1524.783	    1.344	    1.324	  0.063%	 72.349%	     0.000	        1	[xception/block10_sepconv2/separable_conv2d/depthwise1]:68
	                 CONV_2D	         1526.109	   26.048	   26.183	  1.242%	 73.590%	     0.000	        1	[xception/block10_sepconv3_act/Relu;xception/block10_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv2/separable_conv2d]:69
	       DEPTHWISE_CONV_2D	         1552.297	    1.306	    1.354	  0.064%	 73.655%	     0.000	        1	[xception/block10_sepconv3/separable_conv2d/depthwise1]:70
	                 CONV_2D	         1553.653	   26.332	   26.219	  1.243%	 74.898%	     0.000	        1	[xception/block10_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv3/separable_conv2d]:71
	                     ADD	         1579.878	   24.658	   24.666	  1.170%	 76.067%	     0.000	        1	[xception/add_12/add]:72
	                    RELU	         1604.550	   33.569	   33.652	  1.596%	 77.663%	     0.000	        1	[xception/block11_sepconv1_act/Relu]:73
	       DEPTHWISE_CONV_2D	         1638.206	    1.375	    1.273	  0.060%	 77.724%	     0.000	        1	[xception/block11_sepconv1/separable_conv2d/depthwise1]:74
	                 CONV_2D	         1639.482	   26.266	   26.259	  1.245%	 78.969%	     0.000	        1	[xception/block11_sepconv2_act/Relu;xception/block11_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv1/separable_conv2d]:75
	       DEPTHWISE_CONV_2D	         1665.747	    1.356	    1.344	  0.064%	 79.032%	     0.000	        1	[xception/block11_sepconv2/separable_conv2d/depthwise1]:76
	                 CONV_2D	         1667.093	   26.358	   26.316	  1.248%	 80.280%	     0.000	        1	[xception/block11_sepconv3_act/Relu;xception/block11_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv2/separable_conv2d]:77
	       DEPTHWISE_CONV_2D	         1693.414	    1.333	    1.332	  0.063%	 80.343%	     0.000	        1	[xception/block11_sepconv3/separable_conv2d/depthwise1]:78
	                 CONV_2D	         1694.748	   26.413	   26.256	  1.245%	 81.588%	     0.000	        1	[xception/block11_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv3/separable_conv2d]:79
	                     ADD	         1721.011	   24.644	   24.672	  1.170%	 82.758%	     0.000	        1	[xception/add_13/add]:80
	                    RELU	         1745.688	   33.743	   33.641	  1.595%	 84.354%	     0.000	        1	[xception/block12_sepconv1_act/Relu]:81
	       DEPTHWISE_CONV_2D	         1779.334	    1.325	    1.309	  0.062%	 84.416%	     0.000	        1	[xception/block12_sepconv1/separable_conv2d/depthwise1]:82
	                 CONV_2D	         1780.645	   26.284	   26.343	  1.249%	 85.665%	     0.000	        1	[xception/block12_sepconv2_act/Relu;xception/block12_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv1/separable_conv2d]:83
	       DEPTHWISE_CONV_2D	         1806.993	    1.304	    1.349	  0.064%	 85.729%	     0.000	        1	[xception/block12_sepconv2/separable_conv2d/depthwise1]:84
	                 CONV_2D	         1808.344	   26.141	   26.273	  1.246%	 86.975%	     0.000	        1	[xception/block12_sepconv3_act/Relu;xception/block12_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv2/separable_conv2d]:85
	       DEPTHWISE_CONV_2D	         1834.622	    1.295	    1.331	  0.063%	 87.038%	     0.000	        1	[xception/block12_sepconv3/separable_conv2d/depthwise1]:86
	                 CONV_2D	         1835.957	   26.031	   26.214	  1.243%	 88.281%	     0.000	        1	[xception/block12_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv3/separable_conv2d]:87
	                     ADD	         1862.176	   24.773	   24.694	  1.171%	 89.452%	     0.000	        1	[xception/add_14/add]:88
	                    RELU	         1886.874	   33.531	   33.629	  1.595%	 91.046%	     0.000	        1	[xception/block13_sepconv1_act/Relu]:89
	       DEPTHWISE_CONV_2D	         1920.507	    1.258	    1.291	  0.061%	 91.107%	     0.000	        1	[xception/block13_sepconv1/separable_conv2d/depthwise1]:90
	                 CONV_2D	         1921.801	   26.130	   26.328	  1.248%	 92.356%	     0.000	        1	[xception/block13_sepconv2_act/Relu;xception/block13_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv1/separable_conv2d]:91
	       DEPTHWISE_CONV_2D	         1948.135	    1.352	    1.379	  0.065%	 92.421%	     0.000	        1	[xception/block13_sepconv2/separable_conv2d/depthwise1]:92
	                 CONV_2D	         1949.516	   36.650	   36.618	  1.736%	 94.158%	     0.000	        1	[xception/block13_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv2/separable_conv2d]:93
	             MAX_POOL_2D	         1986.139	    2.461	    2.373	  0.113%	 94.270%	     0.000	        1	[xception/block13_pool/MaxPool]:94
	                 CONV_2D	         1988.515	   10.871	   10.816	  0.513%	 94.783%	     0.000	        1	[xception/batch_normalization_300/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/conv2d_300/Conv2D]:95
	                     ADD	         1999.336	    9.580	    9.647	  0.457%	 95.240%	     0.000	        1	[xception/add_15/add]:96
	       DEPTHWISE_CONV_2D	         2008.986	    0.554	    0.505	  0.024%	 95.264%	     0.000	        1	[xception/block14_sepconv1/separable_conv2d/depthwise1]:97
	                 CONV_2D	         2009.492	   21.104	   21.133	  1.002%	 96.266%	     0.000	        1	[xception/block14_sepconv1_act/Relu;xception/block14_sepconv1_bn/FusedBatchNormV3;xception/block14_sepconv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv1/separable_conv2d]:98
	       DEPTHWISE_CONV_2D	         2030.630	    0.799	    0.801	  0.038%	 96.304%	     0.000	        1	[xception/block14_sepconv2/separable_conv2d/depthwise1]:99
	                 CONV_2D	         2031.432	   42.119	   42.032	  1.993%	 98.298%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100
	                    MEAN	         2073.471	   35.046	   35.112	  1.665%	 99.962%	     0.000	        1	[xception/avg_pool/Mean]:101
	         FULLY_CONNECTED	         2108.586	    0.728	    0.709	  0.034%	 99.996%	     0.000	        1	[xception/predictions/MatMul;xception/predictions/BiasAdd]:102
	                 SOFTMAX	         2109.299	    0.097	    0.083	  0.004%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:103

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	          620.381	   96.822	   96.584	  4.580%	  4.580%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	                    RELU	          298.337	   89.026	   89.069	  4.223%	  8.803%	     0.000	        1	[xception/block3_sepconv1_act/Relu]:9
	                 CONV_2D	           14.000	   70.377	   70.079	  3.323%	 12.126%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	                     ADD	          232.624	   65.736	   65.708	  3.116%	 15.242%	     0.000	        1	[xception/add_4/add]:8
	                 CONV_2D	          142.843	   61.899	   62.003	  2.940%	 18.182%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	                 CONV_2D	          428.763	   52.846	   52.966	  2.512%	 20.694%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	                    RELU	          530.835	   45.040	   44.872	  2.128%	 22.821%	     0.000	        1	[xception/block4_sepconv1_act/Relu]:17
	                 CONV_2D	         2031.432	   42.119	   42.032	  1.993%	 24.815%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100
	                 CONV_2D	           89.538	   39.520	   39.704	  1.883%	 26.697%	     0.000	        1	[xception/block2_sepconv2_act/Relu;xception/block2_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv1/separable_conv2d]:3
	                 CONV_2D	          577.369	   37.602	   37.681	  1.787%	 28.484%	     0.000	        1	[xception/block4_sepconv2_act/Relu;xception/block4_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv1/separable_conv2d]:19

Number of nodes executed: 104
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       40	  1199.980	    56.902%	    56.902%	     0.000	       40
	                    RELU	       11	   436.678	    20.707%	    77.609%	     0.000	       11
	                     ADD	       12	   330.326	    15.664%	    93.273%	     0.000	       12
	       DEPTHWISE_CONV_2D	       34	    72.224	     3.425%	    96.698%	     0.000	       34
	                    MEAN	        1	    35.111	     1.665%	    98.363%	     0.000	        1
	             MAX_POOL_2D	        4	    33.742	     1.600%	    99.963%	     0.000	        4
	         FULLY_CONNECTED	        1	     0.708	     0.034%	    99.996%	     0.000	        1
	                 SOFTMAX	        1	     0.082	     0.004%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=2108312 curr=2109193 min=2107305 max=2111597 avg=2.1089e+06 std=950
Memory (bytes): count=0
104 nodes observed



[ perf record: Woken up 173 times to write data ]
Warning:
Processed 181755 events and lost 2 chunks!

Check IO/CPU overload!

[ perf record: Captured and wrote 43.185 MB /tmp/data.record (181358 samples) ]

47.663

