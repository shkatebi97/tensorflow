STARTING!
Duplicate flags: num_threads
Log parameter values verbosely: [0]
Min num runs: [20]
Min runs duration (seconds): [1e-09]
Num threads: [1]
Use caching: [1]
Min warmup runs: [2]
Min warmup runs duration (seconds): [1e-09]
Graph: [/home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [1]
Use xnnpack: [0]
Loaded model /home/pi/Desktop/run-CNNs/models/i8i8/Xception.tflite
INFO: Initialized TensorFlow Lite runtime.
Applying Conv Low-Precision for Kernel shape (27, 32, ), Input shape (89401, 3, ), and Output shape (22201, 32, ), and the ID is 0
	Changing Input Shape
	New Input Shape: (22201, 27, )
	No Changes To Appliability.
	Reserving 5 LowPrecision Tensors In Total
	Allocating Filter Shape: (32, 32, ) DONE
	Allocating A Kernel Temporary Tensor With Shape: (32, 32, ) DONE
	Preparing Filter With Shape: (27, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22208, 32, ) DONE
	Allocating An Input Temporary Tensor With Shape: (22208, 32, ) DONE
	Allocating An Output Temporary Tensor With Shape: (22208, 32, ) DONE
Applying Conv Low-Precision for Kernel shape (288, 64, ), Input shape (22201, 32, ), and Output shape (21609, 64, ), and the ID is 1
	Changing Input Shape
	New Input Shape: (21609, 288, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (288, 64, ) DONE
	Preparing Filter With Shape: (288, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 288, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 288, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21616, 64, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (21609, 128, ), and the ID is 2
	Changing Input Shape
	New Input Shape: (21609, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21616, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 128, ), Input shape (21609, 128, ), and Output shape (21609, 128, ), and the ID is 3
	Changing Input Shape
	New Input Shape: (21609, 128, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 128, ) DONE
	Preparing Filter With Shape: (128, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (21616, 128, ) DONE
	Allocating An Output Temporary Tensor With Shape: (21616, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (64, 128, ), Input shape (21609, 64, ), and Output shape (5476, 128, ), and the ID is 4
	Changing Input Shape
	New Input Shape: (5476, 64, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (64, 128, ) DONE
	Preparing Filter With Shape: (64, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 64, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 64, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5480, 128, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (5476, 256, ), and the ID is 5
	Changing Input Shape
	New Input Shape: (5476, 128, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 256, ) DONE
	Preparing Filter With Shape: (128, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 128, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5480, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 256, ), Input shape (5476, 256, ), and Output shape (5476, 256, ), and the ID is 6
	Changing Input Shape
	New Input Shape: (5476, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 256, ) DONE
	Preparing Filter With Shape: (256, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (5480, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (5480, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (128, 256, ), Input shape (5476, 128, ), and Output shape (1369, 256, ), and the ID is 7
	Changing Input Shape
	New Input Shape: (1369, 128, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (128, 256, ) DONE
	Preparing Filter With Shape: (128, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 128, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 128, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1376, 256, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (1369, 728, ), and the ID is 8
	Changing Input Shape
	New Input Shape: (1369, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 728, ) DONE
	Preparing Filter With Shape: (256, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1376, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (1369, 728, ), and Output shape (1369, 728, ), and the ID is 9
	Changing Input Shape
	New Input Shape: (1369, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (1376, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (1376, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (256, 728, ), Input shape (1369, 256, ), and Output shape (361, 728, ), and the ID is 10
	Changing Input Shape
	New Input Shape: (361, 256, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (256, 728, ) DONE
	Preparing Filter With Shape: (256, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 256, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 256, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 11
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 12
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 13
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 14
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 15
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 16
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 17
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 18
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 19
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 20
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 21
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 22
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 23
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 24
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 25
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 26
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 27
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 28
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 29
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 30
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 31
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 32
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 33
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 34
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 728, ), Input shape (361, 728, ), and Output shape (361, 728, ), and the ID is 35
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 728, ) DONE
	Preparing Filter With Shape: (728, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 728, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (361, 1024, ), and the ID is 36
	Changing Input Shape
	New Input Shape: (361, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 1024, ) DONE
	Preparing Filter With Shape: (728, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (368, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (368, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (728, 1024, ), Input shape (361, 728, ), and Output shape (100, 1024, ), and the ID is 37
	Changing Input Shape
	New Input Shape: (100, 728, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (728, 1024, ) DONE
	Preparing Filter With Shape: (728, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 728, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 728, ) DONE
	Allocating An Output Temporary Tensor With Shape: (104, 1024, ) DONE
Applying Conv Low-Precision for Kernel shape (1024, 1536, ), Input shape (100, 1024, ), and Output shape (100, 1536, ), and the ID is 38
	Changing Input Shape
	New Input Shape: (100, 1024, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1024, 1536, ) DONE
	Preparing Filter With Shape: (1024, 1536, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1024, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1024, ) DONE
	Allocating An Output Temporary Tensor With Shape: (104, 1536, ) DONE
Applying Conv Low-Precision for Kernel shape (1536, 2048, ), Input shape (100, 1536, ), and Output shape (100, 2048, ), and the ID is 39
	Changing Input Shape
	New Input Shape: (100, 1536, )
	No Changes To Appliability.
	Reserving 4 LowPrecision Tensors In Total
	Allocating Filter Shape: (1536, 2048, ) DONE
	Preparing Filter With Shape: (1536, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1536, ) DONE
	Allocating An Input Temporary Tensor With Shape: (104, 1536, ) DONE
	Allocating An Output Temporary Tensor With Shape: (104, 2048, ) DONE
Applying Low-Precision for shape (2048, 1000, ) and Input shape (1, 2048, ) With 9 Number of Temporaries Tensors, and the ID is 0
	Allocating Filter Shape: (2048, 1000, ) DONE
	Preparing Filter With Shape: (2048, 1000, ) DONE
	Allocating An Input Temporary Tensor With Shape: (8, 2048, ) DONE
	Allocating An Input Temporary Tensor With Shape: (8, 2048, ) DONE
	Allocating An Output Temporary Tensor With Shape: (8, 1000, ) DONE
The input model file size (MB): 24.0822
Initialized session in 178.584ms.
Running benchmark for at least 2 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=2 first=1933447 curr=1879199 min=1879199 max=1933447 avg=1.90632e+06 std=27124

Running benchmark for at least 20 iterations and at least 1e-09 seconds but terminate if exceeding 150 seconds.
count=20 first=1881346 curr=1882339 min=1881345 max=1885395 avg=1.88248e+06 std=995

Inference timings in us: Init: 178584, First inference: 1933447, Warmup (avg): 1.90632e+06, Inference (avg): 1.88248e+06
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=48.7344 overall=76.293
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  148.647	  148.647	100.000%	100.000%	 42804.000	        1	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	         AllocateTensors	            0.000	  148.647	  148.647	100.000%	100.000%	 42804.000	        1	AllocateTensors/0

Number of nodes executed: 1
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	         AllocateTensors	        1	   148.647	   100.000%	   100.000%	 42804.000	        1

Timings (microseconds): count=1 curr=148647
Memory (bytes): count=0
1 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                 CONV_2D	            0.018	    9.821	    9.888	  0.525%	  0.525%	     0.000	        1	[xception/block1_conv1_act/Relu;xception/block1_conv1_bn/FusedBatchNormV3;xception/block1_conv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv1/Conv2D]:0
	                 CONV_2D	            9.911	   62.857	   62.736	  3.333%	  3.859%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	       DEPTHWISE_CONV_2D	           72.653	    5.308	    5.401	  0.287%	  4.146%	     0.000	        1	[xception/block2_sepconv1/separable_conv2d/depthwise1]:2
	                 CONV_2D	           78.059	   27.412	   27.378	  1.455%	  5.601%	     0.000	        1	[xception/block2_sepconv2_act/Relu;xception/block2_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv1/separable_conv2d]:3
	       DEPTHWISE_CONV_2D	          105.442	   13.590	   13.467	  0.716%	  6.316%	     0.000	        1	[xception/block2_sepconv2/separable_conv2d/depthwise1]:4
	                 CONV_2D	          118.914	   48.699	   48.860	  2.596%	  8.912%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	             MAX_POOL_2D	          167.779	   16.701	   16.698	  0.887%	  9.800%	     0.000	        1	[xception/block2_pool/MaxPool]:6
	                 CONV_2D	          184.482	    8.151	    8.177	  0.434%	 10.234%	     0.000	        1	[xception/batch_normalization_297/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/conv2d_297/Conv2D]:7
	                     ADD	          192.666	   65.677	   65.638	  3.488%	 13.722%	     0.000	        1	[xception/add_4/add]:8
	                    RELU	          258.308	   85.838	   86.221	  4.581%	 18.303%	     0.000	        1	[xception/block3_sepconv1_act/Relu]:9
	       DEPTHWISE_CONV_2D	          344.535	    3.529	    3.425	  0.182%	 18.485%	     0.000	        1	[xception/block3_sepconv1/separable_conv2d/depthwise1]:10
	                 CONV_2D	          347.965	   24.145	   24.312	  1.292%	 19.777%	     0.000	        1	[xception/block3_sepconv2_act/Relu;xception/block3_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv1/separable_conv2d]:11
	       DEPTHWISE_CONV_2D	          372.282	    7.049	    6.965	  0.370%	 20.147%	     0.000	        1	[xception/block3_sepconv2/separable_conv2d/depthwise1]:12
	                 CONV_2D	          379.252	   43.788	   43.786	  2.327%	 22.473%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	             MAX_POOL_2D	          423.043	    8.087	    8.125	  0.432%	 22.905%	     0.000	        1	[xception/block3_pool/MaxPool]:14
	                 CONV_2D	          431.172	    6.276	    6.380	  0.339%	 23.244%	     0.000	        1	[xception/batch_normalization_298/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/conv2d_298/Conv2D]:15
	                     ADD	          437.563	   32.889	   32.856	  1.746%	 24.990%	     0.000	        1	[xception/add_5/add]:16
	                    RELU	          470.424	   42.468	   42.601	  2.264%	 27.253%	     0.000	        1	[xception/block4_sepconv1_act/Relu]:17
	       DEPTHWISE_CONV_2D	          513.030	    1.622	    1.638	  0.087%	 27.340%	     0.000	        1	[xception/block4_sepconv1/separable_conv2d/depthwise1]:18
	                 CONV_2D	          514.670	   29.736	   29.754	  1.581%	 28.921%	     0.000	        1	[xception/block4_sepconv2_act/Relu;xception/block4_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv1/separable_conv2d]:19
	       DEPTHWISE_CONV_2D	          544.429	    5.121	    5.134	  0.273%	 29.194%	     0.000	        1	[xception/block4_sepconv2/separable_conv2d/depthwise1]:20
	                 CONV_2D	          549.568	   80.805	   80.923	  4.300%	 33.494%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	             MAX_POOL_2D	          630.495	    6.443	    6.465	  0.344%	 33.838%	     0.000	        1	[xception/block4_pool/MaxPool]:22
	                 CONV_2D	          636.964	    8.190	    8.149	  0.433%	 34.271%	     0.000	        1	[xception/batch_normalization_299/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/conv2d_299/Conv2D]:23
	                     ADD	          645.118	   24.615	   24.695	  1.312%	 35.583%	     0.000	        1	[xception/add_6/add]:24
	                    RELU	          669.819	   32.096	   32.151	  1.708%	 37.291%	     0.000	        1	[xception/block5_sepconv1_act/Relu]:25
	       DEPTHWISE_CONV_2D	          701.974	    1.253	    1.287	  0.068%	 37.359%	     0.000	        1	[xception/block5_sepconv1/separable_conv2d/depthwise1]:26
	                 CONV_2D	          703.263	   21.917	   21.920	  1.165%	 38.524%	     0.000	        1	[xception/block5_sepconv2_act/Relu;xception/block5_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv1/separable_conv2d]:27
	       DEPTHWISE_CONV_2D	          725.188	    1.325	    1.357	  0.072%	 38.596%	     0.000	        1	[xception/block5_sepconv2/separable_conv2d/depthwise1]:28
	                 CONV_2D	          726.546	   21.976	   21.886	  1.163%	 39.759%	     0.000	        1	[xception/block5_sepconv3_act/Relu;xception/block5_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv2/separable_conv2d]:29
	       DEPTHWISE_CONV_2D	          748.437	    1.329	    1.362	  0.072%	 39.832%	     0.000	        1	[xception/block5_sepconv3/separable_conv2d/depthwise1]:30
	                 CONV_2D	          749.803	   21.876	   21.878	  1.162%	 40.994%	     0.000	        1	[xception/block5_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block5_sepconv3/separable_conv2d]:31
	                     ADD	          771.685	   24.618	   24.689	  1.312%	 42.306%	     0.000	        1	[xception/add_7/add]:32
	                    RELU	          796.378	   32.226	   32.200	  1.711%	 44.017%	     0.000	        1	[xception/block6_sepconv1_act/Relu]:33
	       DEPTHWISE_CONV_2D	          828.583	    1.266	    1.282	  0.068%	 44.085%	     0.000	        1	[xception/block6_sepconv1/separable_conv2d/depthwise1]:34
	                 CONV_2D	          829.867	   22.026	   21.964	  1.167%	 45.252%	     0.000	        1	[xception/block6_sepconv2_act/Relu;xception/block6_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv1/separable_conv2d]:35
	       DEPTHWISE_CONV_2D	          851.836	    1.311	    1.359	  0.072%	 45.324%	     0.000	        1	[xception/block6_sepconv2/separable_conv2d/depthwise1]:36
	                 CONV_2D	          853.198	   21.781	   21.716	  1.154%	 46.478%	     0.000	        1	[xception/block6_sepconv3_act/Relu;xception/block6_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv2/separable_conv2d]:37
	       DEPTHWISE_CONV_2D	          874.919	    1.369	    1.385	  0.074%	 46.552%	     0.000	        1	[xception/block6_sepconv3/separable_conv2d/depthwise1]:38
	                 CONV_2D	          876.306	   21.869	   21.843	  1.161%	 47.712%	     0.000	        1	[xception/block6_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block6_sepconv3/separable_conv2d]:39
	                     ADD	          898.154	   24.735	   24.683	  1.312%	 49.024%	     0.000	        1	[xception/add_8/add]:40
	                    RELU	          922.842	   32.174	   32.176	  1.710%	 50.733%	     0.000	        1	[xception/block7_sepconv1_act/Relu]:41
	       DEPTHWISE_CONV_2D	          955.022	    1.361	    1.306	  0.069%	 50.803%	     0.000	        1	[xception/block7_sepconv1/separable_conv2d/depthwise1]:42
	                 CONV_2D	          956.330	   21.669	   21.786	  1.158%	 51.960%	     0.000	        1	[xception/block7_sepconv2_act/Relu;xception/block7_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv1/separable_conv2d]:43
	       DEPTHWISE_CONV_2D	          978.121	    1.457	    1.374	  0.073%	 52.033%	     0.000	        1	[xception/block7_sepconv2/separable_conv2d/depthwise1]:44
	                 CONV_2D	          979.497	   21.994	   21.897	  1.164%	 53.197%	     0.000	        1	[xception/block7_sepconv3_act/Relu;xception/block7_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv2/separable_conv2d]:45
	       DEPTHWISE_CONV_2D	         1001.398	    1.399	    1.388	  0.074%	 53.271%	     0.000	        1	[xception/block7_sepconv3/separable_conv2d/depthwise1]:46
	                 CONV_2D	         1002.788	   21.828	   21.823	  1.160%	 54.430%	     0.000	        1	[xception/block7_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block7_sepconv3/separable_conv2d]:47
	                     ADD	         1024.616	   24.691	   24.668	  1.311%	 55.741%	     0.000	        1	[xception/add_9/add]:48
	                    RELU	         1049.290	   32.231	   32.194	  1.711%	 57.452%	     0.000	        1	[xception/block8_sepconv1_act/Relu]:49
	       DEPTHWISE_CONV_2D	         1081.488	    1.255	    1.275	  0.068%	 57.519%	     0.000	        1	[xception/block8_sepconv1/separable_conv2d/depthwise1]:50
	                 CONV_2D	         1082.766	   21.870	   21.727	  1.154%	 58.674%	     0.000	        1	[xception/block8_sepconv2_act/Relu;xception/block8_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv1/separable_conv2d]:51
	       DEPTHWISE_CONV_2D	         1104.500	    1.337	    1.393	  0.074%	 58.748%	     0.000	        1	[xception/block8_sepconv2/separable_conv2d/depthwise1]:52
	                 CONV_2D	         1105.895	   21.721	   21.746	  1.155%	 59.903%	     0.000	        1	[xception/block8_sepconv3_act/Relu;xception/block8_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv2/separable_conv2d]:53
	       DEPTHWISE_CONV_2D	         1127.646	    1.363	    1.369	  0.073%	 59.976%	     0.000	        1	[xception/block8_sepconv3/separable_conv2d/depthwise1]:54
	                 CONV_2D	         1129.017	   21.644	   21.709	  1.153%	 61.130%	     0.000	        1	[xception/block8_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block8_sepconv3/separable_conv2d]:55
	                     ADD	         1150.730	   24.710	   24.683	  1.312%	 62.441%	     0.000	        1	[xception/add_10/add]:56
	                    RELU	         1175.418	   32.121	   32.196	  1.711%	 64.152%	     0.000	        1	[xception/block9_sepconv1_act/Relu]:57
	       DEPTHWISE_CONV_2D	         1207.618	    1.252	    1.299	  0.069%	 64.221%	     0.000	        1	[xception/block9_sepconv1/separable_conv2d/depthwise1]:58
	                 CONV_2D	         1208.919	   21.732	   21.812	  1.159%	 65.380%	     0.000	        1	[xception/block9_sepconv2_act/Relu;xception/block9_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv1/separable_conv2d]:59
	       DEPTHWISE_CONV_2D	         1230.736	    1.499	    1.347	  0.072%	 65.451%	     0.000	        1	[xception/block9_sepconv2/separable_conv2d/depthwise1]:60
	                 CONV_2D	         1232.085	   21.712	   21.830	  1.160%	 66.611%	     0.000	        1	[xception/block9_sepconv3_act/Relu;xception/block9_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv2/separable_conv2d]:61
	       DEPTHWISE_CONV_2D	         1253.920	    1.320	    1.341	  0.071%	 66.683%	     0.000	        1	[xception/block9_sepconv3/separable_conv2d/depthwise1]:62
	                 CONV_2D	         1255.263	   21.788	   21.698	  1.153%	 67.835%	     0.000	        1	[xception/block9_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block9_sepconv3/separable_conv2d]:63
	                     ADD	         1276.967	   24.694	   24.669	  1.311%	 69.146%	     0.000	        1	[xception/add_11/add]:64
	                    RELU	         1301.640	   32.057	   32.189	  1.710%	 70.857%	     0.000	        1	[xception/block10_sepconv1_act/Relu]:65
	       DEPTHWISE_CONV_2D	         1333.833	    1.286	    1.269	  0.067%	 70.924%	     0.000	        1	[xception/block10_sepconv1/separable_conv2d/depthwise1]:66
	                 CONV_2D	         1335.104	   21.670	   21.704	  1.153%	 72.077%	     0.000	        1	[xception/block10_sepconv2_act/Relu;xception/block10_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv1/separable_conv2d]:67
	       DEPTHWISE_CONV_2D	         1356.813	    1.337	    1.355	  0.072%	 72.149%	     0.000	        1	[xception/block10_sepconv2/separable_conv2d/depthwise1]:68
	                 CONV_2D	         1358.171	   22.028	   21.859	  1.161%	 73.311%	     0.000	        1	[xception/block10_sepconv3_act/Relu;xception/block10_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv2/separable_conv2d]:69
	       DEPTHWISE_CONV_2D	         1380.034	    1.326	    1.354	  0.072%	 73.383%	     0.000	        1	[xception/block10_sepconv3/separable_conv2d/depthwise1]:70
	                 CONV_2D	         1381.391	   21.919	   21.798	  1.158%	 74.541%	     0.000	        1	[xception/block10_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block10_sepconv3/separable_conv2d]:71
	                     ADD	         1403.193	   24.671	   24.689	  1.312%	 75.853%	     0.000	        1	[xception/add_12/add]:72
	                    RELU	         1427.886	   32.072	   32.157	  1.709%	 77.561%	     0.000	        1	[xception/block11_sepconv1_act/Relu]:73
	       DEPTHWISE_CONV_2D	         1460.048	    1.276	    1.286	  0.068%	 77.630%	     0.000	        1	[xception/block11_sepconv1/separable_conv2d/depthwise1]:74
	                 CONV_2D	         1461.335	   21.768	   21.782	  1.157%	 78.787%	     0.000	        1	[xception/block11_sepconv2_act/Relu;xception/block11_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv1/separable_conv2d]:75
	       DEPTHWISE_CONV_2D	         1483.122	    1.461	    1.371	  0.073%	 78.860%	     0.000	        1	[xception/block11_sepconv2/separable_conv2d/depthwise1]:76
	                 CONV_2D	         1484.495	   21.628	   21.656	  1.151%	 80.011%	     0.000	        1	[xception/block11_sepconv3_act/Relu;xception/block11_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv2/separable_conv2d]:77
	       DEPTHWISE_CONV_2D	         1506.155	    1.468	    1.360	  0.072%	 80.083%	     0.000	        1	[xception/block11_sepconv3/separable_conv2d/depthwise1]:78
	                 CONV_2D	         1507.518	   21.789	   21.891	  1.163%	 81.246%	     0.000	        1	[xception/block11_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block11_sepconv3/separable_conv2d]:79
	                     ADD	         1529.413	   24.698	   24.675	  1.311%	 82.557%	     0.000	        1	[xception/add_13/add]:80
	                    RELU	         1554.092	   32.123	   32.189	  1.710%	 84.267%	     0.000	        1	[xception/block12_sepconv1_act/Relu]:81
	       DEPTHWISE_CONV_2D	         1586.285	    1.277	    1.278	  0.068%	 84.335%	     0.000	        1	[xception/block12_sepconv1/separable_conv2d/depthwise1]:82
	                 CONV_2D	         1587.564	   21.783	   21.771	  1.157%	 85.492%	     0.000	        1	[xception/block12_sepconv2_act/Relu;xception/block12_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv1/separable_conv2d]:83
	       DEPTHWISE_CONV_2D	         1609.341	    1.321	    1.350	  0.072%	 85.564%	     0.000	        1	[xception/block12_sepconv2/separable_conv2d/depthwise1]:84
	                 CONV_2D	         1610.692	   21.862	   21.805	  1.159%	 86.722%	     0.000	        1	[xception/block12_sepconv3_act/Relu;xception/block12_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv2/separable_conv2d]:85
	       DEPTHWISE_CONV_2D	         1632.501	    1.361	    1.353	  0.072%	 86.794%	     0.000	        1	[xception/block12_sepconv3/separable_conv2d/depthwise1]:86
	                 CONV_2D	         1633.857	   21.842	   21.780	  1.157%	 87.952%	     0.000	        1	[xception/block12_sepconv3_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block12_sepconv3/separable_conv2d]:87
	                     ADD	         1655.641	   24.620	   24.694	  1.312%	 89.264%	     0.000	        1	[xception/add_14/add]:88
	                    RELU	         1680.340	   32.100	   32.177	  1.710%	 90.973%	     0.000	        1	[xception/block13_sepconv1_act/Relu]:89
	       DEPTHWISE_CONV_2D	         1712.521	    1.268	    1.273	  0.068%	 91.041%	     0.000	        1	[xception/block13_sepconv1/separable_conv2d/depthwise1]:90
	                 CONV_2D	         1713.797	   21.823	   21.881	  1.163%	 92.204%	     0.000	        1	[xception/block13_sepconv2_act/Relu;xception/block13_sepconv1_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv1/separable_conv2d]:91
	       DEPTHWISE_CONV_2D	         1735.682	    1.371	    1.389	  0.074%	 92.278%	     0.000	        1	[xception/block13_sepconv2/separable_conv2d/depthwise1]:92
	                 CONV_2D	         1737.074	   30.794	   30.851	  1.639%	 93.917%	     0.000	        1	[xception/block13_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/block13_sepconv2/separable_conv2d]:93
	             MAX_POOL_2D	         1767.929	    2.372	    2.435	  0.129%	 94.046%	     0.000	        1	[xception/block13_pool/MaxPool]:94
	                 CONV_2D	         1770.367	    8.734	    8.854	  0.470%	 94.517%	     0.000	        1	[xception/batch_normalization_300/FusedBatchNormV3;xception/batch_normalization_300/FusedBatchNormV3/ReadVariableOp;xception/conv2d_300/Conv2D]:95
	                     ADD	         1779.227	    9.702	    9.677	  0.514%	 95.031%	     0.000	        1	[xception/add_15/add]:96
	       DEPTHWISE_CONV_2D	         1788.907	    0.504	    0.494	  0.026%	 95.057%	     0.000	        1	[xception/block14_sepconv1/separable_conv2d/depthwise1]:97
	                 CONV_2D	         1789.402	   18.270	   18.335	  0.974%	 96.031%	     0.000	        1	[xception/block14_sepconv1_act/Relu;xception/block14_sepconv1_bn/FusedBatchNormV3;xception/block14_sepconv1_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv1/separable_conv2d]:98
	       DEPTHWISE_CONV_2D	         1807.742	    0.799	    0.834	  0.044%	 96.076%	     0.000	        1	[xception/block14_sepconv2/separable_conv2d/depthwise1]:99
	                 CONV_2D	         1808.578	   36.707	   36.696	  1.950%	 98.025%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100
	                    MEAN	         1845.278	   35.251	   35.196	  1.870%	 99.896%	     0.000	        1	[xception/avg_pool/Mean]:101
	         FULLY_CONNECTED	         1880.478	    1.850	    1.878	  0.100%	 99.995%	     0.000	        1	[xception/predictions/MatMul;xception/predictions/BiasAdd]:102
	                 SOFTMAX	         1882.361	    0.076	    0.086	  0.005%	100.000%	     0.000	        1	[StatefulPartitionedCall:0]:103

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                    RELU	          258.308	   85.838	   86.221	  4.581%	  4.581%	     0.000	        1	[xception/block3_sepconv1_act/Relu]:9
	                 CONV_2D	          549.568	   80.805	   80.923	  4.300%	  8.881%	     0.000	        1	[xception/block4_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_299/FusedBatchNormV3/ReadVariableOp;xception/block4_sepconv2/separable_conv2d]:21
	                     ADD	          192.666	   65.677	   65.638	  3.488%	 12.369%	     0.000	        1	[xception/add_4/add]:8
	                 CONV_2D	            9.911	   62.857	   62.736	  3.333%	 15.702%	     0.000	        1	[xception/block1_conv2_act/Relu;xception/block1_conv2_bn/FusedBatchNormV3;xception/block1_conv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block1_conv2/Conv2D]:1
	                 CONV_2D	          118.914	   48.699	   48.860	  2.596%	 18.298%	     0.000	        1	[xception/block2_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_297/FusedBatchNormV3/ReadVariableOp;xception/block2_sepconv2/separable_conv2d]:5
	                 CONV_2D	          379.252	   43.788	   43.786	  2.327%	 20.625%	     0.000	        1	[xception/block3_sepconv2_bn/FusedBatchNormV3;xception/batch_normalization_298/FusedBatchNormV3/ReadVariableOp;xception/block3_sepconv2/separable_conv2d]:13
	                    RELU	          470.424	   42.468	   42.601	  2.264%	 22.889%	     0.000	        1	[xception/block4_sepconv1_act/Relu]:17
	                 CONV_2D	         1808.578	   36.707	   36.696	  1.950%	 24.838%	     0.000	        1	[xception/block14_sepconv2_act/Relu;xception/block14_sepconv2_bn/FusedBatchNormV3;xception/block14_sepconv2_bn/FusedBatchNormV3/ReadVariableOp;xception/block14_sepconv2/separable_conv2d]:100
	                    MEAN	         1845.278	   35.251	   35.196	  1.870%	 26.709%	     0.000	        1	[xception/avg_pool/Mean]:101
	                     ADD	          437.563	   32.889	   32.856	  1.746%	 28.454%	     0.000	        1	[xception/add_5/add]:16

Number of nodes executed: 104
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       40	   990.226	    52.617%	    52.617%	     0.000	       40
	                    RELU	       11	   418.445	    22.234%	    74.851%	     0.000	       11
	                     ADD	       12	   330.308	    17.551%	    92.402%	     0.000	       12
	       DEPTHWISE_CONV_2D	       34	    72.103	     3.831%	    96.234%	     0.000	       34
	                    MEAN	        1	    35.196	     1.870%	    98.104%	     0.000	        1
	             MAX_POOL_2D	        4	    33.721	     1.792%	    99.896%	     0.000	        4
	         FULLY_CONNECTED	        1	     1.878	     0.100%	    99.995%	     0.000	        1
	                 SOFTMAX	        1	     0.086	     0.005%	   100.000%	     0.000	        1

Timings (microseconds): count=20 first=1880876 curr=1881867 min=1880876 max=1884918 avg=1.88201e+06 std=985
Memory (bytes): count=0
104 nodes observed



[ perf record: Woken up 130 times to write data ]
[ perf record: Captured and wrote 32.259 MB /tmp/data.record (166534 samples) ]

42.625

